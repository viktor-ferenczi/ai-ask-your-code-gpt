File extensions: .ambr .bat .bib .cff .conllu .css .csv .devcontainer/Dockerfile .dockerignore .eml .enex .example .flake8 .gitignore .html .ipynb .js .json .lock .md .py .rst .toml .txt .xml .yaml .yml


File: /.dockerignore

File: /.flake8

File: /.gitignore

File: /.readthedocs.yaml

File: /CITATION.cff

File: /Dockerfile

File: /LICENSE

File: /Makefile

# ü¶úÔ∏èüîó LangChain
## Quick Install
## ü§î What is this?
## üìñ Documentation
## üöÄ What can this help with?
## üíÅ Contributing

File: /poetry.lock

File: /poetry.toml

File: /pyproject.toml

File: /.devcontainer/Dockerfile

File: /.devcontainer/devcontainer.json

File: /.devcontainer/docker-compose.yaml

# Contributing to LangChain
## üó∫Ô∏è Guidelines
### üë©‚Äçüíª Contributing Code
### üö©GitHub Issues
### üôãGetting Help
## üöÄ Quick Start
## ‚úÖ Common Tasks
### Code Formatting
### Linting
### Coverage
### Working with Optional Dependencies
### Testing
#### Unit Tests
#### Integration Tests
### Adding a Jupyter Notebook
## Documentation
### Contribute Documentation
### Build Documentation Locally
## üè≠ Release Process
### üåü Recognition

#### Before submitting
#### Who can review?

File: /docs/Makefile

Python: /docs/conf.py
  Variables: author autodoc_pydantic_config_members autodoc_pydantic_field_list_validators autodoc_pydantic_model_members autodoc_pydantic_model_show_config_summary autodoc_pydantic_model_show_field_summary autodoc_pydantic_model_show_json autodoc_pydantic_model_show_validator_members autodoc_pydantic_model_undoc_members copyright data exclude_patterns extensions html_context html_css_files html_js_files html_last_updated_fmt html_static_path html_theme html_theme_options html_title myst_enable_extensions nb_execution_mode project release source_suffix templates_path version
  Usages: load open toml

# Dependents

File: /docs/index.rst

File: /docs/integrations.rst

File: /docs/make.bat

File: /docs/reference.rst

File: /docs/requirements.txt

Python: /langchain/__init__.py
  Variables: SerpAPIChain __all__ __version__ debug: llm_cache: verbose:
  Usages: Anthropic ArxivAPIWrapper Banana BaseCache BasePromptTemplate CerebriumAI Cohere ConversationChain ElasticVectorSearch FAISS FewShotPromptTemplate ForefrontAI GoogleSearchAPIWrapper GoogleSerperAPIWrapper GooseAI HuggingFaceHub HuggingFacePipeline HuggingFaceTextGenInference InMemoryDocstore LLMBashChain LLMChain LLMCheckerChain LLMMathChain LlamaCpp MRKLChain Modal OpenAI Optional PALChain PackageNotFoundError Petals PipelineAI PowerBIDataset Prompt PromptTemplate QAWithSourcesChain ReActChain SQLDatabase SQLDatabaseChain SagemakerEndpoint SearxSearchWrapper SelfAskWithSearchChain SerpAPIWrapper StochasticAI VectorDBQA VectorDBQAWithSourcesChain Wikipedia WikipediaAPIWrapper WolframAlphaAPIWrapper Writer __package__ agents arxiv bool cache chains debug docstore google_search google_serper huggingface_pipeline importlib langchain llm_cache llms metadata powerbi prompts searx_search serpapi sql_database typing utilities vectorstores verbose version wikipedia wolfram_alpha

Python: /langchain/base_language.py
  Functions: _get_token_ids_default_method
  Classes: BaseLanguageModel
  Methods: agenerate_prompt all_required_field_names apredict apredict_messages generate_prompt get_num_tokens get_num_tokens_from_messages get_token_ids predict predict_messages
  Variables: all_required_field_names tokenizer
  Usages: ABC Any BaseMessage Callbacks GPT2TokenizerFast ImportError LLMResult List Optional PromptValue Sequence Serializable Set ValueError __fields__ abc abstractmethod add alias annotations callbacks classmethod cls encode field from_pretrained get_buffer_string has_alias int kwargs langchain len load manager messages name prompts schema self serializable set stop str sum text transformers typing values

Python: /langchain/cache.py
  Functions: _dump_generations_to_json _ensure_cache_exists _hash _load_generations_from_json _validate_ttl
  Classes: BaseCache FullLLMCache GPTCache InMemoryCache MomentoCache RedisCache RedisSemanticCache SQLAlchemyCache SQLiteCache
  Methods: __init__ __key _get_gptcache _get_llm_cache _index_name _key _new_gptcache clear from_client_params lookup update
  Variables: Base RETURN_VAL_TYPE __tablename__ _embedding _gptcache asynchronous auth_token cache_client configuration create_cache_response credentials engine flush_response generations get_response gptcache_instance handled_data hashed_index idx index_name items key llm llm_cache metadata prompt redis res response results rows self._cache self._cache: self._cache[(prompt, self._cache_dict: self._cache_dict[index_name] self.cache_client self.cache_name self.cache_schema self.embedding self.engine self.gptcache_dict: self.gptcache_dict[llm_string] self.init_gptcache_func: self.redis self.redis_url self.score_threshold self.ttl set_response sig stmt value
  Usages: ABC Any Cache CacheAlreadyExists CacheClient CacheFlush CacheGet CacheSet Callable Column Configuration Configurations CreateCache CredentialProvider Dict Embeddings Engine Error Exception Generation Hit ImportError Integer JSONDecodeError Laptop List Miss Optional Redis RedisVectorstore Session String Success TYPE_CHECKING Tuple Type TypeError Union ValueError _cache _cache_dict _create_index _input abc abstractmethod adapter add_texts annotations api append base begin bool cache_name cache_obj cache_schema cast classmethod cls config create_all create_cache create_engine data_manager data_path database_path datetime declarative declarative_base default_ttl delete delete_documents dict dim document drop_index dumps embed_query embedding embedding_function embeddings encode ensure_cache_exists enumerate execute ext factory fetchall float flush flush_cache flushdb from_existing_index from_string gen generation generation_dict generations_json get get_data_manager get_from_env get_prompt gptcache gptcache_dict hashlib hexdigest hgetall hset init init_func init_gptcache_func inner_exception inspect isinstance item json kwargs langchain len llm_string loads manager mapping md5 merge metadatas momento order_by orm parameters pre pre_embedding_func primary_key processor put query redis_ redis_url responses return_val row schema score_threshold seconds select self session set signature similarity_search_limit_score sqlalchemy str super text texts timedelta ttl typing utils value_string values vectorstores where

File: /langchain/docker-compose.yaml

Python: /langchain/document_transformers.py
  Functions: _filter_similar_embeddings _get_embeddings_from_stateful_docs get_stateful_documents
  Classes: Config EmbeddingsRedundantFilter _DocumentWithState
  Methods: atransform_documents from_document to_document transform_documents
  Variables: arbitrary_types_allowed doc.state["embedded_doc"] embedded_documents embeddings: included_idxs redundant redundant_sorted redundant_stacked similarity similarity_fn: similarity_threshold: state: stateful_documents
  Usages: Any BaseDocumentTransformer BaseModel Callable Document Embeddings Field List NotImplementedError Sequence argsort base classmethod cls column_stack cosine_similarity default_factory dict doc documents embed_documents embedding embeddings first_idx float int isinstance kwargs langchain len list math_utils metadata numpy page_content pydantic range remove schema second_idx self set similarity_fn similarity_threshold sorted state threshold tril typing where zip

Python: /langchain/env.py
  Methods: get_runtime_environment
  Usages: __version__ dict functools langchain lru_cache maxsize platform python_version

Python: /langchain/example_generator.py
  Functions: generate_example
  Variables: TEST_GEN_TEMPLATE_SUFFIX chain prompt
  Usages: BaseLanguageModel FewShotPromptTemplate LLMChain List PromptTemplate base_language chains dict example_prompt examples few_shot input_variables langchain llm predict prompt_template prompts str suffix typing

Python: /langchain/formatting.py
  Classes: StrictFormatter
  Methods: check_unused_args validate_input_variables vformat
  Variables: dummy_inputs extra formatter
  Usages: Any Formatter KeyError List Mapping Sequence Union ValueError args difference format format_string input_variable input_variables int kwargs len self set str string super typing used_args

Python: /langchain/input.py
  Functions: get_bolded_text get_color_mapping get_colored_text print_text
  Variables: _TEXT_COLOR_MAPPING color_mapping color_str colors text_to_print
  Usages: Dict List Optional TextIO color end enumerate excluded_colors file flush item items keys len list print str text typing

Python: /langchain/math_utils.py
  Functions: cosine_similarity cosine_similarity_top_k
  Variables: Matrix X X_norm Y Y_norm ret_idxs score_array score_threshold scores similarity similarity[np.isnan(similarity) sorted_idxs top_idxs top_k
  Usages: List Optional T Tuple Union ValueError argsort array axis dot flatten float int isinf isnan len linalg ndarray norm numpy outer shape tolist typing

Python: /langchain/model_laboratory.py
  Classes: ModelLaboratory
  Methods: __init__ compare from_llms
  Variables: chain_range chains name names output prompt self.chain_colors self.chains self.names
  Usages: BaseLLM Chain LLMChain List Optional PromptTemplate Sequence ValueError annotations base chain chain_colors classmethod cls color end enumerate get_color_mapping input input_keys input_variables isinstance langchain len llm llms output_keys print print_text prompts range run self str template text typing

Python: /langchain/python.py
  Variables: __all__
  Usages: PythonREPL langchain python utilities

Python: /langchain/requests.py
  Classes: Config Requests TextRequestsWrapper
  Methods: _arequest adelete aget apatch apost aput delete get patch post put requests
  Variables: RequestsWrapper aiosession: arbitrary_types_allowed extra headers:
  Usages: Any AsyncGenerator BaseModel ClientResponse ClientSession Dict Extra Optional Response aiohttp aiosession asynccontextmanager contextlib data forbid headers json kwargs method property pydantic request response self session str text typing url

Python: /langchain/schema.py
  Functions: _message_from_dict _message_to_dict get_buffer_string messages_from_dict messages_to_dict
  Classes: AIMessage AgentAction AgentFinish BaseChatMessageHistory BaseDocumentTransformer BaseMemory BaseMessage BaseOutputParser BaseRetriever ChatGeneration ChatMessage ChatResult Config Document Generation HumanMessage LLMResult OutputParserException PromptValue RunInfo SystemMessage
  Methods: __eq__ __init__ _type add_ai_message add_message add_user_message aget_relevant_documents atransform_documents clear dict get_format_instructions get_relevant_documents load_memory_variables memory_variables parse parse_with_prompt save_context set_text to_messages to_string transform_documents type
  Variables: Memory RUN_KEY T _type additional_kwargs: arbitrary_types_allowed content: example: extra generation_info: generations: llm_output: log: message: messages: metadata: output_parser_dict output_parser_dict["_type"] page_content: return_values: role role: run: run_id: self.llm_output self.observation self.send_to_llm string_messages text text: tool: tool_input: values["text"]
  Usages: ABC Any BaseModel Dict Extra Field Generic List NamedTuple NotImplemented NotImplementedError Optional Sequence Serializable TypeVar UUID Union ValueError __class__ __name__ abc abstractmethod additional_kwargs ai_prefix annotations append bool cls completion content default_factory documents error example forbid generation_info generations human_prefix inputs isinstance join kwargs langchain llm_output load log message messages metadata object observation other outputs page_content prompt property pydantic query return_values root_validator run run_id self send_to_llm serializable str super tool tool_input typing uuid values

Python: /langchain/serpapi.py
  Variables: __all__
  Usages: SerpAPIWrapper langchain serpapi utilities

Python: /langchain/server.py
  Functions: main
  Variables: docker_compose_command
  Usages: Path __file__ __name__ absolute cli get_docker_compose_command langchain parent pathlib run str subprocess

Python: /langchain/sql_database.py
  Functions: _format_index truncate_word
  Classes: SQLDatabase
  Methods: __init__ _get_sample_rows _get_table_indexes dialect from_databricks from_uri get_table_info get_table_info_no_throw get_table_names get_usable_table_names run run_no_throw table_info
  Variables: _engine_args all_table_names api_token cluster_id columns_str command context create_table cursor default_api_token default_host final_str has_extra_info host http_path indexes indexes_formatted intersection meta_tables missing_tables result sample_rows sample_rows_result sample_rows_str self._all_tables self._custom_table_info self._engine self._ignore_tables self._include_tables self._indexes_in_table_info self._inspector self._max_string_length self._metadata self._sample_rows_in_table_info self._schema self._usable_tables table_info tables uri usable_tables
  Usages: Any CreateTable Engine ImportError Iterable List MetaData Optional ProgrammingError ReflectedIndex SQLAlchemyError Table TypeError ValueError _all_tables _custom_table_info _engine _ignore_tables _include_tables _indexes_in_table_info _inspector _max_string_length _metadata _sample_rows_in_table_info _schema _usable_tables annotations apiToken append begin bind bool browserHostName catalog classmethod cls clusterId col columns compile connect connection content create_engine custom_table_info database_uri databricks databricks_repl_context dbruntime dict difference engine engine_args exc exec_driver_sql execute fetch fetchall fetchone get_context get_from_env get_indexes get_view_names ignore_tables include_tables index indexes_in_table_info inspect int interfaces isinstance join kwargs langchain len length limit list map max_string_length metadata name only property reflect returns_rows row rsplit rstrip sample_rows_in_table_info schema select self set sorted_tables sql sqlalchemy startswith str suffix table table_names tbl text tuple typing utils view_support views warehouse_id warn warnings

Python: /langchain/text_splitter.py
  Functions: _split_text_with_regex split_text_on_tokens
  Classes: CharacterTextSplitter HeaderType Language LatexTextSplitter LineType MarkdownHeaderTextSplitter MarkdownTextSplitter NLTKTextSplitter PythonCodeTextSplitter RecursiveCharacterTextSplitter SentenceTransformersTokenTextSplitter SpacyTextSplitter TextSplitter TokenTextSplitter Tokenizer
  Methods: __init__ _encode _huggingface_tokenizer_length _initialize_chunk_configuration _join_docs _merge_splits _split_text _tiktoken_encoder aggregate_lines_to_chunks atransform_documents count_tokens create_documents encode_strip_start_and_stop_token_ids from_huggingface_tokenizer from_language from_tiktoken_encoder get_separators_for_language split_documents split_text transform_documents
  Variables: CPP GO HTML JAVA JS LATEX MARKDOWN PHP PROTO PYTHON RST RUBY RUST SCALA SWIFT TS _good_splits _len _max_length_equal_32_bit_integer _metadatas _separator _splits aggregated_chunks: chunk_ids chunk_overlap: content: cur_idx current_content: current_doc current_doc: current_header_level current_metadata current_metadata: data: decode: doc docs documents enc encode: extra_kwargs final_chunks header: header_stack: index initial_metadata: initial_metadata[name] input_ids kwargs level: lines lines_with_metadata: logger merged_text metadata metadata: metadata["start_index"] name: new_doc new_separators other_info popped_header self._add_start_index self._allowed_special self._chunk_overlap self._chunk_size self._disallowed_special self._keep_separator self._length_function self._model self._separator self._separators self._tokenizer self.headers_to_split_on self.maximum_tokens_per_chunk self.model_name self.return_each_line self.tokenizer self.tokens_per_chunk separator separator_len separators splits splits: start_idx stripped_line text texts, token_ids_with_start_and_end_token_ids tokenizer tokens_per_chunk: total
  Usages: ABC AbstractSet Any BaseDocumentTransformer Callable Collection Dict Document Enum ImportError Iterable List Literal NotImplementedError Optional PreTrainedTokenizerBase SentenceTransformer Sequence Tuple Type TypeVar TypedDict Union ValueError __name__ _add_start_index _allowed_special _chunk_overlap _chunk_size _disallowed_special _keep_separator _length_function _model _separators _text _tokenizer abc abstractmethod add_start_index aggregated_chunks allowed_special annotations append bool bound cast chunk chunk_overlap chunk_size classmethod clear cls content copy count current_content data dataclass dataclasses decode deepcopy dict disallowed_special docstore document encode encoding_for_model encoding_name enum enumerate extend find frozen getLogger get_encoding header header_stack headers_to_split_on initial_metadata int isinstance issubclass join keep_separator key langchain language len length_function level line lines_with_metadata list load logging max_length max_seq_length maximum_tokens_per_chunk metadatas min model_name name nltk page_content pipeline pop range return_each_line reverse schema search self sent_tokenize sentence_transformers sents sep set sorted spacy split startswith staticmethod str strip super texts tiktoken tokenize tokens_per_chunk transformers truncation typing warning

Python: /langchain/utils.py
  Functions: comma_list get_from_dict_or_env get_from_env guard_import raise_for_status_with_text stringify_dict stringify_value xor_args
  Classes: MockDateTime
  Methods: decorator mock_now now wrapper
  Variables: counts datetime.datetime invalid_group_names invalid_groups module real_datetime text
  Usages: Any Callable Dict HTTPError ImportError List Optional Response Tuple ValueError arg arg_group arg_groups args classmethod cls contextlib contextmanager count data datetime day default dict dt_value enumerate env_key environ func get hour import_module importlib isinstance item items join key kwargs list microsecond minute module_name month package pip_name raise_for_status requests response second str sum typing tzinfo val value year

# Readme tests(draft)
## Integrations Tests
### Prepare
# add package and install it after adding:
### Prepare environment variables for local testing:
### Recording HTTP interactions with pytest-vcr
### Run some tests with coverage:

Python: /tests/data.py
  Variables: HELLO_PDF LAYOUT_PARSER_PAPER_PDF _EXAMPLES_DIR _THIS_DIR
  Usages: Path __file__ parent pathlib

File: /.github/ISSUE_TEMPLATE/bug-report.yml

File: /.github/ISSUE_TEMPLATE/config.yml

File: /.github/ISSUE_TEMPLATE/documentation.yml

File: /.github/ISSUE_TEMPLATE/feature-request.yml

File: /.github/ISSUE_TEMPLATE/other.yml

File: /.github/workflows/linkcheck.yml

File: /.github/workflows/lint.yml

File: /.github/workflows/release.yml

File: /.github/workflows/test.yml

File: /docs/additional_resources/deploy_llms.rst

PythonNotebook: /docs/additional_resources/model_laboratory.ipynb
  Variables: chains cohere_llm llms model_lab model_lab_with_prompt names open_ai_llm prompt search self_ask_with_search_cohere self_ask_with_search_openai
  Usages: Cohere HuggingFaceHub LLMChain ModelLaboratory OpenAI PromptTemplate SelfAskWithSearchChain SerpAPIWrapper compare from_llms input_variables langchain llm max_tokens model model_kwargs model_laboratory repo_id search_chain str temperature template verbose

# Tracing
## Tracing Walkthrough
## Changing Sessions

# YouTube
### ‚õìÔ∏è[Official LangChain YouTube channel](https://www.youtube.com/@LangChain)‚õìÔ∏è
### Introduction to LangChain with Harrison Chase, creator of LangChain
## Videos (sorted by views)

# Baseten
## Installation and setup
## Invoking a model

# Deployments
## [Anyscale](https://www.anyscale.com/model-serving)
## [Streamlit](https://github.com/hwchase17/langchain-streamlit-template)
## [Gradio (on Hugging Face)](https://github.com/hwchase17/langchain-gradio-template)
## [Chainlit](https://github.com/Chainlit/cookbook)
## [Beam](https://github.com/slai-labs/get-beam/tree/main/examples/langchain-question-answering)
## [Vercel](https://github.com/homanp/vercel-langchain)
## [FastAPI + Vercel](https://github.com/msoedov/langcorn)
## [Kinsta](https://github.com/kinsta/hello-world-langchain)
## [Fly.io](https://github.com/fly-apps/hello-fly-langchain)
## [Digitalocean App Platform](https://github.com/homanp/digitalocean-langchain)
## [Google Cloud Run](https://github.com/homanp/gcp-langchain)
## [SteamShip](https://github.com/steamship-core/steamship-langchain/)
## [Langchain-serve](https://github.com/jina-ai/langchain-serve)
## [BentoML](https://github.com/ssheng/BentoChain)
## [Databutton](https://databutton.com/home?new-data-app=true)

# ModelScope
## Installation and Setup
## Wrappers
### Embeddings

# Concepts
## Chain of Thought
## Action Plan Generation
## ReAct
## Self-ask
## Prompt Chaining
## Memetic Proxy
## Self Consistency
## Inception
## MemPrompt

# Quickstart Guide
## Installation
# or
## Environment Setup
## Building a Language Model Application: LLMs
## LLMs: Get predictions from a language model
## Prompt Templates: Manage prompts for LLMs
## Chains: Combine LLMs and prompts in multi-step workflows
# -> '\n\nSocktastic!'
## Agents: Dynamically Call Chains Based on User Input
# First, let's load the language model we're going to use to control the agent.
# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.
# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.
# Now let's test it out!
## Memory: Add State to Chains and Agents
## Building a Language Model Application: Chat Models
## Get Message Completions from a Chat Model
# -> AIMessage(content="J'aime programmer.", additional_kwargs={})
# -> AIMessage(content="J'aime programmer.", additional_kwargs={})
# -> LLMResult(generations=[[ChatGeneration(text="J'aime programmer.", generation_info=None, message=AIMessage(content="J'aime programmer.", additional_kwargs={}))], [ChatGeneration(text="J'aime l'intelligence artificielle.", generation_info=None, message=AIMessage(content="J'aime l'intelligence artificielle.", additional_kwargs={}))]], llm_output={'token_usage': {'prompt_tokens': 57, 'completion_tokens': 20, 'total_tokens': 77}})
# -> {'prompt_tokens': 57, 'completion_tokens': 20, 'total_tokens': 77}
## Chat Prompt Templates
# get a chat completion from the formatted messages
# -> AIMessage(content="J'aime programmer.", additional_kwargs={})
## Chains with Chat Models
# -> "J'aime programmer."
## Agents with Chat Models
# First, let's load the language model we're going to use to control the agent.
# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.
# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.
# Now let's test it out!
## Memory: Add State to Chains and Agents
# -> 'Hello! How can I assist you today?'
# -> "That sounds like fun! I'm happy to chat with you. Is there anything specific you'd like to talk about?"
# -> "Sure! I am an AI language model created by OpenAI. I was trained on a large dataset of text from the internet, which allows me to understand and generate human-like language. I can answer questions, provide information, and even have conversations like this one. Is there anything else you'd like to know about me?"

# Tutorials
### DeepLearning.AI course
### Handbook
### Tutorials
###
###
###
###
###
###

PythonNotebook: /docs/integrations/agent_with_wandb_tracing.ipynb
  Variables: agent llm os.environ["LANGCHAIN_WANDB_TRACING"] os.environ["WANDB_PROJECT"] tools
  Usages: AgentType OpenAI ZERO_SHOT_REACT_DESCRIPTION agents callbacks environ initialize_agent langchain llms load_tools run temperature verbose wandb_tracing_enabled

# AI21 Labs
## Installation and Setup
## Wrappers
### LLM

PythonNotebook: /docs/integrations/aim_tracking.ipynb
  Variables: agent aim_callback callbacks llm llm_result os.environ["OPENAI_API_KEY"] os.environ["SERPAPI_API_KEY"] prompt_template session_group synopsis_chain template test_prompts tools
  Usages: AgentType AimCallbackHandler LLMChain OpenAI PromptTemplate StdOutCallbackHandler ZERO_SHOT_REACT_DESCRIPTION agents aim apply chains datetime environ experiment_name finish flush_tracker generate google initialize_agent input_variables install langchain langchain_asset llms load_tools now openai prompt prompts repo reset results run search strftime temperature

# Airbyte
## Installation and Setup
## Document Loader

# Aleph Alpha
## Installation and Setup
## LLM
## Text Embedding Models

# Amazon Bedrock
## Installation and Setup
## LLM
## Text Embedding Models

# AnalyticDB
### VectorStore

# Annoy
## Installation and Setup
## Vectorstore

# Anthropic
## Installation and Setup
## Chat Models

# Anyscale
## Installation and Setup
## Wrappers
### LLM

# Apify
## Overview
## Installation and Setup
## Wrappers
### Utility
### Loader

# Argilla
## Installation and Setup
## Tracking

# Arxiv
## Installation and Setup
## Document Loader
## Retriever

# AtlasDB
## Installation and Setup
## Wrappers
### VectorStore

# AwaDB
## Installation and Setup
## VectorStore

# AWS S3 Directory
## Installation and Setup
## Document Loader

# AZLyrics
## Installation and Setup
## Document Loader

# Azure Blob Storage
## Installation and Setup
## Document Loader

# Azure Cognitive Search
## Installation and Setup
## Retriever

# Azure OpenAI
## Installation and Setup
## LLM
## Text Embedding Models
## Chat Models

# Banana
## Installation and Setup
## Define your Banana Template
## Build the Banana app
# Return the results as a dictionary
## Wrappers
### LLM

# Beam
## Installation and Setup
## LLM
### Example of the Beam app
### Deploy the Beam app
### Call the Beam app

# BiliBili
## Installation and Setup
## Document Loader

# Blackboard
## Installation and Setup
## Document Loader

# Cassandra
## Installation and Setup
## Memory

# CerebriumAI
## Installation and Setup
## Wrappers
### LLM

# Chroma
## Installation and Setup
## VectorStore
## Retriever

PythonNotebook: /docs/integrations/clearml_tracking.ipynb
  Variables: agent callbacks clearml_callback llm llm_result os.environ["CLEARML_API_ACCESS_KEY"] os.environ["CLEARML_API_SECRET_KEY"] os.environ["OPENAI_API_KEY"] os.environ["SERPAPI_API_KEY"] tools
  Usages: AgentType ClearMLCallbackHandler OpenAI StdOutCallbackHandler ZERO_SHOT_REACT_DESCRIPTION agents clearml complexity_metrics datetime download en_core_web_sm environ finish flush_tracker generate initialize_agent install langchain langchain_asset llms load_tools name pandas project_name run spacy stream_logs tags task_name task_type temperature textstat visualize ython

# ClickHouse
## Installation
### Configure clickhouse vector index
## Wrappers
### VectorStore

# Cohere
## Installation and Setup
## LLM
## Text Embedding Model
## Retriever

# College Confidential
## Installation and Setup
## Document Loader

PythonNotebook: /docs/integrations/comet_tracking.ipynb
  Classes: Rouge
  Methods: __init__ compute_metric
  Variables: agent callbacks comet_callback llm llm_result os.environ["OPENAI_API_KEY"] os.environ["SERPAPI_API_KEY"] prediction prompt_template reference results rouge_score self.reference self.scorer synopsis_chain template test_prompts tools
  Usages: CometCallbackHandler LLMChain OpenAI PromptTemplate RougeScorer StdOutCallbackHandler agents apply chains comet_ml complexity_metrics custom_metrics datetime download en_core_web_sm environ executable finish flush_tracker fmeasure gen_idx generate generation google init initialize_agent input_variables install langchain llms load_tools openai pandas pip print project_name prompt prompt_idx prompts rouge rouge_scorer run score scorer search self spacy stream_logs sys tags target temperature text textstat use_stemmer verbose visualizations

# Confluence
## Installation and Setup
## Document Loader

# C Transformers
## Installation and Setup
## Wrappers
### LLM

# Databerry
## Installation and Setup
## Retriever

# DeepInfra
## Installation and Setup
## Available Models
## Wrappers
### LLM

# Deep Lake
## Why Deep Lake?
## More Resources
## Installation and Setup
## Wrappers
### VectorStore

# Diffbot
## Installation and Setup
## Document Loader

# Discord
## Installation and Setup
## Document Loader

# Docugami
## Installation and Setup
## Document Loader

# DuckDB
## Installation and Setup
## Document Loader

# Elasticsearch
## Installation and Setup
## Retriever

# EverNote
## Installation and Setup
## Document Loader

# Facebook Chat
## Installation and Setup
## Document Loader

# Figma
## Installation and Setup
## Document Loader

# ForefrontAI
## Installation and Setup
## Wrappers
### LLM

# Git
## Installation and Setup
## Document Loader

# GitBook
## Installation and Setup
## Document Loader

# Google BigQuery
## Installation and Setup
## Document Loader

# Google Cloud Storage
## Installation and Setup
## Document Loader

# Google Drive
## Installation and Setup
## Document Loader

# Google Search
## Installation and Setup
## Wrappers
### Utility
### Tool

# Google Serper
## Setup
## Wrappers
### Utility
#### Output
### Tool

# Google Vertex AI
## Installation and Setup
## Chat Models

# GooseAI
## Installation and Setup
## Wrappers
### LLM

# GPT4All
## Installation and Setup
## Usage
### GPT4All
# Instantiate the model. Callbacks support token-wise streaming
# Generate text
# There are many CallbackHandlers supported, such as
# from langchain.callbacks.streamlit import StreamlitCallbackHandler
# Generate text. Tokens are streamed through the callback manager.
## Model File

# Graphsignal
## Installation and Setup
## Tracing and Monitoring

# Gutenberg
## Installation and Setup
## Document Loader

# Hacker News
## Installation and Setup
## Document Loader

# Hazy Research
## Installation and Setup
## Wrappers
### LLM

# Helicone
## What is Helicone?
## Quick start
## How to enable Helicone caching
## How to use Helicone custom properties

# Hugging Face
## Installation and Setup
## Wrappers
### LLM
### Embeddings
### Tokenizer
### Datasets

# iFixit
## Installation and Setup
## Document Loader

# IMSDb
## Installation and Setup
## Document Loader

# Jina
## Installation and Setup
## Wrappers
### Embeddings

# LanceDB
## Installation and Setup
## Wrappers
### VectorStore

# LangChain Decorators ‚ú®
# run it naturaly
# or
# Quick start
## Installation
## Examples
# Defining other parameters
# define global settings for all prompty (if not set - chatGPT is the current default)
#You can change the default prompt types
# Or you can just define your own ones:
## Passing a memory and/or callbacks:
# Simplified streaming
# this code example is complete and should run as it is
# this will mark the prompt for streaming (useful if we want stream just some prompts in our app... but don't want to pass distribute the callback handlers)
# note that only async functions can be streamed (will get an error if it's not)
# just an arbitrary  function to demonstrate the streaming... wil be some websockets code in the real world
# if we want to capture the stream, we need to wrap the execution into StreamingContext... 
# this will allow us to capture the stream even if the prompt call is hidden inside higher level method
# only the prompts marked with capture_stream will be captured here
# Prompt declarations
## Documenting your prompt
## Chat messages prompt
# Optional sections
# Output parsers
# this code example is complete and should run as it is
## More complex structures
# print the result nicely formatted
# Binding the prompt to an object
# More examples:

# Llama.cpp
## Installation and Setup
## Wrappers
### LLM
### Embeddings

# MediaWikiDump
## Installation and Setup
## Document Loader

# Metal
## What is Metal?
## Quick start

# Microsoft OneDrive
## Installation and Setup
## Document Loader

# Microsoft PowerPoint
## Installation and Setup
## Document Loader

# Microsoft Word
## Installation and Setup
## Document Loader

# Milvus
## Installation and Setup
## Wrappers
### VectorStore

PythonNotebook: /docs/integrations/mlflow_tracking.ipynb
  Variables: agent llm llm_result mlflow_callback os.environ["MLFLOW_TRACKING_URI"] os.environ["OPENAI_API_KEY"] os.environ["SERPAPI_API_KEY"] prompt_template synopsis_chain template test_prompts tools
  Usages: AgentType LLMChain MlflowCallbackHandler OpenAI PromptTemplate ZERO_SHOT_REACT_DESCRIPTION agents apply azureml callbacks chains download en_core_web_sm environ finish flush_tracker generate google initialize_agent input_variables install langchain llms load_tools mlflow model_name openai pandas prompt prompts results run search spacy temperature textstat verbose ython

# Modal
## Installation and Setup
## Define your Modal Functions and Webhooks
## Wrappers
### LLM

# Modern Treasury
## Installation and Setup
## Document Loader

# Momento
## Installation and Setup
## Cache
# Instantiate the Momento client
# Choose a Momento cache name of your choice
# Instantiate the LLM cache
## Memory
### Chat Message History Memory

# MyScale
## Introduction
## Installation and Setup
### Setting up envrionments
## Wrappers
### VectorStore

# NLPCloud
## Installation and Setup
## Wrappers
### LLM

# Notion DB
## Installation and Setup
## Document Loader

# Obsidian
## Installation and Setup
## Document Loader

# OpenAI
## Installation and Setup
## LLM
## Text Embedding Model
## Chat Model
## Tokenizer
## Chain
## Document Loader
## Retriever

# OpenSearch
## Installation and Setup
## Wrappers
### VectorStore

# OpenWeatherMap
## Installation and Setup
## Wrappers
### Utility
### Tool

# Petals
## Installation and Setup
## Wrappers
### LLM

# PGVector
## Installation
## Setup
## Wrappers
### VectorStore
### Usage

# Pinecone
## Installation and Setup
## Vectorstore

# PipelineAI
## Installation and Setup
## Wrappers
### LLM

# Prediction Guard
## Installation and Setup
## LLM 
### Example
#### Basic usage of the controlled or guarded LLM:
# Your Prediction Guard API key. Get one at predictionguard.com
# Define a prompt template
# With "guarding" or controlling the output of the LLM. See the 
# Prediction Guard docs (https://docs.predictionguard.com) to learn how to 
# control the output with integer, float, boolean, JSON, and other types and
# structures.
#### Basic LLM Chaining with the Prediction Guard:
# Optional, add your OpenAI API Key. This is optional, as Prediction Guard allows
# you to access all the latest open access models (see https://docs.predictionguard.com)
# Your Prediction Guard API key. Get one at predictionguard.com

# PromptLayer
## Installation and Setup
## LLM
### Example
## Chat Model

# Psychic
## Installation and Setup
## Advantages vs Other Document Loaders

# Qdrant
## Installation and Setup
## Wrappers
### VectorStore

PythonNotebook: /docs/integrations/ray_serve.ipynb
  Classes: DeployLLM LLMServe
  Methods: __call__ __init__ _run_chain
  Variables: OPENAI_API_KEY PORT_NUMBER deployment llm prompt resp response self.chain template text
  Usages: LLMChain OpenAI PromptTemplate Request api bind chain content decode getpass input_variables langchain llms openai_api_key port post print query_params ray request requests run self serve shutdown starlette str

PythonNotebook: /docs/integrations/rebuff.ipynb
  Functions: rebuff_func
  Variables: REBUFF_API_KEY buffed_prompt, chain completion db_chain detection_metrics, is_canary_word_detected llm prompt_template transformation_chain user_input
  Usages: LLMChain OpenAI PromptTemplate Rebuff SQLDatabase SQLDatabaseChain SimpleSequentialChain TransformChain ValueError add_canaryword api_token api_url buffed_prompt canary_word chains detect_injection detection_metrics from_llm from_uri input_variables inputs is_canary_word_leaked is_injection json langchain llms output_variables print prompt prompts rebuff run sql_database strip temperature template transform verbose

# Reddit
## Installation and Setup
## Document Loader

# Redis
## Installation and Setup
## Wrappers
### Cache
#### Standard Cache
#### Semantic Cache
# use any embedding provider...
### VectorStore
### Retriever
### Memory
#### Vector Store Retriever Memory
#### Chat Message History Memory

# Replicate
## Installation and Setup
## Calling a model

# Roam
## Installation and Setup
## Document Loader

# Runhouse
## Installation and Setup
## Self-hosted LLMs
## Self-hosted Embeddings

# RWKV-4
## Installation and Setup
## Usage
### RWKV
# Test the model
# Instruction:
# Input:
# Response:
# Instruction:
# Response:
## Model File
### Rwkv-4 models -> recommended VRAM

# SageMaker Endpoint
## Installation and Setup
## LLM
## Text Embedding Models

# SearxNG Search API
## Installation and Setup
### Self Hosted Instance:
## Wrappers
### Utility
### Tool

# SerpAPI
## Installation and Setup
## Wrappers
### Utility
### Tool

# Shale Protocol
## How to
### 1. Find the link to our Discord on https://shaleprotocol.com. Generate an API key through the "Shale Bot" on our Discord. No credit card is required and no free trials. It's a forever free tier with 1K limit per day per API key.
### 2. Use https://shale.live/v1 as OpenAI API drop-in replacement 
# Answer: Let's think step by step."""

# scikit-learn
## Installation and Setup
## Wrappers
### VectorStore

# Slack
## Installation and Setup
## Document Loader

# spaCy
## Installation and Setup
## Text Splitter

# Spreedly
## Installation and Setup
## Document Loader

# StochasticAI
## Installation and Setup
## Wrappers
### LLM

# Stripe
## Installation and Setup
## Document Loader

# Tair
## Installation and Setup
## Wrappers
### VectorStore

# Telegram
## Installation and Setup
## Document Loader

# Tensorflow Hub
## Installation and Setup
## Text Embedding Models

# 2Markdown
## Installation and Setup
## Document Loader

# Trello
## Installation and Setup
## Document Loader

# Twitter
## Installation and Setup
## Document Loader

# Unstructured
## Installation and Setup
## Wrappers
### Data Loaders

# Vectara
## Installation and Setup
## Usage
### VectorStore

# Vespa
## Installation and Setup
## Retriever

PythonNotebook: /docs/integrations/wandb_tracking.ipynb
  Variables: agent callbacks llm llm_result os.environ["WANDB_API_KEY"] prompt_template session_group synopsis_chain template test_prompts tools wandb_callback
  Usages: AgentType LLMChain OpenAI PromptTemplate StdOutCallbackHandler WandbCallbackHandler ZERO_SHOT_REACT_DESCRIPTION agents apply chains datetime download en_core_web_sm environ finish flush_tracker generate group initialize_agent input_variables install job_type langchain llms load_tools name now pandas project prompt prompts reset run spacy strftime tags temperature textstat wandb ython

# Weather
## Installation and Setup
## Document Loader

# Weaviate
## Installation and Setup
## Wrappers
### VectorStore

# WhatsApp
## Installation and Setup
## Document Loader

PythonNotebook: /docs/integrations/whylabs_profiling.ipynb
  Variables: llm result whylabs
  Usages: OpenAI WhyLabsCallbackHandler callbacks close flush from_params generate install langchain langkit llms print temperature

# Wikipedia
## Installation and Setup
## Document Loader
## Retriever

# Wolfram Alpha
## Installation and Setup
## Wrappers
### Utility
### Tool

# Writer
## Installation and Setup
## Wrappers
### LLM

# Yeager.ai
## What is Yeager.ai?
## yAgents
### How to use?
### Creating and Executing Tools with yAgents

# YouTube
## Installation and Setup
## Document Loader

# Zep
## Installation and Setup
## Retriever

# Zilliz
## Installation and Setup
## Vectorstore

File: /docs/modules/agents.rst

File: /docs/modules/chains.rst

File: /docs/modules/indexes.rst

File: /docs/modules/memory.rst

File: /docs/modules/models.rst

File: /docs/modules/paul_graham_essay.txt

File: /docs/modules/prompts.rst

File: /docs/modules/state_of_the_union.txt

File: /docs/reference/agents.rst

File: /docs/reference/indexes.rst

# Installation
## Official Releases
## Installing from source

File: /docs/reference/models.rst

File: /docs/reference/prompts.rst

# Title_REPLACE_ME
## Installation and Setup
## LLM
## Text Embedding Models
## Chat Models
## Document Loader

PythonNotebook: /docs/tracing/agent_with_tracing.ipynb
  Variables: agent llm os.environ["LANGCHAIN_TRACING"] os.environ["LANGCHAIN_TRACING_V2"] questions task tasks tools
  Usages: AgentType ChatOpenAI OpenAI Tool ZERO_SHOT_REACT_DESCRIPTION agents arun asyncio callbacks chat_models create_task environ gather initialize_agent langchain llms load_tools range run session temperature tracing_enabled verbose

# Cloud Hosted Setup
## Installation
## Environment Setup

# Locally Hosted Setup
## Installation
## Environment Setup

# Agent Simulations
## Simulations with One Agent
## Simulations with Two Agents
## Simulations with Multiple Agents

# Interacting with APIs
## Chains
## Agents

# Autonomous Agents
## Baby AGI ([Original Repo](https://github.com/yoheinakajima/babyagi))
## AutoGPT ([Original Repo](https://github.com/Significant-Gravitas/Auto-GPT))
## MetaPrompt ([Original Repo](https://github.com/ngoodman/metaprompt))

# Chatbots

# Code Understanding
## Conversational Retriever Chain

File: /docs/use_cases/evaluation.rst

# Extraction

# Agents
## Create Your Own Agent
### Step 1: Create Tools
### (Optional) Step 2: Modify Agent
### (Optional) Step 3: Modify Agent Executor
## Examples

# Question Answering over Docs
## Document Question Answering
## Adding in sources
## Additional Related Resources
## End-to-end examples

# Summarization

# Querying Tabular Data
## Document Loading
## Querying
### Chains
### Agents

Python: /langchain/agents/__init__.py
  Variables: __all__
  Usages: Agent AgentExecutor AgentOutputParser AgentType BaseMultiActionAgent BaseSingleActionAgent ConversationalAgent ConversationalChatAgent LLMSingleActionAgent MRKLChain ReActChain ReActTextWorldAgent SelfAskWithSearchChain StructuredChatAgent Tool ZeroShotAgent agent agent_toolkits agent_types agents base conversational conversational_chat create_csv_agent create_json_agent create_openapi_agent create_pandas_dataframe_agent create_pbi_agent create_pbi_chat_agent create_spark_dataframe_agent create_spark_sql_agent create_sql_agent create_vectorstore_agent create_vectorstore_router_agent get_all_tool_names initialize initialize_agent langchain load_agent load_huggingface_tool load_tools loading mrkl react self_ask_with_search structured_chat tool tools

Python: /langchain/agents/agent.py
  Classes: Agent AgentExecutor AgentOutputParser BaseMultiActionAgent BaseSingleActionAgent ExceptionTool LLMSingleActionAgent
  Methods: _acall _agent_type _aperform_agent_action _areturn _arun _atake_next_step _call _construct_scratchpad _fix_text _get_default_output_parser _get_tool_return _return _run _should_continue _stop _take_next_step _validate_tools aplan create_prompt dict from_agent_and_tools from_llm_and_tools get_allowed_tools get_full_inputs input_keys llm_prefix lookup_tool observation_prefix output_keys parse plan return_stopped_response return_values save save_agent tool_run_logging_kwargs validate_prompt validate_return_direct_tool validate_tools
  Variables: _dict _dict["_type"] _output_parser _type actions actions: agent agent: agent_action, agent_dict allowed_tools allowed_tools: color color_mapping description directory_path early_stopping_method: final_output final_output["intermediate_steps"] full_inputs full_output handle_parsing_errors: intermediate_steps: iterations llm_chain llm_chain: logger max_execution_time: max_iterations: name name_to_tool_map new_inputs next_step_action next_step_output observation output output_parser: parsed_output prompt raise_error result return_direct return_intermediate_steps: save_path start_time stop: text thoughts time_elapsed tool tool_names tool_return tool_run_kwargs tool_run_kwargs["llm_prefix"] tools tools:
  Usages: AgentAction AgentFinish AgentType Any AsyncCallbackManagerForChainRun AsyncCallbackManagerForToolRun BaseCallbackManager BaseLanguageModel BaseMessage BaseModel BaseOutputParser BasePromptTemplate BaseTool Callable CallbackManagerForChainRun CallbackManagerForToolRun Callbacks Chain Dict FewShotPromptTemplate InvalidTool LLMChain List NotImplementedError Optional OutputParserException Path PromptTemplate Sequence TimeoutError Tuple Union ValueError __name__ abc abstractmethod action agent_action agent_types agents annotations append apredict arun asyncio asyncio_timeout base base_language bool callable callback_manager callbacks chains classmethod cls default_flow_style dump early_stopping_method excluded_colors exist_ok extend few_shot file_path float gather getLogger get_child get_color_mapping handle_parsing_errors indent input input_variables inputs int intermediate_steps isinstance json kwargs langchain len list llm llm_output log logging manager max_execution_time max_iterations mkdir on_agent_action on_agent_finish open output_parser parent parents pathlib predict prompts property pydantic query return_intermediate_steps root_validator rstrip run run_manager schema self send_to_llm set stop str suffix super template time tool_input type typing utilities value values verbose warning yaml

Python: /langchain/agents/agent_types.py
  Classes: AgentType
  Variables: CHAT_CONVERSATIONAL_REACT_DESCRIPTION CHAT_ZERO_SHOT_REACT_DESCRIPTION CONVERSATIONAL_REACT_DESCRIPTION REACT_DOCSTORE SELF_ASK_WITH_SEARCH STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION ZERO_SHOT_REACT_DESCRIPTION
  Usages: Enum enum str

Python: /langchain/agents/initialize.py
  Functions: initialize_agent
  Variables: agent agent_cls agent_kwargs agent_obj
  Usages: AGENT_TO_CLASS AgentExecutor AgentType Any BaseCallbackManager BaseLanguageModel BaseTool Optional Sequence ValueError ZERO_SHOT_REACT_DESCRIPTION agent_path agent_types agents base base_language callback_manager callbacks dict from_agent_and_tools from_llm_and_tools keys kwargs langchain llm load_agent loading str tools typing

Python: /langchain/agents/load_tools.py
  Functions: _get_arxiv _get_bing_search _get_ddg_search _get_google_search _get_google_search_results_json _get_google_serper _get_google_serper_results_json _get_graphql_tool _get_human_tool _get_lambda_api _get_llm_math _get_metaphor_search _get_news_api _get_open_meteo_api _get_openweathermap _get_pal_colored_objects _get_pal_math _get_podcast_api _get_pupmed _get_python_repl _get_scenexplain _get_searx_search _get_searx_search_results_json _get_serpapi _get_sleep _get_terminal _get_tmdb_api _get_tools_requests_delete _get_tools_requests_get _get_tools_requests_patch _get_tools_requests_post _get_tools_requests_put _get_twilio _get_wikipedia _get_wolfram_alpha _handle_callbacks get_all_tool_names load_huggingface_tool load_tools
  Variables: _BASE_TOOLS: _EXTRA_LLM_TOOLS: _EXTRA_OPTIONAL_TOOLS: _LLM_TOOLS: _get_llm_tool_func, _get_tool_func, callbacks chain graphql_endpoint hf_tool inputs listen_api_key missing_keys news_api_key outputs requests_method_tools sub_kwargs tmdb_bearer_token tool tool.callbacks tools wrapper wrapper_kwargs
  Usages: APIChain Any Arg ArxivAPIWrapper ArxivQueryRun BaseCallbackManager BaseGraphQLTool BaseLanguageModel BaseTool BingSearchAPIWrapper BingSearchRun Callable Callbacks DeprecationWarning Dict DuckDuckGoSearchAPIWrapper DuckDuckGoSearchRun GoogleSearchAPIWrapper GoogleSearchResults GoogleSearchRun GoogleSerperAPIWrapper GoogleSerperResults GoogleSerperRun GraphQLAPIWrapper HumanInputRun ImportError KwArg LLMMathChain LambdaWrapper List MetaphorSearchAPIWrapper MetaphorSearchResults NEWS_DOCS NotImplementedError OPEN_METEO_DOCS OpenWeatherMapAPIWrapper OpenWeatherMapQueryRun Optional PALChain PODCAST_DOCS PubMedAPIWrapper PubmedQueryRun PythonREPLTool RequestsDeleteTool RequestsGetTool RequestsPatchTool RequestsPostTool RequestsPutTool SceneXplainTool SearxSearchResults SearxSearchRun SearxSearchWrapper SerpAPIWrapper ShellTool SleepTool TMDB_DOCS TextRequestsWrapper Tool Tuple TwilioAPIWrapper ValueError WikipediaAPIWrapper WikipediaQueryRun WolframAlphaAPIWrapper WolframAlphaQueryRun _BASE_TOOLS _EXTRA_LLM_TOOLS _EXTRA_OPTIONAL_TOOLS _LLM_TOOLS __call__ _get_llm_tool_func _get_tool_func _tool agents api api_wrapper append arun arxiv awslambda base base_language bing_search bool callback_manager chains coroutine ddg_search description difference duckduckgo_search extend extra_keys from_colored_object_prompt from_function from_llm from_llm_and_api_docs from_math_prompt func get google_search google_serper graphql graphql_wrapper headers human items kwargs langchain list llm llm_math load_tool manager metaphor_search model_repo_id mypy_extensions name news_docs open_meteo_docs openweathermap pal podcast_docs pubmed python remote requests requests_wrapper run scenexplain searx_search serpapi set shell sleep startswith str task_or_repo_id tmdb_docs token tool_names transformers twilio typing utilities warn warnings wikipedia wolfram_alpha

Python: /langchain/agents/loading.py
  Functions: _load_agent_from_file _load_agent_from_tools load_agent load_agent_from_config
  Variables: URL_BASE agent_cls combined_config config config["llm_chain"] config_type file_path load_from_tools logger
  Usages: AGENT_TO_CLASS Any BaseLanguageModel BaseSingleActionAgent List Optional Path Tool Union ValueError __file__ agent agents base_language chains dict file from_llm_and_tools getLogger hub_result isinstance json kwargs langchain llm load load_chain load_chain_from_config loading logging open path pathlib pop safe_load str suffix tools try_load_from_hub types typing utilities warning yaml

Python: /langchain/agents/schema.py
  Classes: AgentScratchPadChatPromptTemplate
  Methods: _construct_agent_scratchpad _merge_partial_and_user_variables
  Variables: intermediate_steps kwargs["agent_scratchpad"] thoughts
  Usages: AgentAction Any ChatPromptTemplate Dict List Tuple action chat kwargs langchain len log observation pop prompts schema self str typing

Python: /langchain/agents/tools.py
  Classes: InvalidTool
  Methods: _arun _run
  Variables: __all__ description name
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Optional Tool base callbacks langchain manager run_manager self str tool tool_name tools typing

Python: /langchain/agents/types.py
  Variables: AGENT_TO_CLASS:
  Usages: AGENT_TO_CLASS AgentType BaseSingleActionAgent CHAT_CONVERSATIONAL_REACT_DESCRIPTION CHAT_ZERO_SHOT_REACT_DESCRIPTION CONVERSATIONAL_REACT_DESCRIPTION ChatAgent ConversationalAgent ConversationalChatAgent Dict REACT_DOCSTORE ReActDocstoreAgent SELF_ASK_WITH_SEARCH STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION SelfAskWithSearchAgent StructuredChatAgent Type ZERO_SHOT_REACT_DESCRIPTION ZeroShotAgent agent agent_types agents base chat conversational conversational_chat langchain mrkl react self_ask_with_search structured_chat typing

Python: /langchain/agents/utils.py
  Functions: validate_tools_single_input
  Usages: BaseTool Sequence ValueError base class_name is_single_input langchain name str tool tools typing

Python: /langchain/callbacks/__init__.py
  Variables: __all__
  Usages: AimCallbackHandler ArgillaCallbackHandler AsyncIteratorCallbackHandler ClearMLCallbackHandler CometCallbackHandler FileCallbackHandler HumanApprovalCallbackHandler MlflowCallbackHandler OpenAICallbackHandler StdOutCallbackHandler WandbCallbackHandler WhyLabsCallbackHandler aim_callback argilla_callback callbacks clearml_callback comet_ml_callback file get_openai_callback human langchain manager mlflow_callback openai_info stdout streaming_aiter tracing_enabled wandb_callback wandb_tracing_enabled whylabs_callback

Python: /langchain/callbacks/aim_callback.py
  Functions: import_aim
  Classes: AimCallbackHandler BaseMetadataCallbackHandler
  Methods: __init__ always_verbose flush_tracker get_custom_callback_meta ignore_agent ignore_chain ignore_llm on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start reset_callback_meta setup
  Variables: action_res aim finish_res generated inputs_res outputs_res prompts_res resp response_res self._run self._run_hash self.action_records: self.agent_ends self.always_verbose_ self.chain_ends self.chain_starts self.ends self.errors self.experiment_name self.ignore_agent_ self.ignore_chain_ self.ignore_llm_ self.llm_ends self.llm_starts self.llm_streams self.log_system_params self.repo self.starts self.step self.system_tracking_interval self.text_ctr self.tool_ends self.tool_starts text
  Usages: AgentAction AgentFinish Any BaseCallbackHandler Dict Exception ImportError KeyboardInterrupt LLMResult List Optional Run Text Union _run _run_hash action action_records agent_ends always_verbose_ base bool callbacks chain_ends chain_starts close context copy deepcopy dict ends error errors experiment experiment_name finish format generation generations hash ignore_agent_ ignore_chain_ ignore_llm_ input_str inputs int items key kwargs langchain langchain_asset list llm_ends llm_starts llm_streams log log_system_params name output outputs prompt prompts property repo reset response return_values schema self serialized set starts step str strict super system_tracking_interval text_ctr token tool tool_ends tool_input tool_starts track typing update value

Python: /langchain/callbacks/argilla_callback.py
  Classes: ArgillaCallbackHandler
  Methods: __init__ on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Variables: prompts self.dataset self.dataset_name self.prompts: self.workspace_name supported_fields
  Usages: AgentAction AgentFinish Any BaseCallbackHandler ConnectionError Dict Exception FeedbackDataset FileNotFoundError ImportError KeyboardInterrupt LLMResult List Optional Union ValueError action add_records api_key api_url argilla base callbacks dataset dataset_name error field fields finish from_argilla generation generations get_workspace getenv init input_str inputs isinstance join kwargs langchain list llm_prefix name observation_prefix output outputs pop prompt push_to_argilla records response schema self serialized str strip super text token typing update warn warnings with_records workspace workspace_name zip

Python: /langchain/callbacks/arize_callback.py
  Classes: ArizeCallbackHandler
  Methods: __init__ on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Variables: embedding_features future generated_text pred_id prompt prompt_embedding response_embedding result self.api_key self.arize_client self.completion_tokens self.generator self.model_id self.model_version self.pred_timestamps: self.prediction_ids: self.prompt_embeddings: self.prompt_records: self.prompt_tokens self.response_embeddings: self.response_records: self.space_key self.total_tokens tags
  Usages: API_KEY AgentAction AgentFinish Any BaseCallbackHandler Client Dict Embedding EmbeddingGenerator Environments Exception KeyboardInterrupt LLMResult List ModelTypes NLP Optional PRODUCTION SCORE_CATEGORICAL SEQUENCE_CLASSIFICATION SPACE_KEY Series Union UseCases ValueError action api api_key append arize arize_client base batch_size callbacks completion_tokens data drop embeddings environment error finish from_use_case generate_embeddings generation generations generator input_str inputs kwargs langchain llm_output llm_prefix log model_id model_name model_type model_version observation_prefix output outputs pandas pred_timestamps prediction_id prediction_ids prediction_label print prompt_embeddings prompt_records prompt_tokens prompts replace reset_index response response_embeddings response_records schema self serialized space_key status_code str super text text_col token tokenizer_max_length total_tokens types typing use_case utils uuid uuid4 vector

Python: /langchain/callbacks/base.py
  Classes: AsyncCallbackHandler BaseCallbackHandler BaseCallbackManager CallbackManagerMixin ChainManagerMixin LLMManagerMixin RunManagerMixin ToolManagerMixin
  Methods: __init__ add_handler ignore_agent ignore_chain ignore_chat_model ignore_llm is_async on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_chat_model_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start remove_handler set_handler set_handlers
  Variables: raise_error: self.handlers self.handlers: self.inheritable_handlers self.inheritable_handlers: self.parent_run_id:
  Usages: AgentAction AgentFinish Any BaseMessage Dict Exception KeyboardInterrupt LLMResult List NotImplementedError Optional UUID Union __class__ __name__ action annotations append bool error finish handler handlers inherit inheritable_handlers input_str inputs kwargs langchain messages output outputs parent_run_id prompts property raise_error remove response run_id schema self serialized str text token typing uuid

Python: /langchain/callbacks/clearml_callback.py
  Functions: import_clearml
  Classes: ClearMLCallbackHandler
  Methods: __init__ _create_session_analysis_df _init_resp analyze_text flush_tracker on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Variables: chain_input clearml complexity_metrics_columns dep_out dep_output_path doc ent_out ent_output_path generation_resp input_resp input_resp["input"] langchain_asset_path llm_input_prompts_df llm_outputs_df on_llm_end_records_df on_llm_start_records_df output_model prompt_resp prompt_resp["prompts"] resp self.action_records: self.callback_columns: self.complexity_metrics self.logger self.nlp self.project_name self.stream_logs self.tags self.task self.task_name self.task_type self.temp_dir self.visualize session_analysis_df spacy text_complexity_metrics textstat visualizations_columns: warning
  Usages: AgentAction AgentFinish Any BaseCallbackHandler BaseMetadataCallbackHandler DataFrame Dict Exception ImportError KeyboardInterrupt LLMResult List NotImplementedError Optional OutputModel Path Sequence Task TemporaryDirectory Union ValueError action action_records agent_ends append auto_delete_file automated_readability_index axis base bool callback_columns callbacks chain_ends chain_starts cleanup close coleman_liau_index complexity_metrics concat config_text copy crawford current_task dale_chall_readability_score deepcopy dict difficult_words displacy dropna encoding ends error errors fernandez_huerta finish flatten_dict flesch_kincaid_grade flesch_reading_ease flush generation generations get_custom_callback_meta get_logger gulpease_index gunning_fog gutierrez_polini hash_string import_pandas import_spacy import_textstat init inp input_str inputs isinstance jupyter kwargs langchain langchain_asset level linsear_write_formula list llm_ends llm_output llm_starts llm_streams load load_json local_path log logger name nlp on_agent_action_records on_agent_finish_records on_chain_end_records on_chain_start_records on_llm_end_records on_llm_start_records on_llm_token_records on_text_records on_tool_end_records on_tool_start_records open osman output output_uri outputs page pathlib print print_console project_name prompt prompts rename render report_media report_table report_text repr reset_callback_meta response return_values save save_agent schema self serialized smog_index starts step str stream_logs style super szigriszt_pazos table_plot tags target_filename task task_name task_type temp_dir tempfile text text_ctr text_standard token tool tool_ends tool_input tool_starts typing update update_weights utils visualizations_columns visualize wait_for_uploads weights_filename write

Python: /langchain/callbacks/comet_ml_callback.py
  Functions: _fetch_text_complexity_metrics _get_experiment _summarize_metrics_for_generated_outputs import_comet_ml
  Classes: CometCallbackHandler
  Methods: __init__ _create_session_analysis_dataframe _get_complexity_metrics _get_custom_metrics _get_llm_parameters _init_resp _log_model _log_session _log_stream _log_text_metrics _log_visualizations _reset flush_tracker on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Variables: LANGCHAIN_MODEL_NAME _complexity_metrics _custom_metrics _name _project_name _tags _task_type _visualizations _workspace comet_ml complexity_metrics custom_metrics doc experiment generation_resp html input_resp langchain_asset_path llm_end_records_df llm_parameters llm_session_df llm_start_records_df log metadata metrics_df metrics_summary model_name model_parameters num_generations_per_prompt output output_complexity_metrics output_custom_metrics output_resp outputs prompt_resp prompt_resp["prompts"] prompts resp self.action_records: self.callback_columns: self.comet_ml self.complexity_metrics self.custom_metrics self.experiment self.name self.nlp self.project_name self.stream_logs self.tags self.task_type self.temp_dir self.visualizations self.workspace sentence_spans spacy text text_complexity_metrics textstat tool tool_input warning
  Usages: AgentAction AgentFinish Any AttributeError BaseCallbackHandler BaseMetadataCallbackHandler Callable DataFrame Dict Exception Experiment Generation ImportError KeyboardInterrupt LLMResult LOGGER List NotImplementedError Optional Path Sequence TemporaryDirectory Union ValueError __class__ __name__ __version__ action action_records add_tags agent agent_ends append automated_readability_index base bool callback_columns callbacks chain_ends chain_input_key chain_input_val chain_output_key chain_output_val chain_starts coleman_liau_index copy crawford dale_chall_readability_score deepcopy describe dict difficult_words displacy drop end ends enumerate error errors exc_info extra fernandez_huerta finish flatten_dict flesch_kincaid_grade flesch_reading_ease gen_idx generation generations get get_custom_callback_meta gulpease_index gunning_fog gutierrez_polini hasattr idx import_pandas import_spacy import_textstat index input_str inputs int isinstance items jupyter key kwargs langchain langchain_asset left_index linsear_write_formula list llm llm_chain llm_ends llm_output llm_starts llm_streams load loc log_asset_data log_metrics log_model log_other log_parameters log_table log_text merge metrics name nlp on_llm_end_records on_llm_start_records options osman page pathlib prefix project_name prompt prompt_idx render repeat reset reset_callback_meta reset_index response return_values right_index save save_agent schema self sents serialized session_df set_name smog_index starts step str stream_logs style suffixes super szigriszt_pazos tags task_type temp_dir tempfile text_ctr text_standard to_dict token tolist tool_ends tool_starts typing update utils value visualization visualizations workspace zip

Python: /langchain/callbacks/file.py
  Classes: FileCallbackHandler
  Methods: __del__ __init__ on_agent_action on_agent_finish on_chain_end on_chain_start on_text on_tool_end
  Variables: class_name self.color self.file
  Usages: AgentAction AgentFinish Any BaseCallbackHandler Dict Optional TextIO action base callbacks cast close color end file filename finish input inputs kwargs langchain llm_prefix log mode observation_prefix open output outputs print_text schema self serialized str text typing

Python: /langchain/callbacks/human.py
  Functions: _default_approve _default_true
  Classes: HumanApprovalCallbackHandler HumanRejectedException
  Methods: __init__ on_tool_start
  Variables: msg raise_error: resp self._approve self._should_check
  Usages: Any BaseCallbackHandler Callable Dict Exception Optional UUID _approve _input _should_check approve base bool callbacks input input_str kwargs langchain lower parent_run_id raise_error run_id self serialized should_check str typing uuid

Python: /langchain/callbacks/manager.py
  Functions: _ahandle_event _ahandle_event_for_handler _configure _get_debug _handle_event env_var_is_set
  Classes: AsyncCallbackManager AsyncCallbackManagerForChainRun AsyncCallbackManagerForLLMRun AsyncCallbackManagerForToolRun AsyncRunManager BaseRunManager CallbackManager CallbackManagerForChainRun CallbackManagerForLLMRun CallbackManagerForToolRun RunManager
  Methods: __init__ atrace_as_chain_group configure get_child get_noop_manager get_openai_callback is_async on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_chat_model_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start trace_as_chain_group tracing_enabled tracing_v2_enabled wandb_tracing_enabled
  Variables: BRM Callbacks T callback_manager debug event example_id handler inheritable_callbacks_ local_handlers_ logger manager message_strings message_strings: open_ai openai_callback_var: run_id run_manager self.handlers self.inheritable_handlers self.parent_run_id self.run_id session tracer tracer_session tracer_v2 tracing_callback_var: tracing_enabled_ tracing_v2_callback_var: tracing_v2_enabled_ wandb_tracer wandb_tracing_callback_var: wandb_tracing_enabled_
  Usages: AgentAction AgentFinish Any AsyncGenerator BaseCallbackHandler BaseCallbackManager BaseMessage ChainManagerMixin ConsoleCallbackHandler ContextVar Dict Exception Generator KeyboardInterrupt LLMManagerMixin LLMResult LangChainTracer LangChainTracerV1 List NotImplementedError OpenAICallbackHandler Optional RunManagerMixin StdOutCallbackHandler ToolManagerMixin TracerSessionV1 Type TypeVar UUID Union WandbTracer __name__ action add_handler annotations any args asynccontextmanager asyncio base bool bound callback_manager_cls callbacks cast classmethod cls contextlib contextmanager contextvars copy default env_var environ error event_name finish functools gather get getLogger get_buffer_string get_event_loop getattr group_name handlers ignore_condition_name inheritable_callbacks inheritable_handlers input_str inputs iscoroutinefunction isinstance kwargs langchain langchain_v1 list load_session local_callbacks logging messages openai_callback_var openai_info output outputs parent_run_id partial prompts property raise_error response run_in_executor schema self serialized session_name set set_handlers stdout str text token tracers tracing_callback_var tracing_v2_callback_var typing uuid uuid4 verbose wandb wandb_tracing_callback_var warn warning warnings

Python: /langchain/callbacks/mlflow_callback.py
  Functions: analyze_text construct_html_from_prompt_and_generation import_mlflow
  Classes: MlflowCallbackHandler MlflowLogger
  Methods: __init__ _create_session_analysis_df _reset artifact finish_run flush_tracker html jsonf langchain_artifact metric metrics on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start start_run table text
  Variables: agent_ends chain_ends chain_input chain_output chain_starts chat_html complexity_metrics: complexity_metrics_columns dep_out dependency_tree doc ent_out entities experiment_name formatted_generation formatted_prompt generation_resp input_resp input_resp["inputs"] langchain_asset_path llm_ends llm_input_prompts_df llm_outputs_df llm_starts llm_streams name on_llm_end_records_df on_llm_start_records_df prompt_resp prompt_resp["prompt"] resp: rname self.action_records: self.experiment self.metrics self.metrics[k] self.mlf_exp self.mlf_expid self.mlflg self.mlflow self.name self.nlp self.records: self.records[k] self.run self.tags self.temp_dir self.tracking_uri session_analysis_df session_analysis_df["chat_html"] spacy text_complexity_metrics text_ctr text_visualizations textstat tool_ends tool_starts tracking_uri visualizations_columns
  Usages: AgentAction AgentFinish Any AttributeError BaseCallbackHandler BaseMetadataCallbackHandler DataFrame Dict Exception ImportError KeyboardInterrupt LLMResult List MlflowClient NotImplementedError Optional Path TemporaryDirectory Union ValueError action action_records append apply ascii_uppercase automated_readability_index axis base bool callbacks chain choices coleman_liau_index complexity_metrics concat copy crawford create_experiment create_run dale_chall_readability_score data dataframe deepcopy dict difficult_words digits displacy dropna end_run endswith enumerate error experiment experiment_id fernandez_huerta filename finish flatten_dict flesch_kincaid_grade flesch_reading_ease float generation generations get_experiment_by_name get_from_dict_or_env gulpease_index gunning_fog gutierrez_polini hash_string idx import_pandas import_spacy import_textstat info input_str inputs int items join jupyter key kwargs langchain langchain_asset linsear_write_formula list llm_output load log log_artifact log_dict log_metric log_metrics log_model log_text mlf_exp mlf_expid mlflg mlflow nlp osman output outputs page path pathlib pop print print_exc prompt prompts random records regex rename render replace resp response return_values row run run_id run_name run_tags save save_agent schema self serialized set_tracking_uri smog_index step str string style super szigriszt_pazos tags temp_dir tempfile to_html token tolist tool tool_input traceback type typing update utils value

Python: /langchain/callbacks/openai_info.py
  Functions: get_openai_token_cost_for_model standardize_model_name
  Classes: OpenAICallbackHandler
  Methods: __copy__ __deepcopy__ __repr__ always_verbose on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_tool_end on_tool_error on_tool_start
  Variables: MODEL_COST_PER_1K_TOKENS completion_cost completion_tokens completion_tokens: model_name prompt_cost prompt_tokens prompt_tokens: successful_requests: token_usage total_cost: total_tokens:
  Usages: AgentAction AgentFinish Any BaseCallbackHandler Dict Exception KeyboardInterrupt LLMResult List Optional Union ValueError action base bool callbacks color error finish float get input_str inputs int is_completion join keys kwargs langchain llm_output llm_prefix lower memo num_tokens observation_prefix output outputs prompts property response schema self serialized split startswith str successful_requests token total_cost total_tokens typing

Python: /langchain/callbacks/stdout.py
  Classes: StdOutCallbackHandler
  Methods: __init__ on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Variables: class_name self.color
  Usages: AgentAction AgentFinish Any BaseCallbackHandler Dict Exception KeyboardInterrupt LLMResult List Optional Union action base callbacks color end error finish input input_str inputs kwargs langchain llm_prefix log observation_prefix output outputs print print_text prompts response schema self serialized str text token typing

Python: /langchain/callbacks/streaming_aiter.py
  Classes: AsyncIteratorCallbackHandler
  Methods: __init__ aiter always_verbose on_llm_end on_llm_error on_llm_new_token on_llm_start
  Variables: done, done: queue: self.done self.queue token_or_done
  Usages: Any AsyncCallbackHandler AsyncIterator Dict Event Exception FIRST_COMPLETED KeyboardInterrupt LLMResult List Literal Queue Union annotations asyncio base bool callbacks cancel cast clear done empty ensure_future error get is_set kwargs langchain other pop prompts property put_nowait queue response result return_when schema self serialized set str token typing wait

Python: /langchain/callbacks/streaming_stdout.py
  Classes: StreamingStdOutCallbackHandler
  Methods: on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Usages: AgentAction AgentFinish Any BaseCallbackHandler Dict Exception KeyboardInterrupt LLMResult List Union action base callbacks error finish flush input_str inputs kwargs langchain output outputs prompts response schema self serialized stdout str sys text token typing write

Python: /langchain/callbacks/streaming_stdout_final_only.py
  Classes: FinalStreamingStdOutCallbackHandler
  Methods: __init__ append_to_last_tokens check_if_answer_reached on_llm_new_token on_llm_start
  Variables: DEFAULT_ANSWER_PREFIX_TOKENS self.answer_prefix_tokens self.answer_prefix_tokens_stripped self.answer_reached self.last_tokens self.last_tokens_stripped self.stream_prefix self.strip_tokens
  Usages: Any Dict List Optional StreamingStdOutCallbackHandler answer_prefix_tokens answer_prefix_tokens_stripped answer_reached append bool callbacks flush kwargs langchain last_tokens last_tokens_stripped len pop prompts self serialized stdout str stream_prefix streaming_stdout strip strip_tokens super sys token typing write

Python: /langchain/callbacks/streamlit.py
  Classes: StreamlitCallbackHandler
  Methods: __init__ on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Variables: class_name self.tokens_area self.tokens_stream
  Usages: AgentAction AgentFinish Any BaseCallbackHandler Dict Exception KeyboardInterrupt LLMResult List Optional Union action base callbacks empty error finish input_str inputs kwargs langchain llm_prefix log markdown observation_prefix output outputs prompt prompts replace response schema self serialized str streamlit text token tokens_area tokens_stream typing write

Python: /langchain/callbacks/utils.py
  Functions: _flatten_dict flatten_dict hash_string import_pandas import_spacy import_textstat load_json
  Classes: BaseMetadataCallbackHandler
  Methods: __init__ always_verbose get_custom_callback_meta ignore_agent ignore_chain ignore_llm reset_callback_meta
  Variables: data flat_dict new_key self.agent_ends self.always_verbose_ self.chain_ends self.chain_starts self.ends self.errors self.ignore_agent_ self.ignore_chain_ self.ignore_llm_ self.llm_ends self.llm_starts self.llm_streams self.on_agent_action_records self.on_agent_action_records: self.on_agent_finish_records self.on_agent_finish_records: self.on_chain_end_records self.on_chain_end_records: self.on_chain_start_records self.on_chain_start_records: self.on_llm_end_records self.on_llm_end_records: self.on_llm_start_records self.on_llm_start_records: self.on_llm_token_records self.on_llm_token_records: self.on_text_records self.on_text_records: self.on_tool_end_records self.on_tool_end_records: self.on_tool_start_records self.on_tool_start_records: self.starts self.step self.text_ctr self.tool_ends self.tool_starts
  Usages: Any Dict ImportError Iterable Path Tuple Union agent_ends always_verbose_ bool chain_ends chain_starts dict encode ends errors hashlib hexdigest ignore_agent_ ignore_chain_ ignore_llm_ isinstance items json_path key list llm_ends llm_starts llm_streams nested_dict on_agent_action_records on_agent_finish_records on_chain_end_records on_chain_start_records on_llm_end_records on_llm_start_records on_llm_token_records on_text_records on_tool_end_records on_tool_start_records open pandas parent_key pathlib property read self sep sha1 spacy starts step str text_ctr textstat tool_ends tool_starts typing value

Python: /langchain/callbacks/wandb_callback.py
  Functions: analyze_text construct_html_from_prompt_and_generation import_wandb load_json_to_dict
  Classes: WandbCallbackHandler
  Methods: __init__ _create_session_analysis_df _init_resp flush_tracker on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Variables: action_records_table chain_input complexity_metrics_columns data dep_out dep_output_path doc ent_out ent_output_path formatted_generation formatted_prompt generation_resp input_resp input_resp["input"] langchain_asset_path llm_input_prompts_df llm_outputs_df model_artifact model_artifact.metadata on_llm_end_records_df on_llm_start_records_df prompt_resp prompt_resp["prompts"] resp self.action_records: self.callback_columns: self.complexity_metrics self.entity self.group self.job_type self.name self.nlp self.notes self.project self.run: self.stream_logs self.tags self.temp_dir self.visualize session_analysis_df session_analysis_df["chat_html"] session_analysis_table spacy text_complexity_metrics text_visualizations textstat visualizations_columns wandb warning
  Usages: AgentAction AgentFinish Any Artifact BaseCallbackHandler BaseMetadataCallbackHandler DataFrame Dict Exception Html ImportError KeyboardInterrupt LLMResult List NotImplementedError Optional Path Run Sequence Table TemporaryDirectory Union ValueError action action_records add add_file agent_ends append apply automated_readability_index axis base bool callback_columns callbacks chain_ends chain_starts cleanup coleman_liau_index complexity_metrics concat copy crawford dale_chall_readability_score dataframe deepcopy dict difficult_words displacy dropna encoding ends entity error errors fernandez_huerta finish flatten_dict flesch_kincaid_grade flesch_reading_ease generation generations get_custom_callback_meta group gulpease_index gunning_fog gutierrez_polini hash_string import_pandas import_spacy import_textstat init inject inp input_str inputs isinstance job_type json json_path jupyter kwargs langchain langchain_asset linsear_write_formula list llm_ends llm_output llm_starts llm_streams load log log_artifact metadata name nlp notes on_agent_action_records on_agent_finish_records on_chain_end_records on_chain_start_records on_llm_end_records on_llm_start_records on_llm_token_records on_text_records on_tool_end_records on_tool_start_records open osman output output_dir outputs page pathlib print project prompt prompts rename render repeat replace repr reset reset_callback_meta response return_values row run save save_agent schema sdk self serialized smog_index starts step str stream_logs style super szigriszt_pazos tags temp_dir tempfile termwarn text text_ctr text_standard token tool tool_ends tool_input tool_starts type typing update utils visualize wandb_run write

Python: /langchain/callbacks/whylabs_callback.py
  Functions: import_langkit
  Classes: WhyLabsCallbackHandler
  Methods: __enter__ __exit__ __init__ _profile_generations close flush from_params on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start
  Variables: api_key dataset_id diagnostic_logger langkit_schema org_id self.logger whylabs_logger whylabs_writer
  Usages: AgentAction AgentFinish Any BaseCallbackHandler DeclarativeSchema Dict Exception Generation ImportError KeyboardInterrupt LLMResult List Logger Optional TYPE_CHECKING Union WhyLabsWriter __name__ _do_rollover action annotations api append_writer base bool callbacks classmethod cls color core error exception_type exception_value experimental finish gen generate_udf_schema generations getLogger get_from_env info input_str inputs interval kwargs langchain langkit llm_prefix log logger logging metrics mode observation_prefix output outputs prompt prompts regexes response schema self sentiment serialized str super text textstat themes token toxicity traceback typing udf_metric utils when why whylabs whylogs writer

Python: /langchain/chains/__init__.py
  Variables: __all__
  Usages: APIChain AnalyzeDocumentChain ChatVectorDBChain ConstitutionalChain ConversationChain ConversationalRetrievalChain FlareChain GraphCypherQAChain GraphQAChain HypotheticalDocumentEmbedder LLMBashChain LLMChain LLMCheckerChain LLMMathChain LLMRequestsChain LLMSummarizationCheckerChain MapReduceChain NebulaGraphQAChain OpenAIModerationChain OpenAPIEndpointChain PALChain QAGenerationChain QAWithSourcesChain RetrievalQA RetrievalQAWithSourcesChain SQLDatabaseChain SQLDatabaseSequentialChain SequentialChain SimpleSequentialChain TransformChain VectorDBQA VectorDBQAWithSourcesChain api base chain chains combine_documents constitutional_ai conversation conversational_retrieval cypher flare graph_qa hyde langchain llm llm_bash llm_checker llm_math llm_requests llm_summarization_checker load_chain loading mapreduce moderation nebulagraph openapi pal qa_generation qa_with_sources retrieval retrieval_qa sequential sql_database transform vector_db

Python: /langchain/chains/base.py
  Functions: _get_verbosity
  Classes: Chain Config
  Methods: __call__ _acall _call _chain_type _validate_inputs _validate_outputs acall apply arun dict input_keys output_keys prep_inputs prep_outputs raise_deprecation run save set_verbose
  Variables: _dict _dict["_type"] _input_keys arbitrary_types_allowed callback_manager callback_manager: callbacks: chain_dict directory_path external_context final_outputs: final_outputs[RUN_KEY] inputs memory: missing_keys new_arg_supported outputs run_manager save_path values["callbacks"] verbose:
  Usages: ABC Any AsyncCallbackManager AsyncCallbackManagerForChainRun BaseCallbackManager BaseMemory CallbackManager CallbackManagerForChainRun Callbacks DeprecationWarning Dict Exception Field KeyboardInterrupt List NotImplementedError Optional Path RUN_KEY RunInfo Serializable Union ValueError abc abstractmethod always args base bool callbacks cls configure default default_factory default_flow_style difference dump dumpd exclude exist_ok file_path final_outputs get include_run_info indent input_list inspect isinstance json kwargs langchain len list load load_memory_variables manager memory memory_variables mkdir on_chain_end on_chain_error on_chain_start open parameters parent parents pathlib pop pre property pydantic return_only_outputs root_validator run_id save_context schema self serializable set signature str suffix super typing validator values verbose warn warnings yaml

Python: /langchain/chains/llm.py
  Classes: Config LLMChain
  Methods: _acall _call _chain_type _parse_result aapply aapply_and_parse agenerate apply apply_and_parse apredict apredict_and_parse aprep_prompts create_outputs from_string generate input_keys lc_serializable output_keys predict predict_and_parse prep_prompts
  Variables: _colored_text _text arbitrary_types_allowed callback_manager extra llm: output_key: outputs prompt prompt: prompt_template prompts prompts, response result run_manager selected_inputs stop
  Usages: Any AsyncCallbackManager AsyncCallbackManagerForChainRun BaseLanguageModel BasePromptTemplate CallbackManager CallbackManagerForChainRun Callbacks Chain Dict Exception Extra KeyboardInterrupt LLMResult List Optional PromptTemplate PromptValue Sequence Tuple Union ValueError acall agenerate_prompt annotations append base base_language bool callbacks chains classmethod cls configure dump dumpd end forbid format_prompt from_template generate_prompt generation generations get_child get_colored_text input input_list input_variables inputs kwargs langchain llm load manager on_chain_end on_chain_error on_chain_start on_text output_key output_parser parse property pydantic res schema self str template text to_string typing verbose

Python: /langchain/chains/llm_requests.py
  Classes: Config LLMRequestsChain
  Methods: _call _chain_type input_keys output_keys validate_environment
  Variables: DEFAULT_HEADERS _run_manager arbitrary_types_allowed extra input_key: llm_chain: other_keys other_keys[self.requests_key] output_key: requests_key: requests_wrapper: res result soup text_length: url
  Usages: Any BeautifulSoup CallbackManagerForChainRun Chain Dict Extra Field ImportError LLMChain List Optional TextRequestsWrapper ValueError annotations base bs4 callbacks chains cls default_factory exclude forbid get get_child get_noop_manager get_text input_key inputs int items langchain llm_chain manager output_key predict property pydantic requests requests_key requests_wrapper root_validator run_manager self str text_length typing values

Python: /langchain/chains/loading.py
  Functions: _load_api_chain _load_chain_from_file _load_hyde_chain _load_llm_bash_chain _load_llm_chain _load_llm_checker_chain _load_llm_math_chain _load_llm_requests_chain _load_map_reduce_documents_chain _load_map_rerank_documents_chain _load_pal_chain _load_qa_with_sources_chain _load_refine_documents_chain _load_retrieval_qa _load_sql_database_chain _load_stuff_documents_chain _load_vector_db_qa _load_vector_db_qa_with_sources_chain load_chain load_chain_from_config
  Variables: URL_BASE api_answer_chain api_answer_chain_config api_request_chain api_request_chain_config chain_loader check_assertions_prompt check_assertions_prompt_config collapse_document_chain collapse_document_chain_config combine_document_chain combine_document_chain_config combine_documents_chain combine_documents_chain_config config config["memory"] config["verbose"] config_type create_draft_answer_prompt create_draft_answer_prompt_config database document_prompt embeddings file_path initial_llm_chain initial_llm_chain_config list_assertions_prompt list_assertions_prompt_config llm llm_chain llm_chain_config llm_config prompt prompt_config refine_llm_chain refine_llm_chain_config requests_wrapper retriever revised_answer_prompt revised_answer_prompt_config type_to_loader_dict vectorstore
  Usages: APIChain Any Chain HypotheticalDocumentEmbedder LLMBashChain LLMChain LLMCheckerChain LLMMathChain LLMRequestsChain MapReduceDocumentsChain MapRerankDocumentsChain PALChain Path QAWithSourcesChain RefineDocumentsChain RetrievalQA SQLDatabaseChain StuffDocumentsChain Union ValueError VectorDBQA VectorDBQAWithSourcesChain api base base_embeddings chains combine_documents dict file from_llm hub_result hyde isinstance json kwargs langchain llm_bash llm_checker llm_math llm_requests llms load load_llm load_llm_from_config load_prompt load_prompt_from_config loading map_reduce map_rerank open pal path pathlib pop prompts qa_with_sources refine retrieval_qa safe_load sql_database str stuff suffix try_load_from_hub typing utilities vector_db yaml

Python: /langchain/chains/mapreduce.py
  Classes: Config MapReduceChain
  Methods: _call from_params input_keys output_keys
  Variables: _inputs: _run_manager arbitrary_types_allowed combine_documents_chain combine_documents_chain: doc_text docs extra input_key: llm_chain output_key: outputs reduce_chain text_splitter: texts
  Usages: Any BaseCombineDocumentsChain BaseLanguageModel BasePromptTemplate CallbackManagerForChainRun Callbacks Chain Dict Document Extra LLMChain List MapReduceDocumentsChain Mapping Optional StuffDocumentsChain TextSplitter _inputs annotations base base_language callbacks chains classmethod cls combine_chain_kwargs combine_document_chain combine_documents docstore document forbid get_child get_noop_manager input_key inputs kwargs langchain llm manager map_reduce output_key page_content pop prompt prompts property pydantic reduce_chain_kwargs run run_manager self split_text str stuff text text_splitter typing

Python: /langchain/chains/moderation.py
  Classes: OpenAIModerationChain
  Methods: _call _moderate input_keys output_keys validate_environment
  Variables: client: error: error_str input_key: model_name: openai.api_key openai.organization openai_api_key openai_api_key: openai_organization openai_organization: output output_key: results text values["client"]
  Usages: Any CallbackManagerForChainRun Chain Dict ImportError List Moderation Optional ValueError api_key base bool callbacks chains client cls create default dict error get_from_dict_or_env input_key inputs langchain manager model_name openai organization output_key property pydantic root_validator run_manager self str typing utils values

Python: /langchain/chains/prompt_selector.py
  Functions: is_chat_model is_llm
  Classes: BasePromptSelector ConditionalPromptSelector
  Methods: get_prompt
  Variables: conditionals: default_prompt:
  Usages: ABC BaseChatModel BaseLLM BaseLanguageModel BaseModel BasePromptTemplate Callable Field List Tuple abc abstractmethod base base_language bool chat_models condition conditionals default_factory default_prompt isinstance langchain list llm llms prompt prompts pydantic self typing

Python: /langchain/chains/sequential.py
  Classes: Config SequentialChain SimpleSequentialChain
  Methods: _acall _call input_keys output_keys validate_chains
  Variables: _input _run_manager arbitrary_types_allowed callbacks chains chains: color_mapping extra input_key: input_variables input_variables: known_values known_variables memory_keys missing_vars output_key: output_keys output_variables: outputs overlapping_keys return_all: strip_outputs: values["output_variables"]
  Usages: Any AsyncCallbackManagerForChainRun CallbackManagerForChainRun Chain Dict Extra List Optional ValueError acall arun base bool chain cls color copy difference end enumerate forbid get get_child get_color_mapping get_noop_manager input input_key inputs intersection join langchain len list manager memory_variables on_text output_key output_variables pre property pydantic range return_all return_only_outputs root_validator run run_manager self set str strip strip_outputs typing update values verbose

Python: /langchain/chains/transform.py
  Classes: TransformChain
  Methods: _call input_keys output_keys
  Variables: input_variables: output_variables: transform:
  Usages: Callable CallbackManagerForChainRun Chain Dict List Optional base callbacks chains input_variables inputs langchain manager output_variables property run_manager self str transform typing

Python: /langchain/chat_models/__init__.py
  Variables: __all__
  Usages: AzureChatOpenAI ChatAnthropic ChatGooglePalm ChatOpenAI ChatVertexAI PromptLayerChatOpenAI anthropic azure_openai chat_models google_palm langchain openai promptlayer_openai vertexai

Python: /langchain/chat_models/anthropic.py
  Classes: ChatAnthropic Config
  Methods: _agenerate _convert_messages_to_prompt _convert_messages_to_text _convert_one_message_to_text _generate _llm_type get_num_tokens lc_serializable
  Variables: completion delta extra message message_text params: params["stop_sequences"] prompt response stream_resp text
  Usages: AIMessage AI_PROMPT Any AsyncCallbackManagerForLLMRun BaseChatModel BaseMessage CallbackManagerForLLMRun ChatGeneration ChatMessage ChatResult Dict Extra HUMAN_PROMPT HumanMessage List NameError Optional SystemMessage ValueError _AnthropicCommon _default_params acompletion acompletion_stream anthropic append base bool callbacks capitalize chat_models client completion_stream content count_tokens data forbid generations int isinstance join kwargs langchain len llms manager messages on_llm_new_token params property pydantic role rstrip run_manager schema self stop str streaming typing

Python: /langchain/chat_models/azure_openai.py
  Classes: AzureChatOpenAI
  Methods: _create_chat_result _default_params _identifying_params _invocation_params _llm_type validate_environment
  Variables: deployment_name: logger openai_api_base: openai_api_key: openai_api_type: openai_api_version: openai_creds openai_organization: openai_proxy: values["client"] values["openai_api_base"] values["openai_api_key"] values["openai_api_type"] values["openai_api_version"] values["openai_organization"] values["openai_proxy"]
  Usages: Any AttributeError ChatCompletion ChatOpenAI ChatResult Dict ImportError Mapping ValueError __name__ annotations chat_models cls default deployment_name get getLogger get_from_dict_or_env langchain logging openai openai_api_base openai_api_key openai_api_type openai_api_version openai_organization openai_proxy property pydantic res response root_validator schema self str super typing utils values

Python: /langchain/chat_models/base.py
  Functions: _get_verbosity
  Classes: BaseChatModel Config SimpleChatModel
  Methods: __call__ _agenerate _call _call_async _combine_llm_outputs _generate _identifying_params _llm_type agenerate agenerate_prompt apredict apredict_messages call_as_llm dict generate generate_prompt predict predict_messages raise_deprecation
  Variables: _stop arbitrary_types_allowed callback_manager callback_manager: callbacks: extra func generation generations llm_output message new_arg_supported options output output.run output_str params params["stop"] prompt_messages result results run_manager starter_dict starter_dict["_type"] values["callbacks"] verbose:
  Usages: ABC AIMessage Any AsyncCallbackManager AsyncCallbackManagerForLLMRun BaseCallbackManager BaseLanguageModel BaseMessage CallbackManager CallbackManagerForLLMRun Callbacks ChatGeneration ChatResult DeprecationWarning Dict Exception Extra Field HumanMessage KeyboardInterrupt LLMResult List Mapping Optional PromptValue RunInfo Sequence ValueError abc abstractmethod asyncio base base_language bool callbacks cls configure content default default_factory dump dumpd exclude forbid functools gather get get_event_loop inspect invocation_params isinstance kwargs langchain list llm_outputs load manager messages on_chat_model_start on_llm_end on_llm_error parameters partial pop prompts property pydantic res root_validator run run_id run_in_executor schema self signature stop str text to_messages typing values verbose warn warnings

Python: /langchain/chat_models/google_palm.py
  Functions: _create_retry_decorator _messages_to_prompt_dict _response_to_result _truncate_at_stop_tokens achat_with_retry chat_with_retry
  Classes: ChatGooglePalm ChatGooglePalmError
  Methods: _achat_with_retry _agenerate _chat_with_retry _generate _identifying_params _llm_type validate_environment
  Variables: author client: content context context: examples: generations: google_api_key google_api_key: index, logger max_retries max_seconds messages: min_seconds model_name: multiplier prompt remaining response: retry_decorator stop_token_idx temperature: text top_k: top_p: values["client"]
  Usages: AIMessage Any AsyncCallbackManagerForLLMRun BaseChatModel BaseMessage BaseModel Callable CallbackManagerForLLMRun ChatGeneration ChatMessage ChatResponse ChatResult Dict Exception GoogleAPIError HumanMessage ImportError List Mapping MessageDict MessagePromptDict Optional ResourceExhausted ServiceUnavailable SystemMessage TYPE_CHECKING ValueError WARNING __name__ annotations api_core api_key append base before_sleep before_sleep_log callbacks candidate candidate_count candidates chat chat_async chat_models client cls configure enumerate example examples exceptions extend find float genai generations generativeai get getLogger get_from_dict_or_env google index input_message input_messages int isinstance kwargs langchain list llm logging manager max message messages min model model_name next_input_message pop property pydantic reraise response retry retry_if_exception_type role root_validator run_manager schema self stop stop_after_attempt stop_token str temperature tenacity top_k top_p types typing utils values wait wait_exponential

Python: /langchain/chat_models/openai.py
  Functions: _convert_dict_to_message _convert_message_to_dict _create_retry_decorator _import_tiktoken acompletion_with_retry
  Classes: ChatOpenAI Config
  Methods: _agenerate _combine_llm_outputs _completion_with_retry _create_chat_result _create_message_dicts _create_retry_decorator _default_params _generate _get_encoding_model _identifying_params _invocation_params _llm_type build_extra completion_with_retry get_num_tokens_from_messages get_token_ids lc_serializable validate_environment
  Variables: all_required_field_names allow_population_by_field_name client: encoding extra extra[field_name] gen generations inner_completion invalid_model_kwargs llm_output logger max_retries: max_seconds max_tokens: message message_dict message_dict["name"] message_dicts message_dicts, messages_dict min_seconds model model, model_kwargs: model_name: num_tokens openai.proxy openai_api_base: openai_api_key: openai_creds: openai_organization: openai_proxy: overall_token_usage: overall_token_usage[k] params params["stop"] params["stream"] request_timeout: response retry_decorator role streaming: temperature: tiktoken_ token token_usage tokens_per_message tokens_per_name values["client"] values["model_kwargs"] values["openai_api_base"] values["openai_api_key"] values["openai_organization"] values["openai_proxy"]
  Usages: AIMessage APIConnectionError APIError Any AsyncCallbackManagerForLLMRun AttributeError BaseChatModel BaseMessage Callable CallbackManagerForLLMRun ChatCompletion ChatGeneration ChatMessage ChatResult Dict Encoding Extra Field HumanMessage ImportError KeyError List Mapping NotImplementedError Optional RateLimitError ServiceUnavailableError SystemMessage TYPE_CHECKING Timeout Tuple Union ValueError WARNING __name__ _dict acreate additional_kwargs alias annotations append base before_sleep before_sleep_log bool callbacks chat_models client cls content create default default_factory dict encode encoding_for_model encoding_model error field_name float get getLogger get_encoding get_from_dict_or_env ignore int intersection isinstance items key keys kwargs langchain len list llm llm_outputs logging manager max max_retries max_tokens messages min model_kwargs model_name multiplier on_llm_new_token openai openai_api_base openai_api_key openai_creds openai_organization openai_proxy output overall_token_usage pop pre property proxy pydantic request_timeout reraise res retry retry_if_exception_type root_validator run_manager schema self stop stop_after_attempt str stream_resp streaming super sys temperature tenacity text tiktoken typing utils value values version_info wait wait_exponential warning

Python: /langchain/chat_models/promptlayer_openai.py
  Classes: PromptLayerChatOpenAI
  Methods: _agenerate _generate _identifying_params _llm_type
  Variables: generated_responses generation.generation_info generation.generation_info["pl_request_id"] message_dicts, params pl_request_id pl_tags: request_end_time request_start_time response_dict, return_pl_id:
  Usages: Any AsyncCallbackManagerForLLMRun BaseMessage CallbackManagerForLLMRun ChatOpenAI ChatResult List Mapping Optional _create_message_dicts bool callbacks chat_models datetime dict enumerate generation generation_info generations get_api_key isinstance kwargs langchain manager message message_dicts messages now pl_tags promptlayer promptlayer_api_request promptlayer_api_request_async property response_dict return_pl_id run_manager schema self stop str super timestamp typing utils

Python: /langchain/chat_models/vertexai.py
  Functions: _parse_chat_history
  Classes: ChatVertexAI _ChatHistory _MessagePair
  Methods: _agenerate _generate validate_environment
  Variables: answer: chat chat_history context first_message history history: messages_left model_name: params question question: response system_message system_message: text values["client"]
  Usages: AIMessage Any AsyncCallbackManagerForLLMRun BaseChatModel BaseMessage CallbackManagerForLLMRun ChatGeneration ChatModel ChatResult Dict HumanMessage ImportError List NotImplementedError Optional SystemMessage ValueError _VertexAICommon _default_params _enforce_stop_words _history _try_init_vertexai answer append base callbacks chat_models client cls content dataclass dataclasses default_factory field from_pretrained generations isinstance kwargs langchain language_models len list llms manager message messages model_name pair preview pydantic raise_vertex_import_error root_validator run_manager schema self send_message start_chat stop str type typing utilities values vertexai zip

Python: /langchain/client/__init__.py
  Variables: __all__
  Usages: arun_on_dataset arun_on_examples client langchain run_on_dataset run_on_examples runner_utils

Python: /langchain/client/runner_utils.py
  Functions: _arun_llm _arun_llm_or_chain _gather_with_concurrency _get_messages _get_prompts _get_session_name _tracer_initializer arun_on_dataset arun_on_examples run_llm run_llm_or_chain run_on_dataset run_on_examples
  Classes: InputFormatError
  Methods: process_example run_coroutine_with_semaphore
  Variables: MODEL_OR_CHAIN_FACTORY buffer_strings callbacks callbacks: chain client_ converted_messages: current_time dataset examples job_state langchain_tracer.example_id llm_messages llm_output llm_prompts logger messages model_name output output: outputs previous_example_id prompt_ prompts raw_messages result results: results[str(example.id)] semaphore session_name single_input tracer tracer_queue:
  Usages: Any BaseCallbackHandler BaseChatModel BaseLLM BaseLanguageModel BaseMessage Callable Callbacks Chain ChatResult Coroutine Dict Example Exception HumanMessage Iterator LLMResult LangChainPlusClient LangChainTracer List Optional Queue Semaphore Union ValueError __class__ __name__ acall agenerate all annotations append async_func async_funcs asyncio base base_language batch bool chains chat_models client concurrency_level content converted_messages dataset_id dataset_name datetime dict end enumerate example example_id flush function functools gather generate get getLogger get_buffer_string initializer inputs int isinstance iter langchain langchain_tracer langchainplus_sdk len list list_examples llm llm_or_chain_factory llms logging manager messages_from_dict n_repetitions next now num_repetitions partial print prompt put_nowait range read_dataset results schema schemas str strftime tracer_queue tracers type typing values verbose warning

Python: /langchain/docstore/__init__.py
  Variables: __all__
  Usages: InMemoryDocstore Wikipedia docstore in_memory langchain wikipedia

Python: /langchain/docstore/arbitrary_fn.py
  Classes: DocstoreFn
  Methods: __init__ search
  Variables: self._lookup_fn
  Usages: Callable Docstore Document Union ValueError _lookup_fn base docstore isinstance langchain lookup_fn metadata page_content schema self str type typing

Python: /langchain/docstore/base.py
  Classes: AddableMixin Docstore
  Methods: add search
  Usages: ABC Dict Document Union abc abstractmethod docstore document langchain self str texts typing

Python: /langchain/docstore/document.py
  Variables: __all__
  Usages: Document langchain schema

Python: /langchain/docstore/in_memory.py
  Classes: InMemoryDocstore
  Methods: __init__ add search
  Variables: overlapping self._dict
  Usages: AddableMixin Dict Docstore Document Union ValueError _dict base dict docstore document intersection langchain self set str texts typing

Python: /langchain/docstore/wikipedia.py
  Classes: Wikipedia
  Methods: __init__ search
  Variables: page_content result result: url
  Usages: DisambiguationError Docstore Document ImportError PageError Union base content docstore document langchain metadata page self str typing wikipedia

Python: /langchain/document_loaders/__init__.py
  Variables: PagedPDFSplitter TelegramChatLoader __all__
  Usages: AZLyricsLoader AirbyteJSONLoader AirtableLoader ApifyDatasetLoader ArxivLoader AzureBlobStorageContainerLoader AzureBlobStorageFileLoader BSHTMLLoader BibtexLoader BigQueryLoader BiliBiliLoader BlackboardLoader BlockchainDocumentLoader CSVLoader ChatGPTLoader CoNLLULoader CollegeConfidentialLoader ConfluenceLoader DataFrameLoader DiffbotLoader DirectoryLoader DiscordChatLoader DocugamiLoader Docx2txtLoader DuckDBLoader EmbaasBlobLoader EmbaasLoader EverNoteLoader FacebookChatLoader FaunaLoader FigmaFileLoader GCSDirectoryLoader GCSFileLoader GitHubIssuesLoader GitLoader GitbookLoader GoogleApiClient GoogleApiYoutubeLoader GoogleDriveLoader GutenbergLoader HNLoader HuggingFaceDatasetLoader IFixitLoader IMSDbLoader ImageCaptionLoader IuguLoader JSONLoader JoplinLoader MWDumpLoader MastodonTootsLoader MathpixPDFLoader MaxComputeLoader ModernTreasuryLoader NotebookLoader NotionDBLoader NotionDirectoryLoader ObsidianLoader OneDriveFileLoader OneDriveLoader OnlinePDFLoader OutlookMessageLoader PDFMinerLoader PDFMinerPDFasHTMLLoader PDFPlumberLoader PlaywrightURLLoader PsychicLoader PyMuPDFLoader PyPDFDirectoryLoader PyPDFLoader PyPDFium2Loader PySparkDataFrameLoader PythonLoader ReadTheDocsLoader RedditPostsLoader RoamLoader S3DirectoryLoader S3FileLoader SRTLoader SeleniumURLLoader SitemapLoader SlackDirectoryLoader SnowflakeLoader SpreedlyLoader StripeLoader TelegramChatApiLoader TelegramChatFileLoader TextLoader ToMarkdownLoader TomlLoader TrelloLoader TwitterTweetLoader UnstructuredAPIFileIOLoader UnstructuredAPIFileLoader UnstructuredCSVLoader UnstructuredEPubLoader UnstructuredEmailLoader UnstructuredExcelLoader UnstructuredFileIOLoader UnstructuredFileLoader UnstructuredHTMLLoader UnstructuredImageLoader UnstructuredMarkdownLoader UnstructuredODTLoader UnstructuredPDFLoader UnstructuredPowerPointLoader UnstructuredRTFLoader UnstructuredURLLoader UnstructuredWordDocumentLoader UnstructuredXMLLoader WeatherDataLoader WebBaseLoader WhatsAppChatLoader WikipediaLoader YoutubeLoader airbyte_json airtable apify_dataset arxiv azlyrics azure_blob_storage_container azure_blob_storage_file bibtex bigquery bilibili blackboard blockchain chatgpt college_confidential confluence conllu csv_loader dataframe diffbot directory discord docugami document_loaders duckdb_loader email embaas epub evernote excel facebook_chat fauna figma gcs_directory gcs_file git gitbook github googledrive gutenberg html html_bs hugging_face_dataset ifixit image image_captions imsdb iugu joplin json_loader langchain markdown mastodon max_compute mediawikidump modern_treasury notebook notion notiondb obsidian odt onedrive onedrive_file pdf powerpoint psychic pyspark_dataframe python readthedocs reddit roam rtf s3_directory s3_file sitemap slack_directory snowflake_loader spreedly srt stripe telegram text tomarkdown toml trello twitter unstructured url url_playwright url_selenium weather web_base whatsapp_chat wikipedia word_document xml youtube

Python: /langchain/document_loaders/airbyte_json.py
  Classes: AirbyteJSONLoader
  Methods: __init__ load
  Variables: data metadata self.file_path text
  Usages: BaseLoader Document List base docstore document document_loaders file_path json langchain line loads open page_content self str stringify_dict typing utils

Python: /langchain/document_loaders/airtable.py
  Classes: AirtableLoader
  Methods: __init__ lazy_load load
  Variables: records self.api_token self.base_id self.table_id table
  Usages: BaseLoader Document Iterator List Table all api_token base base_id docstore document document_loaders langchain list metadata page_content pyairtable record self str table_id typing

Python: /langchain/document_loaders/apify_dataset.py
  Classes: ApifyDatasetLoader
  Methods: __init__ load validate_environment
  Variables: apify_client: dataset_id: dataset_items dataset_mapping_function: values["apify_client"]
  Usages: Any ApifyClient BaseLoader BaseModel Callable Dict Document ImportError List apify_client base cls dataset dataset_id dataset_mapping_function docstore document document_loaders items langchain list list_items map pydantic root_validator self str super typing values

Python: /langchain/document_loaders/arxiv.py
  Classes: ArxivLoader
  Methods: __init__ load
  Variables: arxiv_client docs self.load_all_available_meta self.load_max_docs self.query
  Usages: ArxivAPIWrapper BaseLoader Document List Optional arxiv base bool docstore document document_loaders int langchain load_all_available_meta load_max_docs query self str typing utilities

Python: /langchain/document_loaders/azlyrics.py
  Classes: AZLyricsLoader
  Methods: load
  Variables: lyrics metadata soup text title
  Usages: Document List WebBaseLoader docstore document document_loaders find_all langchain page_content scrape self typing web_base web_path

Python: /langchain/document_loaders/azure_blob_storage_container.py
  Classes: AzureBlobStorageContainerLoader
  Methods: __init__ load
  Variables: blob_list container docs loader self.conn_str self.container self.prefix
  Usages: AzureBlobStorageFileLoader BaseLoader ContainerClient Document ImportError List ValueError azure azure_blob_storage_file base blob conn_str container_name docstore document document_loaders exc extend from_connection_string langchain list_blobs name name_starts_with prefix self storage str typing

Python: /langchain/document_loaders/azure_blob_storage_file.py
  Classes: AzureBlobStorageFileLoader
  Methods: __init__ load
  Variables: blob_data client file_path loader self.blob self.conn_str self.container
  Usages: BaseLoader BlobClient Document ImportError List TemporaryDirectory UnstructuredFileLoader ValueError azure base blob blob_name conn_str container container_name dirname docstore document document_loaders download_blob exc exist_ok file from_connection_string langchain makedirs open path readinto self storage str temp_dir tempfile typing unstructured

Python: /langchain/document_loaders/base.py
  Classes: BaseBlobParser BaseLoader
  Methods: lazy_load lazy_parse load load_and_split parse
  Variables: _text_splitter _text_splitter: docs
  Usages: ABC Blob Document Iterator List NotImplementedError Optional RecursiveCharacterTextSplitter TextSplitter __class__ __name__ abc abstractmethod blob blob_loaders document_loaders langchain list schema self split_documents text_splitter typing

Python: /langchain/document_loaders/bibtex.py
  Classes: BibtexLoader
  Methods: __init__ _load_entry lazy_load load
  Variables: content doc entries file_names logger metadata parent_dir self.file_path self.file_regex self.load_extra_metadata self.max_content_chars self.max_docs self.parser texts:
  Usages: Any BaseLoader BibtexparserWrapper Document FileNotFoundError ImportError Iterator List Mapping Optional Path __name__ base bibtex bool compile debug docstore document document_loaders entry extend file_name file_path file_pattern file_regex findall fitz get getLogger get_metadata get_text int join langchain list load_bibtex_entries load_extra load_extra_metadata logging max_content_chars max_docs open page page_content parent parser pathlib self str texts typing utilities

Python: /langchain/document_loaders/bigquery.py
  Classes: BigQueryLoader
  Methods: __init__ load
  Variables: bq_client doc docs: metadata metadata_columns page_content page_content_columns query_result self.credentials self.metadata_columns self.page_content_columns self.project self.query
  Usages: BaseLoader Client Credentials Document ImportError List Optional TYPE_CHECKING ValueError annotations append auth base bigquery cloud column credentials docs docstore document document_loaders google items join langchain name project query result row schema self str typing

Python: /langchain/document_loaders/bilibili.py
  Classes: BiliBiliLoader
  Methods: __init__ _get_bilibili_subs_and_info load
  Variables: aid bvid doc raw_sub_titles raw_transcript raw_transcript_with_meta_info result results self.video_urls sub_list sub_url subtitle transcript, video_info
  Usages: AttributeError BaseLoader Document ImportError List Tuple ValueError Video append base bilibili_api content dict docstore document document_loaders get get_info group int join json langchain loads metadata page_content pop requests search self str sync transcript typing update url video video_urls warn warnings

Python: /langchain/document_loaders/blackboard.py
  Classes: BlackboardLoader
  Methods: __init__ _download_attachments _get_attachments _get_documents _get_folder_path _get_paths _load_documents _parse_filename_from_url check_bs4 download load parse_filename
  Variables: attachment: attachments base_url: content_list content_list: cookies course_menu course_name course_name_clean documents filename filename_matches folder_path folder_path: href link: load_all_recursively: loader relative_paths response self.base_url self.folder_path self.load_all_recursively self.session.auth soup_info url
  Usages: Any BeautifulSoup DirectoryLoader Document ImportError IndexError List Optional Path PyPDFLoader Tag Tuple ValueError WebBaseLoader __name__ _scrape allow_redirects append attachment auth base_url basic_auth bbrouter blackboard_course_url bool bs4 content contextlib dict directory docstore document document_loaders exist_ok extend find find_all get glob group langchain len link load_all_recursively loader_cls mkdir name open parents parse path pathlib pdf print replace scrape search self session soup split startswith str strip suffix super suppress text typing unquote update url_path urllib web_base web_path write

Python: /langchain/document_loaders/blockchain.py
  Classes: BlockchainDocumentLoader BlockchainType
  Methods: __init__ _detect_value_type _get_next_tokenId load
  Variables: ETH_GOERLI ETH_MAINNET POLYGON_MAINNET POLYGON_MUMBAI content current_start_token items metadata response result self.api_key self.blockchainType self.contract_address self.get_all_tokens self.max_execution_time self.startToken start_time tokenId url value_int value_type
  Usages: BaseLoader Document Enum List Optional RuntimeError ValueError api_key append base blockchainType bool contract_address docstore document document_loaders enum environ format get get_all_tokens int isinstance item json langchain len match max_execution_time page_content requests self startToken startswith staticmethod status_code str time typing value

Python: /langchain/document_loaders/chatgpt.py
  Functions: concatenate_rows
  Classes: ChatGPTLoader
  Methods: __init__ load
  Variables: data date documents messages metadata self.log_file self.num_logs sender text title
  Usages: BaseLoader Document List append base datetime dict docstore document document_loaders encoding enumerate fromtimestamp idx int join json key langchain log_file message num_logs open page_content self str strftime typing

Python: /langchain/document_loaders/college_confidential.py
  Classes: CollegeConfidentialLoader
  Methods: load
  Variables: metadata soup text
  Usages: Document List WebBaseLoader docstore document document_loaders langchain page_content scrape select_one self typing web_base web_path

Python: /langchain/document_loaders/confluence.py
  Classes: ConfluenceLoader
  Methods: __init__ _search_content_by_cql is_public_page load paginate_request process_attachment process_doc process_image process_page process_pages process_pdf process_svg process_xls validate_init_args
  Variables: absolute_url attachment_texts attachments batch comment_texts comments confluence_kwargs doc docs docs: drawing errors file_data get_page get_pages ids_by_label image image_text images img_data logger max_pages media_type page page_ids pages params: params["includeArchivedSpaces"] response restrictions self.base_url self.confluence self.max_retry_seconds self.min_retry_seconds self.number_of_retries text texts title url workbook
  Usages: Any BaseLoader BeautifulSoup BytesIO Callable Confluence Dict Document Image ImportError List OSError Optional PIL Union ValueError WARNING __name__ absolute api_key append atlassian attachment base base_url before_sleep before_sleep_log bool bs4 cell_value cloud col comment confluence content convert_from_bytes cql depth dict docstore document document_loaders docx2txt drawToFile enumerate expand extend file_contents fmt get getLogger get_all_pages_by_label get_all_pages_from_space get_all_restrictions_for_content get_attachments_from_content get_page_by_id get_page_comments get_text graphics image_to_string include_archived_content include_archived_spaces include_attachments include_comments include_restricted_content int join keys kwargs label lang langchain len limit link list logging max max_retry_seconds metadata min min_retry_seconds multiplier name ncols nrows number_of_retries oauth2 ocr_languages open open_workbook page_content page_id params password path pdf2image pop process pytesseract range renderPM reportlab request reraise retrieval_method retry row seek self set sheet sheets space space_key start staticmethod status status_code stop stop_after_attempt str strip svg2rlg svglib tenacity token typing update username wait wait_exponential xlrd

Python: /langchain/document_loaders/conllu.py
  Classes: CoNLLULoader
  Methods: __init__ load
  Variables: lines metadata self.file_path text tsv
  Usages: BaseLoader Document List base csv delimiter docstore document document_loaders encoding enumerate file_path langchain len line list open page_content reader self str typing

Python: /langchain/document_loaders/csv_loader.py
  Classes: CSVLoader UnstructuredCSVLoader
  Methods: __init__ _get_elements load
  Variables: content csv_reader doc docs metadata self.csv_args self.encoding self.file_path self.source_column source
  Usages: Any BaseLoader Dict DictReader Document KeyError List Optional UnstructuredFileLoader ValueError append base csv csv_args csvfile docstore document document_loaders encoding enumerate file_path filename items join langchain min_unstructured_version mode newline open page_content partition partition_csv row self source_column str strip super typing unstructured unstructured_kwargs validate_unstructured_version

Python: /langchain/document_loaders/dataframe.py
  Classes: DataFrameLoader
  Methods: __init__ load
  Variables: metadata result self.data_frame self.page_content_column text
  Usages: Any BaseLoader DataFrame Document List ValueError append base data_frame docstore document document_loaders isinstance iterrows langchain page_content page_content_column pandas pop row self str to_dict type typing

Python: /langchain/document_loaders/diffbot.py
  Classes: DiffbotLoader
  Methods: __init__ _diffbot_api_url _get_diffbot_data load
  Variables: data diffbot_url docs: logger metadata params response self.api_token self.continue_on_failure self.urls text
  Usages: Any BaseLoader Document Exception List __name__ api_token append base bool continue_on_failure diffbot_api docs docstore document document_loaders error get getLogger json langchain list logging page_content requests self str timeout typing url urls

Python: /langchain/document_loaders/directory.py
  Functions: _is_visible
  Classes: DirectoryLoader
  Methods: __init__ load load_file
  Variables: FILE_LOADER_TYPE docs: items loader_kwargs logger parts pbar self.glob self.load_hidden self.loader_cls self.loader_kwargs self.max_concurrency self.path self.recursive self.show_progress self.silent_errors self.use_multithreading sub_docs
  Usages: Any BSHTMLLoader BaseLoader Document Exception FileNotFoundError ImportError List Optional Path TextLoader ThreadPoolExecutor Type Union UnstructuredFileLoader ValueError __name__ base bool close concurrent dict docs docstore document document_loaders executor exists extend futures getLogger glob html_bs int is_dir is_file item langchain len list load_hidden loader_cls logging map max_concurrency max_workers path pathlib recursive relative_to rglob self show_progress silent_errors startswith str text total tqdm typing unstructured update use_multithreading warning

Python: /langchain/document_loaders/discord.py
  Classes: DiscordChatLoader
  Methods: __init__ load
  Variables: metadata result self.chat_log self.user_id_col user_id
  Usages: BaseLoader DataFrame Document List TYPE_CHECKING ValueError annotations append base chat_log docstore document document_loaders isinstance iterrows langchain page_content pandas pop row self str to_dict type typing user_id_col

Python: /langchain/document_loaders/docugami.py
  Classes: DocugamiLoader
  Methods: _create_doc _document_details_for_docset_id _get_text _has_structural_descendant _is_heading _is_structural _leaf_structural_nodes _load_chunks_for_document _metadata_for_project _parse_dgml _project_details_for_docset_id _structure_value _xpath_for_chunk _xpath_qname_for_chunk load validate_local_or_remote
  Variables: DEFAULT_API_ENDPOINT DOCUMENT_ID_KEY DOCUMENT_NAME_KEY PROJECTS_KEY STRUCTURE_KEY TABLE_NAME TAG_KEY TD_NAME XPATH_KEY _document_details _project_details access_token: all_artifacts all_documents all_projects ancestor_chain api: artifact_doc artifact_name artifact_root artifact_tree artifact_url chunks: combined_project_metadata data doc_id doc_metadata docset_id: document_id document_ids: doppelgangers entries file_paths: heading idx_of_self leaf_nodes logger metadata metadata: metadata[heading] min_chunk_size: parent path per_file_metadata per_file_metadata[doc_id] prev_small_chunk_text project_id qname response root structure text tree url value
  Usages: Any BaseLoader BaseModel BytesIO Dict Document Exception ImportError List Mapping Optional Path Sequence Union ValueError __name__ access_token api append artifact attrib base bool bytes child chunk chunks cls content doc docset_id docstore document document_ids document_loaders entry environ etree extend file file_paths get getLogger getparent getroot headers index int itertext join json langchain len logging lower lxml min_chunk_size name namespaces node nsmap open page_content parse pathlib prefix project pydantic read request requests root_validator self split startswith status_code str strip sub tag typing update values xpath

Python: /langchain/document_loaders/duckdb_loader.py
  Classes: DuckDBLoader
  Methods: __init__ load
  Variables: description doc docs field_names metadata metadata_columns page_content page_content_columns query_result results self.config self.database self.metadata_columns self.page_content_columns self.query self.read_only
  Usages: BaseLoader Dict Document ImportError List Optional append base bool cast column con config connect database docstore document document_loaders duckdb execute fetchall index join langchain list query read_only result self str typing

Python: /langchain/document_loaders/email.py
  Classes: OutlookMessageLoader UnstructuredEmailLoader
  Methods: __init__ _get_elements load
  Variables: filetype msg self.file_path
  Usages: BaseLoader Document EML FileType ImportError List MSG Message UnstructuredFileLoader ValueError base body date detect_filetype docstore document document_loaders email extract_msg file_path file_utils filename isfile langchain metadata page_content partition partition_email partition_msg path satisfies_min_unstructured_version self sender str subject typing unstructured unstructured_kwargs

Python: /langchain/document_loaders/embaas.py
  Classes: BaseEmbaasLoader EmbaasBlobLoader EmbaasDocumentExtractionParameters EmbaasDocumentExtractionPayload EmbaasLoader
  Methods: _api_response_to_documents _generate_payload _get_documents _handle_request lazy_load lazy_parse load load_and_split validate_blob_loader validate_environment
  Variables: EMBAAS_DOC_API_URL api_url: base64_byte_str blob blob_loader: bytes: chunk_overlap: chunk_size: chunk_splitter: doc docs documents embaas_api_key embaas_api_key: file_extension: file_name: file_path: headers instruction: metadata metadata["embedding"] mime_type: model: params: parsed_response payload payload: payload["mime_type"] response separators: should_chunk: should_embed: values["embaas_api_key"]
  Usages: Any BaseBlobParser BaseLoader BaseModel Blob Dict Document Iterator List NotRequired Optional RequestException TextSplitter TypedDict ValueError always api_url append as_bytes b64encode base base64 blob_loader blob_loaders bool bytes chunk chunk_overlap chunk_size chunk_splitter chunks cls decode docstore document document_loaders exceptions file_extension file_name file_path from_path get get_from_dict_or_env instruction int json langchain list mime_type mimetype model page_content params path post pre pydantic raise_for_status requests root_validator self separators should_chunk should_embed staticmethod str super text text_splitter typing typing_extensions utils validator values warn warnings

Python: /langchain/document_loaders/epub.py
  Classes: UnstructuredEPubLoader
  Methods: _get_elements
  Variables: min_unstructured_version
  Usages: List UnstructuredFileLoader ValueError document_loaders epub file_path filename langchain partition partition_epub satisfies_min_unstructured_version self typing unstructured unstructured_kwargs

Python: /langchain/document_loaders/evernote.py
  Classes: EverNoteLoader
  Methods: __init__ _parse_content _parse_note _parse_note_xml _parse_resource add_prefix load
  Variables: additional_attributes context documents note_dict: note_dict["content-raw"] note_dict["resource"] note_dict[elem.tag] resources rsc_dict: rsc_dict["hash"] rsc_dict[elem.tag] self.file_path self.load_single_document
  Usages: Any BaseLoader Dict Document ImportError Iterator List Optional action append b64decode base base64 bool content dict docstore document document_loaders elem element_tag encoding error etree file_path get hashlib hexdigest html2text huge_tree items iterparse join key langchain len list load_single_document logging lxml md5 metadata note note_dict page_content prefix recover resource rsc_dict self staticmethod str strip strip_cdata strptime tag text time typing update value xml_file

Python: /langchain/document_loaders/excel.py
  Classes: UnstructuredExcelLoader
  Methods: __init__ _get_elements
  Usages: Any List UnstructuredFileLoader document_loaders file_path filename langchain min_unstructured_version mode partition partition_xlsx self str super typing unstructured unstructured_kwargs validate_unstructured_version xlsx

Python: /langchain/document_loaders/facebook_chat.py
  Functions: concatenate_rows
  Classes: FacebookChatLoader
  Methods: __init__ load
  Variables: date metadata self.file_path sender text
  Usages: BaseLoader Document List Path base datetime dict docstore document document_loaders encoding file_path fromtimestamp get isinstance join json langchain message open page_content path pathlib row self str strftime typing

Python: /langchain/document_loaders/fauna.py
  Classes: FaunaLoader
  Methods: __init__ lazy_load load
  Variables: client document: document_dict page: page_content response: self.metadata_fields self.page_content_field self.query self.secret
  Usages: BaseLoader Client Document ImportError Iterator List Optional Page QuerySuccess Sequence after base data dict docstore document document_loaders encoding fauna fql items key langchain list metadata metadata_fields page page_content_field query response result secret self str typing value

Python: /langchain/document_loaders/figma.py
  Classes: FigmaFileLoader
  Methods: __init__ _construct_figma_api_url _get_figma_file load
  Variables: api_url data headers json_data metadata request self.access_token self.ids self.key text
  Usages: Any BaseLoader Document List Request access_token base decode docstore document document_loaders ids json key langchain loads page_content read response self str stringify_dict typing urllib urlopen utils

Python: /langchain/document_loaders/gcs_directory.py
  Classes: GCSDirectoryLoader
  Methods: __init__ load
  Variables: client docs loader self.bucket self.prefix self.project_name
  Usages: BaseLoader Client Document GCSFileLoader ImportError List ValueError base blob bucket cloud docstore document document_loaders endswith extend gcs_file google langchain list_blobs name prefix project project_name self storage str typing

Python: /langchain/document_loaders/gcs_file.py
  Classes: GCSFileLoader
  Methods: __init__ load
  Variables: blob bucket file_path loader self.blob self.bucket self.project_name storage_client
  Usages: BaseLoader Client Document ImportError List TemporaryDirectory UnstructuredFileLoader ValueError base cloud dirname docstore document document_loaders download_to_filename exist_ok get_bucket google langchain makedirs path project_name self storage str temp_dir tempfile typing unstructured

Python: /langchain/document_loaders/generic.py
  Classes: GenericLoader
  Methods: __init__ from_filesystem lazy_load load load_and_split
  Variables: DEFAULT _PathLike blob_loader blob_parser self.blob_loader self.blob_parser
  Usages: BaseBlobParser BaseLoader BlobLoader Document FileSystemBlobLoader Iterator List Literal NotImplementedError Optional Path Sequence TextSplitter Union annotations base blob blob_loaders bool classmethod cls document_loaders get_parser glob isinstance langchain lazy_parse list parser parsers path pathlib registry schema self show_progress str suffixes text_splitter typing yield_blobs

Python: /langchain/document_loaders/git.py
  Classes: GitLoader
  Methods: __init__ load
  Variables: content doc docs: file_path file_type ignored_files metadata rel_file_path repo self.branch self.clone_url self.file_filter self.repo_path text_content
  Usages: BaseLoader Blob Callable Document Exception ImportError List Optional Repo UnicodeDecodeError ValueError append base bool branch checkout clone_from clone_url decode docs docstore document document_loaders exists file_filter git ignored isinstance item join langchain len name open page_content path print read relpath repo_path self splitext str traverse tree typing

Python: /langchain/document_loaders/gitbook.py
  Classes: GitbookLoader
  Methods: __init__ _get_document _get_paths load
  Variables: content documents metadata page_content_raw relative_paths self.base_url self.content_selector self.load_all_paths soup_info title title_if_exists url web_paths
  Usages: Any Document List Optional WebBaseLoader _scrape append base_url bool content_selector custom_url docstore document document_loaders endswith find find_all get_text langchain load_all_paths loc page_content parse path print scrape self separator soup str strip super text typing urljoin urllib urlparse web_base web_page web_path

Python: /langchain/document_loaders/github.py
  Classes: BaseGitHubLoader GitHubIssuesLoader
  Methods: headers lazy_load load parse_issue query_params url validate_environment validate_since
  Variables: access_token: assignee: content creator: direction: doc include_prs: issues labels labels: mentioned: metadata milestone: query_params query_params_dict query_params_list repo: response since: sort: state: url url: values["access_token"]
  Usages: ABC BaseLoader BaseModel Dict Document Iterator List Literal Optional Union ValueError abc access_token assignee base bool cls creator datetime dict direction docstore document document_loaders get get_from_dict_or_env include_prs int issue items join json label langchain links list mentioned milestone page_content pre property pydantic raise_for_status repo requests root_validator self since sort state str strptime typing utils validator values

Python: /langchain/document_loaders/googledrive.py
  Classes: GoogleDriveLoader
  Methods: _fetch_files_recursive _load_credentials _load_document_from_id _load_documents_from_folder _load_documents_from_ids _load_file_from_id _load_file_from_ids _load_sheet_from_id full_form load validate_credentials_path validate_inputs
  Variables: SCOPES _files allowed_types content credentials_path: creds docs document_ids: documents done downloader file file_ids: file_types file_types: files flow folder_id: full_names header load_trashed_files: metadata page_content pdf_reader recursive: request result results returns service service_account_key: sheet_name sheets sheets_service short_names spreadsheet status, text title token_path: type_mapping values values["file_types"]
  Usages: Any BaseLoader BaseModel BytesIO Credentials Dict Document HttpError ImportError InstalledAppFlow List MediaIoBaseDownload Optional Path PdfReader PyPDF2 Request Sequence Union ValueError append auth base bool build cls credentials credentials_path decode discovery doc_id docstore document document_ids document_loaders enumerate errors execute exists expired export_media extend extract_text fields fileId file_id file_ids file_type folder_id format from_authorized_user_file from_client_secrets_file from_service_account_file get get_media getvalue google google_auth_oauthlib googleapiclient home http includeItemsFromAllDrives join keys kwargs langchain len list load_trashed_files mimeType next_chunk oauth2 open page pageSize pages pathlib port print pydantic range recursive refresh refresh_token requests resp root_validator row run_local_server scopes self service_account service_account_key sheet spreadsheetId spreadsheets start status str strip supportsAllDrives to_json token token_path transport typing valid validator write

Python: /langchain/document_loaders/gutenberg.py
  Classes: GutenbergLoader
  Methods: __init__ load
  Variables: elements metadata self.file_path text
  Usages: BaseLoader Document List ValueError base decode docstore document document_loaders endswith file_path join langchain page_content request self startswith str typing urllib urlopen

Python: /langchain/document_loaders/helpers.py
  Functions: detect_file_encodings
  Classes: FileEncoding
  Methods: read_and_detect
  Variables: confidence: encoding: encodings future language: rawdata
  Usages: List NamedTuple Optional RuntimeError ThreadPoolExecutor TimeoutError all cast chardet concurrent confidence detect_all dict enc encoding executor file_path float futures int language open read result str submit timeout typing

Python: /langchain/document_loaders/hn.py
  Classes: HNLoader
  Methods: load load_comments load_results
  Variables: comments documents items link metadata ranking soup_info title
  Usages: Any Document List WebBaseLoader append comment docstore document document_loaders find get langchain lineItem page_content scrape select select_one self soup strip text typing web_base web_path

Python: /langchain/document_loaders/html.py
  Classes: UnstructuredHTMLLoader
  Methods: _get_elements
  Usages: List UnstructuredFileLoader document_loaders file_path filename html langchain partition partition_html self typing unstructured unstructured_kwargs

Python: /langchain/document_loaders/html_bs.py
  Classes: BSHTMLLoader
  Methods: __init__ load
  Variables: bs_kwargs logger metadata: self.bs_kwargs self.file_path self.get_text_separator self.open_encoding soup text title
  Usages: BaseLoader BeautifulSoup Dict Document ImportError List Union ValueError __name__ base bs4 dict docstore document document_loaders encoding file_path getLogger get_text get_text_separator langchain logging metadata open open_encoding page_content self str string typing

Python: /langchain/document_loaders/hugging_face_dataset.py
  Classes: HuggingFaceDatasetLoader
  Methods: __init__ lazy_load load
  Variables: dataset self.cache_dir self.data_dir self.data_files self.keep_in_memory self.name self.num_proc self.page_content_column self.path self.save_infos self.use_auth_token
  Usages: BaseLoader Document ImportError Iterator List Mapping Optional Sequence Union base bool cache_dir data_dir data_files datasets docstore document document_loaders int keep_in_memory key keys langchain list load_dataset metadata name num_proc page_content page_content_column path pop row save_infos self str typing use_auth_token

Python: /langchain/document_loaders/ifixit.py
  Classes: IFixitLoader
  Methods: __init__ load load_device load_guide load_questions_and_answers load_suggestions
  Variables: IFIXIT_BASE_URL allowed_paths answersHeader data doc_parts documents guide_urls loader metadata output path pieces res results self.id self.page_type self.web_path soup text title url
  Usages: BaseLoader Document List Optional ValueError WebBaseLoader allowed_path answer any append base bool doc_type docstore document document_loaders find format get guide guide_url has_attr include_guides join json key langchain len line page_content page_type part query replace requests result row scrape select select_one self split startswith staticmethod status_code str strip tool typing url_override web_base web_path

Python: /langchain/document_loaders/image.py
  Classes: UnstructuredImageLoader
  Methods: _get_elements
  Usages: List UnstructuredFileLoader document_loaders file_path filename image langchain partition partition_image self typing unstructured unstructured_kwargs

Python: /langchain/document_loaders/image_captions.py
  Classes: ImageCaptionLoader
  Methods: __init__ _get_captions_and_metadata load
  Variables: caption, caption: doc image inputs metadata: model output processor results self.blip_model self.blip_processor self.image_paths
  Usages: Any BaseLoader BlipForConditionalGeneration BlipProcessor Document Exception Image ImportError List PIL Tuple Union ValueError append base blip_model blip_processor caption convert decode dict docstore document document_loaders from_pretrained generate get image_paths isinstance langchain metadata open page_content path_image path_images raw requests return_tensors self startswith str stream transformers typing

Python: /langchain/document_loaders/imsdb.py
  Classes: IMSDbLoader
  Methods: load
  Variables: metadata soup text
  Usages: Document List WebBaseLoader docstore document document_loaders langchain page_content scrape select_one self typing web_base web_path

Python: /langchain/document_loaders/iugu.py
  Classes: IuguLoader
  Methods: __init__ _get_resource _make_request load
  Variables: IUGU_ENDPOINTS api_token endpoint json_data metadata request self.headers self.resource text
  Usages: BaseLoader Document List Optional Request base decode docstore document document_loaders get get_from_env headers json langchain loads page_content read resource response self str stringify_dict typing url urllib urlopen utils

Python: /langchain/document_loaders/joplin.py
  Classes: JoplinLoader
  Methods: __init__ _convert_date _get_folder _get_notes _get_tags lazy_load load
  Variables: LINK_NOTE_TEMPLATE access_token base_url has_more json_data metadata page req_folder req_note req_tag self._get_folder_url self._get_note_url self._get_tag_url
  Usages: BaseLoader Document Iterator List Optional Request _get_folder_url _get_note_url _get_tag_url base date datetime decode document_loaders folder_id format fromtimestamp get_from_env host int json langchain list loads note note_id page_content port read request response schema self str strftime tag typing urllib urlopen utils

Python: /langchain/document_loaders/json_loader.py
  Classes: JSONLoader
  Methods: __init__ _get_text _validate_content_key load
  Variables: content data docs metadata sample sample_metadata self._content_key self._jq_schema self._metadata_func self._text_content self.file_path text
  Usages: Any BaseLoader Callable Dict Document ImportError List Optional Path Union ValueError _content_key _jq_schema _metadata_func _text_content append base bool compile content_key dict docstore document document_loaders dumps enumerate file_path first get input isinstance jq_schema json langchain loads metadata_func page_content pathlib read_text resolve self seq_num source str text_content type typing

Python: /langchain/document_loaders/markdown.py
  Classes: UnstructuredMarkdownLoader
  Methods: _get_elements
  Variables: _unstructured_version unstructured_version
  Usages: List UnstructuredFileLoader ValueError __unstructured_version__ __version__ document_loaders file_path filename int langchain partition partition_md self split tuple typing unstructured unstructured_kwargs

Python: /langchain/document_loaders/mastodon.py
  Functions: _dependable_mastodon_import
  Classes: MastodonTootsLoader
  Methods: __init__ _format_toots load
  Variables: access_token docs mastodon metadata results: self.api self.exclude_replies self.mastodon_accounts self.number_toots toots user
  Usages: Any BaseLoader Dict Document ImportError Iterable List Mastodon Optional Sequence TYPE_CHECKING ValueError account account_lookup account_statuses annotations api api_base_url base bool dict docstore document document_loaders environ exclude_reblogs exclude_replies extend get int langchain limit mastodon_accounts number_toots only_media page_content pinned results self str toot typing user_info

Python: /langchain/document_loaders/max_compute.py
  Classes: MaxComputeLoader
  Methods: __init__ from_params lazy_load load
  Variables: api_wrapper metadata page_content page_content_data self.api_wrapper self.metadata_columns self.page_content_columns self.query
  Usages: Any BaseLoader Document Iterator List MaxComputeAPIWrapper Optional Sequence access_id annotations base classmethod cls docstore document document_loaders endpoint items join kwargs langchain list max_compute metadata_columns page_content_columns project query row secret_access_key self str typing utilities

Python: /langchain/document_loaders/mediawikidump.py
  Classes: MWDumpLoader
  Methods: __init__ load
  Variables: code docs dump metadata self.encoding self.file_path text
  Usages: BaseLoader Document Dump List Optional append base collapse docstore document document_loaders encoding file_path from_file keep_template_params langchain mwparserfromhell mwxml normalize open page page_content pages parse revision self str strip_code title typing

Python: /langchain/document_loaders/modern_treasury.py
  Classes: ModernTreasuryLoader
  Methods: __init__ _get_resource _make_request load
  Variables: MODERN_TREASURY_ENDPOINTS api_key basic_auth_token credentials endpoint json_data metadata organization_id request self.headers self.resource text
  Usages: BaseLoader Document List Optional Request b64encode base base64 decode docstore document document_loaders encode get get_from_env headers json langchain loads page_content read resource response self str stringify_value typing url urllib urlopen utils

Python: /langchain/document_loaders/notebook.py
  Functions: concatenate_cells remove_newlines
  Classes: NotebookLoader
  Methods: __init__ load
  Variables: cell_type data error_name error_value filtered_data metadata min_output output self.file_path self.include_outputs self.max_output_length self.remove_newline self.traceback source text traceback
  Usages: Any BaseLoader DataFrame Document ImportError List Path apply applymap axis base bool cat cell dict docstore document document_loaders elem encoding file_path include_outputs int isinstance json json_normalize keys langchain len list max_output_length min open page_content pandas path pathlib remove_newline replace self sep str typing

Python: /langchain/document_loaders/notion.py
  Classes: NotionDirectoryLoader
  Methods: __init__ load
  Variables: docs metadata self.file_path text
  Usages: BaseLoader Document List Path append base docstore document document_loaders file_path glob langchain list open page_content path pathlib read self str typing

Python: /langchain/document_loaders/notiondb.py
  Classes: NotionDBLoader
  Methods: __init__ _load_blocks _request _retrieve_page_ids load load_page
  Variables: BLOCK_URL DATABASE_URL NOTION_BASE_URL PAGE_URL children_text cur_block_id cur_block_id: cur_result_text_arr: data metadata: metadata["id"] metadata[prop_name.lower()] page_ids pages: prop_type query_dict["start_cursor"] res result_lines_arr: result_obj self.database_id self.headers self.request_timeout_sec self.token value
  Usages: Any BaseLoader Dict Document List Optional ValueError append base block_id cur_result_text_arr database_id docstore document document_loaders extend format get headers int integration_token item items join json langchain list lower metadata method num_tabs page page_content page_id pages prop_data prop_name query_dict raise_for_status request request_timeout_sec requests result result_lines_arr rich_text self str timeout token typing url

Python: /langchain/document_loaders/obsidian.py
  Classes: ObsidianLoader
  Methods: __init__ _parse_front_matter _remove_front_matter load
  Variables: FRONT_MATTER_REGEX docs front_matter front_matter[key.strip()] key, lines match metadata self.collect_metadata self.encoding self.file_path text
  Usages: BaseLoader DOTALL Document List MULTILINE Path append base bool collect_metadata compile content dict docstore document document_loaders encoding file_path glob group key langchain line list name open page_content path pathlib read search self split st_atime st_ctime st_mtime stat str strip sub typing value

Python: /langchain/document_loaders/odt.py
  Classes: UnstructuredODTLoader
  Methods: __init__ _get_elements
  Usages: Any List UnstructuredFileLoader document_loaders file_path filename langchain min_unstructured_version mode odt partition partition_odt self str super typing unstructured unstructured_kwargs validate_unstructured_version

Python: /langchain/document_loaders/onedrive.py
  Classes: Config OneDriveLoader _FileType _OneDriveSettings _OneDriveTokenStorage _SupportedFileTypes
  Methods: _auth _get_folder_from_path _load_from_folder _load_from_object_ids fetch_mime_types load
  Variables: DOC DOCX PDF SCOPES account auth_with_token: case_sentive client_id: client_secret: docs docs: drive drive_id: env_file env_prefix file file_mime_types file_path file_types file_types: folder folder_path: items loader logger mime_types_mapping mime_types_mapping[ mime_types_mapping[file_type.value] object_ids: settings: storage subfolder_drive subfolders token_backend token_path token_path: token_storage
  Usages: Account AttributeError BaseLoader BaseModel BaseSettings Dict Document Drive Enum Field FileNotFoundError FilePath FileSystemTokenBackend Folder ImportError IndexError List O365 OneDriveFileLoader Optional Path SecretStr TYPE_CHECKING TemporaryDirectory Type Union ValueError __name__ annotations auth_with_token authenticate base bool client_id client_secret credentials default_factory dirname docstore document document_loaders drive_id enum env exist_ok extend file_type filter folder_path format getLogger get_drive get_item get_items get_secret_value home is_file langchain len list logging makedirs mime_type name object_id object_ids onedrive_file parent path pathlib pydantic scopes self settings split str subfolder temp_dir tempfile token_filename typing value values warning

Python: /langchain/document_loaders/onedrive_file.py
  Classes: Config OneDriveFileLoader
  Methods: load
  Variables: CHUNK_SIZE arbitrary_types_allowed file: file_path loader
  Usages: BaseLoader BaseModel Document Field File List O365 TYPE_CHECKING TemporaryDirectory UnstructuredFileLoader annotations base chunk_size docstore document document_loaders download drive file langchain name pydantic self temp_dir tempfile to_path typing unstructured

Python: /langchain/document_loaders/pdf.py
  Classes: BasePDFLoader MathpixPDFLoader OnlinePDFLoader PDFMinerLoader PDFMinerPDFasHTMLLoader PDFPlumberLoader PyMuPDFLoader PyPDFDirectoryLoader PyPDFLoader PyPDFium2Loader UnstructuredPDFLoader
  Methods: __del__ __init__ _get_elements _is_valid_url _is_visible clean_pdf data get_processed_pdf headers lazy_load load send_pdf source url wait_for_processing
  Variables: blob contents doc.metadata["source"] docs files items loader logger metadata options output_string parsed parser pdf_id response response_data self.file_path self.glob self.load_hidden self.mathpix_api_id self.mathpix_api_key self.max_wait_time_seconds self.parser self.path self.processed_file_format self.recursive self.should_clean_pdf self.silent_errors self.temp_file self.text_kwargs self.web_path status sub_docs url
  Usages: ABC Any BaseLoader Blob Document Exception ImportError Iterator LAParams List Mapping NamedTemporaryFile Optional PDFMinerParser PDFPlumberParser Path PyMuPDFParser PyPDFParser PyPDFium2Parser StringIO TimeoutError UnstructuredFileLoader ValueError __file__ abc any base blob_loaders bool close codec content decode dict doc docstore document document_loaders dumps expanduser extend extract_text extract_text_to_fp file_path filename fitz from_path get getLogger get_from_dict_or_env getvalue glob hasattr high_level int is_file isfile join json kwargs langchain laparams layout line list load_hidden logging mathpix_api_id mathpix_api_key max_wait_time_seconds name netloc open open_filename output_type page_content parse parsers part partition partition_pdf parts path pathlib pdf pdfminer pdfplumber post print processed_file_format property pypdf range recursive relative_to replace requests rglob scheme self should_clean_pdf silent_errors sleep split startswith staticmethod status_code str super temp_file tempfile text_kwargs time typing unstructured unstructured_kwargs urllib urlparse utils warning web_path write

Python: /langchain/document_loaders/powerpoint.py
  Classes: UnstructuredPowerPointLoader
  Methods: _get_elements
  Variables: is_ppt unstructured_version
  Usages: FileType ImportError List PPT UnstructuredFileLoader ValueError __unstructured_version__ __version__ detect_filetype document_loaders extension file_path file_utils filename filetype int langchain magic partition partition_ppt partition_pptx path ppt pptx self split splitext str tuple typing unstructured unstructured_kwargs

Python: /langchain/document_loaders/psychic.py
  Classes: PsychicLoader
  Methods: __init__ load
  Variables: psychic_docs self.connection_id self.connector_id self.psychic
  Usages: BaseLoader ConnectorId Document ImportError List Psychic api_key base connection_id connector_id doc docstore document document_loaders get_documents langchain metadata page_content psychic psychicapi secret_key self str typing

Python: /langchain/document_loaders/pyspark_dataframe.py
  Classes: PySparkDataFrameLoader
  Methods: __init__ get_num_rows lazy_load load
  Variables: available_memory estimated_row_size lazy_load_iterator logger max_num_rows mem_info metadata row self.column_names self.df self.fraction_of_memory self.num_rows, self.page_content_column self.rdd_df self.spark text
  Usages: Any BaseLoader DataFrame Document ImportError Iterator List Optional SparkSession TYPE_CHECKING Tuple ValueError __file__ available base builder collect column_names columns count docstore document document_loaders float fraction_of_memory getLogger getOrCreate getsizeof int isinstance islice itertools langchain len limit list logging map min num_rows page_content page_content_column pop psutil pyspark range rdd rdd_df self spark spark_session sql str sys toLocalIterator type typing virtual_memory warning

Python: /langchain/document_loaders/python.py
  Classes: PythonLoader
  Methods: __init__
  Variables: encoding,
  Usages: TextLoader detect_encoding document_loaders encoding file_path langchain open readline self str super text tokenize

Python: /langchain/document_loaders/readthedocs.py
  Classes: ReadTheDocsLoader
  Methods: __init__ _clean_data load
  Variables: docs html_tags metadata self.bs_kwargs self.custom_html_tag self.encoding self.errors self.file_path soup text
  Usages: Any BaseLoader BeautifulSoup Document Exception ImportError List Optional Path Tuple Union ValueError append attrs base bs4 bs_kwargs custom_html_tag data dict docstore document document_loaders encoding errors file_path find get_text is_dir join kwargs langchain open page_content path pathlib read rglob self split str tag typing

Python: /langchain/document_loaders/reddit.py
  Functions: _dependable_praw_import
  Classes: RedditPostsLoader
  Methods: __init__ _subreddit_posts_loader _user_posts_loader load
  Variables: cat_posts docs metadata method praw reddit results: self.categories self.client_id self.client_secret self.mode self.number_posts self.search_queries self.user_agent subreddit user
  Usages: BaseLoader Document ImportError Iterable List Optional Reddit Sequence TYPE_CHECKING ValueError annotations author base categories category client_id client_secret docstore document document_loaders extend getattr int langchain limit mode number_posts page_content post redditor results score search_queries search_query self selftext str submissions subreddit_name_prefixed title typing url user_agent

Python: /langchain/document_loaders/roam.py
  Classes: RoamLoader
  Methods: __init__ load
  Variables: docs metadata self.file_path text
  Usages: BaseLoader Document List Path append base docstore document document_loaders file_path glob langchain list open page_content path pathlib read self str typing

Python: /langchain/document_loaders/rtf.py
  Classes: UnstructuredRTFLoader
  Methods: __init__ _get_elements
  Variables: min_unstructured_version
  Usages: Any List UnstructuredFileLoader ValueError document_loaders file_path filename langchain mode partition partition_rtf rtf satisfies_min_unstructured_version self str super typing unstructured unstructured_kwargs

Python: /langchain/document_loaders/s3_directory.py
  Classes: S3DirectoryLoader
  Methods: __init__ load
  Variables: bucket docs loader self.bucket self.prefix
  Usages: BaseLoader Bucket Document ImportError List Prefix S3FileLoader base boto3 docstore document document_loaders extend filter key langchain obj objects prefix resource s3_file self str typing

Python: /langchain/document_loaders/s3_file.py
  Classes: S3FileLoader
  Methods: __init__ load
  Variables: file_path loader self.bucket self.key
  Usages: BaseLoader Document ImportError List TemporaryDirectory UnstructuredFileLoader base boto3 bucket client dirname docstore document document_loaders download_file exist_ok key langchain makedirs path self str temp_dir tempfile typing unstructured

Python: /langchain/document_loaders/sitemap.py
  Functions: _batch_block _default_meta_function _default_parsing_function
  Classes: SitemapLoader
  Methods: __init__ load parse_sitemap
  Variables: blockcount elblocks els loc loc_text results self.blocknum self.blocksize self.filter_urls self.is_local self.meta_function self.parsing_function soup soup_child
  Usages: Any BeautifulSoup Callable Document Generator ImportError Iterable List Optional ValueError WebBaseLoader _content any append blocknum blocksize bool bs4 content dict document_loaders extend filter_urls find find_all get_text int is_local islice item iter iterable itertools langchain len list lxml match meta meta_function metadata open page_content parsing_function prop range schema scrape scrape_all self sitemap size str strip super tag text typing url web_base web_path

Python: /langchain/document_loaders/slack_directory.py
  Classes: SlackDirectoryLoader
  Methods: __init__ _convert_message_to_document _get_channel_id_map _get_message_metadata _get_message_source _read_json load
  Variables: channel_id channel_name channels data docs document messages metadata self.channel_id_map self.workspace_url self.zip_path source text timestamp user
  Usages: BaseLoader Dict Document KeyError List Optional Path ZipFile append base channel channel_id_map channel_path dict docstore document_loaders endswith file_path get json langchain message name namelist open page_content parent pathlib replace self staticmethod str typing workspace_url zip_file zip_path zipfile

Python: /langchain/document_loaders/snowflake_loader.py
  Classes: SnowflakeLoader
  Methods: __init__ _execute_query _get_columns lazy_load load
  Variables: column_names conn cur doc metadata metadata_columns page_content page_content_columns page_content_columns, query_result self.account self.database self.metadata_columns self.page_content_columns self.parameters self.password self.query self.role self.schema self.user self.warehouse
  Usages: Any BaseLoader Dict Document Exception ImportError Iterator List Optional Tuple ValueError account annotations base close column connect connector cursor database description dict docstore document document_loaders execute fetchall isinstance items join keys langchain list parameters password print query role row schema self snowflake str typing user warehouse zip

Python: /langchain/document_loaders/spreedly.py
  Classes: SpreedlyLoader
  Methods: __init__ _get_resource _make_request load
  Variables: SPREEDLY_ENDPOINTS endpoint json_data metadata request self.access_token self.headers self.resource text
  Usages: BaseLoader Document List Request access_token base decode docstore document document_loaders get headers json langchain loads page_content read resource response self str stringify_dict typing url urllib urlopen utils

Python: /langchain/document_loaders/srt.py
  Classes: SRTLoader
  Methods: __init__ load
  Variables: metadata parsed_info self.file_path text
  Usages: BaseLoader Document ImportError List base docstore document document_loaders file_path join langchain open page_content pysrt self str typing

Python: /langchain/document_loaders/stripe.py
  Classes: StripeLoader
  Methods: __init__ _get_resource _make_request load
  Variables: STRIPE_ENDPOINTS access_token endpoint json_data metadata request self.headers self.resource text
  Usages: BaseLoader Document List Optional Request base decode docstore document document_loaders get get_from_env headers json langchain loads page_content read resource response self str stringify_dict typing url urllib urlopen utils

Python: /langchain/document_loaders/telegram.py
  Functions: concatenate_rows text_to_docs
  Classes: TelegramChatApiLoader TelegramChatFileLoader
  Methods: __init__ _combine_message_texts _get_message_threads fetch_data_from_telegram find_replies load
  Variables: all_replies chunks combined_text combined_texts data date direct_replies doc doc.metadata["page"] doc.metadata["source"] doc_chunks is_reply message_texts message_threads metadata normalized_messages page_docs parent_messages reply_messages reply_messages["reply_to_id"] reply_to_id self.api_hash self.api_id self.chat_entity self.file_path self.username sender text text_splitter
  Usages: BaseLoader DataFrame Dict Document EntityLike ImportError List Optional Path RecursiveCharacterTextSplitter TYPE_CHECKING TelegramClient Union annotations api_hash api_id append apply astype asyncio base chat_entity chunk chunk_overlap chunk_size client dict docstore document document_loaders dropna dump elem encoding ensure_ascii enumerate file_path hints indent int isin isinstance isoformat items iter_messages join json json_normalize langchain message message_ids nest_asyncio open page page_content pandas parent_id path pathlib reply_data reply_id reply_to reply_to_msg_id row run self sender_id separators sort_values split_text str strip subset sync telethon tolist typing username

Python: /langchain/document_loaders/text.py
  Classes: TextLoader
  Methods: __init__ load
  Variables: detected_encodings logger metadata self.autodetect_encoding self.encoding self.file_path text
  Usages: BaseLoader Document Exception List Optional RuntimeError UnicodeDecodeError __name__ autodetect_encoding base bool debug detect_file_encodings docstore document document_loaders encoding file_path getLogger helpers langchain logging open page_content read self str typing

Python: /langchain/document_loaders/tomarkdown.py
  Classes: ToMarkdownLoader
  Methods: __init__ lazy_load load
  Variables: metadata response self.api_key self.url text
  Usages: BaseLoader Document Iterator List annotations api_key base docstore document document_loaders headers json langchain list page_content post requests self str typing url

Python: /langchain/document_loaders/toml.py
  Classes: TomlLoader
  Methods: __init__ lazy_load load
  Variables: content data doc files self.source
  Usages: BaseLoader Document Iterator List Path TOMLDecodeError Union ValueError base docstore document document_loaders dumps encoding file file_path glob is_dir is_file json langchain list loads metadata open page_content pathlib print read self source str suffix tomli typing

Python: /langchain/document_loaders/trello.py
  Classes: TrelloLoader
  Methods: __init__ _card_to_doc _get_board from_credentials load
  Variables: api_key board cards client comments items list_dict metadata metadata["closed"] metadata["due_date"] metadata["labels"] metadata["list"] self.board_name self.card_filter self.client self.extra_metadata self.include_card_name self.include_checklist self.include_comments text_content token
  Usages: Any BaseLoader BeautifulSoup Board Card Document ImportError List Literal Optional TYPE_CHECKING TrelloClient Tuple ValueError annotations base board_name bool bs4 card card_filter checklist checklists classmethod closed cls comment description dict docstore document document_loaders due_date extra_metadata get_cards get_from_env get_text include_card_name include_checklist include_comments item join kwargs label labels langchain list_boards list_id list_item list_lists name next page_content self str strip trello typing url utils

Python: /langchain/document_loaders/twitter.py
  Functions: _dependable_tweepy_import
  Classes: TwitterTweetLoader
  Methods: __init__ _format_tweets from_bearer_token from_secrets load
  Variables: api auth docs metadata results: self.auth self.number_tweets self.twitter_users tweepy tweets user
  Usages: API Any BaseLoader Dict Document ImportError Iterable JSONParser List OAuth2BearerHandler OAuthHandler Optional Sequence TYPE_CHECKING Union access_token access_token_secret annotations auth_handler base classmethod cls consumer_key consumer_secret count dict docstore document document_loaders extend get_user int langchain number_tweets oauth2_bearer_token page_content parser parsers results screen_name self str tweet twitter_users typing user_info user_timeline username

Python: /langchain/document_loaders/unstructured.py
  Functions: get_elements_from_api satisfies_min_unstructured_version validate_unstructured_version
  Classes: UnstructuredAPIFileIOLoader UnstructuredAPIFileLoader UnstructuredBaseLoader UnstructuredFileIOLoader UnstructuredFileLoader
  Methods: __init__ _get_elements _get_metadata load
  Variables: _doc_elements _unstructured_version _valid_modes docs docs: elements metadata metadata["category"] min_version_tuple self.api_key self.file self.file_path self.mode self.unstructured_kwargs self.url text unstructured_version_tuple
  Usages: ABC Any BaseLoader Document IO ImportError List Sequence Union ValueError __unstructured_version__ __version__ _elements abc abstractmethod api api_key api_url append auto base bool category collections dict docstore document document_loaders element extend file file_path filename filenames files hasattr int isinstance join langchain list min_unstructured_version min_version mode page_content partition partition_multiple_via_api partition_via_api pop self split str super to_dict tuple typing unstructured unstructured_kwargs update url

Python: /langchain/document_loaders/url.py
  Classes: UnstructuredURLLoader
  Methods: __init__ __is_headers_available_for_html __is_headers_available_for_non_html __is_non_html_available _validate_mode load
  Variables: _unstructured_version _valid_modes docs: elements headers logger metadata metadata["category"] self.__version self.continue_on_failure self.headers self.mode self.unstructured_kwargs self.urls text unstructured_version warn_about_headers
  Usages: Any BaseLoader Document Exception ImportError List ValueError __name__ __unstructured_version__ __version __version__ append auto base bool category continue_on_failure docs docstore document document_loaders element error getLogger html int join keys langchain len list logging mode page_content partition partition_html pop self split str to_dict tuple typing unstructured unstructured_kwargs url urls warning

Python: /langchain/document_loaders/url_playwright.py
  Classes: PlaywrightURLLoader
  Methods: __init__ load
  Variables: browser docs: elements logger metadata page page_source self.continue_on_failure self.headless self.remove_selectors self.urls text
  Usages: BaseLoader Document Exception ImportError List Optional ValueError __name__ all append base bool chromium close content continue_on_failure docs docstore document document_loaders element error evaluate getLogger goto headless html is_visible join langchain launch list locator logging new_page page_content partition partition_html playwright remove_selectors selector self str sync_api sync_playwright typing unstructured url urls

Python: /langchain/document_loaders/url_selenium.py
  Classes: SeleniumURLLoader
  Methods: __init__ _get_driver load
  Variables: chrome_options chrome_options.binary_location docs: driver elements firefox_options firefox_options.binary_location logger metadata page_content self.arguments self.binary_location self.browser self.continue_on_failure self.executable_path self.headless self.urls text
  Usages: BaseLoader Chrome ChromeOptions Document Exception Firefox FirefoxOptions ImportError List Literal Optional Options TYPE_CHECKING Union ValueError __name__ add_argument append arg arguments base binary_location bool browser chrome continue_on_failure docs docstore document document_loaders error executable_path firefox get getLogger headless html join langchain list logging lower options page_source partition partition_html quit selenium self str typing unstructured url urls webdriver

Python: /langchain/document_loaders/weather.py
  Classes: WeatherDataLoader
  Methods: __init__ from_params lazy_load load
  Variables: client content metadata self.client self.places
  Usages: BaseLoader Document Iterator List OpenWeatherMapAPIWrapper Optional Sequence annotations base classmethod cls datetime docstore document document_loaders langchain list now openweathermap openweathermap_api_key page_content place places run self str super typing utilities

Python: /langchain/document_loaders/web_base.py
  Functions: _build_metadata
  Classes: WebBaseLoader
  Methods: __init__ _check_parser _fetch _fetch_with_rate_limit _scrape aload fetch_all load scrape scrape_all web_path
  Variables: default_header_template default_parser: docs final_results headers headers["User-Agent"] html_doc html_doc.encoding logger metadata metadata["description"] metadata["language"] metadata["title"] parser requests_kwargs: requests_per_second: results self.session self.session.headers self.web_paths semaphore soup task tasks text url valid_parsers web_paths:
  Usages: Any BaseLoader BeautifulSoup ClientConnectionError ClientSession Dict Document ImportError List Optional Semaphore Session Union UserAgent ValueError __name__ aiohttp apparent_encoding append ascii asyncio attrs backoff base bs4 cooldown default_parser desc description dict docstore document document_loaders encoding endswith ensure_future enumerate fake_useragent find float gather get getLogger get_text header_template html info int isinstance join langchain len logging mininterval page_content path property random range requests requests_kwargs requests_per_second response result retries run self session sleep staticmethod str title tqdm tqdm_asyncio typing urls warn warning warnings web_paths

Python: /langchain/document_loaders/whatsapp_chat.py
  Functions: concatenate_rows
  Classes: WhatsAppChatLoader
  Methods: __init__ load
  Variables: date, lines message_line_regex metadata result self.file_path text_content
  Usages: BaseLoader Document List Path VERBOSE base date docstore document document_loaders encoding file_path flags groups langchain line match open page_content path pathlib readlines self sender str strip text typing

Python: /langchain/document_loaders/wikipedia.py
  Classes: WikipediaLoader
  Methods: __init__ load
  Variables: client docs self.lang self.load_all_available_meta self.load_max_docs self.query
  Usages: BaseLoader Document List Optional WikipediaAPIWrapper base bool docstore document document_loaders int lang langchain load_all_available_meta load_max_docs query self str top_k_results typing utilities wikipedia

Python: /langchain/document_loaders/word_document.py
  Classes: Docx2txtLoader UnstructuredWordDocumentLoader
  Methods: __del__ __init__ _get_elements _is_valid_url load
  Variables: is_doc parsed self.file_path self.temp_file self.web_path unstructured_version
  Usages: ABC BaseLoader DOC Document FileType ImportError List NamedTemporaryFile UnstructuredFileLoader ValueError __unstructured_version__ __version__ abc base bool close content detect_filetype doc docstore document document_loaders docx docx2txt expanduser extension file_path file_utils filename filetype get hasattr int isfile langchain magic metadata name netloc page_content parse partition partition_doc partition_docx path process requests scheme self split splitext staticmethod status_code str temp_file tempfile tuple typing unstructured unstructured_kwargs url urllib urlparse web_path write

Python: /langchain/document_loaders/xml.py
  Classes: UnstructuredXMLLoader
  Methods: __init__ _get_elements
  Usages: Any List UnstructuredFileLoader document_loaders file_path filename langchain min_unstructured_version mode partition partition_xml self str super typing unstructured unstructured_kwargs validate_unstructured_version xml

Python: /langchain/document_loaders/youtube.py
  Functions: _parse_video_id
  Classes: GoogleApiClient GoogleApiYoutubeLoader YoutubeLoader
  Methods: __init__ __post_init__ _build_youtube_client _get_channel_id _get_document_for_channel _get_document_for_video_id _get_transcripe_for_video_id _get_video_info _load_credentials extract_video_id from_youtube_url load validate_channel_or_videoIds_is_set
  Variables: ALLOWED_NETLOCK ALLOWED_SCHEMAS SCOPES add_video_info: captions captions_language: channel_id channel_name: continue_on_failure: credentials_path: creds document_list en_transcript flow google_api_client: ids logger meta_data metadata page_content parsed_query parsed_url path query request response self.add_video_info self.continue_on_failure self.creds self.language self.translation self.video_id self.youtube_client service_account_path: token_path: transcript transcript_list transcript_pieces video_id video_ids video_ids: video_info video_response
  Usages: Any BaseLoader Credentials Dict Document ImportError InstalledAppFlow List NoTranscriptFound Optional Path Request Sequence TranscriptsDisabled Union ValueError YouTube YouTubeTranscriptApi __name__ add_video_info annotations append auth author available_transcript base bool build captions_language channel channelId channel_name classmethod cls continue_on_failure credentials credentials_path dataclass dataclasses description dict discovery docstore document document_loaders endswith error execute exists expired extend fetch find_transcript from_authorized_user_file from_client_secrets_file from_service_account_file get getLogger google google_api_client google_auth_oauthlib googleapiclient home isinstance item join kwargs langchain language len length list list_next list_transcripts logging lstrip maxResults netloc oauth2 open parse parse_qs part pathlib pop port publish_date pydantic pytube refresh refresh_token requests root_validator run_local_server scheme search self service_account service_account_path split staticmethod str strftime strip thumbnail_url title to_json token token_path translate translation transport type typing update url urllib urlparse valid values videos views write youtube_client youtube_transcript_api youtube_url

Python: /langchain/embeddings/__init__.py
  Classes: HypotheticalDocumentEmbedder
  Methods: __init__ from_llm
  Variables: __all__ logger
  Usages: AlephAlphaAsymmetricSemanticEmbedding AlephAlphaSymmetricSemanticEmbedding Any BedrockEmbeddings CohereEmbeddings DashScopeEmbeddings DeepInfraEmbeddings ElasticsearchEmbeddings EmbaasEmbeddings FakeEmbeddings GooglePalmEmbeddings H HuggingFaceEmbeddings HuggingFaceHubEmbeddings HuggingFaceInstructEmbeddings JinaEmbeddings LlamaCppEmbeddings MiniMaxEmbeddings ModelScopeEmbeddings MosaicMLInstructorEmbeddings OpenAIEmbeddings SagemakerEndpointEmbeddings SelfHostedEmbeddings SelfHostedHuggingFaceEmbeddings SelfHostedHuggingFaceInstructEmbeddings SentenceTransformerEmbeddings TensorflowHubEmbeddings VertexAIEmbeddings __name__ aleph_alpha args base bedrock chains classmethod cls cohere dashscope deepinfra elasticsearch embaas embeddings fake getLogger google_palm huggingface huggingface_hub hyde jina kwargs langchain llamacpp logging minimax modelscope_hub mosaicml openai sagemaker_endpoint self self_hosted self_hosted_hugging_face sentence_transformer tensorflow_hub typing vertexai warning

Python: /langchain/embeddings/aleph_alpha.py
  Classes: AlephAlphaAsymmetricSemanticEmbedding AlephAlphaSymmetricSemanticEmbedding
  Methods: _embed embed_documents embed_query validate_environment
  Variables: aleph_alpha_api_key aleph_alpha_api_key: client: compress_to_size: contextual_control_threshold: control_log_additive: document_embeddings document_params document_request document_response hosting: model: normalize: query_params query_request query_response symmetric_params symmetric_request symmetric_response values["client"]
  Usages: Any BaseModel Client Dict Document Embeddings ImportError List Optional Prompt Query SemanticEmbeddingRequest SemanticRepresentation Symmetric ValueError aleph_alpha_client append base bool client cls compress_to_size contextual_control_threshold control_log_additive embedding embeddings float from_text get_from_dict_or_env hosting int langchain model normalize pydantic request root_validator self semantic_embed str text texts token typing utils values

Python: /langchain/embeddings/base.py
  Classes: Embeddings
  Methods: embed_documents embed_query
  Usages: ABC List abc abstractmethod float self str text texts typing

Python: /langchain/embeddings/bedrock.py
  Classes: BedrockEmbeddings Config
  Methods: _embedding_func embed_documents embed_query validate_environment
  Variables: _model_kwargs accepts body client: client_params client_params["region_name"] content_type credentials_profile_name: embeddings extra input_body input_body["inputText"] model_id: model_kwargs: region_name: response response_body results session text values["client"]
  Usages: Any BaseModel Dict Embeddings Exception Extra ImportError List ModuleNotFoundError Optional Session ValueError accept append base boto3 chunk_size client cls contentType credentials_profile_name dumps float forbid get int invoke_model json langchain linesep loads modelId model_id model_kwargs profile_name pydantic read region_name replace root_validator self str texts typing values

Python: /langchain/embeddings/cohere.py
  Classes: CohereEmbeddings Config
  Methods: embed_documents embed_query validate_environment
  Variables: client: cohere_api_key cohere_api_key: embedding embeddings extra model: truncate: values["client"]
  Usages: Any BaseModel Client Dict Embeddings Extra ImportError List Optional ValueError base client cls cohere embed float forbid get_from_dict_or_env langchain list map model pydantic root_validator self str text texts truncate typing utils values

Python: /langchain/embeddings/dashscope.py
  Functions: _create_retry_decorator embed_with_retry
  Classes: Config DashScopeEmbeddings
  Methods: _embed_with_retry embed_documents embed_query validate_environment
  Variables: client: dashscope.api_key dashscope_api_key: embedding embedding_list embeddings extra logger max_retries: max_seconds min_seconds model: multiplier resp retry_decorator values["client"] values["dashscope_api_key"]
  Usages: Any BaseModel Callable Dict Embeddings Extra HTTPError ImportError List Optional TextEmbedding ValueError WARNING __name__ annotations api_key base before_sleep before_sleep_log call client cls code dashscope dashscope_api_key exceptions float forbid getLogger get_from_dict_or_env input int item kwargs langchain logging max max_retries message min model output pydantic requests reraise retry retry_if_exception_type root_validator self status_code stop stop_after_attempt str tenacity text text_type texts typing utils values wait wait_exponential

Python: /langchain/embeddings/deepinfra.py
  Classes: Config DeepInfraEmbeddings
  Methods: _embed _identifying_params embed_documents embed_query validate_environment
  Variables: DEFAULT_MODEL_ID _model_kwargs deepinfra_api_token deepinfra_api_token: embed_instruction: embedding embeddings extra headers instruction_pair instruction_pairs model_id: model_kwargs: normalize: query_instruction: res values["deepinfra_api_token"]
  Usages: Any BaseModel Dict Embeddings Extra JSONDecodeError List Mapping Optional RequestException ValueError base bool cls dict embed_instruction exceptions float forbid get_from_dict_or_env input json langchain model_id model_kwargs normalize post property pydantic query_instruction requests root_validator self status_code str text texts typing utils values

Python: /langchain/embeddings/elasticsearch.py
  Classes: ElasticsearchEmbeddings
  Methods: __init__ _embedding_func embed_documents embed_query from_credentials from_es_connection
  Variables: client embeddings es_cloud_id es_connection es_password es_user response self.client self.input_field self.model_id
  Usages: Elasticsearch Embeddings ImportError List MlClient Optional TYPE_CHECKING annotations base basic_auth classmethod cloud_id cls doc docs elasticsearch float get_from_env infer_trained_model input_field langchain model_id self str text texts typing utils

Python: /langchain/embeddings/embaas.py
  Classes: Config EmbaasEmbeddings EmbaasEmbeddingsPayload
  Methods: _generate_embeddings _generate_payload _handle_request _identifying_params embed_documents embed_query validate_environment
  Variables: EMBAAS_API_URL MAX_BATCH_SIZE api_url: batches embaas_api_key embaas_api_key: embeddings extra headers instruction: model: parsed_response payload payload["instruction"] response texts: values["embaas_api_key"]
  Usages: Any BaseModel Dict Embeddings Extra List Mapping NotRequired Optional RequestException TypedDict ValueError api_url base batch cls embedding exceptions float forbid get_from_dict_or_env instruction item json langchain len model post property pydantic raise_for_status range requests root_validator self str text texts typing typing_extensions utils values

Python: /langchain/embeddings/fake.py
  Classes: FakeEmbeddings
  Methods: _get_embedding embed_documents embed_query
  Variables: size:
  Usages: BaseModel Embeddings List base embeddings float int langchain list normal numpy pydantic random self size str text texts typing

Python: /langchain/embeddings/google_palm.py
  Functions: _create_retry_decorator embed_with_retry
  Classes: GooglePalmEmbeddings
  Methods: _embed_with_retry embed_documents embed_query validate_environment
  Variables: client: embedding google_api_key google_api_key: logger max_retries max_seconds min_seconds model_name: multiplier retry_decorator values["client"]
  Usages: Any BaseModel Callable Dict Embeddings GoogleAPIError ImportError List Optional ResourceExhausted ServiceUnavailable WARNING __name__ annotations api_core api_key args base before_sleep before_sleep_log client cls configure embeddings exceptions float genai generate_embeddings generativeai getLogger get_from_dict_or_env google kwargs langchain logging max min model_name pydantic reraise retry retry_if_exception_type root_validator self stop stop_after_attempt str tenacity text texts typing utils values wait wait_exponential

Python: /langchain/embeddings/huggingface.py
  Classes: Config HuggingFaceEmbeddings HuggingFaceInstructEmbeddings
  Methods: __init__ embed_documents embed_query
  Variables: DEFAULT_EMBED_INSTRUCTION DEFAULT_INSTRUCT_MODEL DEFAULT_MODEL_NAME DEFAULT_QUERY_INSTRUCTION cache_folder: client: embed_instruction: embedding embeddings encode_kwargs: extra instruction_pair instruction_pairs model_kwargs: model_name: query_instruction: self.client text texts
  Usages: Any BaseModel Dict Embeddings Extra Field INSTRUCTOR ImportError InstructorEmbedding List Optional SentenceTransformer ValueError base cache_folder client default_factory dict embed_instruction encode encode_kwargs exc float forbid kwargs langchain list map model_kwargs model_name pydantic query_instruction replace self sentence_transformers str super tolist typing

Python: /langchain/embeddings/huggingface_hub.py
  Classes: Config HuggingFaceHubEmbeddings
  Methods: embed_documents embed_query validate_environment
  Variables: DEFAULT_REPO_ID VALID_TASKS _model_kwargs client client: extra huggingfacehub_api_token huggingfacehub_api_token: model_kwargs: repo_id repo_id: response responses task: texts values["client"]
  Usages: Any BaseModel Dict Embeddings Extra ImportError InferenceApi List Optional ValueError base cls dict embeddings float forbid get get_from_dict_or_env huggingface_hub inference_api inputs langchain model_kwargs params pydantic replace root_validator self startswith str task text token typing utils values

Python: /langchain/embeddings/jina.py
  Classes: JinaEmbeddings
  Methods: _post embed_documents embed_query validate_environment
  Variables: client: embedding embeddings endpoint jina_api_url jina_api_url: jina_auth_token jina_auth_token: model_name model_name: payload request_headers: resp values["client"] values["jina_auth_token"] values["request_headers"]
  Usages: Any BaseModel Client Dict Document DocumentArray Embeddings HTTPError ImportError List Optional ValueError base client cls dict docarray docs environ err exceptions float get get_from_dict_or_env headers host inputs jina json kwargs langchain list map metadata post pydantic raise_for_status request_headers requests root_validator self status_code str text texts typing utils values

Python: /langchain/embeddings/llamacpp.py
  Classes: Config LlamaCppEmbeddings
  Methods: embed_documents embed_query validate_environment
  Variables: client: embedding embeddings extra f16_kv: logits_all: model_param_names model_params model_params["n_gpu_layers"] model_path model_path: n_batch: n_ctx: n_gpu_layers: n_parts: n_threads: seed: use_mlock: values["client"] vocab_only:
  Usages: Any BaseModel Dict Embeddings Exception Extra Field ImportError List Llama ModuleNotFoundError Optional ValueError alias base bool client cls embed f16_kv float forbid int langchain list llama_cpp logits_all map n_batch n_ctx n_gpu_layers n_parts n_threads pydantic root_validator seed self str text texts typing use_mlock values vocab_only

Python: /langchain/embeddings/minimax.py
  Functions: _create_retry_decorator embed_with_retry
  Classes: Config MiniMaxEmbeddings
  Methods: _embed_with_retry embed embed_documents embed_query validate_environment
  Variables: embed_type_db: embed_type_query: embeddings endpoint_url: extra headers logger max_retries max_seconds min_seconds minimax_api_key minimax_api_key: minimax_group_id minimax_group_id: model: multiplier params parsed_response payload response retry_decorator values["minimax_api_key"] values["minimax_group_id"]
  Usages: Any BaseModel Callable Dict Embeddings Extra List Optional ValueError WARNING __name__ annotations args base before_sleep before_sleep_log cls embed_type embed_type_db embed_type_query endpoint_url float forbid getLogger get_from_dict_or_env json kwargs langchain logging max min model post pydantic requests reraise retry root_validator self stop stop_after_attempt str tenacity text texts typing utils values wait wait_exponential

Python: /langchain/embeddings/modelscope_hub.py
  Classes: Config ModelScopeEmbeddings
  Methods: __init__ embed_documents embed_query
  Variables: embed: embedding embeddings extra inputs model_id: self.embed text texts
  Usages: Any BaseModel Embeddings Extra ImportError List Tasks base constant embed float forbid input kwargs langchain list map model model_id modelscope pipeline pipelines pydantic replace self sentence_embedding str super tolist typing utils

Python: /langchain/embeddings/mosaicml.py
  Classes: Config MosaicMLInstructorEmbeddings
  Methods: _embed _identifying_params embed_documents embed_query validate_environment
  Variables: embed_instruction: embedding embeddings endpoint_url: extra headers instruction_pair instruction_pairs mosaicml_api_token mosaicml_api_token: parsed_response payload query_instruction: response retry_sleep: values["mosaicml_api_token"]
  Usages: Any BaseModel Dict Embeddings Extra JSONDecodeError List Mapping Optional RequestException Tuple ValueError base bool cls embed_instruction endpoint_url exceptions float forbid get_from_dict_or_env input is_retry json langchain lower post property pydantic query_instruction requests retry_sleep root_validator self sleep str text texts time typing utils values

Python: /langchain/embeddings/openai.py
  Functions: _create_retry_decorator embed_with_retry
  Classes: Config OpenAIEmbeddings
  Methods: _embed_with_retry _embedding_func _get_len_safe_embeddings _invocation_params embed_documents embed_query validate_environment
  Variables: _chunk_size _result allowed_special: average batched_embeddings chunk_size: client: default_api_version deployment: disallowed_special: embedding embedding_ctx_length: embeddings: embeddings[i] encoding extra headers: indices logger max_retries: max_seconds min_seconds model: num_tokens_in_batch: openai.proxy openai_api_base: openai_api_key: openai_api_type: openai_api_version: openai_args openai_organization: openai_proxy: request_timeout: response results: retry_decorator text token tokens values["client"] values["openai_api_base"] values["openai_api_key"] values["openai_api_type"] values["openai_api_version"] values["openai_organization"] values["openai_proxy"]
  Usages: APIConnectionError APIError Any BaseModel Callable Dict Embedding Embeddings Extra ImportError List Literal Optional RateLimitError Sequence ServiceUnavailableError Set Timeout Tuple Union WARNING __name__ allowed_special annotations append axis base before_sleep before_sleep_log chunk_size client cls create default deployment disallowed_special embedding_ctx_length embeddings encode encoding_for_model endswith engine enumerate error float forbid getLogger get_from_dict_or_env headers input int kwargs langchain len linalg logging max max_retries min model multiplier norm num_tokens_in_batch numpy openai openai_api_base openai_api_key openai_api_type openai_api_version openai_organization openai_proxy property proxy pydantic range replace request_timeout reraise results retry retry_if_exception_type root_validator self set stop stop_after_attempt str tenacity texts tiktoken tolist typing utils values wait wait_exponential weights

Python: /langchain/embeddings/sagemaker_endpoint.py
  Classes: Config EmbeddingsContentHandler SagemakerEndpointEmbeddings
  Methods: _embedding_func embed_documents embed_query validate_environment
  Variables: _chunk_size _endpoint_kwargs _model_kwargs accepts arbitrary_types_allowed body client: content_handler: content_type credentials_profile_name: endpoint_kwargs: endpoint_name: extra model_kwargs: region_name: response results session texts values["client"]
  Usages: Accept Any BaseModel Body ContentHandlerBase ContentType Dict Embeddings EndpointName Exception Extra ImportError List Optional Session ValueError base boto3 chunk_size client cls content_handler credentials_profile_name embeddings endpoint_kwargs endpoint_name extend float forbid int invoke_endpoint langchain len list llms map model_kwargs profile_name pydantic range region_name replace root_validator sagemaker_endpoint self str text transform_input transform_output typing values

Python: /langchain/embeddings/self_hosted.py
  Functions: _embed_documents
  Classes: Config SelfHostedEmbeddings
  Methods: embed_documents embed_query
  Variables: embeddings extra inference_fn: inference_kwargs: text texts
  Usages: Any Callable Embeddings Extra List SelfHostedPipeline args base client float forbid inference_fn inference_kwargs isinstance kwargs langchain list llms map pipeline pipeline_ref pydantic replace self str tolist typing

Python: /langchain/embeddings/self_hosted_hugging_face.py
  Functions: _embed_documents load_embedding_model
  Classes: SelfHostedHuggingFaceEmbeddings SelfHostedHuggingFaceInstructEmbeddings
  Methods: __init__ embed_documents embed_query
  Variables: DEFAULT_EMBED_INSTRUCTION DEFAULT_INSTRUCT_MODEL DEFAULT_MODEL_NAME DEFAULT_QUERY_INSTRUCTION client client: cuda_device_count embed_instruction: embedding embeddings hardware: inference_fn: instruction_pair instruction_pairs load_fn_kwargs load_fn_kwargs: load_fn_kwargs["device"] load_fn_kwargs["instruct"] load_fn_kwargs["model_id"] logger model_id: model_load_fn: model_reqs: query_instruction:
  Usages: Any Callable INSTRUCTOR InstructorEmbedding List Optional SelfHostedEmbeddings SentenceTransformer ValueError __name__ append args bool cuda device device_count dict embed_instruction encode find_spec float get getLogger hardware importlib inference_fn instruct int kwargs langchain logging model_id model_load_fn model_reqs pipeline_ref pop query_instruction self self_hosted sentence_transformers str super text texts tolist torch typing util warning

Python: /langchain/embeddings/sentence_transformer.py
  Variables: SentenceTransformerEmbeddings
  Usages: HuggingFaceEmbeddings embeddings huggingface langchain

Python: /langchain/embeddings/tensorflow_hub.py
  Classes: Config TensorflowHubEmbeddings
  Methods: __init__ embed_documents embed_query
  Variables: DEFAULT_MODEL_URL embed: embedding embeddings extra model_url: self.embed text texts
  Usages: Any BaseModel Embeddings Extra ImportError List base embed float forbid kwargs langchain list load map model_url numpy pydantic replace self str super tensorflow_hub tensorflow_text tolist typing

Python: /langchain/embeddings/vertexai.py
  Classes: VertexAIEmbeddings
  Methods: embed_documents embed_query validate_environment
  Variables: embeddings embeddings_batch model_name: text_batch values["client"]
  Usages: Dict Embeddings ImportError List TextEmbeddingModel _VertexAICommon _try_init_vertexai base batch batch_size client cls extend float from_pretrained get_embeddings int langchain language_models len llms model_name preview pydantic raise_vertex_import_error range root_validator self str text texts typing utilities values vertexai

Python: /langchain/evaluation/loading.py
  Functions: load_dataset
  Variables: dataset
  Usages: Dict List datasets str typing uri

Python: /langchain/experimental/__init__.py
  Variables: __all__
  Usages: AutoGPT BabyAGI GenerativeAgent GenerativeAgentMemory PlanAndExecute agent autogpt autonomous_agents baby_agi experimental generative_agent generative_agents langchain load_agent_executor load_chat_planner memory plan_and_execute

Python: /langchain/graphs/__init__.py
  Variables: __all__
  Usages: NebulaGraph Neo4jGraph NetworkxEntityGraph graphs langchain nebula_graph neo4j_graph networkx_graph

Python: /langchain/graphs/nebula_graph.py
  Classes: NebulaGraph
  Methods: __del__ __init__ _get_session_pool execute get_schema query refresh_schema
  Variables: RETRY_TIMES col_list col_name columns config config.max_size d[col_name] edge_schema edge_type_name props, rel_query result self.address self.password self.port self.schema self.session_pool self.session_pool_size self.space self.username session_pool tag_name tag_schema tags_schema,
  Usages: Any AuthFailedException Config Dict Exception IOErrorException ImportError InValidHostname NoValidSessionException RuntimeError SessionPool SessionPoolConfig TTransport TTransportException Template ValueError address all append cast close col_num col_size column_values dict edge_type edge_types_schema error_msg execute_parameter fbthrift gclient init int is_succeeded keys len list logging max_size nebula3 net pandas params password port property props range relationships retry row_size schema self session_pool_size space str string substitute tag tags_schema transport types typing username warning

Python: /langchain/graphs/neo4j_graph.py
  Classes: Neo4jGraph
  Methods: __init__ get_schema query refresh_schema
  Variables: data node_properties node_properties_query rel_properties_query rel_query relationships relationships_properties self._database self._driver self.schema
  Usages: Any AuthError ClientError CypherSyntaxError Dict GraphDatabase ImportError List ServiceUnavailable ValueError _database _driver auth database dict driver exceptions neo4j params password property run schema self session str typing url username verify_connectivity

Python: /langchain/graphs/networkx_graph.py
  Functions: get_entities parse_triples
  Classes: KnowledgeTriple NetworkxEntityGraph
  Methods: __init__ add_triple clear delete_triple from_gml from_string get_entity_knowledge get_triples write_to_gml
  Variables: KG_TRIPLE_DELIMITER graph kg_triple knowledge_str object_ object_: predicate: relation results self._graph subject subject, subject: triple_strs
  Usages: Any DiGraph ImportError List NamedTuple Optional Tuple ValueError _graph add_edge add_node annotations append classmethod cls data depth depth_limit dfs_edges edges entity entity_str gml_path has_edge has_node int isinstance knowledge_triple networkx path predicate read_gml remove_edge self sink split src str strip triple_str triple_string typing write_gml

Python: /langchain/indexes/__init__.py
  Variables: __all__
  Usages: GraphIndexCreator VectorstoreIndexCreator graph indexes langchain vectorstore

Python: /langchain/indexes/graph.py
  Classes: GraphIndexCreator
  Methods: afrom_text from_text
  Variables: chain graph graph_type: knowledge llm: output
  Usages: BaseLanguageModel BaseModel KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT LLMChain NetworkxEntityGraph Optional Type ValueError add_triple apredict base_language chains graph_type graphs indexes knowledge_triplet_extraction langchain llm networkx_graph parse_triples predict prompt prompts pydantic self str text triple typing

Python: /langchain/indexes/vectorstore.py
  Functions: _get_default_text_splitter
  Classes: Config VectorStoreIndexWrapper VectorstoreIndexCreator
  Methods: from_documents from_loaders query query_with_sources
  Variables: arbitrary_types_allowed chain docs embedding: extra llm sub_docs text_splitter: vectorstore vectorstore: vectorstore_cls: vectorstore_kwargs:
  Usages: Any BaseLanguageModel BaseLoader BaseModel Chroma Document Embeddings Extra Field List OpenAI OpenAIEmbeddings Optional RecursiveCharacterTextSplitter RetrievalQA RetrievalQAWithSourcesChain TextSplitter Type VectorStore as_retriever base base_language chains chroma chunk_overlap chunk_size default_factory dict document_loaders documents embedding embeddings extend forbid from_chain_type kwargs langchain llms load loader loaders openai pydantic qa_with_sources question question_key retrieval retrieval_qa retriever run schema self split_documents str temperature text_splitter typing vectorstore_cls vectorstore_kwargs vectorstores

Python: /langchain/llms/__init__.py
  Variables: __all__ type_to_cls_dict:
  Usages: AI21 AlephAlpha Anthropic Anyscale Aviary AzureOpenAI Banana BaseLLM Baseten Beam Bedrock CTransformers CerebriumAI Cohere Databricks DeepInfra Dict FakeListLLM ForefrontAI GPT4All GooglePalm GooseAI HuggingFaceEndpoint HuggingFaceHub HuggingFacePipeline HuggingFaceTextGenInference HumanInputLLM LlamaCpp Modal MosaicML NLPCloud OpenAI OpenAIChat OpenLM Petals PipelineAI PredictionGuard PromptLayerOpenAI PromptLayerOpenAIChat RWKV Replicate SagemakerEndpoint SelfHostedHuggingFaceLLM SelfHostedPipeline StochasticAI Type VertexAI Writer ai21 aleph_alpha anthropic anyscale aviary bananadev base baseten beam bedrock cerebriumai cohere ctransformers databricks deepinfra fake forefrontai google_palm gooseai gpt4all huggingface_endpoint huggingface_hub huggingface_pipeline huggingface_text_gen_inference human langchain llamacpp llms modal mosaicml nlpcloud openai openlm petals pipelineai predictionguard promptlayer_openai replicate rwkv sagemaker_endpoint self_hosted self_hosted_hugging_face stochasticai str type_to_cls_dict typing vertexai writer

Python: /langchain/llms/ai21.py
  Classes: AI21 AI21PenaltyData Config
  Methods: _call _default_params _identifying_params _llm_type validate_environment
  Variables: ai21_api_key ai21_api_key: applyToEmojis: applyToNumbers: applyToPunctuations: applyToStopwords: applyToWhitespaces: base_url base_url: countPenalty: extra frequencyPenalty: logitBias: maxTokens: minTokens: model: numResults: optional_detail params presencePenalty: response response_json scale: stop stop: temperature: topP: values["ai21_api_key"]
  Usages: Any BaseModel CallbackManagerForLLMRun Dict Extra LLM List Optional ValueError applyToEmojis applyToNumbers applyToPunctuations applyToStopwords applyToWhitespaces base bool callbacks cls countPenalty dict float forbid frequencyPenalty get get_from_dict_or_env headers int json kwargs langchain llms logitBias manager maxTokens minTokens model numResults post presencePenalty prompt property pydantic requests root_validator run_manager scale self status_code str temperature topP typing url utils values

Python: /langchain/llms/aleph_alpha.py
  Classes: AlephAlpha Config
  Methods: _call _default_params _identifying_params _llm_type validate_environment
  Variables: aleph_alpha_api_key aleph_alpha_api_key: best_of: client: completion_bias_exclusion: completion_bias_exclusion_first_token_only: completion_bias_inclusion: completion_bias_inclusion_first_token_only: contextual_control_threshold: control_log_additive: disable_optimizations: echo: extra frequency_penalty: log_probs: logit_bias: maximum_tokens: minimum_tokens: model: params params["stop_sequences"] penalty_bias: penalty_exceptions: penalty_exceptions_include_stop_sequences: presence_penalty: raw_completion: repetition_penalties_include_completion: repetition_penalties_include_prompt: request response sequence_penalty: sequence_penalty_min_length: stop_sequences: temperature: text tokens: top_k: top_p: use_multiplicative_frequency_penalty: use_multiplicative_presence_penalty: use_multiplicative_sequence_penalty: values["client"]
  Usages: Any CallbackManagerForLLMRun Client CompletionRequest Dict Extra ImportError LLM List Optional Prompt Sequence ValueError aleph_alpha_client base best_of bool callbacks client cls complete completion completion_bias_exclusion completion_bias_exclusion_first_token_only completion_bias_inclusion completion_bias_inclusion_first_token_only completions contextual_control_threshold control_log_additive disable_optimizations echo enforce_stop_tokens float forbid frequency_penalty from_text get_from_dict_or_env int kwargs langchain llms log_probs logit_bias manager maximum_tokens minimum_tokens model penalty_bias penalty_exceptions penalty_exceptions_include_stop_sequences presence_penalty prompt property pydantic raw_completion repetition_penalties_include_completion repetition_penalties_include_prompt root_validator run_manager self sequence_penalty sequence_penalty_min_length stop stop_sequences str temperature token tokens top_k top_p typing use_multiplicative_frequency_penalty use_multiplicative_presence_penalty use_multiplicative_sequence_penalty utils values

Python: /langchain/llms/anthropic.py
  Classes: Anthropic Config _AnthropicCommon
  Methods: _acall _call _default_params _get_anthropic_stop _identifying_params _llm_type _wrap_prompt get_num_tokens raise_warning stream validate_environment
  Variables: AI_PROMPT: HUMAN_PROMPT: anthropic_api_key anthropic_api_key: client: corrected_prompt, count_tokens: current_completion d["temperature"] d["top_k"] d["top_p"] default_request_timeout: delta extra max_tokens_to_sample: model: params response stop stream_resp streaming: temperature: top_k: top_p: values["AI_PROMPT"] values["HUMAN_PROMPT"] values["client"] values["count_tokens"]
  Usages: AI_PROMPT Any AsyncCallbackManagerForLLMRun BaseModel Callable CallbackManagerForLLMRun Client Dict Extra Generator HUMAN_PROMPT ImportError LLM List Mapping NameError Optional Tuple Union acompletion acompletion_stream anthropic api_key base bool callbacks client cls completion completion_stream corrected_prompt count_tokens data default_request_timeout extend float forbid get_from_dict_or_env int kwargs langchain len llms manager max_tokens_to_sample model n_subs on_llm_new_token prompt property pydantic root_validator run_manager self startswith stop_sequences str streaming subn temperature text top_k top_p typing utils values warn warnings

Python: /langchain/llms/anyscale.py
  Classes: Anyscale Config
  Methods: _call _identifying_params _llm_type validate_environment
  Variables: anyscale_service_endpoint anyscale_service_route anyscale_service_route: anyscale_service_token anyscale_service_token: anyscale_service_url anyscale_service_url: body extra headers model_kwargs: resp text values["anyscale_service_route"] values["anyscale_service_token"] values["anyscale_service_url"]
  Usages: Any CallbackManagerForLLMRun Dict Extra LLM List Mapping Optional RequestException ValueError base callbacks cls dict enforce_stop_tokens exceptions forbid get get_from_dict_or_env json kwargs langchain llms manager model_kwargs post prompt property pydantic requests root_validator run_manager self status_code stop str typing utils values

Python: /langchain/llms/aviary.py
  Classes: Aviary Config
  Methods: _call _identifying_params _llm_type headers validate_environment
  Variables: TIMEOUT aviary_endpoint aviary_token aviary_token: aviary_url aviary_url: extra headers model: response result text url values["aviary_token"] values["aviary_url"]
  Usages: Any CallbackManagerForLLMRun Dict Extra Field JSONDecodeError LLM List Mapping Optional RequestException ValueError base callbacks cls default endswith enforce_stop_tokens exceptions exclude forbid get get_from_dict_or_env json kwargs langchain llms manager model post pre prompt property pydantic replace requests root_validator run_manager self stop str timeout typing utils values

Python: /langchain/llms/bananadev.py
  Classes: Banana Config
  Methods: _call _identifying_params _llm_type build_extra validate_environment
  Variables: all_required_field_names api_key banana_api_key banana_api_key: extra extra[field_name] logger model_inputs model_key model_key: model_kwargs: params response returned text values["banana_api_key"] values["model_kwargs"]
  Usages: Any CallbackManagerForLLMRun Dict Extra Field ImportError KeyError LLM List Mapping Optional TypeError ValueError __fields__ __name__ alias banana banana_dev base callbacks cls default_factory dict enforce_stop_tokens field field_name forbid get getLogger get_from_dict_or_env kwargs langchain list llms logging manager model_kwargs pop pre prompt property pydantic root_validator run run_manager self stop str typing utils values warning

Python: /langchain/llms/base.py
  Functions: _get_verbosity get_prompts update_cache
  Classes: BaseLLM Config LLM
  Methods: __call__ __str__ _acall _agenerate _call _call_async _generate _identifying_params _llm_type agenerate agenerate_prompt apredict apredict_messages dict generate generate_prompt predict predict_messages raise_deprecation save set_verbose
  Variables: _stop arbitrary_types_allowed cache: cache_val callback_manager callback_manager: callbacks: cls_name content directory_path disregard_cache existing_prompts existing_prompts[i] existing_prompts[missing_prompt_idxs[i]] extra generations llm_output llm_string missing_prompt_idxs missing_prompts new_arg_supported new_results options output output.run params params["stop"] prompt prompt_dict prompt_strings result run_info run_manager save_path starter_dict starter_dict["_type"] text values["callbacks"] verbose:
  Usages: ABC AIMessage Any AsyncCallbackManager AsyncCallbackManagerForLLMRun BaseCallbackManager BaseLanguageModel BaseMessage CallbackManager CallbackManagerForLLMRun Callbacks DeprecationWarning Dict Exception Extra Field Generation KeyboardInterrupt LLMResult List Mapping NotImplementedError Optional Path PromptValue RunInfo Sequence Tuple Union ValueError __class__ __name__ abc abstractmethod always append base base_language bool cache callbacks cls configure default default_factory default_flow_style dump dumpd enumerate exclude exist_ok file_path forbid get get_buffer_string indent inspect int invocation_params isinstance items json kwargs langchain len list llm_cache load lookup manager messages mkdir on_llm_end on_llm_error on_llm_start open parameters parent parents pathlib pop pre prompts property pydantic range root_validator run run_id schema self signature sorted stop str suffix to_string type typing update validator values verbose warn warnings yaml

Python: /langchain/llms/baseten.py
  Classes: Baseten
  Methods: _call _identifying_params _llm_type
  Variables: input: logger model model: model_kwargs: response
  Usages: Any ApiError CallbackManagerForLLMRun Dict Field ImportError LLM List Mapping Optional ValueError __name__ base baseten callbacks common core default_factory deployed_model_id deployed_model_version_id dict exc getLogger input join kwargs langchain llms logging manager model_kwargs predict prompt property pydantic run_manager self stop str typing

Python: /langchain/llms/beam.py
  Classes: Beam Config
  Methods: _call _deploy _identifying_params _llm_type app_creation authorization build_extra run_creation validate_environment
  Variables: DEFAULT_NUM_TRIES DEFAULT_SLEEP_TIME all_required_field_names app_id: beam_client_id beam_client_id: beam_client_secret beam_client_secret: cpu: credential_str extra extra[field_name] gpu: headers lines logger max_length: memory: model_kwargs: model_name: name: output payload process python_packages: python_version: request script script_name self.app_id self.url url url: values["beam_client_id"] values["beam_client_secret"] values["model_kwargs"]
  Usages: Any CallbackManagerForLLMRun Dict Extra Field ImportError LLM List Mapping Optional ValueError __fields__ __name__ __path__ alias app_id b64encode base base64 beam callbacks capture_output cls cpu data decode dedent default_factory dict dumps encode field field_name file forbid format get getLogger get_from_dict_or_env gpu info json kwargs langchain line list llms logging manager max_length memory model_kwargs model_name name open pop post pre prompt property pydantic python_packages python_version range requests returncode root_validator run run_manager self shell sleep split startswith status_code stderr stdout stop str strip subprocess text textwrap time typing update utils values warning write

Python: /langchain/llms/bedrock.py
  Classes: Bedrock Config LLMInputOutputAdapter
  Methods: _call _identifying_params _llm_type prepare_input prepare_output validate_environment
  Variables: _model_kwargs accept body client: client_params client_params["region_name"] contentType credentials_profile_name: extra input_body input_body["inputText"] input_body["max_tokens_to_sample"] input_body["prompt"] input_body["textGenerationConfig"] model_id: model_kwargs: params provider region_name: response response_body session text values["client"]
  Usages: Any CallbackManagerForLLMRun Dict Exception Extra ImportError LLM List Mapping ModuleNotFoundError Optional Session ValueError base boto3 callbacks classmethod client cls credentials_profile_name decode dict dumps enforce_stop_tokens forbid get invoke_model json kwargs langchain llms loads manager modelId model_id model_kwargs profile_name prompt property pydantic read region_name root_validator run_manager self split stop str typing utils values

Python: /langchain/llms/cerebriumai.py
  Classes: CerebriumAI Config
  Methods: _call _identifying_params _llm_type build_extra validate_environment
  Variables: all_required_field_names cerebriumai_api_key cerebriumai_api_key: endpoint_url: extra extra[field_name] logger model_kwargs: params response text values["cerebriumai_api_key"] values["model_kwargs"]
  Usages: Any CallbackManagerForLLMRun Dict Extra Field ImportError LLM List Mapping Optional ValueError __fields__ __name__ alias base callbacks cerebrium cls default_factory dict endpoint_url enforce_stop_tokens field field_name forbid get getLogger get_from_dict_or_env kwargs langchain list llms logging manager model_api_request model_kwargs pop pre prompt property pydantic root_validator run_manager self stop str typing utils values warning

Python: /langchain/llms/cohere.py
  Functions: _create_retry_decorator completion_with_retry
  Classes: Cohere Config
  Methods: _call _completion_with_retry _default_params _identifying_params _llm_type validate_environment
  Variables: client: cohere_api_key cohere_api_key: extra frequency_penalty: logger max_retries: max_seconds max_tokens: min_seconds model: params params["stop_sequences"] presence_penalty: response retry_decorator stop: temperature: text truncate: values["client"]
  Usages: Any Callable CallbackManagerForLLMRun Client CohereError Dict Extra ImportError LLM List Optional ValueError WARNING __name__ annotations base before_sleep before_sleep_log callbacks client cls cohere enforce_stop_tokens error float forbid frequency_penalty generate generations getLogger get_from_dict_or_env int kwargs langchain llm llms logging manager max max_retries max_tokens min model multiplier presence_penalty prompt property pydantic reraise retry retry_if_exception_type root_validator run_manager self stop stop_after_attempt str temperature tenacity truncate typing utils values wait wait_exponential

Python: /langchain/llms/ctransformers.py
  Classes: CTransformers
  Methods: _call _identifying_params _llm_type validate_environment
  Variables: _run_manager client: config config: lib: model: model_file: model_type: text values["client"]
  Usages: Any AutoModelForCausalLM CallbackManagerForLLMRun Dict ImportError LLM Optional Sequence append base callbacks chunk client cls ctransformers from_pretrained get_noop_manager join kwargs langchain lib llms manager model model_file model_type on_llm_new_token prompt property pydantic root_validator run_manager self stop str stream typing values verbose

Python: /langchain/llms/databricks.py
  Functions: get_default_api_token get_default_host get_repl_context
  Classes: Config Databricks _DatabricksClientBase _DatabricksClusterDriverProxyClient _DatabricksServingEndpointClient
  Methods: __init__ _call _llm_type post post_raw set_api_url set_cluster_driver_port set_cluster_id set_model_kwargs
  Variables: __all__ _client: api_token api_token: api_url api_url: cluster_driver_port: cluster_id cluster_id: endpoint_name endpoint_name: extra headers host host: model_kwargs: port request response self._client transform_input_fn: transform_output_fn: underscore_attrs_are_private values["api_url"] wrapped_request
  Usages: ABC Any BaseModel Callable CallbackManagerForLLMRun Dict Exception Extra Field ImportError LLM List Optional PrivateAttr ValueError _client abc abstractmethod always apiToken base browserHostName callbacks cls clusterId cluster_driver_port data databricks_repl_context dbruntime default_factory forbid get_context getenv int isinstance json kwargs langchain list llms lstrip manager model_kwargs pre prompt property pydantic requests root_validator rstrip run_manager self status_code stop str super text transform_input_fn transform_output_fn typing update validator values

Python: /langchain/llms/deepinfra.py
  Classes: Config DeepInfra
  Methods: _call _identifying_params _llm_type validate_environment
  Variables: DEFAULT_MODEL_ID _model_kwargs deepinfra_api_token deepinfra_api_token: extra headers model_id: model_kwargs: res text values["deepinfra_api_token"]
  Usages: Any CallbackManagerForLLMRun Dict Extra JSONDecodeError LLM List Mapping Optional RequestException ValueError base callbacks cls dict enforce_stop_tokens exceptions forbid get_from_dict_or_env json kwargs langchain llms manager model_id model_kwargs post prompt property pydantic requests root_validator run_manager self status_code stop str typing utils values

Python: /langchain/llms/fake.py
  Classes: FakeListLLM
  Methods: _acall _call _identifying_params _llm_type
  Variables: response responses:
  Usages: Any AsyncCallbackManagerForLLMRun CallbackManagerForLLMRun LLM List Mapping Optional base callbacks int kwargs langchain llms manager prompt property responses run_manager self stop str typing

Python: /langchain/llms/forefrontai.py
  Classes: Config ForefrontAI
  Methods: _call _default_params _identifying_params _llm_type validate_environment
  Variables: base_url: endpoint_url: extra forefrontai_api_key forefrontai_api_key: length: repetition_penalty: response response_json temperature: text top_k: top_p: values["forefrontai_api_key"]
  Usages: Any CallbackManagerForLLMRun Dict Extra LLM List Mapping Optional base base_url callbacks cls endpoint_url enforce_stop_tokens float forbid get_from_dict_or_env headers int json kwargs langchain length llms manager post prompt property pydantic repetition_penalty requests root_validator run_manager self stop str temperature top_k top_p typing url utils values

Python: /langchain/llms/google_palm.py
  Functions: _create_retry_decorator _strip_erroneous_leading_spaces generate_with_retry
  Classes: GooglePalm
  Methods: _agenerate _generate _generate_with_retry _llm_type validate_environment
  Variables: client: completion generations google_api_key google_api_key: has_leading_space logger max_output_tokens: max_retries max_seconds min_seconds model_name: multiplier prompt_generations raw_text retry_decorator stripped_text temperature: top_k: top_p: values["client"]
  Usages: Any AsyncCallbackManagerForLLMRun BaseLLM BaseModel Callable CallbackManagerForLLMRun Dict Generation GoogleAPIError ImportError LLMResult List NotImplementedError Optional ResourceExhausted ServiceUnavailable ValueError WARNING __name__ all annotations api_core api_key append before_sleep before_sleep_log callbacks candidate candidate_count candidates client cls configure exceptions float genai generate_text generativeai getLogger get_from_dict_or_env google int kwargs langchain line llm llms logging manager max max_output_tokens min model model_name prompt prompts property pydantic replace reraise retry retry_if_exception_type root_validator run_manager schema self split stop stop_after_attempt stop_sequences str temperature tenacity text top_k top_p typing utils values wait wait_exponential

Python: /langchain/llms/gooseai.py
  Classes: Config GooseAI
  Methods: _call _default_params _identifying_params _llm_type build_extra validate_environment
  Variables: all_required_field_names client: extra extra[field_name] frequency_penalty: gooseai_api_key gooseai_api_key: logger logit_bias: max_tokens: min_tokens: model_kwargs: model_name: normal_params openai.api_base openai.api_key params params["stop"] presence_penalty: response temperature: text top_p: values["client"] values["model_kwargs"]
  Usages: Any CallbackManagerForLLMRun Completion Dict Extra Field ImportError LLM List Mapping Optional ValueError __fields__ __name__ alias api_base api_key base callbacks choices client cls create default_factory dict engine field field_name float frequency_penalty get getLogger get_from_dict_or_env ignore int kwargs langchain list llms logging logit_bias manager max_tokens min_tokens model_kwargs model_name openai pop pre presence_penalty prompt property pydantic root_validator run_manager self stop str temperature top_p typing utils values warning

Python: /langchain/llms/gpt4all.py
  Classes: Config GPT4All
  Methods: _call _default_params _identifying_params _llm_type _model_param_names validate_environment
  Variables: allow_download: backend: client: context_erase: echo: embedding: extra f16_kv: full_path logits_all: model: model_path, n_batch: n_ctx: n_parts: n_predict: n_threads: params repeat_last_n: repeat_penalty: seed: stop: streaming: temp: text text_callback top_k: top_p: use_mlock: values["backend"] values["client"] vocab_only:
  Usages: Any AttributeError CallbackManagerForLLMRun Dict Extra Field GPT4AllModel ImportError LLM List Mapping Optional Set __dict__ alias allow_download backend base bool callbacks client cls context_erase delimiter echo embedding enforce_stop_tokens f16_kv float forbid functools generate gpt4all int items kwargs langchain llms logits_all manager model model_name model_path model_type n_batch n_ctx n_parts n_predict n_threads on_llm_new_token partial prompt property pydantic repeat_last_n repeat_penalty root_validator rpartition run_manager seed self set_thread_count staticmethod stop str streaming temp token top_k top_p typing use_mlock utils values verbose vocab_only

Python: /langchain/llms/huggingface_endpoint.py
  Classes: Config HuggingFaceEndpoint
  Methods: _call _identifying_params _llm_type validate_environment
  Variables: VALID_TASKS _model_kwargs endpoint_url: extra generated_text headers huggingfacehub_api_token huggingfacehub_api_token: model_kwargs: parameter_payload params response task: text values["huggingfacehub_api_token"]
  Usages: Any CallbackManagerForLLMRun Dict Exception Extra HfApi ImportError LLM List Mapping Optional RequestException ValueError base callbacks cls dict endpoint endpoint_url enforce_stop_tokens exceptions forbid get_from_dict_or_env hf_api huggingface_hub json kwargs langchain len llms manager model_kwargs post prompt property pydantic requests root_validator run_manager self stop str task token typing utils values whoami

Python: /langchain/llms/huggingface_hub.py
  Classes: Config HuggingFaceHub
  Methods: _call _identifying_params _llm_type validate_environment
  Variables: DEFAULT_REPO_ID VALID_TASKS _model_kwargs client client: extra huggingfacehub_api_token huggingfacehub_api_token: model_kwargs: params repo_id repo_id: response task: text values["client"]
  Usages: Any CallbackManagerForLLMRun Dict Extra ImportError InferenceApi LLM List Mapping Optional ValueError base callbacks cls dict enforce_stop_tokens forbid get get_from_dict_or_env huggingface_hub inference_api inputs kwargs langchain len llms manager model_kwargs prompt property pydantic root_validator run_manager self stop str task token typing utils values

Python: /langchain/llms/huggingface_pipeline.py
  Classes: Config HuggingFacePipeline
  Methods: _call _identifying_params _llm_type from_model_id
  Variables: DEFAULT_MODEL_ID DEFAULT_TASK VALID_TASKS _model_kwargs _pipeline_kwargs cuda_device_count extra logger model model_id: model_kwargs: pipeline pipeline: pipeline_kwargs: response text tokenizer
  Usages: Any AutoModelForCausalLM AutoModelForSeq2SeqLM AutoTokenizer CallbackManagerForLLMRun Extra ImportError LLM List Mapping Optional ValueError __name__ base callbacks classmethod cls cuda device device_count dict enforce_stop_tokens find_spec forbid from_pretrained getLogger hf_pipeline importlib int items kwargs langchain len llms logging manager model_id model_kwargs pipeline_kwargs prompt property pydantic run_manager self stop str task torch transformers typing util utils warning

Python: /langchain/llms/huggingface_text_gen_inference.py
  Classes: Config HuggingFaceTextGenInference
  Methods: _call _llm_type validate_environment
  Variables: client: extra inference_server_url: is_stop max_new_tokens: params repetition_penalty: res res.generated_text seed: stop stop_sequences: stream: temperature: text text_callback timeout: token top_k: top_p: typical_p: values["client"]
  Usages: Any CallbackManagerForLLMRun Client Dict Extra Field ImportError LLM List Optional base bool callbacks client cls default_factory float forbid functools generate generate_stream generated_text index inference_server_url int kwargs langchain list llms manager max_new_tokens on_llm_new_token partial prompt property pydantic repetition_penalty root_validator run_manager seed self special stop_seq stop_sequences str stream temperature text_generation timeout top_k top_p typical_p typing values verbose

Python: /langchain/llms/human.py
  Functions: _collect_user_input _display_prompt
  Classes: HumanInputLLM
  Methods: _call _identifying_params _llm_type
  Variables: input_func: input_kwargs: line lines multi_line_input prompt_func: prompt_kwargs: separator separator: user_input
  Usages: Any Callable CallbackManagerForLLMRun Field LLM List Mapping Optional any append base callbacks default_factory enforce_stop_tokens input input_func input_kwargs join kwargs langchain llms manager print prompt prompt_func prompt_kwargs property pydantic run_manager self seq stop str typing utils

Python: /langchain/llms/llamacpp.py
  Classes: LlamaCpp
  Methods: _call _default_params _get_parameters _identifying_params _llm_type get_num_tokens stream validate_environment
  Variables: client: combined_text_output echo: f16_kv: last_n_tokens_size: log_probs logger logits_all: logprobs: lora_base: lora_path: max_tokens: model_param_names model_params model_params["n_gpu_layers"] model_path model_path: n_batch: n_ctx: n_gpu_layers: n_parts: n_threads: params params["stop"] repeat_penalty: result seed: stop: streaming: suffix: temperature: token tokenized_text top_k: top_p: use_mlock: use_mmap: values["client"] vocab_only:
  Usages: Any CallbackManagerForLLMRun Dict Exception Field Generator ImportError LLM List Llama ModuleNotFoundError Optional ValueError __name__ alias base bool callbacks chunk client cls echo encode f16_kv float get getLogger int kwargs langchain last_n_tokens_size len llama_cpp llms logging logits_all logprobs lora_base lora_path manager max_tokens n_batch n_ctx n_gpu_layers n_parts n_threads on_llm_new_token pop prompt property pydantic repeat_penalty root_validator run_manager seed self stop str streaming suffix temperature text tokenize top_k top_p typing use_mlock use_mmap values verbose vocab_only

Python: /langchain/llms/loading.py
  Functions: load_llm load_llm_from_config
  Variables: config config_type file_path llm_cls
  Usages: BaseLLM Path Union ValueError base dict file isinstance json langchain llms load open pathlib pop safe_load str suffix type_to_cls_dict typing yaml

Python: /langchain/llms/manifest.py
  Classes: Config ManifestWrapper
  Methods: _call _identifying_params _llm_type validate_environment
  Variables: client: extra kwargs llm_kwargs: params params["stop_token"]
  Usages: Any CallbackManagerForLLMRun Dict Extra ImportError LLM List Manifest Mapping NotImplementedError Optional ValueError base callbacks client cls forbid get_model_params isinstance langchain len llm_kwargs llms manager manifest prompt property pydantic root_validator run run_manager self stop str typing values

Python: /langchain/llms/modal.py
  Classes: Config Modal
  Methods: _call _identifying_params _llm_type build_extra
  Variables: all_required_field_names endpoint_url: extra extra[field_name] logger model_kwargs: params response response_json text values["model_kwargs"]
  Usages: Any CallbackManagerForLLMRun Dict Extra Field KeyError LLM List Mapping Optional ValueError __fields__ __name__ alias base callbacks cls default_factory dict endpoint_url enforce_stop_tokens field field_name forbid get getLogger headers json kwargs langchain list llms logging manager model_kwargs pop post pre prompt property pydantic requests root_validator run_manager self stop str typing url utils values warning

Python: /langchain/llms/mosaicml.py
  Classes: Config MosaicML
  Methods: _call _identifying_params _llm_type _transform_prompt validate_environment
  Variables: INSTRUCTION_KEY INTRO_BLURB PROMPT_FOR_GENERATION_FORMAT RESPONSE_KEY _model_kwargs endpoint_url: extra generated_text headers inject_instruction_format: model_kwargs: mosaicml_api_token mosaicml_api_token: parsed_response payload prompt response retry_sleep: text values["mosaicml_api_token"]
  Usages: Any CallbackManagerForLLMRun Dict Extra JSONDecodeError LLM List Mapping Optional RequestException ValueError base bool callbacks cls dict endpoint_url enforce_stop_tokens exceptions float forbid format get_from_dict_or_env inject_instruction_format instruction instruction_key intro is_retry json kwargs langchain len llms lower manager model_kwargs post property pydantic requests response_key retry_sleep root_validator run_manager self sleep stop str time typing update utils values

Python: /langchain/llms/nlpcloud.py
  Classes: Config NLPCloud
  Methods: _call _default_params _identifying_params _llm_type validate_environment
  Variables: bad_words: client: do_sample: early_stopping: end_sequence extra length_no_input: length_penalty: max_length: min_length: model_name: nlpcloud_api_key nlpcloud_api_key: num_beams: num_return_sequences: params remove_end_sequence: remove_input: repetition_penalty: response temperature: top_k: top_p: values["client"]
  Usages: Any CallbackManagerForLLMRun Client Dict Extra ImportError LLM List Mapping Optional ValueError bad_words base bool callbacks client cls do_sample early_stopping float forbid generation get_from_dict_or_env gpu int kwargs lang langchain len length_no_input length_penalty llms manager max_length min_length model_name nlpcloud num_beams num_return_sequences prompt property pydantic remove_end_sequence remove_input repetition_penalty root_validator run_manager self stop str temperature top_k top_p typing utils values

Python: /langchain/llms/openai.py
  Functions: _create_retry_decorator _streaming_response_template _update_response acompletion_with_retry completion_with_retry update_token_usage
  Classes: AzureOpenAI BaseOpenAI Config OpenAI OpenAIChat
  Methods: __new__ _agenerate _completion_with_retry _default_params _generate _get_chat_params _identifying_params _invocation_params _llm_type build_extra create_llm_result get_sub_prompts get_token_ids lc_secrets lc_serializable max_tokens_for_prompt modelname_to_contextsize prep_streaming_params stream validate_azure_settings validate_environment
  Variables: _keys _keys_to_use all_required_field_names allow_population_by_field_name allowed_special: batch_size: best_of: choices client: context_size deployment_name: disallowed_special: enc extra extra[field_name] frequency_penalty: full_response generations generator invalid_model_kwargs llm_output logger logit_bias: max_retries: max_seconds max_size max_tokens: messages messages, min_seconds model_kwargs: model_name model_name: model_token_mapping modelname normal_params normal_params["best_of"] num_tokens openai.api_base openai.api_key openai.organization openai.proxy openai_api_base openai_api_base: openai_api_key openai_api_key: openai_api_type: openai_api_version: openai_creds: openai_organization openai_organization: openai_params openai_proxy openai_proxy: params params: params["max_tokens"] params["stop"] params["stream"] prefix_messages: presence_penalty: request_timeout: response response["choices"][0]["finish_reason"] response["choices"][0]["logprobs"] retry_decorator streaming: sub_choices sub_prompts temperature: token token_usage: token_usage[_key] top_p: values["client"] values["model_kwargs"] values["openai_api_base"] values["openai_api_key"] values["openai_api_type"] values["openai_api_version"] values["openai_organization"] values["openai_proxy"]
  Usages: APIConnectionError APIError AbstractSet Any AsyncCallbackManagerForLLMRun AttributeError BaseLLM Callable CallbackManagerForLLMRun ChatCompletion Collection Completion Dict Extra Field Generation Generator ImportError LLMResult List Literal Mapping Optional RateLimitError ServiceUnavailableError Set Timeout Tuple Union ValueError WARNING __fields__ __name__ _key _prompts acreate alias allowed_special annotations api_base api_key append base batch_size before_sleep before_sleep_log best_of bool callbacks choice client cls create data default default_factory deployment_name dict disallowed_special encode encoding_for_model enumerate error extend field field_name finish_reason float frequency_penalty generation_info get getLogger get_from_dict_or_env get_num_tokens ignore int intersection join keys kwargs langchain len list llm llms logging logit_bias logprobs manager max max_retries max_tokens min model_kwargs multiplier on_llm_new_token openai openai_api_type openai_api_version openai_creds organization pop pre prefix_messages presence_penalty prompt prompts property proxy pydantic range request_timeout reraise retry retry_if_exception_type root_validator run_manager schema self set split startswith stop stop_after_attempt str stream_resp stream_response streaming super sys temperature tenacity text tiktoken token_usage top_p typing utils values verbose version_info wait wait_exponential warn warning warnings

Python: /langchain/llms/openlm.py
  Classes: OpenLM
  Methods: _invocation_params validate_environment
  Variables: values["client"]
  Usages: Any BaseOpenAI Completion Dict ImportError ValueError cls langchain llms model_name openai openlm property pydantic root_validator self str super typing values

Python: /langchain/llms/petals.py
  Classes: Config Petals
  Methods: _call _default_params _identifying_params _llm_type build_extra validate_environment
  Variables: all_required_field_names client: do_sample: extra extra[field_name] huggingface_api_key huggingface_api_key: inputs logger max_length: max_new_tokens: model_kwargs: model_name model_name: normal_params outputs params temperature: text tokenizer: top_k: top_p: values["client"] values["huggingface_api_key"] values["model_kwargs"] values["tokenizer"]
  Usages: Any BloomTokenizerFast CallbackManagerForLLMRun Dict DistributedBloomForCausalLM Extra Field ImportError LLM List Mapping Optional ValueError __fields__ __name__ alias base bool callbacks client cls decode default_factory dict do_sample enforce_stop_tokens field field_name float forbid from_pretrained generate get getLogger get_from_dict_or_env int kwargs langchain list llms logging manager max_length max_new_tokens model_kwargs petals pop pre prompt property pydantic return_tensors root_validator run_manager self stop str temperature tokenizer top_k top_p transformers typing utils values warning

Python: /langchain/llms/pipelineai.py
  Classes: Config PipelineAI
  Methods: _call _identifying_params _llm_type build_extra validate_environment
  Variables: all_required_field_names client extra extra[field_name] logger params pipeline_api_key pipeline_api_key: pipeline_key: pipeline_kwargs: run text values["pipeline_api_key"] values["pipeline_kwargs"]
  Usages: Any AttributeError BaseModel CallbackManagerForLLMRun Dict Extra Field ImportError LLM List Mapping Optional PipelineCloud ValueError __fields__ __name__ alias base callbacks cls default_factory dict enforce_stop_tokens field field_name forbid get getLogger get_from_dict_or_env kwargs langchain list llms logging manager pipeline pipeline_key pipeline_kwargs pop pre prompt property pydantic result_preview root_validator run_manager run_pipeline self stop str token typing utils values warning

Python: /langchain/llms/predictionguard.py
  Classes: Config PredictionGuard
  Methods: _call _default_params _identifying_params _llm_type validate_environment
  Variables: client: extra logger max_tokens: model: output: params params["stop_sequences"] response stop: temperature: text token token: values["client"]
  Usages: Any CallbackManagerForLLMRun Client Completion Dict Extra ImportError LLM List Optional ValueError __name__ base callbacks client cls create enforce_stop_tokens float forbid getLogger get_from_dict_or_env int kwargs langchain llms logging manager max_tokens model output predictionguard prompt property pydantic root_validator run_manager self stop str temperature typing utils values

Python: /langchain/llms/promptlayer_openai.py
  Classes: PromptLayerOpenAI PromptLayerOpenAIChat
  Methods: _agenerate _generate
  Variables: generated_responses generation generation.generation_info generation.generation_info["pl_request_id"] params pl_request_id pl_tags: prompt request_end_time request_start_time resp return_pl_id:
  Usages: Any AsyncCallbackManagerForLLMRun CallbackManagerForLLMRun LLMResult List OpenAI OpenAIChat Optional _identifying_params bool callbacks datetime dict generation_info generations get_api_key isinstance kwargs langchain len llm_output llms manager now pl_tags promptlayer promptlayer_api_request promptlayer_api_request_async prompts range return_pl_id run_manager schema self stop str super text timestamp typing utils

Python: /langchain/llms/replicate.py
  Classes: Config Replicate
  Methods: _call _identifying_params _llm_type build_extra validate_environment
  Variables: all_required_field_names extra extra[field_name] first_input_name input: input_properties inputs iterator logger model model: model_kwargs: model_str, replicate_api_token replicate_api_token: values["model_kwargs"] values["replicate_api_token"] version
  Usages: Any CallbackManagerForLLMRun Dict Extra Field ImportError LLM List Mapping Optional ValueError __fields__ __name__ alias base callbacks cls default_factory dict field field_name forbid get getLogger get_from_dict_or_env input item items join key kwargs langchain list llms logging manager model_kwargs model_str models openapi_schema output pop pre prompt property pydantic replicate replicate_python root_validator run run_manager self sorted split stop str typing utils values version_str versions warning

Python: /langchain/llms/rwkv.py
  Classes: Config RWKV
  Methods: _call _default_params _identifying_params _llm_type _rwkv_param_names run_rnn rwkv_generate validate_environment
  Variables: AVOID_REPEAT AVOID_REPEAT_TOKENS CHUNK_LEN: END_OF_LINE END_OF_TEXT begin client: decoded extra logits max_tokens_per_generation: model: model_kwargs model_kwargs["verbose"] model_state: model_tokens: occurrence: occurrence[token] out, out: out[self.model_tokens[-1]] out_last penalty_alpha_frequency: penalty_alpha_presence: pipeline: rwkv_keys rwkv_verbose: self.model_state self.model_tokens strategy: temperature: text token tokenizer: tokens tokens_path: top_p: values["client"] values["pipeline"] values["tokenizer"] xxx
  Usages: Any BaseModel CHUNK_LEN CallbackManagerForLLMRun Dict Extra ImportError LLM List Mapping Optional PIPELINE RWKVMODEL Set Tokenizer ValueError __dict__ _tokens base bool callbacks client cls decode encode enforce_stop_tokens float forbid forward from_file ids int items kwargs langchain len llms manager max_tokens_per_generation model model_state model_tokens newline_adj occurrence out penalty_alpha_frequency penalty_alpha_presence pipeline prompt property pydantic range root_validator run_manager rwkv rwkv_verbose sample_logits self staticmethod stop str strategy temperature tokenizer tokenizers tokens_path top_p typing utils values verbose

Python: /langchain/llms/sagemaker_endpoint.py
  Classes: Config ContentHandlerBase LLMContentHandler SagemakerEndpoint
  Methods: _call _identifying_params _llm_type transform_input transform_output validate_environment
  Variables: INPUT_TYPE OUTPUT_TYPE _endpoint_kwargs _model_kwargs accepts accepts: body client: content_handler: content_type content_type: credentials_profile_name: endpoint_kwargs: endpoint_name: extra model_kwargs: region_name: response session text values["client"]
  Usages: Accept Any Body CallbackManagerForLLMRun ContentType Dict EndpointName Exception Extra Generic ImportError LLM List Mapping Optional Session TypeVar Union ValueError abc abstractmethod base boto3 bound bytes callbacks client cls content_handler credentials_profile_name endpoint_kwargs endpoint_name enforce_stop_tokens float forbid invoke_endpoint kwargs langchain llms manager model_kwargs output profile_name prompt property pydantic region_name root_validator run_manager self stop str typing utils values

Python: /langchain/llms/self_hosted.py
  Functions: _generate_text _send_pipeline_to_device
  Classes: Config SelfHostedPipeline
  Methods: __init__ _call _identifying_params _llm_type from_pipeline
  Variables: _load_fn_kwargs client: cuda_device_count extra hardware: inference_fn: load_fn_kwargs load_fn_kwargs: logger model_load_fn: model_reqs: pipeline pipeline.device pipeline.model pipeline_ref: remote_load_fn self.client self.pipeline_ref text
  Usages: Any Callable CallbackManagerForLLMRun Extra ImportError LLM List Mapping Optional ValueError __name__ args base callbacks classmethod client cls cuda device device_count dict enforce_stop_tokens find_spec forbid function getLogger hardware importlib inference_fn int isinstance kwargs langchain llms load logging manager model model_load_fn model_reqs open pickle pipeline_ref prompt property pydantic remote reqs run_manager runhouse self stop str super torch typing util utils warning

Python: /langchain/llms/self_hosted_hugging_face.py
  Functions: _generate_text _load_transformer
  Classes: Config SelfHostedHuggingFaceLLM
  Methods: __init__ _call _identifying_params _llm_type
  Variables: DEFAULT_MODEL_ID DEFAULT_TASK VALID_TASKS _model_kwargs cuda_device_count device: extra hardware: inference_fn: load_fn_kwargs logger model model_id: model_kwargs: model_load_fn: model_reqs: pipeline response task: text tokenizer
  Usages: Any AutoModelForCausalLM AutoModelForSeq2SeqLM AutoTokenizer Callable CallbackManagerForLLMRun Extra ImportError List Mapping Optional SelfHostedPipeline ValueError __name__ args callbacks client cuda device device_count dict enforce_stop_tokens find_spec forbid from_pretrained get getLogger hardware hf_pipeline importlib inference_fn int kwargs langchain len llms logging manager model_id model_kwargs model_load_fn model_reqs pipeline_ref prompt property pydantic run_manager self self_hosted stop str super task torch transformers typing util utils warning

Python: /langchain/llms/stochasticai.py
  Classes: Config StochasticAI
  Methods: _call _identifying_params _llm_type build_extra validate_environment
  Variables: all_required_field_names api_url: completed extra extra[field_name] logger model_kwargs: params response_get response_get_json response_post response_post_json stochasticai_api_key stochasticai_api_key: text values["model_kwargs"] values["stochasticai_api_key"]
  Usages: Any CallbackManagerForLLMRun Dict Extra Field LLM List Mapping Optional ValueError __fields__ __name__ alias api_url base callbacks cls default_factory dict enforce_stop_tokens field field_name forbid get getLogger get_from_dict_or_env headers json kwargs langchain list llms logging manager model_kwargs pop post pre prompt property pydantic raise_for_status requests root_validator run_manager self sleep stop str time typing url utils values warning

Python: /langchain/llms/utils.py
  Functions: enforce_stop_tokens
  Usages: List join split stop str text typing

Python: /langchain/llms/vertexai.py
  Classes: VertexAI _VertexAICommon
  Methods: _call _default_params _enforce_stop_words _llm_type _predict _try_init_vertexai validate_environment
  Variables: allowed_params base_params client: credentials: location: max_output_tokens: model_name: params project: res stop stop: temperature: top_k: top_p: tuned_model_name tuned_model_name: values["client"]
  Usages: Any BaseModel CallbackManagerForLLMRun Dict ImportError LLM List Optional TYPE_CHECKING TextGenerationModel _LanguageModel _language_models base callbacks classmethod client cls credentials enforce_stop_tokens float from_pretrained get get_tuned_model init_vertexai int items kwargs langchain language_models llms location manager max_output_tokens model_name predict preview project prompt property pydantic raise_vertex_import_error root_validator run_manager self str temperature text top_k top_p typing utilities utils values vertexai

Python: /langchain/llms/writer.py
  Classes: Config Writer
  Methods: _call _default_params _identifying_params _llm_type validate_environment
  Variables: base_url base_url: best_of: extra logprobs: max_tokens: min_tokens: model_id: params presence_penalty: repetition_penalty: response stop: temperature: text top_p: values["writer_api_key"] values["writer_org_id"] writer_api_key writer_api_key: writer_org_id writer_org_id:
  Usages: Any CallbackManagerForLLMRun Dict Extra LLM List Mapping Optional base best_of bool callbacks cls enforce_stop_tokens float forbid get_from_dict_or_env headers int json kwargs langchain llms logprobs manager max_tokens min_tokens model_id post presence_penalty prompt property pydantic repetition_penalty requests root_validator run_manager self stop str temperature top_p typing url utils values

Python: /langchain/load/dump.py
  Functions: default dumpd dumps
  Usages: Any Dict Serializable bool indent isinstance json langchain load loads obj pretty serializable str to_json to_json_not_implemented typing

Python: /langchain/load/load.py
  Functions: loads
  Classes: Reviver
  Methods: __call__ __init__
  Variables: [*namespace, [key] cls kwargs mod self.secrets_map
  Usages: Any Dict KeyError NotImplementedError Optional Serializable ValueError dict get getattr import_module importlib issubclass join json key langchain len load name namespace object_hook secrets_map self serializable str text typing value

Python: /langchain/load/serializable.py
  Functions: _replace_secrets to_json_not_implemented
  Classes: BaseSerialized Serializable SerializedConstructor SerializedNotImplemented SerializedSecret
  Methods: __init__ lc_attributes lc_namespace lc_secrets lc_serializable to_json to_json_not_implemented
  Variables: [*parts, _id _id: current current[last] current[part] id: kwargs: lc: lc_kwargs lc_kwargs: result secrets self.lc_kwargs this type:
  Usages: ABC Any BaseModel Dict Exception Field List Literal TypedDict Union __class__ __exclude_fields__ __module__ __name__ abc bool cast cls copy default_factory dict exclude get getattr hasattr int items kwargs last mro obj object part parts path property pydantic repr root secret_id secrets_map self split str super type typing update

Python: /langchain/memory/__init__.py
  Variables: __all__
  Usages: CassandraChatMessageHistory ChatMessageHistory CombinedMemory ConversationBufferMemory ConversationBufferWindowMemory ConversationEntityMemory ConversationKGMemory ConversationStringBufferMemory ConversationSummaryBufferMemory ConversationSummaryMemory ConversationTokenBufferMemory CosmosDBChatMessageHistory DynamoDBChatMessageHistory FileChatMessageHistory InMemoryEntityStore MomentoChatMessageHistory MongoDBChatMessageHistory PostgresChatMessageHistory ReadOnlySharedMemory RedisChatMessageHistory RedisEntityStore SQLiteEntityStore SimpleMemory VectorStoreRetrieverMemory buffer buffer_window cassandra chat_message_histories combined cosmos_db dynamodb entity file in_memory langchain memory mongodb postgres readonly redis simple summary summary_buffer token_buffer vectorstore

Python: /langchain/memory/buffer.py
  Classes: ConversationBufferMemory ConversationStringBufferMemory
  Methods: buffer clear load_memory_variables memory_variables save_context validate_chains
  Variables: ai_prefix: buffer: human human_prefix: input_key: memory_key: output_key output_key: prompt_input_key self.buffer
  Usages: Any BaseChatMemory BaseMemory Dict List Optional ValueError ai_prefix chat_memory cls get get_buffer_string get_prompt_input_key human_prefix input_key inputs join keys langchain len list memory memory_key messages outputs property pydantic return_messages root_validator schema self str typing utils values

Python: /langchain/memory/buffer_window.py
  Classes: ConversationBufferWindowMemory
  Methods: buffer load_memory_variables memory_variables
  Variables: ai_prefix: buffer buffer: human_prefix: memory_key:
  Usages: Any BaseChatMemory BaseMessage Dict List ai_prefix chat_memory get_buffer_string human_prefix inputs int langchain memory memory_key messages property return_messages schema self str typing

Python: /langchain/memory/chat_memory.py
  Classes: BaseChatMemory
  Methods: _get_input_output clear save_context
  Variables: chat_memory: input_key: input_str, output_key output_key: prompt_input_key return_messages:
  Usages: ABC Any BaseChatMessageHistory BaseMemory ChatMessageHistory Dict Field Optional Tuple ValueError abc add_ai_message add_user_message bool chat_memory chat_message_histories default_factory get_prompt_input_key in_memory input_key input_str inputs keys langchain len list memory memory_variables output_str outputs pydantic return_messages schema self str typing utils

Python: /langchain/memory/combined.py
  Classes: CombinedMemory
  Methods: check_input_key check_repeated_memory_variable clear load_memory_variables memory_variables save_context
  Variables: all_variables: data memories: memory_data memory_data: memory_variables overlap
  Usages: Any BaseChatMemory BaseMemory Dict List Set ValueError all_variables chat_memory cls extend input_key inputs intersection isinstance langchain memories memory outputs property pydantic schema self set str typing val validator value warn warnings

Python: /langchain/memory/entity.py
  Classes: BaseEntityStore ConversationEntityMemory InMemoryEntityStore RedisEntityStore SQLiteEntityStore
  Methods: __init__ _create_table_if_not_exists batched buffer clear delete exists full_key_prefix full_table_name get load_memory_variables memory_variables save_context set
  Variables: ai_prefix: buffer buffer: buffer_string chain chat_history_key: create_table_query cursor entities entity_cache: entity_extraction_prompt: entity_store: entity_summaries entity_summaries[entity] entity_summarization_prompt: existing_summary human_prefix: input_data iterator key_prefix: llm: logger output prompt_input_key query recall_ttl: redis_client: res result self.conn self.entity_cache self.key_prefix self.recall_ttl self.redis_client self.session_id self.store[key] self.table_name self.ttl session_id: store: table_name: ttl: value
  Usages: ABC Any BaseChatMemory BaseLanguageModel BaseMessage BaseModel BasePromptTemplate ConnectionError Dict ENTITY_EXTRACTION_PROMPT ENTITY_SUMMARIZATION_PROMPT Field ImportError Iterable LLMChain List Optional Redis __name__ abc abstractmethod ai_prefix args base base_language batch batch_size bool chains chat_history_key chat_memory conn connect db_file debug decode_responses default default_factory entity entity_cache entity_extraction_prompt entity_store entity_summarization_prompt error exceptions execute fetchone from_url getLogger get_buffer_string get_prompt_input_key getex history human_prefix input input_key inputs int islice iter iterable itertools key key_prefix keybatch kwargs langchain list llm logging memory messages outputs predict prompt prompts property pydantic recall_ttl redis redis_client return_messages scan_iter schema self session_id split sqlite3 store str strip summary super table_name ttl typing url utils

Python: /langchain/memory/kg.py
  Classes: ConversationKGMemory
  Methods: _get_and_update_kg _get_current_entities _get_prompt_input_key _get_prompt_output_key clear get_current_entities get_knowledge_triplets load_memory_variables memory_variables save_context
  Variables: ai_prefix: buffer_string chain context context: entities entity_extraction_prompt: human_prefix: kg: knowledge knowledge_extraction_prompt: llm: memory_key: output prompt_input_key summary summary_message_cls: summary_strings
  Usages: Any BaseChatMemory BaseLanguageModel BaseMessage BasePromptTemplate Dict ENTITY_EXTRACTION_PROMPT Field KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT KnowledgeTriple LLMChain List NetworkxEntityGraph SystemMessage Type Union ValueError add_triple ai_prefix append base base_language chains chat_memory content default_factory entity entity_extraction_prompt get_buffer_string get_entities get_entity_knowledge get_prompt_input_key graphs history human_prefix input input_key input_string inputs int join keys knowledge_extraction_prompt langchain len list llm memory memory_key messages networkx_graph output_key outputs parse_triples predict prompt prompts property pydantic return_messages schema self str summary_message_cls super text triple typing utils verbose

Python: /langchain/memory/motorhead_memory.py
  Classes: MotorheadMemory
  Methods: __get_headers init load_memory_variables memory_variables save_context
  Variables: MANAGED_URL api_key: client_id: context context: headers headers["x-metal-api-key"] headers["x-metal-client-id"] input_str, is_managed memory_key messages res res_data self.context session_id: timeout url:
  Usages: Any BaseChatMemory Dict List Optional ValueError _get_input_output add_ai_message add_user_message api_key chat_memory client_id get get_buffer_string input_str inputs json langchain memory message output_str outputs post property requests return_messages reversed schema self session_id str super typing url values

Python: /langchain/memory/prompt.py
  Variables: ENTITY_EXTRACTION_PROMPT ENTITY_MEMORY_CONVERSATION_TEMPLATE ENTITY_SUMMARIZATION_PROMPT KG_TRIPLE_DELIMITER KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT SUMMARY_PROMPT _DEFAULT_ENTITY_EXTRACTION_TEMPLATE _DEFAULT_ENTITY_MEMORY_CONVERSATION_TEMPLATE _DEFAULT_ENTITY_SUMMARIZATION_TEMPLATE _DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE _DEFAULT_SUMMARIZER_TEMPLATE
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/memory/readonly.py
  Classes: ReadOnlySharedMemory
  Methods: clear load_memory_variables memory_variables save_context
  Variables: memory:
  Usages: Any BaseMemory Dict List inputs langchain memory outputs property schema self str typing

Python: /langchain/memory/simple.py
  Classes: SimpleMemory
  Methods: clear load_memory_variables memory_variables save_context
  Variables: memories:
  Usages: Any BaseMemory Dict List dict inputs keys langchain list memories outputs property schema self str typing

Python: /langchain/memory/summary.py
  Classes: ConversationSummaryMemory SummarizerMixin
  Methods: clear from_messages load_memory_variables memory_variables predict_new_summary save_context validate_prompt_input_variables
  Variables: ai_prefix: buffer buffer: chain expected_keys human_prefix: llm: memory_key: new_lines obj obj.buffer prompt: prompt_variables self.buffer summary_message_cls:
  Usages: Any BaseChatMemory BaseChatMessageHistory BaseLanguageModel BaseMessage BaseModel BasePromptTemplate Dict LLMChain List SUMMARY_PROMPT SystemMessage Type ValueError ai_prefix annotations base base_language chains chat_memory classmethod cls content existing_summary get_buffer_string human_prefix input_variables inputs int kwargs langchain len llm memory memory_key messages outputs predict prompt prompts property pydantic range return_messages root_validator schema self set str summarize_step summary summary_message_cls super typing values

Python: /langchain/memory/summary_buffer.py
  Classes: ConversationSummaryBufferMemory
  Methods: buffer clear load_memory_variables memory_variables prune save_context validate_prompt_input_variables
  Variables: buffer curr_buffer_length expected_keys final_buffer final_buffer: first_messages: max_token_limit: memory_key: moving_summary_buffer: prompt_variables pruned_memory self.moving_summary_buffer
  Usages: Any BaseChatMemory BaseMessage Dict List SummarizerMixin ValueError ai_prefix append chat_memory cls content first_messages get_buffer_string get_num_tokens_from_messages human_prefix input_variables inputs int langchain llm max_token_limit memory memory_key messages moving_summary_buffer outputs pop predict_new_summary property pydantic return_messages root_validator schema self set str summary summary_message_cls super typing values

Python: /langchain/memory/token_buffer.py
  Classes: ConversationTokenBufferMemory
  Methods: buffer load_memory_variables memory_variables save_context
  Variables: ai_prefix: buffer buffer: curr_buffer_length final_buffer final_buffer: human_prefix: llm: max_token_limit: memory_key: pruned_memory
  Usages: Any BaseChatMemory BaseLanguageModel BaseMessage Dict List ai_prefix append base_language chat_memory get_buffer_string get_num_tokens_from_messages human_prefix inputs int langchain llm max_token_limit memory memory_key messages outputs pop property return_messages schema self str super typing

Python: /langchain/memory/utils.py
  Functions: get_prompt_input_key
  Variables: prompt_input_keys
  Usages: Any Dict List ValueError difference get_buffer_string inputs langchain len list memory_variables schema set str typing

Python: /langchain/memory/vectorstore.py
  Classes: VectorStoreRetrieverMemory
  Methods: _form_documents _get_prompt_input_key clear load_memory_variables memory_variables save_context
  Variables: docs documents filtered_inputs input_key input_key: memory_key: page_content query result result: retriever: return_docs: texts
  Usages: Any BaseMemory Dict Document Field List Optional Union VectorStoreRetriever add_documents base bool chat_memory doc exclude get_prompt_input_key get_relevant_documents inputs items join langchain list memory memory_key outputs property pydantic retriever return_docs schema self str typing utils vectorstores

Python: /langchain/output_parsers/__init__.py
  Variables: __all__
  Usages: CommaSeparatedListOutputParser DatetimeOutputParser GuardrailsOutputParser ListOutputParser OutputFixingParser PydanticOutputParser RegexDictParser RegexParser ResponseSchema RetryOutputParser RetryWithErrorOutputParser StructuredOutputParser datetime fix langchain list output_parsers pydantic rail_parser regex regex_dict retry structured

Python: /langchain/output_parsers/boolean.py
  Classes: BooleanOutputParser
  Methods: _type parse
  Variables: cleaned_text false_val: true_val:
  Usages: BaseOutputParser ValueError bool false_val langchain property schema self str strip text true_val upper

Python: /langchain/output_parsers/combining.py
  Classes: CombiningOutputParser
  Methods: _type get_format_instructions parse validate_parsers
  Variables: initial output parsers parsers: subsequent texts
  Usages: Any BaseOutputParser Dict List ValueError annotations cls dict join langchain len parser property pydantic root_validator schema self split str strip text txt typing update values zip

Python: /langchain/output_parsers/datetime.py
  Functions: _generate_random_datetime_strings
  Classes: DatetimeOutputParser
  Methods: _type get_format_instructions parse
  Variables: date_string delta examples format: random_delta
  Usages: BaseOutputParser List OutputParserException ValueError append comma_list datetime days end_date format int langchain now pattern property random range response schema seconds self start_date str strftime strip strptime timedelta total_seconds typing uniform utils

Python: /langchain/output_parsers/enum.py
  Classes: EnumOutputParser
  Methods: _valid_values get_format_instructions parse raise_deprecation
  Variables: enum enum:
  Usages: Any BaseOutputParser Dict Enum List OutputParserException Type ValueError all cls isinstance join langchain property pydantic response root_validator schema self str strip typing value values

Python: /langchain/output_parsers/fix.py
  Classes: OutputFixingParser
  Methods: _type from_llm get_format_instructions parse
  Variables: T chain new_completion parsed_completion parser: retry_chain:
  Usages: BaseLanguageModel BaseOutputParser BasePromptTemplate LLMChain NAIVE_FIX_PROMPT OutputParserException TypeVar annotations base base_language chains classmethod cls completion error instructions langchain llm output_parsers parser prompt prompts property repr retry_chain run schema self str typing

Python: /langchain/output_parsers/format_instructions.py
  Variables: PYDANTIC_FORMAT_INSTRUCTIONS STRUCTURED_FORMAT_INSTRUCTIONS

Python: /langchain/output_parsers/json.py
  Functions: parse_and_check_json_markdown parse_json_markdown
  Variables: json_obj json_str match parsed
  Usages: DOTALL JSONDecodeError List OutputParserException annotations dict expected_keys group json json_string key langchain loads schema search str strip text typing

Python: /langchain/output_parsers/list.py
  Classes: CommaSeparatedListOutputParser ListOutputParser
  Methods: _type get_format_instructions parse
  Usages: BaseOutputParser List abc abstractmethod annotations langchain property schema self split str strip text typing

Python: /langchain/output_parsers/loading.py
  Functions: load_output_parser
  Variables: _config config["output_parsers"] output_parser output_parser_type
  Usages: RegexParser ValueError config dict langchain output_parsers regex

Python: /langchain/output_parsers/prompts.py
  Variables: NAIVE_FIX NAIVE_FIX_PROMPT
  Usages: PromptTemplate from_template langchain prompt prompts

Python: /langchain/output_parsers/pydantic.py
  Classes: PydanticOutputParser
  Methods: _type get_format_instructions parse
  Variables: T json_object json_str match msg name pydantic_object: reduced_schema schema schema_str
  Usages: BaseModel BaseOutputParser DOTALL IGNORECASE JSONDecodeError MULTILINE OutputParserException PYDANTIC_FORMAT_INSTRUCTIONS Type TypeVar ValidationError __name__ bound dumps format format_instructions group json langchain loads output_parsers parse_obj property pydantic pydantic_object search self str strict strip text typing

Python: /langchain/output_parsers/rail_parser.py
  Classes: GuardrailsOutputParser
  Methods: _type from_rail from_rail_string get_format_instructions parse
  Variables: guard:
  Usages: Any BaseOutputParser Dict Guard ImportError ValueError annotations classmethod cls format_instructions guard guardrails int langchain num_reasks property rail_file rail_str raw_prompt schema self str text typing

Python: /langchain/output_parsers/regex.py
  Classes: RegexParser
  Methods: _type parse
  Variables: default_output_key: match output_keys: regex:
  Usages: BaseOutputParser Dict List Optional ValueError annotations default_output_key enumerate group key langchain output_keys property regex schema search self str text typing

Python: /langchain/output_parsers/regex_dict.py
  Classes: RegexDictParser
  Methods: _type parse
  Variables: matches no_update_value: output_key_to_format: regex_pattern: result result[output_key] specific_regex
  Usages: BaseOutputParser Dict Optional ValueError annotations escape expected_format findall format items langchain len no_update_value output_key output_key_to_format property regex_pattern schema self str text typing

Python: /langchain/output_parsers/retry.py
  Classes: RetryOutputParser RetryWithErrorOutputParser
  Methods: _type from_llm get_format_instructions parse parse_with_prompt
  Variables: NAIVE_COMPLETION_RETRY NAIVE_COMPLETION_RETRY_WITH_ERROR NAIVE_RETRY_PROMPT NAIVE_RETRY_WITH_ERROR_PROMPT T chain new_completion parsed_completion parser: retry_chain:
  Usages: BaseLanguageModel BaseOutputParser BasePromptTemplate LLMChain NotImplementedError OutputParserException PromptTemplate PromptValue TypeVar annotations base base_language chains classmethod cls completion error from_template langchain llm parser prompt prompt_value prompts property repr retry_chain run schema self str to_string typing

Python: /langchain/output_parsers/structured.py
  Functions: _get_sub_string
  Classes: ResponseSchema StructuredOutputParser
  Methods: _type from_response_schemas get_format_instructions parse
  Variables: description: expected_keys line_template name: response_schemas: schema_str type:
  Usages: Any BaseModel BaseOutputParser List STRUCTURED_FORMAT_INSTRUCTIONS annotations classmethod cls description format format_instructions join json langchain name output_parsers parse_and_check_json_markdown property pydantic response_schemas schema self str text type typing

Python: /langchain/prompts/__init__.py
  Variables: __all__
  Usages: AIMessagePromptTemplate BaseChatPromptTemplate BasePromptTemplate ChatMessagePromptTemplate ChatPromptTemplate FewShotPromptTemplate FewShotPromptWithTemplates HumanMessagePromptTemplate MessagesPlaceholder Prompt PromptTemplate StringPromptTemplate SystemMessagePromptTemplate base chat few_shot few_shot_with_templates langchain load_prompt loading prompt prompts

Python: /langchain/prompts/base.py
  Functions: _get_jinja2_variables_from_template check_valid_template jinja2_formatter validate_jinja2
  Classes: BasePromptTemplate Config StringPromptTemplate StringPromptValue
  Methods: _merge_partial_and_user_variables _prompt_type dict format format_prompt lc_serializable partial save to_messages to_string validate_variable_names
  Variables: DEFAULT_FORMATTER_MAPPING: DEFAULT_VALIDATOR_MAPPING: arbitrary_types_allowed ast directory_path env error_message extra extra_variables input_variables: input_variables_set missing_variables output_parser: overall partial_kwargs partial_variables: prompt_dict prompt_dict["_type"] prompt_dict["input_variables"] prompt_dict["partial_variables"] save_path text: valid_formats valid_variables validator_func variables
  Usages: ABC Any BaseMessage BaseOutputParser Callable DEFAULT_FORMATTER_MAPPING DEFAULT_VALIDATOR_MAPPING Dict Environment Extra Field HumanMessage ImportError KeyError List Mapping NotImplementedError Optional Path PromptValue Serializable Set Template Union ValueError __dict__ abc abstractmethod annotations bool cls content copy default_factory default_flow_style difference dump exist_ok file_path find_undeclared_variables forbid formatter formatting indent input_variables intersection isinstance items jinja2 json kwargs langchain list load meta mkdir open output_parser parent parents parse partial_variables pathlib property pydantic render root_validator schema self serializable set str strip suffix super template template_format text type typing validate_input_variables values yaml

Python: /langchain/prompts/chat.py
  Classes: AIMessagePromptTemplate BaseChatPromptTemplate BaseMessagePromptTemplate BaseStringMessagePromptTemplate ChatMessagePromptTemplate ChatPromptTemplate ChatPromptValue HumanMessagePromptTemplate MessagesPlaceholder SystemMessagePromptTemplate
  Methods: _prompt_type format format_messages format_prompt from_messages from_role_strings from_strings from_template from_template_file input_variables lc_serializable partial save to_messages to_string
  Variables: MessagePromptTemplateT additional_kwargs: input_variables: input_vars kwargs message messages messages: prompt prompt: prompt_template rel_params result role: text value variable_name:
  Usages: ABC AIMessage Any BaseMessage BasePromptTemplate Callable ChatMessage Field HumanMessage List NotImplementedError Path PromptTemplate PromptValue Sequence Serializable StringPromptTemplate SystemMessage Tuple Type TypeVar Union ValueError _merge_partial_and_user_variables abc abstractmethod additional_kwargs annotations base bool bound buffer classmethod cls content default_factory dict extend file_path from_file get_buffer_string isinstance items langchain list load memory message_template pathlib prompts property pydantic role schema self serializable set str string_messages template template_file template_format typing update variable_name

Python: /langchain/prompts/few_shot.py
  Classes: Config FewShotPromptTemplate
  Methods: _get_examples _prompt_type check_examples_and_selector dict format lc_serializable template_is_valid
  Variables: arbitrary_types_allowed example_prompt: example_selector example_selector: example_separator: example_strings examples examples: extra input_variables: kwargs pieces prefix: suffix: template template_format: validate_template:
  Usages: Any BaseExampleSelector DEFAULT_FORMATTER_MAPPING Dict Extra List Optional PromptTemplate StringPromptTemplate ValueError _merge_partial_and_user_variables base bool check_valid_template cls example example_prompt example_separator forbid get input_variables join langchain list piece pre prefix prompt prompts property pydantic root_validator select_examples self str suffix super template_format typing validate_template values

Python: /langchain/prompts/few_shot_with_templates.py
  Classes: Config FewShotPromptWithTemplates
  Methods: _get_examples _prompt_type check_examples_and_selector dict format template_is_valid
  Variables: arbitrary_types_allowed example_prompt: example_selector example_selector: example_separator: example_strings examples examples: expected_input_variables extra input_variables input_variables: kwargs missing_vars pieces prefix prefix: prefix_kwargs suffix suffix: suffix_kwargs template template_format: validate_template:
  Usages: Any BaseExampleSelector DEFAULT_FORMATTER_MAPPING Dict Extra List Optional PromptTemplate StringPromptTemplate ValueError _merge_partial_and_user_variables base bool cls difference example example_prompt example_separator forbid get items join keys langchain piece pop pre prompt prompts property pydantic root_validator select_examples self set str super template_format typing validate_template values

Python: /langchain/prompts/loading.py
  Functions: _load_examples _load_few_shot_prompt _load_output_parser _load_prompt _load_prompt_from_file _load_template load_prompt load_prompt_from_config
  Variables: URL_BASE _config config config["example_prompt"] config["examples"] config["output_parser"] config[var_name] config_type examples file_path helper logger output_parser output_parser_type prompt_loader spec template template_path type_to_loader_dict
  Usages: BasePromptTemplate FewShotPromptTemplate PROMPT Path PromptTemplate RegexParser Union ValueError __dict__ __name__ base dict endswith exec few_shot file getLogger hub_result importlib isinstance json langchain list load loader loading logging module_from_spec open origin output_parsers path pathlib pop prompt prompts read regex safe_load spec_from_loader str suffix try_load_from_hub typing util utilities var_name warning yaml

Python: /langchain/prompts/pipeline.py
  Functions: _get_inputs
  Classes: PipelinePromptTemplate
  Methods: _prompt_type format format_prompt get_input_variables
  Variables: _inputs all_variables created_variables final_prompt: kwargs[k] pipeline_prompts: values["input_variables"]
  Usages: Any BaseChatPromptTemplate BasePromptTemplate Dict List PromptValue Tuple ValueError add base chat cls dict difference final_prompt format_messages input_variables inputs isinstance kwargs langchain list pipeline_prompts pre prompt prompts property pydantic root_validator schema self set str to_string typing update values

Python: /langchain/prompts/prompt.py
  Classes: Config PromptTemplate
  Methods: _prompt_type format from_examples from_file from_template lc_attributes template_is_valid
  Variables: Prompt all_inputs extra input_variables input_variables: kwargs partial_variables template template: template_format: validate_template:
  Usages: Any DEFAULT_FORMATTER_MAPPING Dict Extra Formatter List Path StringPromptTemplate Union _get_jinja2_variables_from_template _merge_partial_and_user_variables annotations base bool check_valid_template classmethod cls example_separator examples forbid join langchain list open parse pathlib prefix prompts property pydantic read root_validator self sorted str string suffix template_file template_format typing validate_template values var

Python: /langchain/retrievers/__init__.py
  Variables: __all__
  Usages: ArxivRetriever AwsKendraIndexRetriever AzureCognitiveSearchRetriever ChatGPTPluginRetriever ContextualCompressionRetriever DataberryRetriever ElasticSearchBM25Retriever KNNRetriever MergerRetriever MetalRetriever PineconeHybridSearchRetriever PubMedRetriever RemoteLangChainRetriever SVMRetriever SelfQueryRetriever TFIDFRetriever TimeWeightedVectorStoreRetriever VespaRetriever WeaviateHybridSearchRetriever WikipediaRetriever ZepRetriever arxiv aws_kendra_index_retriever azure_cognitive_search base chatgpt_plugin_retriever contextual_compression databerry elastic_search_bm25 knn langchain merger_retriever metal pinecone_hybrid_search pupmed remote_retriever retrievers self_query svm tfidf time_weighted_retriever vespa_retriever weaviate_hybrid_search wikipedia zep

Python: /langchain/retrievers/arxiv.py
  Classes: ArxivRetriever
  Methods: aget_relevant_documents get_relevant_documents
  Usages: ArxivAPIWrapper BaseRetriever Document List NotImplementedError arxiv langchain load query schema self str typing utilities

Python: /langchain/retrievers/aws_kendra_index_retriever.py
  Classes: AwsKendraIndexRetriever
  Methods: __init__ _clean_result _get_top_n_results _kendra_query aget_relevant_documents get_relevant_documents
  Variables: combined_text doc_excerpt doc_title doc_uri kclient: kendraindex: languagecode: r_count r_type res_text response self.k self.kclient self.kendraindex self.languagecode
  Usages: Any AttributeFilter BaseRetriever Dict Document IndexId List NotImplementedError QueryText count int kclient kendraindex kquery langchain languagecode len metadata page_content query range replace resp schema self str strip sub typing

Python: /langchain/retrievers/azure_cognitive_search.py
  Classes: AzureCognitiveSearchRetriever Config
  Methods: _asearch _build_search_url _headers _search aget_relevant_documents get_relevant_documents validate_environment
  Variables: aiosession: api_key: api_version: arbitrary_types_allowed base_url content_key: endpoint_path extra index_name: response response_json search_results search_url service_name: values["api_key"] values["index_name"] values["service_name"]
  Usages: BaseModel BaseRetriever ClientSession Dict Document Exception Extra List Optional aiohttp aiosession annotations api_key api_version cls content_key dict forbid get get_from_dict_or_env headers index_name json langchain loads metadata page_content pop pre property pydantic query requests result root_validator schema self service_name session status_code str text typing utils values

Python: /langchain/retrievers/chatgpt_plugin_retriever.py
  Classes: ChatGPTPluginRetriever Config
  Methods: _create_request aget_relevant_documents get_relevant_documents
  Variables: aiosession: arbitrary_types_allowed bearer_token: content docs filter: headers json res response results top_k: url url, url:
  Usages: BaseModel BaseRetriever ClientSession Document List Optional aiohttp aiosession annotations append bearer_token dict filter int langchain metadata page_content pop post pydantic query requests schema self session str top_k tuple typing

Python: /langchain/retrievers/contextual_compression.py
  Classes: Config ContextualCompressionRetriever
  Methods: aget_relevant_documents get_relevant_documents
  Variables: arbitrary_types_allowed base_compressor: base_retriever: compressed_docs docs extra
  Usages: BaseDocumentCompressor BaseModel BaseRetriever Document Extra List acompress_documents base base_compressor base_retriever compress_documents document_compressors forbid langchain list pydantic query retrievers schema self str typing

Python: /langchain/retrievers/databerry.py
  Classes: DataberryRetriever
  Methods: __init__ aget_relevant_documents get_relevant_documents
  Variables: api_key: data datastore_url: response self.api_key self.datastore_url self.top_k top_k:
  Usages: BaseRetriever ClientSession Document List Optional aiohttp api_key datastore_url headers int json langchain metadata page_content post query request requests schema self session str top_k typing

Python: /langchain/retrievers/elastic_search_bm25.py
  Classes: ElasticSearchBM25Retriever
  Methods: __init__ add_texts aget_relevant_documents create get_relevant_documents
  Variables: _id docs ids mappings query_dict request requests res self.client self.index_name settings
  Usages: Any BaseRetriever Document Elasticsearch ImportError Iterable List NotImplementedError ValueError annotations append body bool bulk classmethod client cls docstore document elasticsearch elasticsearch_url enumerate float helpers index index_name indices langchain page_content query refresh refresh_indices schema search self str text texts typing uuid uuid4

Python: /langchain/retrievers/knn.py
  Functions: create_index
  Classes: Config KNNRetriever
  Methods: aget_relevant_documents from_texts get_relevant_documents
  Variables: arbitrary_types_allowed denominator embeddings: index index: index_embeds normalized_similarities query_embeds relevancy_threshold: similarities sorted_ix texts: top_k_results
  Usages: Any BaseModel BaseRetriever Document Embeddings List NotImplementedError Optional ThreadPoolExecutor annotations argsort array base classmethod cls concurrent contexts dot embed_query embeddings executor float futures int keepdims kwargs langchain list map max min ndarray numpy page_content pydantic query relevancy_threshold row schema self sqrt str sum texts typing

Python: /langchain/retrievers/llama_index.py
  Classes: LlamaIndexGraphRetriever LlamaIndexRetriever
  Methods: aget_relevant_documents get_relevant_documents
  Variables: docs graph graph: index index: metadata query_config["response_mode"] query_configs query_configs: query_kwargs: response
  Usages: Any BaseGPTIndex BaseModel BaseRetriever ComposableGraph Dict Document Field ImportError List NotImplementedError QUERY_CONFIG_TYPE Response append base cast composability default_factory dict extra_info indices langchain list llama_index page_content pydantic query query_config query_kwargs response_mode schema self source_node source_nodes source_text str typing

Python: /langchain/retrievers/merger_retriever.py
  Classes: MergerRetriever
  Methods: __init__ aget_relevant_documents amerge_documents get_relevant_documents merge_documents
  Variables: max_docs merged_documents retriever_docs self.retrievers
  Usages: BaseRetriever Document List append doc docs langchain len max query range retriever retrievers schema self str typing zip

Python: /langchain/retrievers/metal.py
  Classes: MetalRetriever
  Methods: __init__ aget_relevant_documents get_relevant_documents
  Variables: final_results metadata results self.client: self.params
  Usages: Any BaseRetriever Document List Metal NotImplementedError Optional ValueError append client dict isinstance items langchain metal metal_sdk page_content params query schema search self str type typing

Python: /langchain/retrievers/milvus.py
  Functions: MilvusRetreiver
  Classes: MilvusRetriever
  Methods: __init__ add_texts aget_relevant_documents get_relevant_documents
  Variables: self.retriever self.store
  Usages: Any BaseRetriever DeprecationWarning Dict Document Embeddings List Milvus NotImplementedError Optional args as_retriever base collection_name connection_args consistency_level dict embedding_function embeddings kwargs langchain metadatas milvus query retriever schema search_kwargs search_params self store str texts typing vectorstores warn warnings

Python: /langchain/retrievers/pinecone_hybrid_search.py
  Functions: create_index hash_text
  Classes: Config PineconeHybridSearchRetriever
  Methods: add_texts aget_relevant_documents get_relevant_documents validate_environment
  Variables: _iterator alpha: arbitrary_types_allowed batch_ids batch_size context context_batch dense_embeds dense_vec dense_vec, embeddings: extra final_result i_end ids index: meta metadata_batch result s["values"] sparse_embeds sparse_encoder: sparse_vec sparse_vec["values"] top_k: vectors
  Usages: Any BaseModel BaseRetriever BaseSparseEncoder Dict Document Embeddings Extra ImportError List NotImplementedError Optional ValueError alpha append auto base base_sparse_encoder cls contexts dense dict doc_id embed_documents embed_query embeddings encode encode_documents encode_queries float forbid hashlib hexdigest hybrid hybrid_convex_scale include_metadata index int langchain len metadata metadatas min page_content pinecone_text pop pydantic query range res root_validator schema self sha256 sparse sparse_encoder sparse_vector str text texts top_k tqdm typing upsert values vector zip

Python: /langchain/retrievers/pupmed.py
  Classes: PubMedRetriever
  Methods: aget_relevant_documents get_relevant_documents
  Usages: BaseRetriever Document List NotImplementedError PubMedAPIWrapper langchain load_docs pupmed query schema self str typing utilities

Python: /langchain/retrievers/remote_retriever.py
  Classes: RemoteLangChainRetriever
  Methods: aget_relevant_documents get_relevant_documents
  Variables: headers: input_key: metadata_key: page_content_key: response response_key: result url:
  Usages: BaseModel BaseRetriever ClientSession Document List Optional aiohttp dict headers input_key json langchain metadata metadata_key page_content page_content_key post pydantic query request requests response_key schema self session str typing url

Python: /langchain/retrievers/svm.py
  Functions: create_index
  Classes: Config SVMRetriever
  Methods: aget_relevant_documents from_texts get_relevant_documents
  Variables: arbitrary_types_allowed clf denominator embeddings: index index: normalized_similarities query_embeds relevancy_threshold: similarities sorted_ix sorted_ix[0], texts: top_k_results y[0] zero_index
  Usages: Any BaseModel BaseRetriever C Document Embeddings LinearSVC List NotImplementedError Optional ThreadPoolExecutor annotations append argsort array base class_weight classmethod cls concatenate concurrent contexts decision_function embed_query embeddings executor fit float futures int kwargs langchain list map max max_iter min ndarray numpy page_content pydantic query relevancy_threshold row schema self shape sklearn str svm texts tol typing verbose where zeros

Python: /langchain/retrievers/tfidf.py
  Classes: Config TFIDFRetriever
  Methods: aget_relevant_documents from_documents from_texts get_relevant_documents
  Variables: arbitrary_types_allowed docs docs: metadatas query_vec results return_docs texts, tfidf_array tfidf_array: tfidf_params vectorizer vectorizer:
  Usages: Any BaseModel BaseRetriever Dict Document ImportError Iterable List NotImplementedError Optional TfidfVectorizer annotations argsort classmethod cls cosine_similarity dict documents feature_extraction fit_transform int kwargs langchain metadata metrics page_content pairwise pydantic query reshape schema self sklearn str text texts transform typing zip

Python: /langchain/retrievers/time_weighted_retriever.py
  Functions: _get_hours_passed
  Classes: Config TimeWeightedVectorStoreRetriever
  Methods: _get_combined_score aadd_documents add_documents aget_relevant_documents get_relevant_documents get_salient_docs
  Variables: arbitrary_types_allowed buffer_idx buffered_doc buffered_doc.metadata["last_accessed_at"] current_time decay_rate: default_salience: doc doc.metadata["buffer_idx"] doc.metadata["created_at"] doc.metadata["last_accessed_at"] docs_and_scores docs_and_scores: dup_docs hours_passed memory_stream: other_score_keys: rescored_docs result results results[buffer_idx] score search_kwargs: vectorstore:
  Usages: Any BaseModel BaseRetriever Dict Document Field List NotImplementedError Optional Tuple VectorStore append base copy datetime decay_rate deepcopy default default_factory default_salience dict document documents enumerate extend fetched_doc float get int key kwargs langchain len list memory_stream metadata now other_score_keys pydantic query ref_time relevance reverse schema search_kwargs self similarity_search_with_relevance_scores sort str time total_seconds typing update values vector_relevance vectorstore vectorstores

Python: /langchain/retrievers/vespa_retriever.py
  Classes: VespaRetriever
  Methods: __init__ _query aget_relevant_documents from_params get_relevant_documents get_relevant_documents_with_filter
  Variables: _fields _filter _sources app body body["hits"] body["query"] body["summary"] body["yql"] docs metadata metadata["id"] page_content response root self._application self._content_field self._metadata_fields self._query_body yql
  Usages: Any BaseRetriever Dict Document ImportError List Literal NotImplementedError Optional RuntimeError Sequence TYPE_CHECKING Union ValueError Vespa _application _content_field _metadata_fields _query_body annotations append application child classmethod cls content_field copy dumps format get hits int isinstance join json kwargs langchain list metadata_fields pop query schema self sources startswith status_code str typing url vespa

Python: /langchain/retrievers/weaviate_hybrid_search.py
  Classes: Config WeaviateHybridSearchRetriever
  Methods: __init__ _create_schema_if_missing add_documents aget_relevant_documents get_relevant_documents
  Variables: _id arbitrary_types_allowed class_obj data_properties docs extra ids metadata query_obj result self._client self._index_name self._query_attrs self._text_key self.alpha self.k text
  Usages: Any BaseRetriever Client Dict Document Extra ImportError List NotImplementedError Optional ValueError _client _index_name _query_attrs _text_key add_data_object alpha annotations append attributes batch bool client create_class create_schema_if_missing doc docstore document enumerate exists extend float forbid get get_valid_uuid index_name int isinstance kwargs langchain object page_content pop pydantic query res schema self str text_key type typing util uuid uuid4 weaviate where_filter with_hybrid with_limit with_where

Python: /langchain/retrievers/wikipedia.py
  Classes: WikipediaRetriever
  Methods: aget_relevant_documents get_relevant_documents
  Usages: BaseRetriever Document List NotImplementedError WikipediaAPIWrapper langchain load query schema self str typing utilities wikipedia

Python: /langchain/retrievers/zep.py
  Classes: ZepRetriever
  Methods: __init__ _search_result_to_doc aget_relevant_documents get_relevant_documents
  Variables: payload: results: self.session_id self.top_k self.zep_client
  Usages: BaseRetriever Dict Document ImportError List MemorySearchPayload MemorySearchResult Optional TYPE_CHECKING ValueError ZepClient annotations asearch_memory base_url dist int langchain limit message metadata page_content payload pop query results schema search_memory self session_id str text top_k typing url zep_client zep_python

Python: /langchain/retrievers/zilliz.py
  Functions: ZillizRetreiver
  Classes: ZillizRetriever
  Methods: __init__ add_texts aget_relevant_documents get_relevant_documents
  Variables: self.retriever self.store
  Usages: Any BaseRetriever DeprecationWarning Dict Document Embeddings List NotImplementedError Optional Zilliz args as_retriever base collection_name connection_args consistency_level dict embedding_function embeddings kwargs langchain metadatas query retriever schema search_kwargs search_params self store str texts typing vectorstores warn warnings zilliz

Python: /langchain/tools/__init__.py
  Variables: __all__
  Usages: AIPluginTool APIOperation AzureCogsFormRecognizerTool AzureCogsImageAnalysisTool AzureCogsSpeech2TextTool AzureCogsText2SpeechTool BaseTool BingSearchResults BingSearchRun BraveSearch ClickTool CopyFileTool CurrentWebPageTool DeleteFileTool DuckDuckGoSearchResults DuckDuckGoSearchRun ExtractHyperlinksTool ExtractTextTool FileSearchTool GetElementsTool GmailCreateDraft GmailGetMessage GmailGetThread GmailSearch GmailSendMessage GooglePlacesTool GoogleSearchResults GoogleSearchRun GoogleSerperResults GoogleSerperRun HumanInputRun IFTTTWebhook InfoPowerBITool ListDirectoryTool ListPowerBITool MetaphorSearchResults MoveFileTool NavigateBackTool NavigateTool OpenAPISpec OpenWeatherMapQueryRun PubmedQueryRun QueryPowerBITool ReadFileTool SceneXplainTool ShellTool SteamshipImageGenerationTool StructuredTool Tool VectorStoreQATool VectorStoreQAWithSourcesTool WikipediaQueryRun WolframAlphaQueryRun WriteFileTool YouTubeSearchTool ZapierNLAListActions ZapierNLARunAction api_models azure_cognitive_services base bing_search brave_search copy ddg_search delete file_management file_search gmail google_places google_search google_serper human ifttt langchain list_dir metaphor_search move openapi openapi_utils openweathermap playwright plugin powerbi pubmed read scenexplain search shell steamship_image_generation tool tools utils vectorstore wikipedia wolfram_alpha write youtube zapier

Python: /langchain/tools/base.py
  Functions: _create_subset_model _get_filtered_args create_schema_from_function tool
  Classes: BaseTool Config SchemaAnnotationError StructuredTool Tool ToolException ToolMetaclass _SchemaConfig
  Methods: __call__ __init__ __new__ _arun _make_tool _make_with_name _parse_input _partial _run _to_args_and_kwargs args arun from_function is_single_input raise_deprecation run
  Variables: _args_schema all_args arbitrary_types_allowed args, args_schema: args_schema_type callback_manager callback_manager: callbacks: coroutine: description description: extra field fields fields[field_name] func: handle_tool_error: inferred_model input_args key_ keys name name: new_arg_supported new_argument_supported observation parsed_input result return_direct: run_manager schema schema_annotations schema_type: tool_args, typehint_mandate valid_keys valid_properties validated values["callbacks"] verbose: verbose_
  Usages: ABC Any AsyncCallbackManager AsyncCallbackManagerForToolRun Awaitable BaseCallbackManager BaseModel Callable CallbackManager CallbackManagerForToolRun Callbacks DeprecationWarning Dict Exception Extra Field KeyboardInterrupt ModelMetaclass NotImplementedError Optional Tuple Type TypeError Union ValueError __doc__ __fields__ __name__ abc abstractmethod annotations args_schema base bases bool callable callbacks classmethod cls color config configure coroutine create_model dct default dict exclude field_info field_name field_names forbid func get get_child handle_tool_error infer_schema inspect isinstance items iter kwargs langchain len list main manager metaclass model model_name next on_tool_end on_tool_error on_tool_start parameters parse_obj pop property pydantic return_direct root_validator schema_type self signature start_color str strip super tool_args tool_input tool_kwargs tool_name tuple type_ typing validate validate_arguments values verbose warn warnings

Python: /langchain/tools/ifttt.py
  Classes: IFTTTWebhook
  Methods: _arun _run
  Variables: body response url:
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun NotImplementedError Optional base callbacks data langchain manager post requests run_manager self str text tool_input tools typing url

Python: /langchain/tools/plugin.py
  Functions: marshal_spec
  Classes: AIPlugin AIPluginTool AIPluginToolSchema ApiConfig
  Methods: _arun _run from_plugin_url from_url
  Variables: api: api_spec api_spec: args_schema: auth: contact_email: description description_for_human: description_for_model: has_user_authentication: legal_info_url: logo_url: name_for_human: name_for_model: open_api_spec open_api_spec_str plugin plugin: response schema_version: tool_input: type: url:
  Usages: AsyncCallbackManagerForToolRun BaseModel BaseTool CallbackManagerForToolRun JSONDecodeError Optional Type annotations api args_schema auth base bool callbacks classmethod cls contact_email description_for_human description_for_model dict get has_user_authentication json langchain legal_info_url loads logo_url manager name name_for_human name_for_model pydantic requests run_manager safe_load schema_version self str text tool_input tools txt type typing url yaml

Python: /langchain/utilities/__init__.py
  Variables: __all__
  Usages: ApifyWrapper ArxivAPIWrapper BashProcess BingSearchAPIWrapper DuckDuckGoSearchAPIWrapper GooglePlacesAPIWrapper GoogleSearchAPIWrapper GoogleSerperAPIWrapper GraphQLAPIWrapper LambdaWrapper MetaphorSearchAPIWrapper OpenWeatherMapAPIWrapper PowerBIDataset PubMedAPIWrapper PythonREPL SearxSearchWrapper SerpAPIWrapper SparkSQL TextRequestsWrapper TwilioAPIWrapper WikipediaAPIWrapper WolframAlphaAPIWrapper apify arxiv awslambda bash bing_search duckduckgo_search google_places_api google_search google_serper graphql langchain metaphor_search openweathermap powerbi pupmed python requests searx_search serpapi spark_sql twilio utilities wikipedia wolfram_alpha

Python: /langchain/utilities/apify.py
  Classes: ApifyWrapper
  Methods: acall_actor call_actor validate_environment
  Variables: actor_call apify_api_token apify_client: apify_client_async: values["apify_client"] values["apify_client_async"]
  Usages: Any ApifyClient ApifyClientAsync ApifyDatasetLoader BaseModel Callable Dict Document ImportError Optional ValueError actor actor_id apify_client apify_client_async base build call cls dataset_id dataset_mapping_function document_loaders get_from_dict_or_env int langchain memory_mbytes pydantic root_validator run_input self str timeout_secs typing utils values

Python: /langchain/utilities/arxiv.py
  Classes: ArxivAPIWrapper Config
  Methods: load run validate_environment
  Variables: ARXIV_MAX_QUERY_LENGTH arxiv_exceptions: arxiv_search: doc doc_content_chars_max: doc_file_name: docs docs: extra extra_metadata load_all_available_meta: load_max_docs: logger metadata results text: top_k_results: values["arxiv_exceptions"] values["arxiv_result"] values["arxiv_search"]
  Usages: Any ArxivError BaseModel Dict Document Extra FileNotFoundError HTTPError ImportError List Result Search UnexpectedEmptyPageError __name__ append arxiv arxiv_exceptions arxiv_search authors bool categories cls comment date debug doc_content_chars_max doc_file doc_file_name doi download_pdf entry_id f_ex fitz forbid getLogger get_text href int join journal_ref langchain link links load_all_available_meta load_max_docs logging max_results name open page page_content primary_category published pydantic query remove result root_validator schema self str summary text title top_k_results typing updated values

Python: /langchain/utilities/asyncio.py
  Variables: __all__
  Usages: async_timeout asyncio asyncio_timeout sys timeout version_info

Python: /langchain/utilities/awslambda.py
  Classes: Config LambdaWrapper
  Methods: run validate_environment
  Variables: answer awslambda_tool_description: awslambda_tool_name: extra function_name: lambda_client: payload_stream payload_string res values["function_name"] values["lambda_client"]
  Usages: Any BaseModel Dict Extra FunctionName ImportError InvocationType Optional Payload StopIteration awslambda_tool_description awslambda_tool_name boto3 client cls decode dumps forbid function_name invoke json lambda_client loads pydantic query read root_validator self str typing values

Python: /langchain/utilities/bash.py
  Functions: _lazy_import_pexpect
  Classes: BashProcess
  Methods: __init__ _initialize_persistent_process _run _run_persistent process_output run
  Variables: commands output pattern pexpect process self.process self.prompt self.return_err_output self.strip_newlines
  Usages: CalledProcessError EOF ImportError List PIPE STDOUT TIMEOUT TYPE_CHECKING Union ValueError after annotations before bool check command count decode encoding error escape exitstatus expect expect_exact isinstance join persistent platform prompt return_err_output self sendline shell spawn staticmethod stderr stdout str strip strip_newlines sub subprocess system timeout typing uuid uuid4

Python: /langchain/utilities/bibtex.py
  Classes: BibtexparserWrapper Config
  Methods: get_metadata load_bibtex_entries validate_environment
  Variables: OPTIONAL_FIELDS entries extra logger meta meta[field] publication url
  Usages: Any BaseModel Dict Extra ImportError List Mapping __name__ bibtexparser bool cls entry field file forbid get getLogger items load load_extra logging open path pydantic root_validator self str typing values

Python: /langchain/utilities/bing_search.py
  Classes: BingSearchAPIWrapper Config
  Methods: _bing_search_results results run validate_environment
  Variables: bing_search_url bing_search_url: bing_subscription_key bing_subscription_key: extra headers metadata_result metadata_results params response results search_results snippets values["bing_search_url"] values["bing_subscription_key"]
  Usages: BaseModel Dict Extra List append cls count dict forbid get get_from_dict_or_env int join json langchain len num_results pre pydantic query raise_for_status requests result root_validator search_term self str typing utils values

Python: /langchain/utilities/brave_search.py
  Classes: BraveSearchWrapper
  Methods: run
  Variables: api_key: base_url final_results headers params parsed_response req response search_kwargs: web_search_results
  Usages: BaseModel Exception Field PreparedRequest ValueError api_key append default_factory dict dumps get isinstance item json list prepare_url pydantic query requests search_kwargs self status_code str url

Python: /langchain/utilities/duckduckgo_search.py
  Classes: Config DuckDuckGoSearchAPIWrapper
  Methods: get_snippets results run to_metadata validate_environment
  Variables: extra max_results: region: results safesearch: snippets time:
  Usages: BaseModel Dict Extra ImportError List Optional ValueError class_validators cls ddg duckduckgo_search forbid int join len max_results num_results pydantic query region result root_validator safesearch self str time typing values

Python: /langchain/utilities/google_places_api.py
  Classes: Config GooglePlacesAPIWrapper
  Methods: fetch_place_details format_place_details run validate_environment
  Variables: address arbitrary_types_allowed details extra formatted_details google_map_client: gplaces_api_key gplaces_api_key: name num_to_return phone_number place_details places result search_results top_k_results: values["google_map_client"] values["gplaces_api_key"] website
  Usages: Any BaseModel Client Dict Exception Extra ImportError Optional append cls enumerate error forbid get get_from_dict_or_env google_map_client googlemaps int item join langchain len logging min place place_id pydantic query range root_validator self str top_k_results typing utils values

Python: /langchain/utilities/google_search.py
  Classes: Config GoogleSearchAPIWrapper
  Methods: _google_search_results results run validate_environment
  Variables: cse extra google_api_key google_api_key: google_cse_id google_cse_id: metadata_result metadata_result["snippet"] metadata_results res results search_engine: service siterestrict: snippets values["google_api_key"] values["google_cse_id"] values["search_engine"]
  Usages: Any BaseModel Dict Extra ImportError List Optional append bool build cls developerKey dict discovery execute forbid get get_from_dict_or_env googleapiclient int join kwargs langchain len list num num_results pydantic query result root_validator search_engine search_term self siterestrict str typing utils values

Python: /langchain/utilities/google_serper.py
  Classes: Config GoogleSerperAPIWrapper
  Methods: _async_google_serper_search_results _google_serper_api_results _parse_results _parse_snippets aresults arun results run validate_environment
  Variables: aiosession: answer_box arbitrary_types_allowed description entity_type gl: headers hl: params response result_key_for_type results search_results serper_api_key serper_api_key: snippets tbs: title type: url values["serper_api_key"]
  Usages: Any BaseModel ClientSession Dict List Literal Optional aiohttp aiosession append attribute class_validators cls dict get get_from_dict_or_env int items join json key kwargs langchain len main num post pydantic query raise_for_status replace requests result root_validator search_term search_type self session str tbs type typing typing_extensions utils value values

Python: /langchain/utilities/graphql.py
  Classes: Config GraphQLAPIWrapper
  Methods: _execute_query run validate_environment
  Variables: client custom_headers: document_node extra gql_client: gql_function: graphql_endpoint: headers result transport values["gql_client"] values["gql_function"]
  Usages: Any BaseModel Callable Client Dict Extra ImportError Optional RequestsHTTPTransport cls custom_headers dumps execute fetch_schema_from_transport forbid get gql gql_client gql_function graphql_endpoint indent json pre pydantic query requests root_validator self str typing url values

Python: /langchain/utilities/jira.py
  Classes: Config JiraAPIWrapper
  Methods: create list other parse_issues parse_projects project run search validate_environment
  Variables: assignee context created extra issues jira jira: jira_api_token jira_api_token: jira_instance_url jira_instance_url: jira_username jira_username: key name operations: params parsed parsed_issues parsed_issues_str parsed_projects parsed_projects_str priority projects rel_issues rel_key rel_summary rel_type result status style summary type values["jira"] values["jira_api_token"] values["jira_instance_url"] values["jira_username"]
  Usages: Any BaseModel Dict Exception Extra ImportError JIRA_CATCH_ALL_PROMPT JIRA_GET_ALL_PROJECTS_PROMPT JIRA_ISSUE_CREATE_PROMPT JIRA_JQL_PROMPT Jira List Optional ValueError append atlassian cloud cls dict exec fields forbid get_from_dict_or_env issue issue_create jql json keys langchain len loads mode operations password prompt pydantic query related_issue root_validator self str tools typing url username utils values

Python: /langchain/utilities/loading.py
  Functions: try_load_from_hub
  Variables: DEFAULT_REF HUB_PATH_RE T URL_BASE file full_url ref ref, remote_path
  Usages: Any Callable Optional Path PurePosixPath Set TemporaryDirectory TypeVar Union ValueError __str__ compile content environ format get groups isinstance kwargs loader match name open parse parts path pathlib remote_path_str requests status_code str suffix tempfile timeout tmpdirname typing urljoin urllib valid_prefix valid_suffixes write

Python: /langchain/utilities/max_compute.py
  Classes: MaxComputeAPIWrapper
  Methods: __init__ from_params lazy_query query
  Variables: access_id client secret_access_key self.client
  Usages: ImportError Iterator List ODPS Optional TYPE_CHECKING ValueError annotations classmethod cls count dict endpoint execute_sql exist_project get_from_env langchain list odps open_reader project reader record self str typing utils

Python: /langchain/utilities/metaphor_search.py
  Classes: Config MetaphorSearchAPIWrapper
  Methods: _clean_results _metaphor_search_results fetch results results_async validate_environment
  Variables: METAPHOR_API_URL cleaned_results data extra headers metaphor_api_key metaphor_api_key: params raw_search_results response results_json results_json_str search_results values["metaphor_api_key"]
  Usages: BaseModel ClientSession Dict Exception Extra List aiohttp append cls dict forbid get_from_dict_or_env int json langchain loads num_results post pre print pydantic query raise_for_status reason requests res result root_validator self session status str text typing utils values

Python: /langchain/utilities/openweathermap.py
  Classes: Config OpenWeatherMapAPIWrapper
  Methods: _format_weather_info run validate_environment
  Variables: clouds detailed_status extra heat_index humidity mgr observation openweathermap_api_key openweathermap_api_key: owm owm: rain temperature values["owm"] wind
  Usages: Any BaseModel Dict Extra ImportError OWM Optional base cls forbid get_from_dict_or_env langchain location pre pydantic pyowm root_validator self str tools typing utils values weather weather_at_place weather_manager

Python: /langchain/utilities/powerbi.py
  Functions: fix_table_name json_to_md
  Classes: Config PowerBIDataset
  Methods: _aget_schema _create_json_content _get_schema _get_schema_for_tables _get_tables_to_query _get_tables_todo aget_table_info arun fix_table_names get_schemas get_table_info get_table_names headers request_url run table_info token_or_credential_present
  Variables: BASE_URL _LOGGER aiosession: arbitrary_types_allowed credential: dataset_id: fixed_tables group_id: headers impersonated_user_name: non_existing_tables output_md response_json result sample_rows_in_table_info: schemas schemas: self.schemas[table] table_names: tables tables_requested tables_todo token token:
  Usages: Any BaseModel ClientAuthenticationError ClientSession Dict Exception Field Iterable List Optional ServerTimeoutError TYPE_CHECKING Timeout TokenCredential Union ValueError __name__ aiohttp aiosession allow_reuse annotations asyncio azure cls command core credential credentials dataset_id debug default default_factory dict endswith exc exceptions float gather getLogger get_token getenv group_id header impersonated_user_name int isinstance items join json json_contents key keys len list logging post pre property pydantic replace requests response root_validator row sample_rows_in_table_info schema self session startswith str table table_name table_names timeout typing validator value values warning

Python: /langchain/utilities/pupmed.py
  Classes: Config PubMedAPIWrapper
  Methods: _transform_doc load load_docs retrieve_article run
  Variables: ARXIV_MAX_QUERY_LENGTH abstract article articles base_url_efetch base_url_esearch doc_content_chars_max: docs document_dicts email: end_tag extra json_text load_all_available_meta: load_max_docs: logger max_retry pub_date result retry sleep_time start_tag summary text title top_k_results: url webenv xml_text
  Usages: BaseModel Document Exception Extra HTTPError List __name__ append bool code decode dict doc doc_content_chars_max email error forbid getLogger index int join json langchain len load_all_available_meta load_max_docs loads logging metadata page_content parse pop print pydantic query quote read request schema self sleep str time top_k_results typing uid urllib urlopen

Python: /langchain/utilities/python.py
  Classes: PythonREPL
  Methods: run
  Variables: globals: locals: old_stdout output sys.stdout
  Usages: BaseModel Dict Exception Field Optional StringIO alias command default_factory dict exec getvalue globals locals mystdout pydantic repr self stdout str sys typing

Python: /langchain/utilities/scenexplain.py
  Classes: SceneXplainAPIWrapper
  Methods: _describe_image run validate_environment
  Variables: description headers img payload response result scenex_api_key scenex_api_key: scenex_api_url: values["scenex_api_key"]
  Usages: BaseModel BaseSettings Dict Field cls env get get_from_dict_or_env image json langchain post pre pydantic raise_for_status requests root_validator scenex_api_url self str typing utils values

Python: /langchain/utilities/searx_search.py
  Functions: _get_default_params
  Classes: Config SearxResults SearxSearchWrapper
  Methods: __init__ __str__ _asearx_api_query _searx_api_query answers aresults arun disable_ssl_warnings results run validate_params
  Variables: _data _params _result: aiosession: categories categories: default engines engines: extra headers: json_data params params: params["categories"] params["engines"] query_suffix: raw_result res result results searx_host searx_host: self.__dict__ self._result toret unsecure: user_params values["params"] values["params"]["categories"] values["params"]["engines"] values["searx_host"] values["unsecure"]
  Usages: Any BaseModel ClientSession Dict Extra Field ImportError List Optional PrivateAttr ValueError __dict__ _result aiohttp aiosession bool cls data default_factory dict disable_warnings forbid get get_from_dict_or_env headers int isinstance join json kwargs langchain len list loads num_results print property pydantic query query_suffix requests response root_validator self session ssl startswith str super text typing unsecure urllib3 utils validator values verify

Python: /langchain/utilities/serpapi.py
  Classes: Config HiddenPrints SerpAPIWrapper
  Methods: __enter__ __exit__ _process_response aresults arun construct_url_and_params get_params results run validate_environment
  Variables: _params aiosession: arbitrary_types_allowed extra params params: params["output"] params["serp_api_key"] params["source"] res search search_engine: self._original_stdout serpapi_api_key serpapi_api_key: sys.stdout toret url url, values["search_engine"] values["serpapi_api_key"]
  Usages: Any BaseModel ClientSession Dict Extra Field GoogleSearch ImportError Optional Tuple ValueError _original_stdout aiohttp aiosession close cls default devnull dict forbid get get_dict get_from_dict_or_env json keys kwargs langchain open pydantic query response root_validator search_engine self serpapi session staticmethod stdout str sys typing utils values

Python: /langchain/utilities/spark_sql.py
  Classes: SparkSQL
  Methods: __init__ _convert_row_as_tuple _get_all_table_names _get_create_table_stmt _get_dataframe_results _get_sample_spark_rows from_uri get_table_info get_table_info_no_throw get_usable_table_names run run_no_throw
  Variables: all_table_names columns_str final_str missing_tables query rows sample_rows sample_rows_str self._all_tables self._ignore_tables self._include_tables self._sample_rows_in_table_info self._spark self._usable_tables spark statement table_info tables usable_tables using_clause_index
  Usages: Any DataFrame Exception ImportError Iterable List Optional PySparkException Row SparkSession TYPE_CHECKING TypeError ValueError _all_tables _ignore_tables _include_tables _sample_rows_in_table_info _spark _usable_tables annotations append asDict builder catalog classmethod cls collect command createtab_stmt database_uri dict difference engine_args errors fetch fields find getOrCreate ignore_tables include_tables int isinstance join kwargs limit list map name pyspark remote row sample_rows_in_table_info schema select self set setCurrentCatalog setCurrentDatabase sorted spark_session sql str table tableName table_name table_names tuple typing values

Python: /langchain/utilities/twilio.py
  Classes: Config TwilioAPIWrapper
  Methods: run validate_environment
  Variables: account_sid account_sid: arbitrary_types_allowed auth_token auth_token: client: extra from_number: message values["client"] values["from_number"]
  Usages: Any BaseModel Client Dict Extra ImportError Optional body client cls create forbid from_ from_number get_from_dict_or_env langchain messages pydantic rest root_validator self sid str twilio typing utils values

Python: /langchain/utilities/vertexai.py
  Functions: init_vertexai raise_vertex_import_error
  Variables: sdk
  Usages: Credentials ImportError Optional TYPE_CHECKING auth credentials google init location project str typing vertexai

Python: /langchain/utilities/wikipedia.py
  Classes: Config WikipediaAPIWrapper
  Methods: _fetch_page _formatted_page_summary _page_to_document load run validate_environment
  Variables: WIKIPEDIA_MAX_QUERY_LENGTH add_meta doc doc_content_chars_max: docs extra lang: load_all_available_meta: logger main_meta page_titles summaries top_k_results: values["wiki_client"] wiki_client:
  Usages: Any BaseModel Dict DisambiguationError Document Extra ImportError List Optional PageError __name__ append auto_suggest bool categories cls content doc_content_chars_max exceptions forbid getLogger images int join lang langchain links load_all_available_meta logging metadata page page_content page_title parent_id pydantic query references revision_id root_validator schema search sections self set_lang staticmethod str summary title top_k_results typing url values wiki_client wiki_page wikipedia

Python: /langchain/utilities/wolfram_alpha.py
  Classes: Config WolframAlphaAPIWrapper
  Methods: run validate_environment
  Variables: answer assumption client extra res values["wolfram_alpha_appid"] values["wolfram_client"] wolfram_alpha_appid wolfram_alpha_appid: wolfram_client:
  Usages: Any BaseModel Client Dict Extra ImportError Optional StopIteration cls forbid get_from_dict_or_env langchain next pods pydantic query results root_validator self str text typing utils values wolfram_client wolframalpha

Python: /langchain/utilities/zapier.py
  Classes: Config ZapierNLAWrapper
  Methods: _get_action_request _get_session list list_as_str preview preview_as_str run run_as_str validate_environment
  Variables: actions data extra params request response session session.params values["zapier_nla_api_key"] values["zapier_nla_oauth_access_token"] zapier_nla_api_base: zapier_nla_api_key zapier_nla_api_key: zapier_nla_api_key_default zapier_nla_oauth_access_token:
  Usages: BaseModel Dict Extra List Optional Request Session action_id args cls dumps forbid get get_from_dict_or_env headers instructions json kwargs langchain pre prepare_request pydantic raise_for_status requests root_validator self send str typing update utils values zapier_nla_api_base zapier_nla_oauth_access_token

Python: /langchain/vectorstores/__init__.py
  Variables: __all__
  Usages: AnalyticDB Annoy AtlasDB AwaDB AzureSearch Chroma Clickhouse ClickhouseSettings DeepLake DocArrayHnswSearch DocArrayInMemorySearch ElasticVectorSearch FAISS Hologres LanceDB MatchingEngine Milvus MongoDBAtlasVectorSearch MyScale MyScaleSettings OpenSearchVectorSearch Pinecone Qdrant Redis SKLearnVectorStore SingleStoreDB SupabaseVectorStore Tair Tigris Typesense Vectara VectorStore Weaviate Zilliz analyticdb annoy atlas awadb azuresearch base chroma clickhouse deeplake docarray elastic_vector_search faiss hologres lancedb langchain matching_engine milvus mongodb_atlas myscale opensearch_vector_search pinecone qdrant redis singlestoredb sklearn supabase tair tigris typesense vectara vectorstores weaviate zilliz

Python: /langchain/vectorstores/analyticdb.py
  Classes: AnalyticDB BaseModel CollectionStore EmbeddingStore QueryResult
  Methods: __init__ __post_init__ add_texts connect connection_string_from_db_params create_collection create_tables_if_not_exists delete_collection drop_tables from_documents from_texts get_by_name get_collection get_connection_string get_or_create similarity_search similarity_search_by_vector similarity_search_with_score similarity_search_with_score_by_vector
  Variables: ADA_TOKEN_COUNT Base EmbeddingStore: _LANGCHAIN_DEFAULT_COLLECTION_NAME __abstract__ __tablename__ cmetadata collection collection_id conn connection_string connection_string: created custom_id distance: docs docs_and_scores document embedding embedding: embedding_store embeddings engine filter_by filter_by_metadata filter_clauses ids kwargs["connection_string"] langchain_pg_embedding_vector_idx metadatas name results: self._conn self.collection_metadata self.collection_name self.connection_string self.embedding_function self.logger self.pre_delete_collection store texts uuid
  Usages: ARRAY Any Column Connection Dict Document Embeddings ForeignKey ImportError Index Iterable JSON List Logger Optional REAL Session String Tuple UUID ValueError VectorStore __name__ _conn add all and_ annotations append as_uuid astext back_populates base bool classmethod cls collection_metadata collection_name commit create_all create_engine data database debug declarative declarative_base default delete dialects dict distance doc docstore documents driver drop_all embed_documents embed_query embedding_function env_key error expression ext filter first float func getLogger get_from_dict_or_env host int items join key kwargs l2_distance label langchain limit list logger logging metadata nullable ondelete order_by orm page_content passive_deletes password port postgresql postgresql_using postgresql_with pre_delete_collection primary_key query relationship result results self session sql sqlalchemy str text typing user utils uuid1 uuid4 value vectorstores zip

Python: /langchain/vectorstores/annoy.py
  Functions: dependable_annoy_import
  Classes: Annoy
  Methods: __from __init__ add_texts from_embeddings from_texts load_local max_marginal_relevance_search max_marginal_relevance_search_by_vector process_index_results save_local similarity_search similarity_search_by_index similarity_search_by_vector similarity_search_with_score similarity_search_with_score_by_index similarity_search_with_score_by_vector
  Variables: DEFAULT_METRIC INDEX_METRICS _id annoy config_object config_object["ANNOY"] doc docs docs_and_scores docstore docstore, documents embedding embeddings idxs idxs, index index_to_id metadata metric mmr_selected path selected_indices self.docstore self.embedding_function self.index self.index_to_docstore_id self.metric texts
  Usages: AnnoyIndex Any Callable ConfigParser Dict Docstore Document Embeddings ImportError InMemoryDocstore Iterable List NotImplementedError Optional Path Tuple ValueError VectorStore add_item annotations append array base bool build classmethod cls configparser dict dist dists docstore_index document dtype dump emb embed_documents embed_query embedding_function enumerate exist_ok fetch_k file float float32 folder_path frozenset get_item_vector get_nns_by_item get_nns_by_vector idx in_memory include_distances index_to_docstore_id int isinstance kwargs lambda_mult langchain len list load makedirs maximal_marginal_relevance metadatas n_jobs numpy open page_content pathlib pickle prefault query range save search search_k self str text text_embeddings trees typing utils uuid uuid4 vectorstores zip

Python: /langchain/vectorstores/atlas.py
  Classes: AtlasDB
  Methods: __init__ add_texts create_index from_documents from_texts similarity_search
  Variables: _ATLAS_DEFAULT_ID_FIELD _embedding _embeddings all_index_kwargs all_index_kwargs[k] atlasDB data datas docs embedding embeddings ids logger metadatas metadatas[i]["text"] metadatas[i][AtlasDB._ATLAS_DEFAULT_ID_FIELD] modality neighbors, self._embedding_function self.project texts
  Usages: Any AtlasProject Document Embeddings ImportError Iterable List NotImplementedError Optional Type ValueError VectorStore __name__ _embedding_function _latest_project_state _validate_map_data_inputs add_embeddings add_text annotations api_key array base bool classmethod cls description dict doc docstore document documents embed_documents embedding_function enumerate getLogger get_data id_field index_kwargs indices int is_public items keys kwargs langchain len list logging login metadata name neighbor neighbors nomic numpy page_content persist_directory project projections queries query range rebuild_maps refresh reset_project_if_exists reshape self stack str text typing unique_id_field uuid uuid1 vector_search vectorstores wait_for_project_lock

Python: /langchain/vectorstores/awadb.py
  Classes: AwaDB
  Methods: __init__ add_texts from_documents from_texts load_local similarity_search similarity_search_by_vector similarity_search_with_relevance_scores similarity_search_with_score
  Variables: DEFAULT_TOPN L2_Norm _DEFAULT_TABLE_NAME added_results: awadb_client content dict_tmp dict_tmp["embedding_text"] doc: doc_no doc_tuple embedding embeddings llm logger meta_data meta_data[item_key] metadatas results: retrieval_docs score scores: self.added_doc_count self.awadb_client self.embedding_model show_results texts
  Usages: Add Any Client Create Document Embedding Embeddings ImportError Iterable LLMEmbedding List Load Optional Search TYPE_CHECKING Tuple Type ValueError VectorStore __len__ added_doc_count added_results annotations append awadb base bool classmethod client cls dict doc docstore document documents embed_documents embed_query embedding_model float getLogger int item_detail item_key kwargs langchain list llm_embedding log_and_data_dir logging logging_and_data_dir metadata page_content pow query results scores self str table_name text typing vectorstores

Python: /langchain/vectorstores/azuresearch.py
  Functions: _get_search_client
  Classes: AzureSearch AzureSearchVectorStoreRetriever Config
  Methods: __init__ add_texts aget_relevant_documents from_texts get_relevant_documents hybrid_search hybrid_search_with_score semantic_hybrid_search semantic_hybrid_search_with_score similarity_search validate_search_type vector_search vector_search_with_score
  Variables: FIELDS_CONTENT FIELDS_CONTENT_VECTOR FIELDS_ID FIELDS_METADATA MAX_UPLOAD_BATCH_SIZE arbitrary_types_allowed azure_search credential data docs docs_and_scores fields ids index index_client: key keys logger metadata response results search_type search_type: self.client self.embedding_function self.search_type self.semantic_configuration_name self.semantic_query_language semantic_answers semantic_answers_dict semantic_answers_dict[semantic_answer.key] semantic_settings vector_search vectorstore:
  Usages: Any AzureKeyCredential BaseModel BaseRetriever Callable Collection DefaultAzureCredential Dict Document Embeddings Exception Iterable List NotImplementedError Optional PrioritizedFields ResourceNotFoundError SearchClient SearchField SearchFieldDataType SearchIndex SearchIndexClient SearchableField SemanticConfiguration SemanticField SemanticSettings SimpleField Single String TYPE_CHECKING Tuple Type ValueError Vector VectorSearch VectorSearchAlgorithmConfiguration VectorStore algorithm_configurations all annotations append array azure azure_search_endpoint azure_search_key base base64 bytes classmethod client cls configurations core create_index credentials decode default dict dimensions doc docstore document documents dtype dumps embed_query embedding embedding_function embeddings endpoint enumerate env_key exceptions field_name filter filterable filters float float32 get getLogger get_answers get_from_env get_index highlights hnsw_parameters identity index_client index_name indexes int json kind kwargs langchain len loads logging metadatas models name numpy page_content prioritized_content_fields prioritized_fields pydantic query query_answer query_caption query_language query_type result retrievable root_validator schema search search_text searchable select self semantic_answer semantic_configuration_name semantic_query_language str succeeded text texts tolist top type typing upload_documents urlsafe_b64encode utils uuid uuid4 value values vector vector_search_configuration vectorstore vectorstores

Python: /langchain/vectorstores/base.py
  Classes: Config VectorStore VectorStoreRetriever
  Methods: _similarity_search_with_relevance_scores aadd_documents aadd_texts add_documents add_texts afrom_documents afrom_texts aget_relevant_documents amax_marginal_relevance_search amax_marginal_relevance_search_by_vector as_retriever asearch asimilarity_search asimilarity_search_by_vector asimilarity_search_with_relevance_scores from_documents from_texts get_relevant_documents max_marginal_relevance_search max_marginal_relevance_search_by_vector search similarity_search similarity_search_by_vector similarity_search_with_relevance_scores validate_search_type
  Variables: VST allowed_search_types: arbitrary_types_allowed docs docs_and_similarities func metadatas score_threshold search_kwargs: search_type search_type: texts vectorstore:
  Usages: ABC Any BaseModel BaseRetriever ClassVar Collection Dict Document Embeddings Field Iterable List NotImplementedError Optional Tuple Type TypeVar ValueError abc abstractmethod allowed_search_types annotations any asyncio base bound classmethod cls default_factory dict doc docstore document documents embedding embeddings fetch_k float functools get get_event_loop int isinstance kwargs lambda_mult langchain len metadata page_content partial pydantic query root_validator run_in_executor schema search_kwargs self similarity str typing values vectorstore warn warnings

Python: /langchain/vectorstores/chroma.py
  Functions: _results_to_docs _results_to_docs_and_scores
  Classes: Chroma
  Methods: __init__ __query_collection _similarity_search_with_relevance_scores add_texts delete_collection from_documents from_texts get max_marginal_relevance_search max_marginal_relevance_search_by_vector persist similarity_search similarity_search_by_vector similarity_search_with_score update_document
  Variables: DEFAULT_K _LANGCHAIN_DEFAULT_COLLECTION_NAME candidates chroma_collection docs docs_and_scores embedding embeddings ids logger metadata metadatas mmr_selected query_embedding results selected_results self._client self._client_settings self._collection self._embedding_function self._persist_directory text texts
  Usages: Any Client Dict Document Embeddings ImportError Iterable List NotEnoughElementsException Optional Settings TYPE_CHECKING Tuple Type ValueError VectorStore _client _client_settings _collection _embedding_function _persist_directory add annotations array base chroma_db_impl chromadb classmethod client client_settings cls collection_metadata collection_name config dict doc docstore document document_id documents dtype embed_documents embed_query embedding_function enumerate error errors fetch_k filter float float32 getLogger get_or_create_collection include int kwargs lambda_mul lambda_mult langchain list logging maximal_marginal_relevance n_results name numpy page_content persist_directory query query_embeddings query_texts range result self str typing update utils uuid uuid1 vectorstores where xor_args zip

Python: /langchain/vectorstores/clickhouse.py
  Functions: has_mul_sub_str
  Classes: Clickhouse ClickhouseSettings Config
  Methods: __getitem__ __init__ __repr__ _build_insert_sql _build_query_sql _insert add_texts drop escape_str from_texts metadata_column similarity_search similarity_search_by_vector similarity_search_with_relevance_scores
  Variables: _data _insert_query _repr colmap_ column_map: column_names column_names[colmap_["metadata"]] ctx database: dim env_file env_file_encoding env_prefix host: i_str ids index_param: index_params index_query_params: index_type: keys, logger metadatas metric: password: port: q_emb_str q_str self.BS self.client self.config self.dim self.dist_order self.embedding_function self.must_escape self.pgbar self.schema settings_strs table: transac username: where_str
  Usages: Any BS BaseSettings Dict Document Embeddings Exception ImportError Iterable List Optional Thread Tuple Union ValueError VectorStore annotations append args base batch_size bool classmethod clickhouse_connect client cls column_map command config database desc dict dist_order docstore document dumps embed_documents embed_query embedding embedding_function embeddings encode error float getLogger get_client getattr hashlib hexdigest host index index_param index_query_params index_type int isinstance item items join json keys kwargs langchain len list logging map metadata metric must_escape named_results page_content password pgbar port property pydantic q_emb query schema self set sha1 start str super table target text_ids texts threading topk total tqdm type typing username value values vectorstores zip

Python: /langchain/vectorstores/deeplake.py
  Functions: dp_filter vector_search
  Classes: DeepLake
  Methods: __init__ _search_helper add_texts delete delete_dataset force_delete_by_path from_texts ingest max_marginal_relevance_search max_marginal_relevance_search_by_vector persist similarity_search similarity_search_by_vector similarity_search_with_score
  Variables: _LANGCHAIN_DEFAULT_DEEPLAKE_PATH batch_size batched creds_args deeplake_dataset distance_metric_map distances docs elements emb embeddings embeds embeds: filter ids indices indices, k_search lambda_mult logger metadata metadatas nearest_indices query_emb scores self._deeplake self._embedding_function self.dataset_path self.ds self.ingestion_batch_size self.num_workers self.verbose text_list view
  Usages: Any Callable Dict Document Embeddings ImportError Iterable List MB Optional Sequence T Tuple ValueError VectorStore __name__ _deeplake _embedding_function all allow_empty annotations append argsort array axis base bool chunk_compression classmethod cls commit compute constants create_id_tensor create_sample_info_tensor create_shape_tensor create_tensor data data_vectors dataset_path deeplake delete_all dict distance_metric doc docstore document dot dtype embed_documents embed_query embedding embedding_function empty eval exists fetch_chunks fetch_k float float32 flush force functools get getLogger htype inf info ingestion_batch_size int isinstance items kwargs langchain large_ok len linalg list load logging lower max max_chunk_size maximal_marginal_relevance min ndarray norm num_workers numpy ord overwrite page_content partial path pop print query query_embedding range read_only return_score sample_in sample_indices sample_out score self shape sorted str summary texts token tolist typing use_maximal_marginal_relevance utils uuid uuid1 vectorstores verbose zip

Python: /langchain/vectorstores/elastic_vector_search.py
  Functions: _default_script_query _default_text_mapping
  Classes: ElasticKnnSearch ElasticVectorSearch
  Methods: __init__ _default_knn_mapping _default_knn_query add_texts client_search create_index from_texts knn_hybrid_search knn_search similarity_search similarity_search_with_score
  Variables: ((key, _id _ssl_verify dim docs_and_scores documents elasticsearch_url embedding embeddings filter hits ids index_name knn: knn["query_vector"] knn["query_vector_builder"] knn_query_body knn_query_body["boost"] mapping match_query_body metadata request requests res response script_query self.client self.embedding self.index_name self.query_field self.vector_query_field vectorsearch version_num
  Usages: ABC Any Dict Document Elasticsearch Embeddings ImportError Iterable List Mapping NotFoundError Optional TYPE_CHECKING Tuple Union ValueError VectorStore abc annotations append base basic_auth body bool bulk classmethod client cloud_id cls create dict dims docstore document elasticsearch embed_documents embed_query enumerate es_cloud_id es_connection es_password es_user exceptions fields float get get_from_env helpers hex hit index indices info int items key knn knn_boost kwargs langchain len list mappings metadatas model_id num_candidates page_content query query_boost query_field query_vector refresh refresh_indices search self size source ssl_verify staticmethod str text texts typing utils uuid uuid4 value vector_query_field vectorstores

Python: /langchain/vectorstores/faiss.py
  Functions: _default_relevance_score_fn dependable_faiss_import
  Classes: FAISS
  Methods: __add __from __init__ _similarity_search_with_relevance_scores add_embeddings add_texts from_embeddings from_texts load_local max_marginal_relevance_search max_marginal_relevance_search_by_vector merge_from save_local similarity_search similarity_search_by_vector similarity_search_with_score similarity_search_with_score_by_vector
  Variables: _id doc docs docs_and_scores docstore docstore, documents embedding embeddings faiss filtered_indices full_info ids index index_to_id indices metadata mmr_selected no_avx2 path scores, selected_indices self._normalize_L2 self.docstore self.embedding_function self.index self.index_to_docstore_id self.relevance_score_fn starting_len texts texts, vector
  Usages: AddableMixin Any Callable Dict Docstore Document Embeddings ImportError InMemoryDocstore IndexFlatL2 Iterable List Optional Path Tuple ValueError VectorStore _normalize_L2 add all annotations append array base bool classmethod cls dict document dtype dump embed_documents embed_query embedding_function enumerate environ exist_ok fetch_k filter float float32 folder_path format get getenv in_memory index_name index_to_docstore_id int isinstance items key kwargs lambda_mult langchain len load math maximal_marginal_relevance metadatas mkdir normalize_L2 numpy open page_content parents pathlib pickle query read_index reconstruct relevance_score_fn score scores search self sqrt str swigfaiss target target_id text text_embeddings typing update utils uuid uuid4 value values vectorstores write_index zip

Python: /langchain/vectorstores/hologres.py
  Classes: Hologres HologresWrapper
  Methods: __from __init__ __post_init__ add_embeddings add_texts connection_string_from_db_params create_table create_vector_extension from_documents from_embeddings from_existing_index from_texts get_by_id get_connection_string insert query_nearest_neighbours similarity_search similarity_search_by_vector similarity_search_with_score similarity_search_with_score_by_vector
  Variables: ADA_TOKEN_COUNT _LANGCHAIN_DEFAULT_TABLE_NAME conjuncts connection_string connection_string: docs docs_and_scores embedding embeddings filter_clause ids kwargs["connection_string"] metadatas params results: self.conn self.conn.autocommit self.connection_string self.cursor self.embedding_function self.logger self.ndims self.pre_delete_table self.storage self.table_name sql statement store texts
  Usages: Any Dict Document Embeddings Exception Iterable List Logger Optional Tuple Type ValueError VectorStore __name__ annotations append autocommit base bool classmethod cls commit conn connect cursor data database dict doc docstore document documents drop_if_exist dumps embed_documents embed_query embedding_function env_key exception execute fetchall filter float getLogger get_from_dict_or_env host int items join json key kwargs langchain list loads logger logging metadata ndims page_content password port pre_delete_collection pre_delete_table psycopg2 query result results self storage str table_name text text_embeddings tuple typing user utils uuid uuid1 val vectorstores zip

Python: /langchain/vectorstores/lancedb.py
  Classes: LanceDB
  Methods: __init__ add_texts from_texts similarity_search
  Variables: docs embedding embeddings ids instance metadata self._connection self._embedding self._id_key self._text_key self._vector_key
  Usages: Any Document Embeddings ImportError Iterable LanceTable List Optional ValueError VectorStore _connection _embedding _id_key _text_key _vector_key add annotations append base classmethod cls columns connection dict docstore document embed_documents embed_query enumerate id_key idx int isinstance iterrows kwargs lancedb langchain limit list metadatas page_content query row search self str text text_key texts to_df type typing uuid uuid4 vector_key vectorstores

Python: /langchain/vectorstores/matching_engine.py
  Classes: MatchingEngine
  Methods: __init__ _create_credentials_from_file _create_endpoint_by_id _create_index_by_id _download_from_gcs _get_default_embeddings _get_gcs_client _get_index_id _init_aiplatform _upload_to_gcs _validate_gcs_bucket _validate_google_libraries_installation add_texts from_components from_texts similarity_search
  Variables: blob bucket credentials embedding_query embeddings endpoint filename filename_prefix gcs_bucket_name gcs_client ids index jsons logger page_content response result_str results self.credentials self.embedding self.endpoint self.gcs_bucket_name self.gcs_client self.index self.project_id
  Usages: Any Client Credentials Document Embeddings ImportError Iterable List MatchingEngineIndex MatchingEngineIndexEndpoint NotImplementedError Optional TYPE_CHECKING TensorflowHubEmbeddings Type ValueError VectorStore aiplatform annotations append base classmethod cloud cls contents_delta_uri credentials_path data debug deployed_index_id deployed_indexes dict display_name doc docstore document download_as_string dumps embed_documents embedding endpoint_id from_service_account_file gcs_location getLogger get_bucket google index_endpoint_name index_id index_name init int join json json_credentials_path kwargs langchain len list location logging match metadatas num_neighbors oauth2 project project_id queries query region replace resource_name self service_account staging_bucket storage str super text texts time typing update_embeddings upload_from_string uuid uuid4 vectorstores zip

Python: /langchain/vectorstores/milvus.py
  Classes: Milvus
  Methods: __init__ _create_collection _create_connection_alias _create_index _create_search_params _extract_fields _get_index _init _load add_texts from_texts max_marginal_relevance_search max_marginal_relevance_search_by_vector similarity_search similarity_search_by_vector similarity_search_with_score similarity_search_with_score_by_vector
  Variables: DEFAULT_MILVUS_CONNECTION addr address: alias connection_args dim doc documents dtype embedding embeddings end fields given_address host: ids index index_type: insert_dict: insert_list logger meta metric_type: new_ordering ordered_result_embeddings output_fields pair param pks: port: res res: ret schema scores self._primary_field self._text_field self._vector_field self.alias self.col self.col: self.collection_name self.consistency_level self.default_search_params self.embedding_func self.fields: self.index_params self.search_params self.search_params["metric_type"] texts tmp_user total_count uri: user vector_db vectors vectors:
  Usages: Any Collection CollectionSchema DataType Document Embeddings FieldSchema INT64 ImportError Iterable List MilvusException NONE NotImplementedError Optional Tuple UNKNOWN Union VARCHAR ValueError VectorStore __name__ _primary_field _text_field _vector_field address annotations anns_field append array auto_id base batch_size bool classmethod cls col collection_name con connect connections consistency_level create_index data debug default_search_params dict docstore document drop drop_old embed_documents embed_query embedding_func embedding_function entity error expr extend fetch_k field_name float get getLogger get_connection_addr has_collection hex host index_params index_type indexes infer_dtype_bydata insert insert_dict int is_primary isinstance items key kwargs lambda_mult langchain len limit list list_connections load logging max_length maximal_marginal_relevance metadata metadatas metric_type min name numpy orm page_content pks pop port primary_keys pymilvus query range remove result score search search_params self setdefault split str timeout to_dict types typing uri using utility utils uuid uuid4 value vectorstores

Python: /langchain/vectorstores/mongodb_atlas.py
  Classes: MongoDBAtlasVectorSearch
  Methods: __init__ _insert_texts add_texts from_connection_string from_texts similarity_search similarity_search_with_score
  Variables: DEFAULT_INSERT_BATCH_SIZE MongoDBDocumentType _metadatas: batch_size client: collection cursor db_name, docs docs_and_scores embeddings insert_result knn_beta knn_beta["filter"] logger metadatas_batch pipeline result_ids score self._collection self._embedding self._embedding_key self._index_name self._text_key text texts_batch to_insert vecstore
  Usages: Any Collection Dict Document Embeddings Generator ImportError Iterable List MongoClient Optional TYPE_CHECKING Tuple TypeVar Union ValueError VectorStore __name__ _collection _embedding _embedding_key _index_name _metadatas _text_key aggregate annotations append base bound classmethod client cls collection_name connection_string db_name dict doc docstore document embed_documents embed_query embedding embedding_key enumerate extend float get getLogger index_name insert_many inserted_ids int kwargs langchain logging metadata metadatas namespace page_content pop post_filter_pipeline pre_filter pymongo query res self split str text_key texts typing vectorstores zip

Python: /langchain/vectorstores/myscale.py
  Functions: has_mul_sub_str
  Classes: Config MyScale MyScaleSettings
  Methods: __getitem__ __init__ __repr__ _build_istr _build_qstr _insert add_texts drop escape_str from_texts metadata_column similarity_search similarity_search_by_vector similarity_search_with_relevance_scores
  Variables: _data _i_str _repr colmap_ column_map: column_names column_names[colmap_["metadata"]] ctx database: dim env_file env_file_encoding env_prefix host: i_str ids index_param: index_params index_type: keys, logger metadatas metric: password: port: q_emb_str q_str schema_ self.BS self.client self.config self.dim self.dist_order self.embedding_function self.must_escape self.pgbar table: transac username: where_str
  Usages: Any BS BaseSettings Dict Document Embeddings Exception ImportError Iterable List Optional Thread Tuple ValueError VectorStore annotations append args base batch_size bool classmethod clickhouse_connect client cls column_map command config database desc dict dist_order docstore document dumps embed_query embedding embedding_function embeddings encode error float getLogger get_client getattr hashlib hexdigest host index index_param index_type int item items join json keys kwargs langchain len logging map metadata metric must_escape named_results page_content password pgbar port property pydantic q_emb query self set sha1 start str super table target text_ids texts threading topk total tqdm type typing username value values vectorstores zip

Python: /langchain/vectorstores/opensearch_vector_search.py
  Functions: __get_painless_scripting_source _approximate_search_query_with_boolean_filter _approximate_search_query_with_lucene_filter _bulk_ingest_embeddings _default_approximate_search_query _default_painless_scripting_query _default_script_query _default_scripting_text_mapping _default_text_mapping _get_kwargs_value _get_opensearch_client _import_bulk _import_not_found_error _import_opensearch _validate_embeddings_and_bulk_size
  Classes: OpenSearchVectorSearch
  Methods: __init__ add_texts from_texts similarity_search similarity_search_with_score
  Variables: IMPORT_OPENSEARCH_PY_ERROR MATCH_ALL_QUERY PAINLESS_SCRIPTING_SEARCH SCRIPT_SCORING_SEARCH _id boolean_filter bulk client dim docs_with_scores documents_with_scores ef_construction ef_search embedding embeddings engine hits ids index_name is_appx_search keys_list lucene_filter mapping metadata metadata_field not_found_error opensearch opensearch_url pre_filter request requests response search_query search_query["query"]["knn"][vector_field]["filter"] search_type self.client self.embedding_function self.index_name source source_value space_type subquery_clause text_field vector_field
  Usages: Any Dict Document Embeddings ImportError Iterable List NotFoundError OpenSearch Optional RuntimeError Tuple ValueError VectorStore annotations append base body bulk_size classmethod cls create default default_value dict doc docstore document embed_documents embed_query embedding_function embeddings_length enumerate exceptions float get get_from_dict_or_env helpers hex hit index indices int key kwargs langchain len list metadatas opensearchpy page_content pop query query_vector refresh search self str text texts typing utils uuid uuid4 vectorstores

Python: /langchain/vectorstores/pgvector.py
  Classes: BaseModel CollectionStore DistanceStrategy EmbeddingStore PGVector QueryResult
  Methods: __from __init__ __post_init__ add_embeddings add_texts connect connection_string_from_db_params create_collection create_tables_if_not_exists create_vector_extension delete_collection drop_tables from_documents from_embeddings from_existing_index from_texts get_by_name get_collection get_connection_string get_or_create similarity_search similarity_search_by_vector similarity_search_with_score similarity_search_with_score_by_vector
  Variables: ADA_TOKEN_COUNT Base COSINE DEFAULT_DISTANCE_STRATEGY EUCLIDEAN EmbeddingStore: IN MAX_INNER_PRODUCT _LANGCHAIN_DEFAULT_COLLECTION_NAME __abstract__ __tablename__ cmetadata collection collection_id conn connection_string connection_string: created custom_id distance: docs docs_and_scores document embedding embedding: embedding_store embeddings engine filter_by filter_by_metadata filter_clauses ids kwargs["connection_string"] metadatas name results: self._conn self.collection_metadata self.collection_name self.connection_string self.distance_strategy self.embedding_function self.logger self.pre_delete_collection statement store texts uuid value_case_insensitive
  Usages: Any Column Connection Dict Document Embeddings Enum Exception ForeignKey Iterable JSON List Logger Optional Session String Tuple Type UUID ValueError Vector VectorStore __name__ _conn add all and_ annotations append as_uuid asc astext back_populates base begin bool classmethod cls collection_metadata collection_name commit cosine_distance create_all create_engine data database debug declarative_base default delete dialects dict distance distance_strategy doc docstore documents driver drop_all embed_documents embed_query embedding_function enum env_key exception execute filter first float getLogger get_from_dict_or_env host in_ int isinstance items join key kwargs l2_distance label langchain limit list logger logging lower map max_inner_product metadata nullable ondelete order_by orm page_content passive_deletes password pgvector port postgresql pre_delete_collection primary_key query relationship result results self session sqlalchemy str text text_embeddings typing user utils uuid1 uuid4 value vectorstores warning zip

Python: /langchain/vectorstores/pinecone.py
  Classes: Pinecone
  Methods: __init__ add_texts from_existing_index from_texts similarity_search similarity_search_with_score
  Variables: docs docs_and_scores embedding embeds i_end ids ids_batch index indexes lines_batch logger metadata metadata[j][text_key] metadata[self._text_key] namespace query_obj results score self._embedding_function self._index self._namespace self._text_key text to_upsert
  Usages: Any Callable Document Embeddings ImportError Index Iterable List Optional Tuple ValueError VectorStore __name__ _embedding_function _index _namespace _text_key annotations append base batch_size classmethod cls dict doc docstore document embed_documents embed_query embedding_function embeddings enumerate filter float getLogger include_metadata index_name int isinstance join kwargs langchain len line list list_indexes logging metadatas min page_content pinecone pop query range res self str text_key texts top_k type typing upsert uuid uuid4 vectors vectorstores warning zip

Python: /langchain/vectorstores/qdrant.py
  Classes: Qdrant
  Methods: __init__ _build_condition _build_payloads _document_from_scored_point _embed_query _embed_texts _qdrant_filter_from_dict _similarity_search_with_relevance_scores add_texts from_texts max_marginal_relevance_search similarity_search similarity_search_with_score
  Variables: CONTENT_KEY DictFilter METADATA_KEY MetadataFilter added_ids batch_embeddings batch_ids batch_metadatas client collection_name distance_func embedding embeddings ids_iterator metadata metadatas_iterator mmr_selected out partial_embeddings payloads qdrant_filter results self._embeddings_function self.client: self.collection_name self.content_payload_key self.embeddings self.metadata_payload_key texts_iterator vector_size
  Usages: Any Batch Callable DeprecationWarning Dict Distance Document Embeddings FieldCondition Filter HnswConfigDiff ImportError InitFrom Iterable List MatchValue OptimizersConfigDiff Optional QdrantClient QuantizationConfig ReadConsistency SearchParams Sequence TYPE_CHECKING Tuple Type Union ValueError VectorParams VectorStore WalConfigDiff _embeddings_function _key _value annotations api_key append array base batch_size batch_texts bool classmethod cls common_types condition consistency construct content_payload_key conversions dict distance docstore document embed_documents embed_query embedding_function enumerate extend fetch_k filter float get grpc_port hasattr hex hnsw_config host http https ids init_from int isinstance islice itemgetter items iter itertools key kwargs lambda_mult langchain len limit list location map match maximal_marginal_relevance metadata_payload_key metadatas models must numpy offset on_disk_payload operator optimizers_config page_content path payload points port prefer_grpc prefix qdrant_client quantization_config query query_filter query_vector recreate_collection replication_factor rest result score score_threshold scored_point search search_params self shard_number size str text texts timeout tolist type typing upper upsert url utils uuid uuid4 value vector vectors vectors_config vectorstores wal_config warn warnings with_payload with_vectors write_consistency_factor

Python: /langchain/vectorstores/redis.py
  Functions: _check_index_exists _check_redis_module_exist _default_relevance_score _redis_key _redis_prefix
  Classes: Config Redis RedisVectorStoreRetriever
  Methods: __init__ _create_index _prepare_query _similarity_search_with_relevance_scores aadd_documents add_documents add_texts aget_relevant_documents as_retriever drop_index from_existing_index from_texts from_texts_return_keys get_relevant_documents similarity_search similarity_search_limit_score similarity_search_with_score validate_search_type
  Variables: REDIS_DISTANCE_METRICS REDIS_REQUIRED_MODULES arbitrary_types_allowed base_query client docs docs_and_scores embedding embeddings error_message hybrid_fields ids index_name installed_modules instance instance, key keys logger metadata params_dict: pipeline prefix redis_client redis_query redis_url results return_fields schema score_threshold: search_type search_type: self.client self.content_key self.embedding_function self.index_name self.metadata_key self.relevance_score_fn self.vector_key vectorstore:
  Usages: Any BaseModel Callable Dict Document Embeddings Exception HASH ImportError IndexDefinition IndexType Iterable List Literal Mapping NotImplementedError Optional Query RedisType TYPE_CHECKING TextField Tuple Type ValueError VectorField VectorStore VectorStoreRetriever __name__ annotations append array astype base batch_size bool classmethod cls commands content content_key create_index decode definition delete_documents dialect dict dim distance_metric doc docstore document documents dropindex dtype dumps embed_documents embed_query embedding_function enumerate error execute field fields float float32 from_url getLogger get_from_dict_or_env hex hset indexDefinition index_type info int json kwargs langchain len loads logging mapping metadata_key metadatas module module_list name numpy page_content paging params_dict pop pydantic query redis relevance_score_fn required_modules result root_validator score score_threshold search self sort_by staticmethod str text texts tobytes transaction typing url utils uuid uuid4 val values vector_key vector_score vectorstore vectorstores

Python: /langchain/vectorstores/singlestoredb.py
  Classes: SingleStoreDB SingleStoreDBRetriever
  Methods: __init__ _create_table _get_connection add_texts aget_relevant_documents as_retriever from_texts get_relevant_documents similarity_search similarity_search_with_score
  Variables: allowed_search_types: conn cur doc docs docs_and_scores embedding instance metadata result self.connection_kwargs self.connection_pool self.content_field self.embedding self.metadata_field self.table_name self.vector_field vectorstore:
  Usages: Any ClassVar Collection Document Embeddings ImportError Iterable List NotImplementedError Optional QueuePool Tuple Type ValueError VectorStore VectorStoreRetriever allowed_search_types annotations append base classmethod close cls connect connection_kwargs connection_pool content_field cursor dict docstore document dumps embed_documents embed_query embeddings enumerate execute fetchall float format int join json kwargs langchain map max_overflow metadata_field metadatas page_content pool pool_size query row search_type self singlestoredb sqlalchemy str table_name text texts timeout typing vector_field vectorstore vectorstores

Python: /langchain/vectorstores/sklearn.py
  Classes: BaseSerializer BsonSerializer JsonSerializer ParquetSerializer SKLearnVectorStore SKLearnVectorStoreException
  Methods: __init__ _load _similarity_index_search_with_score _similarity_search_with_relevance_scores _update_neighbors add_texts extension from_texts load max_marginal_relevance_search max_marginal_relevance_search_by_vector persist save similarity_search similarity_search_with_score
  Variables: DEFAULT_FETCH_K DEFAULT_K SERIALIZER_MAP: _ids _texts backup_path data docs docs, docs_dists docs_scores embedding indices, indices_dists mmr_indices mmr_selected neigh_dists, query_embedding result_embeddings scores self._embedding_function self._embeddings self._embeddings: self._embeddings_np self._embeddings_np: self._ids self._ids: self._metadatas self._metadatas: self._neighbors self._neighbors_fitted self._np self._persist_path self._serializer self._serializer: self._texts self._texts: self.bson self.pa self.pd self.persist_path self.pq serializer_cls sklearn_neighbors table
  Usages: ABC Any DataFrame Dict Document Embeddings Exception Iterable List Literal NearestNeighbors Optional RuntimeError SERIALIZER_MAP Table Tuple Type ValueError VectorStore _embedding_function _embeddings _embeddings_np _metadatas _neighbors _neighbors_fitted _np _persist_path _serializer abc abstractmethod array asarray base bson classmethod cls col dict dist dists doc docstore document dtype dump dumps embed_documents embed_query embeddings exc exists exp extend fetch_k fit float float32 from_pandas guard_import ids idx indices int isfile items json kneighbors kwargs lambda_mul lambda_mult langchain len list loads math maximal_marginal_relevance metadata metadatas metric n_neighbors neigh_dists neigh_idxs open page_content path persist_path pip_name query read read_table remove rename self serializer series str super texts to_pandas tolist typing utils uuid uuid4 vectorstores write write_table zip

Python: /langchain/vectorstores/supabase.py
  Classes: SupabaseVectorStore
  Methods: __init__ _add_vectors _texts_to_documents add_texts add_vectors from_texts max_marginal_relevance_search max_marginal_relevance_search_by_vector similarity_search similarity_search_by_vector similarity_search_by_vector_returning_embeddings similarity_search_by_vector_with_relevance_scores similarity_search_with_relevance_scores
  Variables: _client: _embedding: _ids chunk chunk_size docs documents embedding embeddings filtered_documents id_list: ids match_documents_params match_result matched_documents matched_embeddings metadatas mmr_selected query_name: res result rows: self._client self._embedding: self.query_name self.table_name table_name: vectors
  Usages: Any Client Document Embeddings Exception ImportError Iterable List Optional TYPE_CHECKING Tuple Type Union ValueError VectorStore _client _embedding annotations array base classmethod client cls data dict doc doc_tuple docstore document dtype embed_documents enumerate execute extend fetch_k float float32 from_ fromstring get id_list idx insert int itertools kwargs lambda_mult langchain len list match_count maximal_marginal_relevance metadata ndarray numpy page_content query query_embedding query_name range repeat rows rpc search self sep staticmethod str strip supabase table_name text texts typing utils vectorstores zip

Python: /langchain/vectorstores/tair.py
  Functions: _uuid_key
  Classes: Tair
  Methods: __init__ add_texts create_index_if_not_exist drop_index from_documents from_existing_index from_texts similarity_search
  Variables: client data_type distance_type docs embedding embeddings ids index index_params index_type key keys keys_and_scores logger metadata metadatas pipeline ret search_params self.client self.content_key self.embedding_function self.index_name self.metadata_key self.search_params tair_vector_store texts url
  Usages: Any DataType DistanceMetric Document Embeddings Float32 HNSW ImportError IndexType InnerProduct Iterable List Optional TairClient Type ValueError VectorStore __name__ annotations append base bool classmethod cls content_key dict dim docstore document documents dumps embed_documents embed_query embedding_function enumerate execute from_url get getLogger get_from_dict_or_env hex index_name info int json kwargs langchain len list loads logging metadata_key page_content pop query self staticmethod str tair tairvector text transaction tvs_create_index tvs_del_index tvs_get_index tvs_hmget tvs_hset tvs_knnsearch typing utils uuid uuid4 vectorstores

Python: /langchain/vectorstores/tigris.py
  Classes: Tigris
  Methods: __init__ _prep_docs add_texts from_texts search_index similarity_search similarity_search_with_score
  Variables: client doc: doc["id"] docs docs: docs_with_scores embeddings: result self._embed_fn self._vector_store store vector
  Usages: Any Document Embeddings Filter ImportError Iterable List Optional TYPE_CHECKING TigrisClient TigrisDocument TigrisFilter TigrisVectorStore Tuple ValueError VectorStore _embed_fn _id _vector_store add_documents annotations append base classmethod cls dict doc embed_documents embed_query embedding embeddings filter filter_by filters float get get_search ids index_name int itertools kwargs langchain list metadata metadatas page_content property query schema score self str texts tigrisdb types typing vectorstores zip_longest

Python: /langchain/vectorstores/typesense.py
  Classes: Typesense
  Methods: __init__ _collection _create_collection _prep_texts add_texts from_client_params from_texts similarity_search similarity_search_with_score
  Variables: _ids _metadatas: client_config docs docs_and_score document embedded_query embedded_texts fields metadata node query_obj response score self._embedding self._text_key self._typesense_client self._typesense_collection_name text typesense_api_key vectorstore
  Usages: Any Client Collection Document Embeddings ImportError Iterable List ObjectNotFound Optional TYPE_CHECKING Tuple Union ValueError VectorStore _embedding _id _metadatas _text_key _typesense_client _typesense_collection_name annotations append base classmethod client cls collection collections connection_timeout_seconds create dict doc docstore documents embed_documents embed_query embedding embeddings exceptions filter float get_from_env hit host ids import_ int isinstance join kwargs langchain len list metadatas multi_search num_dim page_content perform port property protocol query self str text_key texts type typesense typesense_client typesense_client_params typesense_collection_name typing utils uuid uuid4 vec vectorstores zip

Python: /langchain/vectorstores/utils.py
  Functions: maximal_marginal_relevance
  Variables: best_score equation_score idx_to_add idxs most_similar query_embedding redundant_score selected similarity_to_query similarity_to_selected
  Usages: List append argmax array axis cosine_similarity embedding_list enumerate expand_dims float inf int lambda_mult langchain len list math_utils max min ndarray ndim numpy query_score typing

Python: /langchain/vectorstores/vectara.py
  Classes: Vectara VectaraRetriever
  Methods: __init__ _delete_doc _get_post_headers _index_doc add_texts as_retriever from_texts similarity_search similarity_search_with_score
  Variables: adapter body data doc doc_hash doc_id docs docs_and_scores metadatas request: request["corpus_id"] request["customer_id"] request["document"] response responses result search_kwargs: self._session self._vectara_api_key self._vectara_corpus_id self._vectara_customer_id status_code status_str succeeded vectara vectara_default_metadata vectorstore:
  Usages: Any Document Embeddings Field HTTPAdapter Iterable List Optional Session Tuple Type VectorStore VectorStoreRetriever _session _vectara_api_key _vectara_corpus_id _vectara_customer_id adapters annotations base bool classmethod cls debug default_factory dict dumps embedding embeddings encode environ error filter float get hashlib headers hexdigest int json kwargs lambda_val lamnbda_val langchain logging max_retries md5 metadata mount n_sentence_context page_content post pydantic query reason request requests schema search_kwargs self str text texts timeout typing update url vectara_api_key vectara_corpus_id vectara_customer_id vectorstore vectorstores verify warning zip

Python: /langchain/vectorstores/weaviate.py
  Functions: _create_weaviate_client _default_schema _default_score_normalizer _json_serializable
  Classes: Weaviate
  Methods: __init__ _similarity_search_with_relevance_scores add_texts from_texts max_marginal_relevance_search max_marginal_relevance_search_by_vector similarity_search similarity_search_by_text similarity_search_by_vector similarity_search_with_score
  Variables: _id attributes auth by_text: client content: content["certainty"] data_properties data_properties[key] docs docs_and_scores embedding embeddings ids index_name meta mmr_selected params params["vector"] payload query_obj relevance_score_fn result results schema score self._by_text self._client self._embedding self._index_name self._query_attrs self._relevance_score_fn self._text_key text text_key vector weaviate_api_key weaviate_url
  Usages: Any AuthApiKey Callable Client Dict Document Embeddings ImportError Iterable List Optional Tuple Type ValueError VectorStore _by_text _client _embedding _index_name _query_attrs _relevance_score_fn _text_key add_data_object annotations api_key append array auth_client_secret base batch bool by_text class_name classmethod cls contains content create_class data_object datetime dict doc docstore document dot embed_documents embed_query enumerate exp extend fetch_k float flush get get_from_dict_or_env get_valid_uuid hex idx int isinstance isoformat items key keys kwargs lambda_mult langchain list maximal_marginal_relevance metadata metadatas numpy page_content pop query res self str texts type typing util utils uuid uuid4 val value vectorstores weaviate with_additional with_limit with_near_text with_near_vector with_where

Python: /langchain/vectorstores/zilliz.py
  Classes: Zilliz
  Methods: _create_index from_texts
  Variables: logger self.index_params vector_db
  Usages: Any Collection Embeddings List Milvus MilvusException Optional __name__ _get_index _vector_field add_texts alias annotations base bool classmethod cls col collection_name connection_args consistency_level create_index debug dict drop_old embedding embedding_function embeddings error getLogger index_params isinstance kwargs langchain logging metadatas milvus pymilvus search_params self str texts typing using vectorstores

File: /tests/integration_tests/.env.example

Python: /tests/integration_tests/conftest.py
  Functions: _load_env
  Methods: test_dir vcr_cassette_dir
  Variables: ABS_PATH PROJECT_DIR dotenv_path
  Usages: FixtureRequest Path __file__ abspath basename dirname dotenv exists fixture join load_dotenv module pardir path pathlib pytest replace request scope str

Python: /tests/integration_tests/test_document_transformers.py
  Functions: test_embeddings_redundant_filter test_embeddings_redundant_filter_with_state
  Variables: actual docs embeddings redundant_filter state texts
  Usages: Document EmbeddingsRedundantFilter OpenAIEmbeddings _DocumentWithState document_transformers intersection langchain len page_content schema set transform_documents

Python: /tests/integration_tests/test_nebulagraph.py
  Classes: TestNebulaGraph
  Methods: setUp test_del test_execute test_get_session_pool test_init test_refresh_schema
  Variables: mock_session_pool.return_value nebula_graph query result self.address self.password self.port self.session_pool_size self.space self.username session_pool
  Usages: Any MagicMock NebulaGraph TestCase __del__ _get_session_pool address assertEqual assertIsInstance assertNotEqual assert_called_once close execute get_schema graphs langchain mock mock_session_pool password patch port refresh_schema return_value self session_pool_size space typing unittest username

Python: /tests/integration_tests/test_nlp_text_splitters.py
  Functions: test_nltk_text_splitter test_nltk_text_splitting_args test_spacy_text_splitter test_spacy_text_splitting_args
  Variables: expected_output output separator splitter text
  Usages: NLTKTextSplitter SpacyTextSplitter ValueError chunk_overlap chunk_size langchain pytest raises split_text text_splitter

Python: /tests/integration_tests/test_pdf_pagesplitter.py
  Functions: test_pdf_pagesplitter
  Variables: docs faiss_index loader script_dir
  Usages: FAISS OpenAIEmbeddings PyPDFLoader __file__ dirname document_loaders embeddings from_documents join langchain load metadata openai page_content path similarity_search vectorstores

Python: /tests/integration_tests/test_schema.py
  Classes: TestTokenCountingWithGPT2Tokenizer
  Methods: test_empty_token test_multiple_tokens test_special_tokens test_tokenization
  Usages: _get_token_ids_default_method base_language langchain len self

Python: /tests/integration_tests/test_text_splitter.py
  Functions: test_huggingface_tokenizer test_huggingface_type_check test_sentence_transformers_count_tokens test_sentence_transformers_multiple_tokens test_sentence_transformers_split_text test_token_text_splitter test_token_text_splitter_from_tiktoken test_token_text_splitter_overlap
  Variables: actual actual_tokenizer count_start_and_end_tokens expected expected_number_of_chunks expected_output expected_start_stop_token_count expected_text_chunks expected_text_token_count expected_token_count expected_tokenizer output splitter text text_chunks text_splitter text_to_embed text_token_count_including_start_and_stop_tokens token_count token_multiplier tokenizer
  Usages: CharacterTextSplitter GPT2TokenizerFast SentenceTransformersTokenTextSplitter TokenTextSplitter ValueError _tokenizer chunk_overlap chunk_size count_tokens from_huggingface_tokenizer from_pretrained from_tiktoken_encoder langchain len maximum_tokens_per_chunk model_name name pytest raises separator split_text transformers

Python: /tests/unit_tests/conftest.py
  Functions: pytest_addoption pytest_collection_modifyitems
  Variables: only_core only_extended required_pkgs required_pkgs_info: required_pkgs_info[pkg] requires_marker
  Usages: Config Dict Function Parser Sequence ValueError action add_marker addoption args bool config fail find_spec get_closest_marker getoption help importlib item items mark parser pkg pytest reason required_pkgs_info skip str typing util

Python: /tests/unit_tests/test_bash.py
  Methods: test_create_bash_persistent test_create_directory_and_files test_incorrect_command test_incorrect_command_return_err_output test_pwd_command test_pwd_command_persistent
  Variables: commands new_output output response session temp_dir
  Usages: BashProcess Path bash check_output decode langchain mark match mkdir parent pathlib persistent platform pytest reason return_err_output run shell skip skipif startswith strip strip_newlines subprocess sys tmp_path utilities

Python: /tests/unit_tests/test_dependencies.py
  Functions: test_imports test_required_dependencies test_test_group_dependencies
  Methods: poetry_conf
  Variables: HERE PYPROJECT_TOML dependencies required_dependencies test_group_deps
  Usages: Any BSHTMLLoader BasePromptTemplate ChatOpenAI Dict DuckDuckGoSearchResults FAISS LLMChain Mapping OpenAI OpenAIEmbeddings Path SerpAPIWrapper VespaRetriever __file__ chains chat_models document_loaders embeddings fixture get isinstance items langchain llms load open package_name parent pathlib prompts pytest requirements retrievers sorted str toml tools typing utilities vectorstores

Python: /tests/unit_tests/test_document_transformers.py
  Functions: test__filter_similar_embeddings test__filter_similar_embeddings_empty
  Variables: actual embedded_docs expected threshold
  Usages: _filter_similar_embeddings cosine_similarity document_transformers langchain len math_utils

Python: /tests/unit_tests/test_formatting.py
  Functions: test_does_not_allow_args test_does_not_allow_extra_kwargs test_valid_formatting
  Variables: expected_output output template
  Usages: KeyError ValueError bar foo format formatter formatting langchain pytest raises

Python: /tests/unit_tests/test_math_utils.py
  Functions: test_cosine_similarity test_cosine_similarity_empty test_cosine_similarity_identity test_cosine_similarity_score_threshold test_cosine_similarity_top_k test_cosine_similarity_top_k_and_score_threshold test_cosine_similarity_zero
  Methods: X Y
  Variables: X Y actual actual_idxs, empty_list: expected expected_idxs expected_scores
  Usages: List actual_idxs actual_scores allclose cosine_similarity cosine_similarity_top_k diag empty_list fixture float langchain len math_utils numpy ones pytest random score_threshold top_k typing zeros

Python: /tests/unit_tests/test_pytest_config.py
  Functions: test_socket_disabled
  Usages: SocketBlockedError get pytest pytest_socket raises requests

Python: /tests/unit_tests/test_python.py
  Functions: test_function test_functionality test_functionality_multiline test_python_ast_repl_multi_statement test_python_ast_repl_multiline test_python_repl test_python_repl_no_previous_variables test_python_repl_pass_in_locals
  Variables: _AST_SAMPLE_CODE _AST_SAMPLE_CODE_EXECUTE _SAMPLE_CODE _locals chain code foo output repl tool
  Usages: PythonAstREPLTool PythonREPL PythonREPLTool langchain locals pytest python python_repl run skip sys tools utilities version_info

Python: /tests/unit_tests/test_schema.py
  Classes: TestGetBufferString TestMessageDictConversion
  Methods: test_custom_ai_prefix test_custom_human_prefix test_empty_input test_multiple_msg test_valid_single_message
  Variables: ai_msg: expected_output human_msg: msgs prefix sys_msg:
  Usages: AIMessage HumanMessage SystemMessage TestCase additional_kwargs ai_msg ai_prefix assertEqual content get_buffer_string human_msg human_prefix join langchain messages_from_dict messages_to_dict schema self sys_msg unittest

Python: /tests/unit_tests/test_sql_database.py
  Functions: test_sql_database_run test_sql_database_run_update test_table_info test_table_info_w_sample_rows test_truncate_word
  Variables: command company engine expected_output metadata_obj output stmt user user_bio values
  Usages: Column Integer MetaData SQLDatabase String Table Text begin conn create_all create_engine execute insert join langchain length nullable primary_key run sample_rows_in_table_info sorted split sql_database sqlalchemy suffix table_info truncate_word user_id user_name

Python: /tests/unit_tests/test_sql_database_schema.py
  Functions: test_sql_database_run test_table_info
  Variables: command company engine expected_output metadata_obj output stmt user
  Usages: Column CreateSchema Integer MetaData SQLDatabase Sequence String Table Warning args begin conn create_all create_engine event execute insert isinstance join langchain len listen message metadata nullable primary_key pytest records run schema sorted split sql_database sqlalchemy table_info user_id user_name values warns

Python: /tests/unit_tests/test_text_splitter.py
  Functions: __test_iterative_text_splitter test_character_text_splitter test_character_text_splitter_empty_doc test_character_text_splitter_long test_character_text_splitter_longer_words test_character_text_splitter_separtor_empty_doc test_character_text_splitter_short_words_first test_character_text_splitting_args test_cpp_code_splitter test_create_documents test_create_documents_with_metadata test_create_documents_with_start_index test_golang_code_splitter test_html_code_splitter test_iterative_text_splitter test_iterative_text_splitter_discard_separator test_iterative_text_splitter_keep_separator test_java_code_splitter test_javascript_code_splitter test_markdown_code_splitter test_merge_splits test_metadata_not_shallow test_php_code_splitter test_proto_file_splitter test_python_code_splitter test_python_text_splitter test_rst_code_splitter test_ruby_code_splitter test_rust_code_splitter test_scala_code_splitter test_split_documents test_swift_code_splitter
  Variables: CHUNK_SIZE FAKE_PYTHON_TEXT chunk_size chunks code docs docs[0].metadata["foo"] expected_docs expected_output expected_splits output split_0 split_1 split_2 split_3 splits splitter text texts
  Usages: CPP CharacterTextSplitter Document GO HTML JAVA JS Language List MARKDOWN PHP PROTO PYTHON PythonCodeTextSplitter RST RUBY RUST RecursiveCharacterTextSplitter SCALA SWIFT ValueError _merge_splits add_start_index bool chunk chunk_overlap create_documents docstore document from_language int keep_separator langchain len metadata page_content pytest raises separator separators split_documents split_text str text_splitter typing

File: /.github/actions/poetry_setup/action.yml

CSS: /docs/_static/css/custom.css
  Classes: container container-lg container-md container-sm container-xl

JavaScript: /docs/_static/js/mendablesearch.js
  Functions: createRootElement initializeMendable loadScript
  Variables: icon iconSpan1 iconSpan2 mendableFloatingButton rootElement script
  Usages: Mendable MendableFloatingButton React ReactDOM document onLoadCallback src

PythonNotebook: /docs/integrations/databricks/databricks.ipynb
  Variables: agent db_chain llm toolkit
  Usages: ChatOpenAI SQLDatabase SQLDatabaseChain SQLDatabaseToolkit agent_toolkits agents catalog chat_models connector create_sql_agent databricks from_databricks from_llm install langchain model_name run schema sql temperature verbose

PythonNotebook: /docs/integrations/vectara/vectara_chat.ipynb
  Functions: get_chat_history
  Variables: chain chat_history doc_chain documents llm loader memory openai_api_key query question_generator res result retriever streaming_llm vectordbkwargs vectorstore
  Usages: CONDENSE_QUESTION_PROMPT ConversationBufferMemory ConversationalRetrievalChain LLMChain OpenAI QA_PROMPT StreamingStdOutCallbackHandler TextLoader Vectara VectaraRetriever append as_retriever callbacks chain_type chains combine_docs_chain conversational_retrieval document_loaders embedding environ filter from_documents from_llm get_relevant_documents human inputs join lambda_val langchain llms load load_qa_chain load_qa_with_sources_chain memory_key print prompt prompts qa_with_sources question_answering return_messages return_source_documents str streaming streaming_stdout temperature vectara vectorstores

PythonNotebook: /docs/integrations/vectara/vectara_text_generation.ipynb
  Functions: generate_blog_post get_github_docs
  Variables: PROMPT chain docs git_sha github_url inputs llm markdown_files prompt_template relative_path repo_path search_index source_chunks sources splitter
  Usages: CharacterTextSplitter Document LLMChain OpenAI Path PromptTemplate TemporaryDirectory Vectara append apply chains check_call check_output chunk chunk_overlap chunk_size cwd decode doc docstore document embedding environ from_texts glob input_variables langchain list llms markdown_file metadata open openai_api_key page_content pathlib print prompt prompts read relative_to repo_name repo_owner requests separator shell similarity_search source split_text strip subprocess temperature tempfile template text_splitter topic vectorstores

File: /docs/modules/agents/agent_executors.rst

File: /docs/modules/agents/agents.rst

PythonNotebook: /docs/modules/agents/getting_started.ipynb
  Variables: agent llm tools
  Usages: AgentType OpenAI ZERO_SHOT_REACT_DESCRIPTION agents initialize_agent langchain llms load_tools run temperature verbose

File: /docs/modules/agents/how_to_guides.rst

PythonNotebook: /docs/modules/agents/plan_and_execute.ipynb
  Variables: agent executor llm llm_math_chain model planner search tools
  Usages: ChatOpenAI LLMMathChain OpenAI PlanAndExecute SerpAPIWrapper Tool agents chat_models description experimental from_llm func langchain llms load_agent_executor load_chat_planner name plan_and_execute run temperature verbose

PythonNotebook: /docs/modules/agents/streaming_stdout_final_only.ipynb
  Classes: MyCallbackHandler
  Methods: on_llm_new_token
  Variables: agent llm tools
  Usages: AgentType BaseCallbackHandler FinalStreamingStdOutCallbackHandler OpenAI ZERO_SHOT_REACT_DESCRIPTION agents answer_prefix_tokens base callbacks initialize_agent kwargs langchain llms load_tools print run self streaming streaming_stdout_final_only temperature token verbose

File: /docs/modules/agents/toolkits.rst

File: /docs/modules/agents/tools.rst

PythonNotebook: /docs/modules/callbacks/filecallbackhandler.ipynb
  Variables: answer chain content conv handler html llm logfile prompt
  Usages: Ansi2HTMLConverter FileCallbackHandler HTML IPython LLMChain OpenAI PromptTemplate add ansi2html callbacks chains colorize convert dev display enqueue from_template full info install langchain llms logger loguru null number open prompts read run verbose

PythonNotebook: /docs/modules/callbacks/getting_started.ipynb
  Classes: MyCustomAsyncHandler MyCustomHandler MyCustomHandlerOne MyCustomHandlerTwo MyCustomSyncHandler
  Methods: on_agent_action on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_tool_start
  Variables: agent chain chat class_name handler handler1 handler2 llm os.environ["LANGCHAIN_TRACING"] prompt questions task tasks tools total_tokens
  Usages: AgentAction AgentType Any AsyncCallbackHandler BaseCallbackHandler ChatOpenAI Dict Exception HumanMessage KeyboardInterrupt LLMChain LLMResult List OpenAI PromptTemplate StdOutCallbackHandler Union ZERO_SHOT_REACT_DESCRIPTION action agenerate agents arun asyncio base callbacks chains chat_models content create_task environ error from_template gather get_openai_callback initialize_agent input_str inputs kwargs langchain llms load_tools max_tokens number print prompts range response run schema self serialized session sleep str streaming temperature token tracing_enabled typing verbose

PythonNotebook: /docs/modules/chains/getting_started.ipynb
  Classes: ConcatenateChain
  Methods: _call input_keys output_keys
  Variables: all_input_vars catchphrase chain chain_1 chain_1: chain_2 chain_2: chain_two chat chat_prompt_template concat_chain concat_output conversation human_message_prompt llm llm_chain output_1 output_2 overall_chain prompt prompt_1 prompt_2 prompt_template second_prompt
  Usages: Chain ChatOpenAI ChatPromptTemplate ConversationBufferMemory ConversationChain Dict HumanMessagePromptTemplate LLMChain List OpenAI PromptTemplate SimpleSequentialChain base chains chat_models from_messages from_template input_variables inputs langchain list llms memory print prompts property return_only_outputs run self set str temperature template typing union verbose

File: /docs/modules/chains/how_to_guides.rst

File: /docs/modules/indexes/document_loaders.rst

PythonNotebook: /docs/modules/indexes/getting_started.ipynb
  Classes: BaseRetriever
  Methods: get_relevant_documents
  Variables: documents embeddings index index_creator loader query retriever text_splitter texts
  Usages: ABC CharacterTextSplitter Chroma Document List OpenAI OpenAIEmbeddings RetrievalQA TextLoader VectorstoreIndexCreator abc abstractmethod as_retriever chain_type chains chunk_overlap chunk_size document_loaders embedding encoding from_chain_type from_documents from_loaders indexes langchain llm llms load query_with_sources run schema self split_documents str typing vectorstore vectorstore_cls vectorstores

File: /docs/modules/indexes/retrievers.rst

File: /docs/modules/indexes/text_splitters.rst

File: /docs/modules/indexes/vectorstores.rst

PythonNotebook: /docs/modules/memory/getting_started.ipynb
  Variables: conversation dicts history llm memory new_messages
  Usages: ChatMessageHistory ConversationBufferMemory ConversationChain OpenAI add_ai_message add_user_message chains chat_memory input json langchain llms load_memory_variables messages messages_from_dict messages_to_dict predict return_messages schema temperature verbose

File: /docs/modules/memory/how_to_guides.rst

File: /docs/modules/models/chat.rst

PythonNotebook: /docs/modules/models/getting_started.ipynb
  Variables: chat_model llm
  Usages: ChatOpenAI HumanMessage OpenAI chat_models content langchain llms predict predict_messages schema

File: /docs/modules/models/llms.rst

File: /docs/modules/models/text_embedding.rst

PythonNotebook: /docs/modules/prompts/chat_prompt_template.ipynb
  Variables: ai_message chat_message_prompt chat_prompt human_message human_message_prompt human_message_template human_prompt human_template output output_2 prompt system_message_prompt system_message_prompt_2 template
  Usages: AIMessage AIMessagePromptTemplate ChatMessagePromptTemplate ChatPromptTemplate HumanMessage HumanMessagePromptTemplate MessagesPlaceholder PromptTemplate SystemMessage SystemMessagePromptTemplate content conversation format format_prompt from_messages from_template input_language input_variables langchain output_language prompts role schema subject text to_messages to_string variable_name word_count

File: /docs/modules/prompts/example_selectors.rst

PythonNotebook: /docs/modules/prompts/getting_started.ipynb
  Variables: chat_prompt chat_prompt_value string_prompt string_prompt_value
  Usages: ChatPromptTemplate PromptTemplate format_prompt from_template langchain prompts subject to_messages to_string

File: /docs/modules/prompts/output_parsers.rst

File: /docs/modules/prompts/prompt_templates.rst

File: /docs/reference/modules/agent_toolkits.rst

File: /docs/reference/modules/agents.rst

File: /docs/reference/modules/chains.rst

File: /docs/reference/modules/chat_models.rst

File: /docs/reference/modules/docstore.rst

File: /docs/reference/modules/document_compressors.rst

File: /docs/reference/modules/document_loaders.rst

File: /docs/reference/modules/document_transformers.rst

File: /docs/reference/modules/embeddings.rst

File: /docs/reference/modules/example_selector.rst

File: /docs/reference/modules/experimental.rst

File: /docs/reference/modules/llms.rst

File: /docs/reference/modules/memory.rst

File: /docs/reference/modules/output_parsers.rst

File: /docs/reference/modules/prompts.rst

File: /docs/reference/modules/python.rst

File: /docs/reference/modules/retrievers.rst

File: /docs/reference/modules/searx_search.rst

File: /docs/reference/modules/serpapi.rst

File: /docs/reference/modules/text_splitter.rst

File: /docs/reference/modules/tools.rst

File: /docs/reference/modules/utilities.rst

File: /docs/reference/modules/vectorstores.rst

PythonNotebook: /docs/use_cases/agent_simulations/camel_role_playing.ipynb
  Functions: get_sys_msgs
  Classes: CAMELAgent
  Methods: __init__ init_messages reset step update_messages
  Variables: assistant_agent assistant_ai_msg assistant_inception_prompt assistant_msg assistant_role_name assistant_sys_msg assistant_sys_msg, assistant_sys_template chat_turn_limit, messages os.environ["OPENAI_API_KEY"] output_message self.model self.stored_messages self.system_message specified_task specified_task_msg task task_specifier_msg task_specifier_prompt task_specifier_sys_msg task_specifier_template task_specify_agent user_agent user_ai_msg user_inception_prompt user_msg user_role_name user_sys_msg user_sys_template word_limit
  Usages: AIMessage BaseMessage ChatOpenAI HumanMessage HumanMessagePromptTemplate List SystemMessage SystemMessagePromptTemplate append chat chat_models chat_turn_limit content environ format_messages from_template input_message langchain message model print prompts schema self stored_messages str system_message temperature template typing

PythonNotebook: /docs/use_cases/agent_simulations/characters.ipynb
  Functions: create_new_memory_retriever interview_agent relevance_score_fn run_conversation
  Variables: LLM USER_NAME agents break_dialogue embedding_size embeddings_model eve eve_observations eves_memory index new_message observations stay_in_dialogue, tommie tommie_observations tommies_memory turns vectorstore yesterday
  Usages: ChatOpenAI ERROR FAISS GenerativeAgent GenerativeAgentMemory InMemoryDocstore IndexFlatL2 List OpenAIEmbeddings TimeWeightedVectorStoreRetriever add_memory age agent basicConfig chat_models colored daily_summaries datetime days dev docstore embed_query embeddings enumerate experimental faiss float force_refresh generate_dialogue_response generate_reaction generative_agents get_summary initial_observation install langchain level llm logging math max_tokens memory memory_retriever message name now null observation other_score_keys print reaction reflection_threshold retrievers score sqrt status stay_in_dialogue str strftime termcolor timedelta traits typing vectorstores verbose

PythonNotebook: /docs/use_cases/agent_simulations/gymnasium.ipynb
  Classes: GymnasiumAgent
  Methods: __init__ _act act get_docs observe random_action reset
  Variables: act_message action agent env obs_message observation, self.action_parser self.docs self.env self.instructions self.message_history self.model self.ret
  Usages: AIMessage BaseMessage ChatOpenAI HumanMessage RegexParser RetryError Retrying SystemMessage ValueError __doc__ action_parser action_space append attempt before_sleep chat_models classmethod close cls content default_output_key docs exception gym gymnasium info inspect install instructions int langchain make message_history model obs observation outcome output_keys output_parsers parse print regex ret retry retry_if_exception_type retry_state rew reward sample schema self step stop stop_after_attempt temperature tenacity term termination trunc truncation unwrapped wait wait_none

PythonNotebook: /docs/use_cases/agent_simulations/multi_player_dnd.ipynb
  Functions: generate_character_description generate_character_system_message select_next_speaker
  Classes: DialogueAgent DialogueSimulator
  Methods: __init__ inject receive reset send step
  Variables: character_description character_descriptions character_names character_specifier_prompt character_system_messages characters game_description idx max_iters message name, player_descriptor_system_message quest quest_specifier_prompt self._step self.agents self.message_history self.model self.name self.prefix self.select_next_speaker self.system_message simulator speaker speaker_idx specified_quest storyteller storyteller_description storyteller_name storyteller_specifier_prompt storyteller_system_message word_limit
  Usages: AIMessage BaseMessage Callable ChatOpenAI Dict HumanMessage List SystemMessage _step agent agents append character_name character_system_message chat_models content int join langchain len message_history model name prefix print receiver schema selection_function self str system_message temperature tuple typing zip

PythonNotebook: /docs/use_cases/agent_simulations/multiagent_authoritarian.ipynb
  Functions: generate_agent_description generate_agent_header generate_agent_system_message select_next_speaker
  Classes: DialogueAgent DialogueSimulator DirectorDialogueAgent IntegerOutputParser
  Methods: __init__ _choose_next_speaker _generate_response get_format_instructions inject receive reset select_next_speaker send step
  Variables: agent_description agent_descriptions agent_descriptor_system_message agent_headers agent_specifier_prompt agent_summaries agent_summary_string agent_system_messages agents choice choice_prompt choice_string conversation_description director director_name idx message name, next_prompt response_prompt sample self._step self.agents self.choice_parser self.choose_next_speaker_prompt_template self.chosen_speaker_id self.continuation_clause self.message_history self.model self.name self.next_speaker self.prefix self.prompt_next_speaker_prompt_template self.response self.response_prompt_template self.select_next_speaker self.speakers self.stop self.stopping_probability self.system_message self.termination_clause simulator speaker speaker_idx speaker_names specified_topic topic topic_specifier_prompt word_limit
  Usages: AIMessage BaseMessage Callable ChatOpenAI ChatPromptTemplate Dict HumanMessage HumanMessagePromptTemplate LLMChain List OrderedDict PromptTemplate RegexParser SystemMessage ValueError _step agent agent_header agent_location agent_name agent_role append before_sleep chains chat_models choice_parser choose_next_speaker_prompt_template chosen_speaker_id collections content continuation_clause default_output_key description enumerate exception float format functools header input_variables int items join keys langchain list location message_history model name next_speaker outcome output_keys output_parsers parse partial prefix print prompt_next_speaker_prompt_template prompts random receiver regex response response_prompt_template retry retry_error_callback retry_if_exception_type retry_state role schema selection_function self speakers stop stop_after_attempt stopping_probability str super system_message temperature template tenacity termination_clause tuple typing uniform wait wait_none zip

PythonNotebook: /docs/use_cases/agent_simulations/multiagent_bidding.ipynb
  Functions: generate_character_bidding_template generate_character_description generate_character_header generate_character_system_message select_next_speaker
  Classes: BidOutputParser BiddingDialogueAgent DialogueAgent DialogueSimulator
  Methods: __init__ ask_for_bid bid get_format_instructions inject receive reset send step
  Variables: bid bid_parser bid_string bidding_template bids character_bidding_templates character_description character_descriptions character_headers character_names character_specifier_prompt character_system_messages characters game_description idx max_indices max_iters max_value message name, player_descriptor_system_message prompt selected_name self._step self.agents self.bidding_template self.message_history self.model self.name self.prefix self.select_next_speaker self.system_message simulator speaker speaker_idx specified_topic topic topic_specifier_prompt word_limit
  Usages: AIMessage BaseMessage Callable ChatOpenAI Dict HumanMessage List PromptTemplate RegexParser SystemMessage ValueError _step agent agents append before_sleep character_header character_name character_system_message chat_models choice content default_output_key enumerate exception format input_variables int join langchain max message_history model name numpy outcome output_keys output_parsers parse prefix print random receiver recent_message regex retry retry_error_callback retry_if_exception_type retry_state schema selection_function self stop stop_after_attempt str super system_message temperature template tenacity tuple typing wait wait_none where zip

PythonNotebook: /docs/use_cases/agent_simulations/petting_zoo.ipynb
  Functions: main
  Classes: ActionMaskAgent GymnasiumAgent PettingZooAgent
  Methods: __init__ _act act get_docs observe random_action reset
  Variables: act_message action agents env obs obs_message observation, self.action_parser self.docs self.env self.instructions self.message_history self.model self.name self.obs_buffer self.ret valid_action_instruction
  Usages: ChatOpenAI HumanMessage RegexParser RetryError Retrying SystemMessage ValueError __doc__ action_parser action_space agent agent_iter agent_name append attempt before_sleep chat_models classic classmethod close cls collections content default_output_key deque docs exception getmodule info inspect install instructions int items langchain last max_cycles maxlen message_history model name num_players obs_buffer observation outcome output_keys output_parsers parse pettingzoo possible_agents print pygame regex render_mode ret retry retry_if_exception_type retry_state rew reward rlcard rps_v2 sample schema self step stop stop_after_attempt super temperature tenacity term termination texas_holdem_no_limit_v6 tictactoe_v3 trunc truncation unwrapped wait wait_none

PythonNotebook: /docs/use_cases/agent_simulations/two_agent_debate_tools.ipynb
  Functions: generate_agent_description generate_system_message select_next_speaker
  Classes: DialogueAgent DialogueAgentWithTools DialogueSimulator
  Methods: __init__ inject receive reset send step
  Variables: agent_chain agent_description agent_descriptions agent_descriptor_system_message agent_specifier_prompt agent_system_messages agents conversation_description idx max_iters message name, names self._step self.agents self.message_history self.model self.name self.prefix self.select_next_speaker self.system_message self.tools simulator speaker speaker_idx specified_topic topic topic_specifier_prompt word_limit
  Usages: AIMessage AgentType BaseMessage CHAT_CONVERSATIONAL_REACT_DESCRIPTION Callable ChatOpenAI ConversationBufferMemory ConversationChain Dict HumanMessage List OpenAI PromptTemplate SystemMessage Tool _step agent append chains chat_models content description initialize_agent input int items join keys langchain len llms load_tools memory memory_key message_history model model_name name prefix print prompt prompts receiver return_messages run schema selection_function self str super system_message temperature tool_kwargs tool_names tools top_k_results tuple typing values verbose zip

PythonNotebook: /docs/use_cases/agent_simulations/two_player_dnd.ipynb
  Functions: select_next_speaker
  Classes: DialogueAgent DialogueSimulator
  Methods: __init__ inject receive reset send step
  Variables: game_description idx max_iters message name, player_descriptor_system_message protagonist protagonist_description protagonist_name protagonist_specifier_prompt protagonist_system_message quest quest_specifier_prompt self._step self.agents self.message_history self.model self.name self.prefix self.select_next_speaker self.system_message simulator speaker speaker_idx specified_quest storyteller storyteller_description storyteller_name storyteller_specifier_prompt storyteller_system_message word_limit
  Usages: Callable ChatOpenAI Dict HumanMessage List SystemMessage _step agent agents append chat_models content int join langchain len message_history model name prefix print receiver schema selection_function self str system_message temperature tuple typing

PythonNotebook: /docs/use_cases/agents/baby_agi.ipynb
  Functions: _get_top_tasks execute_task get_next_task prioritize_tasks
  Classes: BabyAGI Config ExecutionChain TaskCreationChain TaskPrioritizationChain
  Methods: _call add_task from_llm input_keys output_keys print_next_task print_task_list print_task_result
  Variables: OBJECTIVE arbitrary_types_allowed baby_agi context embedding_size embeddings_model execution_chain execution_chain: execution_template first_task incomplete_tasks index llm max_iterations: new_tasks next_task_id num_iters objective prioritized_task_list prompt response result result_id results self.task_list sorted_results, task task_creation_chain task_creation_chain: task_creation_template task_id task_id_counter: task_list: task_name task_names task_parts task_prioritization_chain task_prioritization_chain: task_prioritization_template this_task_id vectorstore vectorstore: verbose
  Usages: Any BaseLLM BaseModel Chain Dict FAISS Field InMemoryDocstore IndexFlatL2 LLMChain List OpenAI OpenAIEmbeddings Optional PromptTemplate VectorStore add_texts append base bool chains classmethod cls collections default_factory deque docstore embed_query embeddings faiss get ids init input_variables inputs int item join key kwargs langchain len list llms max_iterations metadata metadatas new_task popleft print property pydantic query reverse run self similarity_search_with_score sorted sorted_results split str strip task_description task_id_counter task_list task_string temperature template texts typing update vectorstores zip

PythonNotebook: /docs/use_cases/agents/baby_agi_with_agent.ipynb
  Functions: _get_top_tasks execute_task get_next_task prioritize_tasks
  Classes: BabyAGI Config TaskCreationChain TaskPrioritizationChain
  Methods: _call add_task from_llm input_keys output_keys print_next_task print_task_list print_task_result
  Variables: OBJECTIVE agent agent_executor arbitrary_types_allowed baby_agi context embedding_size embeddings_model execution_chain: first_task incomplete_tasks index llm llm_chain max_iterations: new_tasks next_task_id num_iters objective prefix prioritized_task_list prompt response result result_id results search self.task_list sorted_results, suffix task task_creation_chain task_creation_chain: task_creation_template task_id task_id_counter: task_list: task_name task_names task_parts task_prioritization_chain task_prioritization_chain: task_prioritization_template this_task_id todo_chain todo_prompt tool_names tools vectorstore vectorstore: verbose
  Usages: AgentExecutor Any BaseLLM BaseModel Chain Dict FAISS Field InMemoryDocstore IndexFlatL2 LLMChain List OpenAI OpenAIEmbeddings Optional PromptTemplate SerpAPIWrapper Tool VectorStore ZeroShotAgent add_texts agents allowed_tools append base bool chains classmethod cls collections cpu create_prompt default_factory deque description dev docstore embed_query embeddings execution_chain faiss from_agent_and_tools from_template func get google ids init input_variables inputs install int item join key kwargs langchain len list llms max_iterations metadata metadatas name new_task null pip popleft print property pydantic query reverse run self similarity_search_with_score sorted sorted_results split str strip task_description task_id_counter task_list task_string temperature template texts tool typing update vectorstores zip

PythonNotebook: /docs/use_cases/agents/camel_role_playing.ipynb
  Functions: get_sys_msgs
  Classes: CAMELAgent
  Methods: __init__ init_messages reset step update_messages
  Variables: assistant_agent assistant_ai_msg assistant_inception_prompt assistant_msg assistant_role_name assistant_sys_msg assistant_sys_msg, assistant_sys_template chat_turn_limit, messages os.environ["OPENAI_API_KEY"] output_message self.model self.stored_messages self.system_message specified_task specified_task_msg task task_specifier_msg task_specifier_prompt task_specifier_sys_msg task_specifier_template task_specify_agent user_agent user_ai_msg user_inception_prompt user_msg user_role_name user_sys_msg user_sys_template word_limit
  Usages: AIMessage BaseMessage ChatOpenAI HumanMessage HumanMessagePromptTemplate List SystemMessage SystemMessagePromptTemplate append chat chat_models chat_turn_limit content environ format_messages from_template input_message langchain message model print prompts schema self stored_messages str system_message temperature template typing

PythonNotebook: /docs/use_cases/agents/custom_agent_with_plugin_retrieval.ipynb
  Functions: get_tools
  Classes: CustomOutputParser CustomPromptTemplate
  Methods: format parse
  Variables: AI_PLUGINS action action_input agent agent_executor docs embeddings intermediate_steps kwargs["agent_scratchpad"] kwargs["tool_names"] kwargs["tools"] llm llm_chain match output_parser prompt regex retriever template template: thoughts tool_kits tool_names toolkits_dict tools tools_getter: urls vector_store
  Usages: AIPlugin AgentAction AgentExecutor AgentFinish AgentOutputParser Callable DOTALL Document FAISS LLMChain LLMSingleActionAgent List NLAToolkit OpenAI OpenAIEmbeddings SerpAPIWrapper StringPromptTemplate Tool Union ValueError agent_toolkits agents allowed_tools as_retriever description description_for_model extend from_agent_and_tools from_documents from_llm_and_ai_plugin from_url get_relevant_documents group input_variables join kwargs langchain llm_output log metadata name name_for_model nla_tools observation page_content plugin pop prompts query return_values run schema search self split stop str strip temperature tool tool_input tools_getter typing url vectorstores verbose

PythonNotebook: /docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.ipynb
  Functions: get_tools
  Classes: CustomOutputParser CustomPromptTemplate
  Methods: format parse
  Variables: AI_PLUGINS action action_input agent agent_executor docs embeddings intermediate_steps kwargs["agent_scratchpad"] kwargs["tool_names"] kwargs["tools"] llm llm_chain match output_parser prompt regex retriever template template: thoughts tool_kits tool_names toolkits_dict tools tools_getter: urls vector_store
  Usages: AIPlugin AgentAction AgentExecutor AgentFinish AgentOutputParser Callable DOTALL Document FAISS LLMChain LLMSingleActionAgent List NLAToolkit OpenAI OpenAIEmbeddings SerpAPIWrapper StringPromptTemplate Tool Union ValueError agent_toolkits agents allowed_tools as_retriever description description_for_model extend filter from_agent_and_tools from_documents from_llm_and_ai_plugin from_url get_plugins get_relevant_documents group input_variables install join kwargs langchain llm_output log metadata name name_for_model nla_tools observation page_content pip plugin plugnplai pop prompts query return_values run schema search self split stop str strip temperature tool tool_input tools_getter typing url vectorstores verbose

PythonNotebook: /docs/use_cases/agents/multi_modal_output_agent.ipynb
  Functions: show_output
  Variables: UUID_PATTERN llm maybe_block_id mrkl output outputs tools
  Usages: AgentType Block IPython Image OpenAI Steamship SteamshipImageGenerationTool ZERO_SHOT_REACT_DESCRIPTION _id agent agents compile display end get group initialize_agent langchain model_name print raw run search split steamship sub temperature verbose

PythonNotebook: /docs/use_cases/agents/sales_agent_with_context.ipynb
  Classes: SalesConversationChain SalesGPT StageAnalyzerChain
  Methods: _call determine_conversation_stage from_llm human_step input_keys output_keys retrieve_conversation_stage seed_agent step
  Variables: ai_message company_business: company_name: company_values: config conversation_history: conversation_purpose: conversation_stage_dict: conversation_stage_id conversation_stages conversation_type: current_conversation_stage: human_input llm os.environ['OPENAI_API_KEY'] prompt sales_agent sales_agent_inception_prompt sales_conversation_utterance_chain sales_conversation_utterance_chain: salesperson_name: salesperson_role: self.conversation_history self.current_conversation_stage stage_analyzer_chain stage_analyzer_chain: stage_analyzer_inception_prompt_template verbose
  Usages: Any BaseLLM BaseModel Chain ChatOpenAI Dict Field LLMChain List PromptTemplate append base bool chains chat_models classmethod cls company_business company_name company_values conversation_history conversation_purpose conversation_stage conversation_stage_dict conversation_type current_conversation_stage dict environ get input_variables inputs join key kwargs langchain llms print property pydantic rstrip run salesperson_name salesperson_role self str temperature template typing

PythonNotebook: /docs/use_cases/agents/wikibase_agent.ipynb
  Functions: get_nested_value run_sparql vocab_lookup
  Classes: CustomOutputParser CustomPromptTemplate
  Methods: format parse
  Variables: action action_input agent agent_executor config current headers headers['User-Agent'] intermediate_steps kwargs["agent_scratchpad"] kwargs["tool_names"] kwargs["tools"] llm llm_chain match openai_api_key output_parser params prompt regex response results srnamespace srqiprofile template template: thoughts title tool_names tools tools: wikidata_user_agent_header
  Usages: AgentAction AgentExecutor AgentFinish AgentOutputParser Any ChatOpenAI ConfigParser DOTALL Dict LLMChain LLMSingleActionAgent List OpenAI Optional StringPromptTemplate Tool Union ValueError agents allowed_tools any chat_models configparser description dict dumps entity_type environ from_agent_and_tools func get group has_section input_variables join json key kwargs langchain list llm_output log model_name name observation path pop print prompts query read requests return_values run schema search self split status_code stop str strip temperature tool tool_input typing update url user_agent_header verbose

PythonNotebook: /docs/use_cases/autonomous_agents/autogpt.ipynb
  Variables: agent agent.chain.verbose embedding_size embeddings_model index search tools vectorstore
  Usages: AutoGPT ChatOpenAI FAISS InMemoryDocstore IndexFlatL2 OpenAIEmbeddings ReadFileTool SerpAPIWrapper Tool WriteFileTool agents ai_name ai_role as_retriever chain chat_models description docstore embed_query embeddings experimental faiss file_management from_llm_and_tools func langchain llm memory name read run temperature utilities vectorstores verbose write

PythonNotebook: /docs/use_cases/autonomous_agents/baby_agi.ipynb
  Variables: OBJECTIVE baby_agi embedding_size embeddings_model index llm max_iterations: vectorstore verbose
  Usages: Any BabyAGI BaseLLM BaseModel Chain Dict FAISS Field InMemoryDocstore IndexFlatL2 LLMChain List OpenAI OpenAIEmbeddings Optional PromptTemplate VectorStore base chains collections deque docstore embed_query embeddings experimental faiss from_llm int langchain llms max_iterations pydantic temperature typing vectorstores

PythonNotebook: /docs/use_cases/autonomous_agents/baby_agi_with_agent.ipynb
  Variables: OBJECTIVE agent agent_executor baby_agi embedding_size embeddings_model index llm llm_chain max_iterations: prefix prompt search suffix todo_chain todo_prompt tool_names tools vectorstore verbose
  Usages: AgentExecutor Any BabyAGI BaseLLM BaseModel Chain Dict FAISS Field InMemoryDocstore IndexFlatL2 LLMChain List OpenAI OpenAIEmbeddings Optional PromptTemplate SerpAPIWrapper Tool VectorStore ZeroShotAgent agents allowed_tools base chains collections cpu create_prompt deque description dev docstore embed_query embeddings experimental faiss from_agent_and_tools from_llm from_template func google input_variables install int langchain llms max_iterations name null pip pydantic results run task_execution_chain temperature tool typing vectorstores

PythonNotebook: /docs/use_cases/autonomous_agents/marathon_times.ipynb
  Functions: _get_text_splitter async_load_playwright run_async
  Classes: WebpageQATool
  Methods: _arun _run browse_web_page process_csv pushd
  Variables: ROOT_DIR agent browser chunks description docs embedding_size embeddings_model event_loop index input_docs lines llm name page page_source prev_dir qa_chain: query_website_tool result results results_docs soup text text_splitter: tools vectorstore web_docs web_search window_result
  Usages: AutoGPT BaseCombineDocumentsChain BaseTool BeautifulSoup ChatOpenAI Document DuckDuckGoSearchRun Exception FAISS Field HumanInputRun InMemoryDocstore IndexFlatL2 NotImplementedError OpenAIEmbeddings Optional ReadFileTool RecursiveCharacterTextSplitter WriteFileTool agent_toolkits agents ai_name ai_role append apply as_retriever async_api async_playwright asyncio autogpt autonomous_agents base bs4 chains chat_models chdir chromium chunk chunk_overlap chunk_size close content contextlib contextmanager coro create_pandas_dataframe_agent csv_file_path default_factory docstore document embed_query embeddings experimental extract faiss file_management from_llm_and_tools get_event_loop get_text getcwd goto headless human instructions join langchain launch len length_function line load_qa_with_sources_chain loading max_iterations memory metadata model_name nest_asyncio new_dir new_page output_path page_content pandas phrase playwright pydantic qa_chain qa_with_sources question range read read_csv return_only_outputs root_dir run run_until_complete script search_kwargs self split split_documents splitlines str strip temperature text_splitter tool typing url vectorstores verbose write

PythonNotebook: /docs/use_cases/autonomous_agents/meta_prompt.ipynb
  Functions: get_chat_history get_new_instructions initialize_chain initialize_meta_chain main
  Variables: chain chat_history delimiter failed_phrase human_input instructions key_phrases memory memory.ai_prefix memory_key meta_chain meta_output meta_prompt meta_template new_instructions output prompt success_phrase task template
  Usages: ConversationBufferWindowMemory LLMChain OpenAI PromptTemplate ai_prefix any chain_memory find input input_variables langchain len llm load_memory_variables lower max_iters max_meta_iters phrase predict print range temperature verbose

PythonNotebook: /docs/use_cases/chatbots/voice_assistant.ipynb
  Functions: listen
  Variables: audio chatgpt_chain engine prompt response_text template text unrecognized_speech_text
  Usages: ConversationBufferWindowMemory ConversationChain Exception LLMChain Microphone OpenAI PromptTemplate Recognizer adjust_for_ambient_noise duration human_input init input_variables langchain llm memory model phrase_time_limit predict print pyttsx3 recognize_whisper runAndWait say show_dict source speech_recognition temperature timeout verbose

PythonNotebook: /docs/use_cases/code/code-analysis-deeplake.ipynb
  Functions: filter
  Variables: chat_history docs embeddings loader metadata model os.environ['ACTIVELOOP_TOKEN'] os.environ['OPENAI_API_KEY'] questions result retriever retriever.search_kwargs['distance_metric'] retriever.search_kwargs['fetch_k'] retriever.search_kwargs['k'] retriever.search_kwargs['maximal_marginal_relevance'] root_dir text_splitter texts
  Usages: CharacterTextSplitter ChatOpenAI ConversationalRetrievalChain DEEPLAKE_ACCOUNT_NAME DeepLake Exception OpenAIEmbeddings TextLoader append as_retriever chains chat_models chunk_overlap chunk_size data dataset_path dirnames dirpath document_loaders embedding_function encoding endswith environ extend file filenames from_documents from_llm getpass join langchain len load_and_split model_name openai path print question read_only search_kwargs split_documents vectorstores walk

PythonNotebook: /docs/use_cases/code/twitter-the-algorithm-analysis-deeplake.ipynb
  Functions: filter
  Variables: chat_history docs embeddings https://github.com/twitter/the-algorithm loader metadata model os.environ['ACTIVELOOP_TOKEN'] os.environ['OPENAI_API_KEY'] questions result retriever retriever.search_kwargs['distance_metric'] retriever.search_kwargs['fetch_k'] retriever.search_kwargs['k'] retriever.search_kwargs['maximal_marginal_relevance'] root_dir text_splitter texts username
  Usages: CharacterTextSplitter ChatOpenAI ConversationalRetrievalChain DeepLake Exception OpenAIEmbeddings TextLoader add_documents algorithm append as_retriever chains chat_models chunk_overlap chunk_size clone com data dataset_path deeplake dirnames dirpath disallowed_special document_loaders embedding_function encoding environ extend file filenames from_llm getpass github https install join langchain load_and_split model_name openai path pip print public question read_only search_kwargs split_documents the tiktoken twitter upgrade vectorstores walk ython3

PythonNotebook: /docs/use_cases/evaluation/agent_benchmarking.ipynb
  Variables: agent dataset error_dataset eval_chain graded_outputs incorrect llm new_data os.environ["LANGCHAIN_HANDLER"] predicted_dataset prediction['grade'] predictions tools
  Usages: AgentType Counter Exception LLMMathChain OpenAI QAEvalChain Tool ZERO_SHOT_REACT_DESCRIPTION agents append chains collections data enumerate environ evaluate evaluation from_llm initialize_agent langchain llms load_dataset load_tools loading pred prediction prediction_key print question_key run str temperature verbose

PythonNotebook: /docs/use_cases/evaluation/agent_vectordb_sota_pg.ipynb
  Variables: agent chain_pg chain_sota dataset error_dataset eval_chain graded_outputs incorrect llm loader new_data os.environ["LANGCHAIN_HANDLER"] predicted_dataset prediction['grade'] predictions tools vectorstore_pg vectorstore_sota
  Usages: AgentType Counter Exception OpenAI QAEvalChain RetrievalQA TextLoader Tool VectorstoreIndexCreator ZERO_SHOT_REACT_DESCRIPTION agents append as_retriever chain_type chains collections data description document_loaders enumerate environ evaluate evaluation from_chain_type from_llm from_loaders func indexes initialize_agent input_key langchain llms load_dataset loading max_iterations name pred prediction prediction_key question_key retriever run temperature vectorstore vectorstore_kwargs

PythonNotebook: /docs/use_cases/evaluation/benchmarking_template.ipynb
  Variables: dataset os.environ["LANGCHAIN_HANDLER"]
  Usages: environ evaluation langchain load_dataset loading

PythonNotebook: /docs/use_cases/evaluation/data_augmented_question_answering.ipynb
  Variables: critique critique_data docsearch documents embeddings eval_chain eval_results example_gen_chain examples graded_outputs llm loader metrics new_examples predictions score_string text_splitter texts
  Usages: CharacterTextSplitter Chroma Critique OpenAI OpenAIEmbeddings QAEvalChain QAGenerateChain RetrievalQA TextLoader api_key apply apply_and_parse as_retriever chains chunk_overlap chunk_size config dataset document_loaders enumerate environ evaluate evaluation from_documents from_llm inspiredco items join langchain llms load metric openai pred print retriever split_documents temperature vectorstores

PythonNotebook: /docs/use_cases/evaluation/generic_agent_evaluation.ipynb
  Variables: agent docstore eval_chain evaluation llm llm_math_chain math_llm memory query_one query_two question, search test_outputs_one test_outputs_two tools
  Usages: AgentType CHAT_CONVERSATIONAL_REACT_DESCRIPTION ChatOpenAI ConversationBufferMemory DocstoreExplorer LLMMathChain OpenAI SerpAPIWrapper Tool TrajectoryEvalChain Wikipedia agent_tools agents answer base chat_models description from_llm func get_agent_trajectory initialize_agent inputs langchain llms lookup memory_key model_name name output_key print question react return_intermediate_steps return_messages return_only_outputs return_reasoning run steps temperature verbose

PythonNotebook: /docs/use_cases/evaluation/huggingface_datasets.ipynb
  Variables: chain dataset eval_chain examples graded_outputs llm predictions prompt
  Usages: LLMChain OpenAI PromptTemplate QAEvalChain answer_key apply chains datasets evaluate evaluation from_llm input_variables langchain list llms load_dataset model_name prediction_key prompts question_key temperature template

PythonNotebook: /docs/use_cases/evaluation/llm_math.ipynb
  Variables: chain correct dataset llm numeric_output os.environ["LANGCHAIN_HANDLER"] predictions
  Usages: LLMMathChain OpenAI apply chains enumerate environ evaluation example float langchain len llms load_dataset loading print strip sum

PythonNotebook: /docs/use_cases/evaluation/openapi_eval.ipynb
  Functions: parse_eval_results parse_list
  Variables: answers api_chain api_responses chain_outputs correction_chain correction_template dataset eval_chain eval_output failed_examples feedback generation_chain ground_truth header llm matches mean_scores methods num_to_generate operation parsed_response_results parsed_results paths predicted_outputs predicted_queries prompt purpose queries questions raise_error request_args request_eval_results resolved response_eval_results row rubric scores spec template text truth_queries verbose
  Usages: APIOperation Exception LLMChain List OpenAI OpenAPIEndpointChain OpenAPISpec PromptTemplate Requests answer api_response append chains collections data defaultdict dumps evaluation extend findall float format from_api_operation from_openapi_spec from_template from_url get_methods_for_path group input items json keys langchain len list llms load_dataset loading max max_tokens metric metric_scores min output predict_query print prompts query question request request_arg requests res results return_intermediate_steps run search sorted split str strip sub sum temperature to_typescript tools truth_query typing user_feedback zip

PythonNotebook: /docs/use_cases/evaluation/qa_benchmarking_pg.ipynb
  Variables: chain dataset eval_chain graded_outputs incorrect llm loader os.environ["LANGCHAIN_HANDLER"] prediction['grade'] predictions vectorstore
  Usages: Counter OpenAI QAEvalChain RetrievalQA TextLoader VectorstoreIndexCreator apply as_retriever chain_type chains collections document_loaders enumerate environ evaluate evaluation from_chain_type from_llm from_loaders indexes input_key langchain llms load_dataset loading pred prediction prediction_key question_key retriever temperature

PythonNotebook: /docs/use_cases/evaluation/qa_benchmarking_sota.ipynb
  Variables: chain dataset eval_chain graded_outputs incorrect llm loader os.environ["LANGCHAIN_HANDLER"] prediction['grade'] predictions vectorstore
  Usages: Counter OpenAI QAEvalChain RetrievalQA TextLoader VectorstoreIndexCreator apply as_retriever chain_type chains collections document_loaders enumerate environ evaluate evaluation from_chain_type from_llm from_loaders indexes input_key langchain llms load_dataset loading pred prediction prediction_key question_key retriever temperature

PythonNotebook: /docs/use_cases/evaluation/qa_generation.ipynb
  Variables: chain doc loader
  Usages: ChatOpenAI QAGenerationChain TextLoader chains chat_models document_loaders from_llm langchain load page_content run temperature

PythonNotebook: /docs/use_cases/evaluation/question_answering.ipynb
  Variables: PROMPT QA_PROMPT _PROMPT_TEMPLATE chain context_examples eg['answers'] eg['id'] eval_chain evalchain examples graded_outputs llm new_examples predictions predictions[i]['id'] predictions[i]['prediction_text'] prompt qa_chain results squad_metric template
  Usages: ContextQAEvalChain LLMChain OpenAI PromptTemplate QAEvalChain answer_key apply chains compute copy enumerate evaluate evaluation from_llm input_variables langchain llms load model_name prediction_key print prompts question_key references str temperature

PythonNotebook: /docs/use_cases/evaluation/sql_qa_benchmarking_chinook.ipynb
  Variables: chain dataset error_dataset eval_chain graded_outputs incorrect llm os.environ["LANGCHAIN_HANDLER"] predicted_dataset prediction['grade'] predictions
  Usages: Counter OpenAI QAEvalChain SQLDatabase SQLDatabaseChain append collections data enumerate environ evaluate evaluation from_llm from_uri input_key langchain load_dataset loading pred prediction prediction_key question_key temperature

PythonNotebook: /docs/use_cases/multi_modal/image_agent.ipynb
  Functions: show_output
  Variables: UUID_PATTERN llm maybe_block_id mrkl output outputs tools
  Usages: AgentType Block IPython Image OpenAI Steamship SteamshipImageGenerationTool ZERO_SHOT_REACT_DESCRIPTION _id agent agents compile display end get group initialize_agent langchain model_name print raw run search split steamship sub temperature verbose

File: /docs/use_cases/question_answering/messages.txt

PythonNotebook: /docs/use_cases/question_answering/semantic-search-over-chat.ipynb
  Variables: ans dataset_path embeddings org os.environ['ACTIVELOOP_ORG'] os.environ['ACTIVELOOP_TOKEN'] os.environ['OPENAI_API_KEY'] pages query retriever retriever.search_kwargs['distance_metric'] retriever.search_kwargs['k'] state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter ChatOpenAI ConversationalRetrievalChain DeepLake OpenAI OpenAIEmbeddings PyPDFLoader RecursiveCharacterTextSplitter RetrievalQA TextLoader as_retriever chain_type chains chat_models chunk_overlap chunk_size create_documents deeplake document_loaders embedding_function environ from_chain_type from_documents getpass input install langchain llm llms open openai overwrite pip print read read_only return_source_documents search_kwargs split_text tiktoken upgrade vectorstores ython3

Python: /langchain/agents/agent_toolkits/__init__.py
  Variables: __all__
  Usages: AzureCognitiveServicesToolkit FileManagementToolkit GmailToolkit JiraToolkit JsonToolkit NLAToolkit OpenAPIToolkit PlayWrightBrowserToolkit PowerBIToolkit SQLDatabaseToolkit SparkSQLToolkit VectorStoreInfo VectorStoreRouterToolkit VectorStoreToolkit ZapierToolkit agent_toolkits agents azure_cognitive_services base chat_base create_csv_agent create_json_agent create_openapi_agent create_pandas_dataframe_agent create_pbi_agent create_pbi_chat_agent create_python_agent create_spark_dataframe_agent create_spark_sql_agent create_sql_agent create_vectorstore_agent create_vectorstore_router_agent csv file_management gmail jira json langchain nla openapi pandas playwright powerbi python spark spark_sql sql toolkit vectorstore zapier

Python: /langchain/agents/agent_toolkits/base.py
  Classes: BaseToolkit
  Methods: get_tools
  Usages: BaseModel BaseTool List abc abstractmethod langchain pydantic self tools typing

Python: /langchain/agents/chat/base.py
  Classes: ChatAgent
  Methods: _agent_type _construct_scratchpad _get_default_output_parser _stop _validate_tools create_prompt from_llm_and_tools llm_prefix observation_prefix
  Variables: _output_parser agent_scratchpad format_instructions input_variables llm_chain messages output_parser: prompt template tool_names tool_strings
  Usages: Agent AgentAction AgentOutputParser Any BaseCallbackManager BaseLanguageModel BasePromptTemplate BaseTool ChatOutputParser ChatPromptTemplate FORMAT_INSTRUCTIONS Field HUMAN_MESSAGE HumanMessagePromptTemplate LLMChain List Optional SYSTEM_MESSAGE_PREFIX SYSTEM_MESSAGE_SUFFIX Sequence SystemMessagePromptTemplate Tuple ValueError __name__ agent agents allowed_tools base base_language callback_manager callbacks chains chat class_name classmethod cls default_factory description format from_template human_message intermediate_steps isinstance join kwargs langchain llm name output_parser prompts property pydantic schema self str super system_message_prefix system_message_suffix tool tools typing utils validate_tools_single_input

Python: /langchain/agents/chat/output_parser.py
  Classes: ChatOutputParser
  Methods: _type get_format_instructions parse
  Variables: FINAL_ANSWER_ACTION action includes_action includes_answer response
  Usages: AgentAction AgentFinish AgentOutputParser Exception FORMAT_INSTRUCTIONS OutputParserException Union agent agents chat json langchain loads prompt property schema self split str strip text typing

Python: /langchain/agents/chat/prompt.py
  Variables: FORMAT_INSTRUCTIONS HUMAN_MESSAGE SYSTEM_MESSAGE_PREFIX SYSTEM_MESSAGE_SUFFIX

Python: /langchain/agents/conversational/base.py
  Classes: ConversationalAgent
  Methods: _agent_type _get_default_output_parser _validate_tools create_prompt from_llm_and_tools llm_prefix observation_prefix
  Variables: _output_parser ai_prefix: format_instructions input_variables llm_chain output_parser: prompt template tool_names tool_strings
  Usages: Agent AgentOutputParser AgentType Any BaseCallbackManager BaseLanguageModel BaseTool CONVERSATIONAL_REACT_DESCRIPTION ConvoOutputParser FORMAT_INSTRUCTIONS Field LLMChain List Optional PREFIX PromptTemplate SUFFIX Sequence __name__ agent agent_types agents ai_prefix allowed_tools annotations base base_language callback_manager callbacks chains classmethod cls conversational default_factory description format human_prefix join kwargs langchain llm name output_parser prefix prompts property pydantic self str suffix super tool tools typing utils validate_tools_single_input

Python: /langchain/agents/conversational/output_parser.py
  Classes: ConvoOutputParser
  Methods: _type get_format_instructions parse
  Variables: action action_input ai_prefix: match regex
  Usages: AgentAction AgentFinish AgentOutputParser FORMAT_INSTRUCTIONS OutputParserException Union agent agents ai_prefix conversational group langchain prompt property schema search self split str strip text typing

Python: /langchain/agents/conversational/prompt.py
  Variables: FORMAT_INSTRUCTIONS PREFIX SUFFIX

Python: /langchain/agents/conversational_chat/base.py
  Classes: ConversationalChatAgent
  Methods: _agent_type _construct_scratchpad _get_default_output_parser _validate_tools create_prompt from_llm_and_tools llm_prefix observation_prefix
  Variables: _output_parser final_prompt format_instructions human_message input_variables llm_chain messages output_parser: prompt template_tool_response: thoughts: tool_names tool_strings
  Usages: AIMessage Agent AgentAction AgentOutputParser Any BaseCallbackManager BaseLanguageModel BaseMessage BaseOutputParser BasePromptTemplate BaseTool ChatPromptTemplate ConvoOutputParser Field HumanMessage HumanMessagePromptTemplate LLMChain List MessagesPlaceholder NotImplementedError Optional PREFIX SUFFIX Sequence SystemMessagePromptTemplate TEMPLATE_TOOL_RESPONSE Tuple __name__ action agent agents allowed_tools annotations append base base_language callback_manager callbacks chains chat classmethod cls content conversational_chat default_factory description format from_template get_format_instructions intermediate_steps join kwargs langchain llm log name observation output_parser prompts property pydantic schema self str super system_message template_tool_response thoughts tool tools typing utils validate_tools_single_input variable_name

Python: /langchain/agents/conversational_chat/output_parser.py
  Classes: ConvoOutputParser
  Methods: _type get_format_instructions parse
  Variables: action, response
  Usages: AgentAction AgentFinish AgentOutputParser Exception FORMAT_INSTRUCTIONS OutputParserException Union action action_input agents annotations conversational_chat json langchain output_parsers parse_json_markdown prompt property schema self str text typing

Python: /langchain/agents/conversational_chat/prompt.py
  Variables: FORMAT_INSTRUCTIONS PREFIX SUFFIX TEMPLATE_TOOL_RESPONSE

Python: /langchain/agents/mrkl/base.py
  Classes: ChainConfig MRKLChain ZeroShotAgent
  Methods: _agent_type _get_default_output_parser _validate_tools create_prompt from_chains from_llm_and_tools llm_prefix observation_prefix
  Variables: _output_parser action: action_description: action_name: agent format_instructions input_variables llm_chain output_parser: prompt template tool_names tool_strings tools
  Usages: Agent AgentExecutor AgentOutputParser AgentType Any BaseCallbackManager BaseLanguageModel BaseTool Callable FORMAT_INSTRUCTIONS Field LLMChain List MRKLOutputParser NamedTuple Optional PREFIX PromptTemplate SUFFIX Sequence Tool ValueError ZERO_SHOT_REACT_DESCRIPTION __name__ action action_description action_name agent_types agents allowed_tools annotations base base_language callback_manager callbacks chains classmethod cls default_factory description format func join kwargs langchain llm mrkl name output_parser prefix prompts property pydantic self str suffix super tool typing utils validate_tools_single_input

Python: /langchain/agents/mrkl/output_parser.py
  Classes: MRKLOutputParser
  Methods: _type get_format_instructions parse
  Variables: FINAL_ANSWER_ACTION action action_input action_match includes_answer regex tool_input
  Usages: AgentAction AgentFinish AgentOutputParser DOTALL FORMAT_INSTRUCTIONS OutputParserException Union agent agents group langchain llm_output mrkl observation prompt property schema search self send_to_llm split startswith str strip text typing

Python: /langchain/agents/mrkl/prompt.py
  Variables: FORMAT_INSTRUCTIONS PREFIX SUFFIX

Python: /langchain/agents/react/base.py
  Classes: DocstoreExplorer ReActChain ReActDocstoreAgent ReActTextWorldAgent
  Methods: __init__ _agent_type _get_default_output_parser _paragraphs _stop _summary _validate_tools create_prompt llm_prefix lookup observation_prefix search
  Variables: agent docstore_explorer lookups output_parser: result result_prefix self.docstore self.document self.document: self.lookup_index self.lookup_str tool_names tools
  Usages: Agent AgentExecutor AgentOutputParser AgentType Any BaseLanguageModel BasePromptTemplate BaseTool Docstore Document Field List Optional REACT_DOCSTORE ReActOutputParser Sequence TEXTWORLD_PROMPT Tool ValueError WIKI_PROMPT __name__ agent_types agents base base_language classmethod cls default_factory description docstore document from_llm_and_tools func isinstance kwargs langchain len llm lookup_index lookup_str lower name output_parser page_content prompts property pydantic react self split str super term textworld_prompt tool typing utils validate_tools_single_input wiki_prompt

Python: /langchain/agents/react/output_parser.py
  Classes: ReActOutputParser
  Methods: _type parse
  Variables: action, action_block action_prefix action_str re_matches
  Usages: AgentAction AgentFinish AgentOutputParser OutputParserException Union action action_input agent agents group langchain len property schema search self split startswith str strip text typing

Python: /langchain/agents/react/textworld_prompt.py
  Variables: EXAMPLES SUFFIX TEXTWORLD_PROMPT
  Usages: PromptTemplate from_examples langchain prompt prompts

Python: /langchain/agents/react/wiki_prompt.py
  Variables: EXAMPLES SUFFIX WIKI_PROMPT
  Usages: PromptTemplate from_examples langchain prompt prompts

Python: /langchain/agents/self_ask_with_search/base.py
  Classes: SelfAskWithSearchAgent SelfAskWithSearchChain
  Methods: __init__ _agent_type _get_default_output_parser _validate_tools create_prompt llm_prefix observation_prefix
  Variables: agent output_parser: search_tool tool_names
  Usages: Agent AgentExecutor AgentOutputParser AgentType Any BaseLanguageModel BasePromptTemplate BaseTool Field GoogleSerperAPIWrapper PROMPT SELF_ASK_WITH_SEARCH SelfAskOutputParser Sequence SerpAPIWrapper Tool Union ValueError __name__ agent_types agents arun base base_language classmethod cls coroutine default_factory description from_llm_and_tools func google_serper kwargs langchain len llm name output_parser prompt prompts property pydantic run search_chain self self_ask_with_search serpapi str super tool tools typing utilities utils validate_tools_single_input

Python: /langchain/agents/self_ask_with_search/output_parser.py
  Classes: SelfAskOutputParser
  Methods: _type parse
  Variables: after_colon finish_string: followups: last_line
  Usages: AgentAction AgentFinish AgentOutputParser OutputParserException Sequence Union agent agents any finish_string follow followups langchain len property schema self split str strip text typing

Python: /langchain/agents/self_ask_with_search/prompt.py
  Variables: PROMPT _DEFAULT_TEMPLATE
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/agents/structured_chat/base.py
  Classes: StructuredChatAgent
  Methods: _agent_type _construct_scratchpad _get_default_output_parser _stop _validate_tools create_prompt from_llm_and_tools llm_prefix observation_prefix
  Variables: HUMAN_MESSAGE_TEMPLATE _memory_prompts _output_parser agent_scratchpad args_schema format_instructions formatted_tools input_variables llm_chain messages output_parser: prompt template tool_names tool_strings
  Usages: Agent AgentAction AgentOutputParser Any BaseCallbackManager BaseLanguageModel BasePromptTemplate BaseTool ChatPromptTemplate FORMAT_INSTRUCTIONS Field HumanMessagePromptTemplate LLMChain List Optional PREFIX SUFFIX Sequence StructuredChatOutputParserWithRetries SystemMessagePromptTemplate Tuple ValueError agent agents allowed_tools append args base base_language callback_manager callbacks chains chat classmethod cls default_factory description format from_llm from_template human_message_template intermediate_steps isinstance join kwargs langchain llm memory_prompts name output_parser prefix prompts property pydantic schema self str structured_chat sub suffix super tool tools typing

Python: /langchain/agents/structured_chat/output_parser.py
  Classes: StructuredChatOutputParser StructuredChatOutputParserWithRetries
  Methods: _type from_llm get_format_instructions parse
  Variables: action_match base_parser base_parser: logger output_fixing_parser output_fixing_parser: parsed_obj parsed_obj: response
  Usages: AgentAction AgentFinish AgentOutputParser BaseLanguageModel DOTALL Exception FORMAT_INSTRUCTIONS Field Optional OutputFixingParser OutputParserException Union __name__ agent agents annotations base_language classmethod cls default_factory get getLogger group isinstance json langchain list llm loads logging output_parsers parser prompt property pydantic schema search self str strict strip structured_chat text typing warning

Python: /langchain/agents/structured_chat/prompt.py
  Variables: FORMAT_INSTRUCTIONS PREFIX SUFFIX

Python: /langchain/callbacks/tracers/__init__.py
  Variables: __all__
  Usages: ConsoleCallbackHandler LangChainTracer LangChainTracerV1 WandbTracer callbacks langchain langchain_v1 stdout tracers wandb

Python: /langchain/callbacks/tracers/base.py
  Classes: BaseTracer TracerException
  Methods: __copy__ __deepcopy__ __init__ _add_child_run _end_trace _get_execution_order _on_chain_end _on_chain_error _on_chain_start _on_chat_model_start _on_llm_end _on_llm_error _on_llm_start _on_tool_end _on_tool_error _on_tool_start _persist_run _start_trace on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_start on_tool_end on_tool_error on_tool_start
  Variables: chain_run chain_run.end_time chain_run.error chain_run.outputs execution_order llm_run llm_run.end_time llm_run.error llm_run.outputs parent_run parent_run.child_execution_order parent_run_id_ run_id_ self.run_map: self.run_map[str(run.id)] tool_run tool_run.end_time tool_run.error tool_run.outputs
  Usages: ABC Any BaseCallbackHandler Dict Exception KeyboardInterrupt LLMResult List Optional Run RunTypeEnum UUID Union abc abstractmethod annotations append base callbacks chain child_execution_order child_run child_runs datetime dict end_time error extra get input_str inputs int kwargs langchain llm memo output outputs parent_run_id pop prompts repr response run run_id run_map run_type schema schemas self serialized start_time staticmethod str super tool tracers typing utcnow uuid

Python: /langchain/callbacks/tracers/langchain.py
  Functions: log_error_once
  Classes: LangChainTracer
  Methods: __init__ _on_chain_end _on_chain_error _on_chain_start _on_chat_model_start _on_llm_end _on_llm_error _on_llm_start _on_tool_end _on_tool_error _on_tool_start _persist_run _persist_run_single _update_run_single on_chat_model_start
  Variables: _LOGGED chat_model_run execution_order extra extra["runtime"] logger parent_run_id_ run run.reference_example_id run_dict run_dict["extra"] self.client self.example_id self.executor self.session: self.session_name
  Usages: Any BaseMessage BaseTracer Dict Exception LangChainPlusClient List Optional Run RunTypeEnum ThreadPoolExecutor TracerSession UUID Union __name__ _get_execution_order _start_trace add annotations base batch callbacks child_execution_order client concurrent copy create_run datetime deep dict env error example_id exception exclude executor futures get getLogger get_runtime_environment getenv inputs isinstance kwargs langchain langchainplus_sdk llm logging max_workers messages messages_to_dict method parent_run_id reference_example_id run_id run_type schema schemas self serialized session session_name set start_time str submit super tracers type typing update_run utcnow uuid

Python: /langchain/callbacks/tracers/langchain_v1.py
  Functions: _get_endpoint get_headers
  Classes: LangChainTracerV1
  Methods: __init__ _convert_to_v1_run _load_session _persist_run _persist_session load_default_session load_session
  Variables: child_runs endpoint headers: headers["x-api-key"] prompts response self._endpoint self._headers self.session self.session: session session_type tracer_session url v1_run
  Usages: Any BaseTracer ChainRun Dict Exception LLMRun Optional Run ToolRun TracerSession TracerSessionV1 TracerSessionV1Base Union ValueError _endpoint _headers action annotations base batch callbacks child_chain_runs child_execution_order child_llm_runs child_tool_runs data dict end_time error execution_order extra get get_buffer_string getenv headers inputs isinstance json kwargs langchain logging output outputs parent_run_id parent_uuid post raise_for_status_with_text requests run run_type schema schemas self serialized session_create session_id session_name start_time str super tool_input tracers type typing utils uuid warning

Python: /langchain/callbacks/tracers/schemas.py
  Classes: BaseRun ChainRun LLMRun Run RunBase RunCreate RunTypeEnum RunUpdate ToolRun TracerSession TracerSessionBase TracerSessionV1 TracerSessionV1Base TracerSessionV1Create
  Methods: add_runtime_env assign_name
  Variables: action: chain child_chain_runs: child_execution_order: child_llm_runs: child_runs: child_tool_runs: end_time: error: execution_order: extra extra: extra["runtime"] id: inputs: llm name: output: outputs: parent_run_id: parent_uuid: prompts: reference_example_id: response: run_type: serialized: session_id: session_name: start_time: tenant_id: tool tool_input: uuid: values["extra"] values["name"]
  Usages: Any BaseModel Dict Enum Field LLMResult List Optional UUID action annotations child_chain_runs child_execution_order child_llm_runs child_runs child_tool_runs cls datetime default_factory dict end_time enum env error execution_order get get_runtime_environment inputs int langchain list name output outputs parent_run_id parent_uuid pre prompts pydantic reference_example_id response root_validator run_type schema serialized session_id session_name start_time str tenant_id tool_input typing update_forward_refs utcnow uuid values

Python: /langchain/callbacks/tracers/stdout.py
  Functions: elapsed try_json_stringify
  Classes: ConsoleCallbackHandler
  Methods: _on_chain_end _on_chain_error _on_chain_start _on_llm_end _on_llm_error _on_llm_start _on_tool_end _on_tool_error _on_tool_start _persist_run get_breadcrumbs get_parents
  Variables: crumbs current_run elapsed_time inputs milliseconds name parent parents string
  Usages: Any BaseTracer Exception List Run append base callbacks color dumps end_time ensure_ascii enumerate error execution_order fallback get get_bolded_text get_colored_text indent input join json langchain len obj outputs parent_run_id print run run_map run_type schemas self start_time str strip total_seconds tracers typing

Python: /langchain/callbacks/tracers/wandb.py
  Functions: _convert_chain_run_to_wb_span _convert_lc_run_to_wb_span _convert_llm_run_to_wb_span _convert_run_to_wb_span _convert_tool_run_to_wb_span _replace_type_with_kind _serialize_inputs
  Classes: WandbRunArgs WandbTracer
  Methods: __init__ _ensure_run _log_trace_from_run _persist_run finish
  Variables: PRINT_WARNINGS _run: _run_args: _type allow_val_change: anonymous: attributes attributes["execution_order"] base_span base_span.child_spans base_span.results base_span.span_kind config: config_exclude_keys: config_include_keys: data["_kind"] dir: docs entity: force: group: id: job_type: magic: mode: model_dict model_trace monitor_gym: name: notes: project: reinit: resume: root_span run_args run_args: run_args["settings"] run_url save_code: self._run_args self._trace_tree self._wandb settings: sync_tensorboard: tags: tensorboard:
  Usages: AGENT Any BaseTracer CHAIN Dict ERROR Exception ImportError LLM List Optional Result Run RunTypeEnum SUCCESS Sequence Settings Span SpanKind StatusCode StrPath TOOL TYPE_CHECKING TypedDict Union WBRun WBSettings WBTraceTree _label _run _run_args _trace_tree _wandb allow_val_change annotations anonymous base bool callbacks chain child_run child_runs child_spans config config_exclude_keys config_include_keys data data_types dict dir doc end_time end_time_ms entity enumerate error execution_order extra force g_i gen get group init inputs int isinstance items job_type json kwargs langchain len lib list llm log lower magic mode monitor_gym name ndx notes outputs paths pop project prompt reinit repo results resume run run_inputs run_type save_code schemas sdk self serialized set settings should_print_url span_id span_kind start_time start_time_ms status_code status_message str super sync_tensorboard tags tensorboard termlog termwarn timestamp tool trace_tree tracers tuple typing wandb wandb_run

Python: /langchain/chains/api/base.py
  Classes: APIChain
  Methods: _acall _call _chain_type from_llm_and_api_docs input_keys output_keys validate_api_answer_prompt validate_api_request_prompt
  Variables: _run_manager answer api_answer_chain: api_docs: api_request_chain: api_response api_url expected_vars get_answer_chain get_request_chain input_vars output_key: question question_key: requests_wrapper requests_wrapper:
  Usages: API_RESPONSE_PROMPT API_URL_PROMPT Any AsyncCallbackManagerForChainRun BaseLanguageModel BasePromptTemplate CallbackManagerForChainRun Chain Dict Field LLMChain List Optional TextRequestsWrapper ValueError aget annotations api api_answer_chain api_docs api_request_chain api_response_prompt api_url_prompt apredict base base_language callbacks chains classmethod cls color dict end exclude get get_child get_noop_manager headers input_variables inputs kwargs langchain llm manager on_text output_key pre predict prompt prompts property pydantic question_key requests root_validator run_manager self set str strip typing values verbose

Python: /langchain/chains/api/news_docs.py
  Variables: NEWS_DOCS

Python: /langchain/chains/api/open_meteo_docs.py
  Variables: OPEN_METEO_DOCS

Python: /langchain/chains/api/podcast_docs.py
  Variables: PODCAST_DOCS

Python: /langchain/chains/api/prompt.py
  Variables: API_RESPONSE_PROMPT API_RESPONSE_PROMPT_TEMPLATE API_URL_PROMPT API_URL_PROMPT_TEMPLATE
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/chains/api/tmdb_docs.py
  Variables: TMDB_DOCS

Python: /langchain/chains/chat_vector_db/prompts.py
  Variables: CONDENSE_QUESTION_PROMPT QA_PROMPT _template prompt_template
  Usages: PromptTemplate from_template input_variables langchain prompt prompts template

Python: /langchain/chains/combine_documents/base.py
  Functions: format_document
  Classes: AnalyzeDocumentChain BaseCombineDocumentsChain
  Methods: _acall _call acombine_docs combine_docs input_keys output_keys prompt_length
  Variables: _run_manager base_info combine_docs_chain: docs document document_info extra_return_dict[self.output_key] input_key: missing_metadata other_keys other_keys: other_keys[self.combine_docs_chain.input_key] output, output_key: required_metadata text_splitter:
  Usages: ABC Any AsyncCallbackManagerForChainRun BasePromptTemplate CallbackManagerForChainRun Chain Dict Document Field List Optional RecursiveCharacterTextSplitter TextSplitter Tuple ValueError abc abstractmethod base callbacks chains combine_docs_chain create_documents default_factory dict difference doc docstore extra_return_dict format get_child get_noop_manager input_key input_variables inputs int items kwargs langchain len list manager metadata output output_key page_content prompt prompts property pydantic return_only_outputs run_manager self set str text_splitter typing update

Python: /langchain/chains/combine_documents/map_reduce.py
  Functions: _collapse_docs _split_list_of_docs
  Classes: CombineDocsProtocol Config MapReduceDocumentsChain
  Methods: __call__ _chain_type _collapse_chain _collapse_docs_func _process_results acombine_docs combine_docs get_default_document_variable_name get_return_intermediate_steps output_keys
  Variables: _num_tokens _output_keys _results _sub_result_docs arbitrary_types_allowed collapse_document_chain: combine_document_chain: combined_metadata combined_metadata[k] document_variable_name: extra extra_return_dict length_func llm_chain: llm_chain_variables new_doc new_result_doc_list num_tokens output question_result_key result result_docs results return_intermediate_steps: values["document_variable_name"] values["return_intermediate_steps"]
  Usages: Any BaseCombineDocumentsChain Callable Callbacks Dict Document Extra LLMChain List Optional Protocol Tuple ValueError aapply annotations append apply base bool callbacks chains cls collapse_document_chain combine_document_chain combine_document_func combine_documents dict doc docs docstore document document_variable_name enumerate forbid input_documents input_variables int items kwargs langchain len llm llm_chain manager metadata output_key page_content pre prompt prompt_length property pydantic return_intermediate_steps root_validator run self str super token_max typing values

Python: /langchain/chains/combine_documents/map_rerank.py
  Classes: Config MapRerankDocumentsChain
  Methods: _chain_type _process_results acombine_docs combine_docs get_default_document_variable_name output_keys validate_llm_output
  Variables: _output_keys answer_key: arbitrary_types_allowed document_variable_name: extra extra_info extra_info["intermediate_steps"] extra_info[key] llm_chain: llm_chain_variables metadata_keys: output, output_keys output_parser rank_key: results return_intermediate_steps: sorted_res typed_results values["document_variable_name"]
  Usages: Any BaseCombineDocumentsChain Callbacks Dict Document Extra LLMChain List Optional RegexParser Sequence Tuple Union ValueError aapply_and_parse annotations answer_key apply_and_parse base bool callbacks cast chains cls combine_documents dict docs docstore document document_variable_name forbid input_variables int isinstance key kwargs langchain len llm llm_chain manager metadata metadata_keys output output_parsers page_content pre prompt property pydantic rank_key regex return_intermediate_steps root_validator self sorted str super typing values zip

Python: /langchain/chains/combine_documents/refine.py
  Functions: _get_default_document_prompt
  Classes: Config RefineDocumentsChain
  Methods: _chain_type _construct_initial_inputs _construct_refine_inputs _construct_result acombine_docs combine_docs get_default_document_variable_name get_return_intermediate_steps output_keys
  Variables: _output_keys arbitrary_types_allowed base_info base_inputs base_inputs: document_info document_prompt: document_variable_name: extra extra_return_dict initial_llm_chain: initial_response_name: inputs llm_chain_variables refine_llm_chain: refine_steps res return_intermediate_steps: values["document_variable_name"] values["return_intermediate_steps"]
  Usages: Any BaseCombineDocumentsChain BasePromptTemplate Callbacks Dict Document Extra Field LLMChain List PromptTemplate Tuple ValueError annotations append apredict base bool callbacks chains cls combine_documents default_factory dict doc docs docstore document document_prompt document_variable_name forbid format format_document initial_llm_chain initial_response_name input_variables kwargs langchain len llm manager metadata page_content pre predict prompt prompts property pydantic refine_llm_chain return_intermediate_steps root_validator self str super template typing update values

Python: /langchain/chains/combine_documents/stuff.py
  Functions: _get_default_document_prompt
  Classes: Config StuffDocumentsChain
  Methods: _chain_type _get_inputs acombine_docs combine_docs get_default_document_variable_name prompt_length
  Variables: arbitrary_types_allowed doc_strings document_prompt: document_separator: document_variable_name: extra inputs inputs[self.document_variable_name] llm_chain: llm_chain_variables prompt values["document_variable_name"]
  Usages: Any BaseCombineDocumentsChain BasePromptTemplate Callbacks Dict Document Extra Field LLMChain List Optional PromptTemplate Tuple ValueError apredict base callbacks chains cls combine_documents default_factory dict doc docs docstore document document_prompt document_separator document_variable_name forbid format format_document get_num_tokens input_variables int items join kwargs langchain len llm llm_chain manager pre predict prompts property pydantic root_validator self str template typing values

Python: /langchain/chains/constitutional_ai/base.py
  Classes: ConstitutionalChain
  Methods: _call _parse_critique from_llm get_principles input_keys output_keys
  Variables: _run_manager chain: constitutional_principles: critique critique_chain critique_chain: critiques_and_revisions final_output: final_output["critiques_and_revisions"] final_output["initial_output"] initial_response input_prompt output_string raw_critique response return_intermediate_steps: revision revision_chain revision_chain:
  Usages: Any BaseLanguageModel BasePromptTemplate CRITIQUE_PROMPT CallbackManagerForChainRun Chain ConstitutionalPrinciple Dict LLMChain List Optional PRINCIPLES REVISION_PROMPT append base base_language bool callbacks chain chains classmethod cls color constitutional_ai constitutional_principle constitutional_principles critique_prompt critique_request final_output format get_child get_noop_manager inputs kwargs langchain list llm lower manager models name names on_text output_from_model principles prompt prompts property return_intermediate_steps revision_prompt revision_request run run_manager self split staticmethod str strip text typing values verbose

Python: /langchain/chains/constitutional_ai/models.py
  Classes: ConstitutionalPrinciple
  Variables: critique_request: name: revision_request:
  Usages: BaseModel critique_request name pydantic revision_request str

Python: /langchain/chains/constitutional_ai/principles.py
  Variables: PRINCIPLES:
  Usages: ConstitutionalPrinciple Dict PRINCIPLES chains constitutional_ai critique_request langchain models name revision_request str typing

Python: /langchain/chains/constitutional_ai/prompts.py
  Variables: CRITIQUE_PROMPT REVISION_PROMPT critique_example examples
  Usages: FewShotPromptTemplate PromptTemplate copy deepcopy example_prompt example_separator few_shot input_variables items langchain prefix prompt prompts suffix template

Python: /langchain/chains/conversation/base.py
  Classes: Config ConversationChain
  Methods: input_keys validate_prompt_input_variables
  Variables: arbitrary_types_allowed expected_keys extra input_key input_key: memory: memory_keys output_key: prompt: prompt_variables
  Usages: BaseMemory BasePromptTemplate ConversationBufferMemory Dict Extra Field LLMChain List PROMPT ValueError base buffer chains cls conversation default_factory forbid input_variables langchain llm memory memory_variables output_key prompt prompts property pydantic root_validator schema self set str typing values

Python: /langchain/chains/conversation/memory.py
  Variables: __all__
  Usages: CombinedMemory ConversationBufferMemory ConversationBufferWindowMemory ConversationEntityMemory ConversationKGMemory ConversationStringBufferMemory ConversationSummaryBufferMemory ConversationSummaryMemory buffer buffer_window combined entity langchain memory summary summary_buffer

Python: /langchain/chains/conversation/prompt.py
  Variables: DEFAULT_TEMPLATE PROMPT __all__
  Usages: ENTITY_EXTRACTION_PROMPT ENTITY_MEMORY_CONVERSATION_TEMPLATE ENTITY_SUMMARIZATION_PROMPT KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT PromptTemplate SUMMARY_PROMPT input_variables langchain memory prompt prompts template

Python: /langchain/chains/conversational_retrieval/base.py
  Functions: _get_chat_history
  Classes: BaseConversationalRetrievalChain ChatVectorDBChain Config ConversationalRetrievalChain
  Methods: _acall _aget_docs _call _chain_type _get_docs _reduce_tokens_below_limit from_llm input_keys output_keys raise_deprecation save
  Variables: CHAT_TURN_TYPE _ROLE_MAP _llm _output_keys _run_manager allow_population_by_field_name answer arbitrary_types_allowed buffer callbacks chat_history_str combine_docs_chain: combine_docs_chain_kwargs condense_question_chain doc_chain docs extra full_kwargs get_chat_history get_chat_history: human max_tokens_limit: new_inputs new_inputs["chat_history"] new_inputs["question"] new_question num_docs output: output["generated_question"] output["source_documents"] output_key: question question_generator: retriever: return_generated_question: return_source_documents: role_prefix search_kwargs: token_count tokens top_k_docs_for_context: vectordbkwargs vectorstore:
  Usages: Any AsyncCallbackManagerForChainRun BaseCombineDocumentsChain BaseLanguageModel BaseMessage BasePromptTemplate BaseRetriever CONDENSE_QUESTION_PROMPT Callable CallbackManagerForChainRun Callbacks Chain Dict Document Extra Field LLMChain List NotImplementedError Optional Path StuffDocumentsChain Tuple Union ValueError VectorStore abc abstractmethod aget_relevant_documents alias annotations arun base base_language bool chain_type chains chat_history classmethod cls combine_docs_chain combine_documents condense_question_llm condense_question_prompt content conversational_retrieval copy default_factory dialogue_turn dict doc file_path forbid get get_child get_noop_manager get_num_tokens get_relevant_documents input_documents inputs int isinstance join kwargs langchain len llm llm_chain load_qa_chain manager max_tokens_limit output output_key page_content pathlib prompt prompts property pydantic question_answering question_generator retriever return_generated_question return_source_documents root_validator run run_manager schema search_kwargs self similarity_search str stuff sum super top_k_docs_for_context tuple type typing values vectorstore vectorstores verbose warn warnings

Python: /langchain/chains/conversational_retrieval/prompts.py
  Variables: CONDENSE_QUESTION_PROMPT QA_PROMPT _template prompt_template
  Usages: PromptTemplate from_template input_variables langchain prompt prompts template

Python: /langchain/chains/flare/base.py
  Functions: _low_confidence_spans
  Classes: FlareChain QuestionGeneratorChain _OpenAIResponseChain _ResponseChain
  Methods: _call _do_generation _do_retrieval _extract_tokens_and_log_probs from_llm generate_tokens_and_log_probs input_keys output_keys
  Variables: _input _low_idx _run_manager callbacks context docs end final_response, initial_response llm: llm_result log_probs low_confidence_spans low_idx marginal, max_iter: min_prob: min_token_gap: num_pad_tokens: output_parser: prompt: question_gen_chain question_gen_inputs question_gen_outputs question_generator_chain: questions response response_chain response_chain: response_llm result retriever: spans spans[-1][1] start_with_retrieval: tokens tokens, user_input
  Usages: Any BaseLanguageModel BasePromptTemplate BaseRetriever CallbackManagerForChainRun Chain Dict Field FinishedOutputParser Generation LLMChain List OpenAI Optional PROMPT QUESTION_GENERATOR_PROMPT Sequence Tuple ValueError abc abstractmethod annotations append apply base base_language bool chains classmethod cls color default_factory enumerate exp extend final_response finished flare float gen generate generation_info generations get_child get_noop_manager get_relevant_documents idx input_variables inputs int join kwargs langchain len llm llms manager marginal max_generation_len max_iter max_tokens min_prob min_token_gap model_kwargs num_pad_tokens numpy on_text output output_parser page_content parse predict prompt prompts property pydantic question question_generator_chain range retriever run_manager schema search self span start start_with_retrieval str strip temperature typing where

Python: /langchain/chains/flare/prompts.py
  Classes: FinishedOutputParser
  Methods: parse
  Variables: PROMPT PROMPT_TEMPLATE QUESTION_GENERATOR_PROMPT QUESTION_GENERATOR_PROMPT_TEMPLATE cleaned finished finished_value:
  Usages: BaseOutputParser PromptTemplate Tuple bool finished_value input_variables langchain prompts replace schema self str strip template text typing

Python: /langchain/chains/graph_qa/base.py
  Classes: GraphQAChain
  Methods: _call from_llm input_keys output_keys
  Variables: _output_keys _run_manager context entities entity_chain entity_extraction_chain: entity_string graph: input_key: output_key: qa_chain qa_chain: question result triplets
  Usages: Any BaseLanguageModel BasePromptTemplate CallbackManagerForChainRun Chain Dict ENTITY_EXTRACTION_PROMPT Field LLMChain List NetworkxEntityGraph Optional PROMPT annotations base base_language callbacks chains classmethod cls color end entity entity_extraction_chain entity_prompt exclude get_child get_entities get_entity_knowledge get_noop_manager graph graph_qa graphs input_key inputs join kwargs langchain llm manager networkx_graph on_text output_key prompt prompts property pydantic qa_prompt run run_manager self str typing verbose

Python: /langchain/chains/graph_qa/cypher.py
  Functions: extract_cypher
  Classes: GraphCypherQAChain
  Methods: _call from_llm input_keys output_keys
  Variables: INTERMEDIATE_STEPS_KEY _output_keys _run_manager callbacks chain_result: chain_result[INTERMEDIATE_STEPS_KEY] context cypher_generation_chain cypher_generation_chain: final_result generated_cypher graph: input_key: intermediate_steps: matches output_key: pattern qa_chain qa_chain: question result return_direct: return_intermediate_steps: top_k:
  Usages: Any BaseLanguageModel BasePromptTemplate CYPHER_GENERATION_PROMPT CYPHER_QA_PROMPT CallbackManagerForChainRun Chain DOTALL Dict Field LLMChain List Neo4jGraph Optional annotations append base base_language bool chain_result chains classmethod cls color cypher_prompt end exclude findall get_child get_noop_manager get_schema graph graph_qa graphs input_key inputs int intermediate_steps kwargs langchain llm manager neo4j_graph on_text output_key prompt prompts property pydantic qa_prompt query return_direct return_intermediate_steps run run_manager self str text top_k typing verbose

Python: /langchain/chains/graph_qa/nebulagraph.py
  Classes: NebulaGraphQAChain
  Methods: _call from_llm input_keys output_keys
  Variables: _output_keys _run_manager callbacks context generated_ngql graph: input_key: ngql_generation_chain ngql_generation_chain: output_key: qa_chain qa_chain: question result
  Usages: Any BaseLanguageModel BasePromptTemplate CYPHER_QA_PROMPT CallbackManagerForChainRun Chain Dict Field LLMChain List NGQL_GENERATION_PROMPT NebulaGraph Optional annotations base base_language chains classmethod cls color end exclude get_child get_noop_manager get_schema graph graph_qa graphs input_key inputs kwargs langchain llm manager nebula_graph ngql_prompt on_text output_key prompt prompts property pydantic qa_prompt query run run_manager self str typing verbose

Python: /langchain/chains/graph_qa/prompts.py
  Variables: CYPHER_GENERATION_PROMPT CYPHER_GENERATION_TEMPLATE CYPHER_QA_PROMPT CYPHER_QA_TEMPLATE ENTITY_EXTRACTION_PROMPT NEBULAGRAPH_EXTRA_INSTRUCTIONS NGQL_GENERATION_PROMPT NGQL_GENERATION_TEMPLATE PROMPT _DEFAULT_ENTITY_EXTRACTION_TEMPLATE prompt_template
  Usages: PromptTemplate input_variables langchain prompt prompts replace template

Python: /langchain/chains/hyde/base.py
  Classes: Config HypotheticalDocumentEmbedder
  Methods: _call _chain_type combine_embeddings embed_documents embed_query from_llm input_keys output_keys
  Variables: _run_manager arbitrary_types_allowed base_embeddings: documents embeddings extra llm_chain llm_chain: prompt result var_name
  Usages: Any BaseLanguageModel CallbackManagerForChainRun Chain Dict Embeddings Extra LLMChain List Optional PROMPT_MAP annotations array axis base base_embeddings base_language callbacks chains classmethod cls float forbid generate generation generations get_child get_noop_manager hyde inputs kwargs langchain list llm manager mean numpy prompt_key prompts property pydantic run_manager self str text texts typing

Python: /langchain/chains/hyde/prompts.py
  Variables: PROMPT_MAP arguana arguana_template dbpedia_entity dbpedia_entity_template fiqa fiqa_template mr_tydi mr_tydi_template sci_fact sci_fact_template trec_covid trec_covid_template trec_news trec_news_template web_search web_search_template
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/chains/llm_bash/base.py
  Classes: Config LLMBashChain
  Methods: _call _chain_type from_llm input_keys output_keys raise_deprecation validate_prompt
  Variables: _run_manager arbitrary_types_allowed bash_process: command_list extra input_key: llm: llm_chain llm_chain: logger output output_key: parser prompt prompt: values["llm_chain"]
  Usages: Any BaseLanguageModel BasePromptTemplate BashProcess CallbackManagerForChainRun Chain Dict Extra Field LLMChain List Optional OutputParserException PROMPT ValueError __name__ annotations base base_language bash bash_process callbacks chains classmethod cls color default_factory forbid get getLogger get_child get_noop_manager input_key inputs kwargs langchain llm llm_bash logging manager on_chain_error on_text output_key output_parser parse pre predict prompts property pydantic question root_validator run run_manager schema self str strip typing utilities values verbose warn warnings

Python: /langchain/chains/llm_bash/prompt.py
  Classes: BashOutputParser
  Methods: _type get_code_blocks parse
  Variables: PROMPT _PROMPT_TEMPLATE code_blocks: matched pattern
  Usages: BaseOutputParser DOTALL List OutputParserException PromptTemplate annotations code_blocks compile extend finditer group input_variables langchain line match output_parser prompt prompts property schema self split staticmethod str strip template text typing

Python: /langchain/chains/llm_checker/base.py
  Functions: _load_question_to_checked_assertions_chain
  Classes: Config LLMCheckerChain
  Methods: _call _chain_type from_llm input_keys output_keys raise_deprecation
  Variables: _run_manager arbitrary_types_allowed chains check_assertions_chain check_assertions_prompt: create_draft_answer_chain create_draft_answer_prompt: extra input_key: list_assertions_chain list_assertions_prompt: llm: output output_key: question question_to_checked_assertions_chain question_to_checked_assertions_chain: revised_answer_chain revised_answer_prompt: values[
  Usages: Any BaseLanguageModel CHECK_ASSERTIONS_PROMPT CREATE_DRAFT_ANSWER_PROMPT CallbackManagerForChainRun Chain Dict Extra LIST_ASSERTIONS_PROMPT LLMChain List Optional PromptTemplate REVISED_ANSWER_PROMPT SequentialChain annotations base base_language callbacks check_assertions_prompt classmethod cls create_draft_answer_prompt forbid get get_child get_noop_manager input_key input_variables inputs kwargs langchain list_assertions_prompt llm llm_checker manager output_key output_variables pre prompt prompts property pydantic revised_answer_prompt root_validator run_manager self sequential str typing values verbose warn warnings

Python: /langchain/chains/llm_checker/prompt.py
  Variables: CHECK_ASSERTIONS_PROMPT CREATE_DRAFT_ANSWER_PROMPT LIST_ASSERTIONS_PROMPT REVISED_ANSWER_PROMPT _CHECK_ASSERTIONS_TEMPLATE _CREATE_DRAFT_ANSWER_TEMPLATE _LIST_ASSERTIONS_TEMPLATE _REVISED_ANSWER_TEMPLATE
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/chains/llm_math/base.py
  Classes: Config LLMMathChain
  Methods: _acall _aprocess_llm_result _call _chain_type _evaluate_expression _process_llm_result from_llm input_keys output_keys raise_deprecation
  Variables: _run_manager answer arbitrary_types_allowed expression extra input_key: llm: llm_chain llm_chain: llm_output local_dict output output_key: prompt prompt: text_match values["llm_chain"]
  Usages: Any AsyncCallbackManagerForChainRun BaseLanguageModel BasePromptTemplate CallbackManagerForChainRun Chain DOTALL Dict Exception Extra LLMChain List Optional PROMPT ValueError annotations apredict base base_language callbacks chains classmethod cls color evaluate forbid get get_child get_noop_manager global_dict group input_key inputs kwargs langchain llm llm_math manager math numexpr on_text output_key pre predict prompts property pydantic question root_validator run_manager search self split startswith stop str strip sub typing values verbose warn warnings

Python: /langchain/chains/llm_math/prompt.py
  Variables: PROMPT _PROMPT_TEMPLATE
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/chains/llm_summarization_checker/base.py
  Functions: _load_sequential_chain
  Classes: Config LLMSummarizationCheckerChain
  Methods: _call _chain_type from_llm input_keys output_keys raise_deprecation
  Variables: ARE_ALL_TRUE_PROMPT CHECK_ASSERTIONS_PROMPT CREATE_ASSERTIONS_PROMPT PROMPTS_DIR REVISED_SUMMARY_PROMPT _run_manager all_true arbitrary_types_allowed are_all_true_prompt: chain chain_input check_assertions_prompt: count create_assertions_prompt: extra input_key: llm: max_checks: original_input output output_key: revised_summary_prompt: sequential_chain: values["sequential_chain"]
  Usages: Any BaseLanguageModel CallbackManagerForChainRun Chain Dict Extra LLMChain List Optional Path PromptTemplate SequentialChain ValueError __file__ annotations are_all_true_prompt base base_language bool callbacks chains check_assertions_prompt classmethod cls create_assertions_prompt forbid from_file get get_child get_noop_manager input_key input_variables inputs int kwargs langchain llm manager max_checks output_key output_variables parent pathlib pre print prompt prompts property pydantic revised_summary_prompt root_validator run_manager self sequential sequential_chain str strip typing values verbose warn warnings

Python: /langchain/chains/natbot/base.py
  Classes: Config NatBotChain
  Methods: _call _chain_type execute from_default from_llm input_keys output_keys raise_deprecation
  Variables: _inputs _run_manager arbitrary_types_allowed browser_content extra input_browser_content_key: input_url_key: llm llm: llm_chain llm_chain: llm_cmd objective: output_key: previous_command: self.previous_command url values["llm_chain"]
  Usages: Any BaseLanguageModel CallbackManagerForChainRun Chain Dict Extra LLMChain List OpenAI Optional PROMPT annotations base base_language best_of callbacks chains classmethod cls forbid get_child get_noop_manager input_browser_content_key input_url_key inputs kwargs langchain llms manager max_tokens natbot objective openai output_key pre predict previous_command prompt property pydantic root_validator run_manager self str strip temperature typing values warn warnings

Python: /langchain/chains/natbot/crawler.py
  Classes: Crawler ElementInViewPort
  Methods: __init__ add_to_hash_tree click convert_name crawl enter find_attributes go_to_page scroll type
  Variables: [x, ancestor_exception ancestor_node ancestor_node_key anchor_ancestry: attributes: backend_node_id: black_listed_elements: bounds: button_ancestry: center_x: center_y: child_nodes: converted_node_name cursor cursor: device_pixel_ratio device_pixel_ratio: document: elem_left_bound elem_lower_bound elem_right_bound elem_top_bound element element_attributes element_node_value elements_in_view_port: elements_of_interest entry_key entry_type entry_value grand_parent_id hash_tree[str(node_id)] id_counter inner_text input_value: input_value_index: input_value_values: is_ancestor_of_anchor, is_ancestor_of_button, is_clickable: is_parent_desc_anchor, key layout: layout_node_index: meta meta_data: meta_string node_index node_index: node_input_text_index node_is_clickable node_meta: node_meta_data: node_name node_name: node_names: node_parent node_value: nodes: origin_x: origin_y: page page_element_buffer page_element_buffer[id_counter] page_state_as_text parent: parent_id_str parent_name partially_is_in_viewport percentage_progress_end percentage_progress_start self.browser: self.client self.client: self.page: self.page_element_buffer self.page_element_buffer: start strings: text text_index tree value value: values values[key] win_height: win_left_bound: win_lower_bound: win_right_bound: win_upper_bound: win_width:
  Usages: Any Browser CDPSession Dict ImportError Iterable List Optional Page Set TYPE_CHECKING Tuple TypedDict Union ValueError anchor_ancestry anchor_id append attributes backend_node_id black_listed_elements bool bounds browser button_ancestry button_id center_x center_y child child_nodes chromium client context direction document elements_in_view_port enumerate evaluate float format get goto has_click_handler hash_tree headless height index input_value input_value_index input_value_values int is_ancestor_of_anchor is_ancestor_of_button is_clickable is_parent_desc_anchor iter join key_index keyboard keys launch layout layout_node_index lower meta_data mouse new_cdp_session new_page node_id node_meta node_meta_data node_name_index node_names node_value nodes origin_x origin_y parent parent_id platform playwright pop press print remove round self send set set_viewport_size setdefault str strings strip sync_api sync_playwright sys tag time typing url value_index width win_height win_left_bound win_lower_bound win_right_bound win_upper_bound win_width zip

Python: /langchain/chains/natbot/prompt.py
  Variables: PROMPT _PROMPT_TEMPLATE
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/chains/pal/base.py
  Classes: Config PALChain
  Methods: _call _chain_type from_colored_object_prompt from_math_prompt input_keys output_keys raise_deprecation
  Variables: _run_manager arbitrary_types_allowed code extra get_answer_expr: llm: llm_chain llm_chain: output output["intermediate_steps"] output_key: prompt: python_globals: python_locals: repl res return_intermediate_steps: stop: values["llm_chain"]
  Usages: Any BaseLanguageModel BasePromptTemplate COLORED_OBJECT_PROMPT CallbackManagerForChainRun Chain Dict Extra LLMChain List MATH_PROMPT Optional PythonREPL _globals _locals annotations base base_language bool callbacks chains classmethod cls color colored_object_prompt end forbid get_answer_expr get_child get_noop_manager input_variables inputs kwargs langchain llm manager math_prompt on_text output_key pal pre predict prompt prompts property pydantic python_globals python_locals return_intermediate_steps root_validator run run_manager self stop str strip typing utilities values verbose warn warnings

Python: /langchain/chains/pal/colored_object_prompt.py
  Variables: COLORED_OBJECT_PROMPT template
  Usages: PromptTemplate input_variables langchain prompt prompts strip

Python: /langchain/chains/pal/math_prompt.py
  Variables: MATH_PROMPT template
  Usages: PromptTemplate input_variables langchain prompt prompts strip

Python: /langchain/chains/qa_generation/base.py
  Classes: QAGenerationChain
  Methods: _call _chain_type from_llm input_keys output_keys
  Variables: _prompt chain docs input_key: llm_chain: output_key: results text_splitter:
  Usages: Any BaseLanguageModel BasePromptTemplate CallbackManagerForChainRun Chain Dict Field LLMChain List NotImplementedError Optional PROMPT_SELECTOR RecursiveCharacterTextSplitter TextSplitter annotations base base_language callbacks chains chunk_overlap classmethod cls create_documents default generate generations get_prompt input_key inputs int json kwargs langchain llm llm_chain loads manager output_key page_content prompt prompts property pydantic qa_generation res run_manager self str text text_splitter typing

Python: /langchain/chains/qa_generation/prompt.py
  Variables: CHAT_PROMPT PROMPT PROMPT_SELECTOR templ templ1 templ2
  Usages: ChatPromptTemplate ConditionalPromptSelector HumanMessagePromptTemplate PromptTemplate SystemMessagePromptTemplate chains chat conditionals default_prompt from_messages from_template is_chat_model langchain prompt prompt_selector prompts

Python: /langchain/chains/qa_with_sources/__init__.py
  Variables: __all__
  Usages: chains langchain load_qa_with_sources_chain loading qa_with_sources

Python: /langchain/chains/qa_with_sources/base.py
  Classes: BaseQAWithSourcesChain Config QAWithSourcesChain
  Methods: _acall _aget_docs _call _chain_type _get_docs from_chain_type from_llm input_keys output_keys validate_naming
  Variables: _chain_kwargs _output_keys _run_manager answer answer, answer_key: arbitrary_types_allowed combine_document_chain combine_documents_chain: combine_results_chain docs extra input_docs_key: llm_combine_chain llm_question_chain question_key: result: result["source_documents"] return_source_documents: sources sources_answer_key: values["combine_documents_chain"]
  Usages: ABC Any AsyncCallbackManagerForChainRun BaseCombineDocumentsChain BaseLanguageModel BasePromptTemplate COMBINE_PROMPT CallbackManagerForChainRun Chain Dict Document EXAMPLE_PROMPT Extra LLMChain List MapReduceDocumentsChain Optional QUESTION_PROMPT StuffDocumentsChain abc abstractmethod annotations answer_key arun base base_language bool callbacks chain_type chain_type_kwargs chains classmethod cls combine_documents combine_documents_chain combine_prompt dict docstore document document_prompt document_variable_name forbid get_child get_noop_manager input_docs_key input_documents inputs kwargs langchain llm llm_chain load_qa_with_sources_chain loading manager map_reduce map_reduce_prompt pop pre prompt prompts property pydantic qa_with_sources question_key question_prompt result return_source_documents root_validator run run_manager search self sources_answer_key split str stuff typing values

Python: /langchain/chains/qa_with_sources/loading.py
  Functions: _load_map_reduce_chain _load_map_rerank_chain _load_refine_chain _load_stuff_chain load_qa_with_sources_chain
  Classes: LoadingCallable
  Methods: __call__
  Variables: _collapse_llm _func: _reduce_llm _refine_llm collapse_chain combine_document_chain initial_chain llm_chain loader_mapping: map_chain reduce_chain refine_chain
  Usages: Any BaseCombineDocumentsChain BaseLanguageModel BasePromptTemplate COMBINE_PROMPT DEFAULT_REFINE_PROMPT DEFAULT_TEXT_QA_PROMPT EXAMPLE_PROMPT LLMChain MapReduceDocumentsChain MapRerankDocumentsChain Mapping Optional PROMPT Protocol QUESTION_PROMPT RefineDocumentsChain StuffDocumentsChain ValueError _func answer_key base base_language bool chain_type chains collapse_document_chain collapse_llm collapse_prompt combine_document_variable_name combine_documents combine_prompt document_prompt document_variable_name initial_llm_chain initial_response_name keys kwargs langchain llm loader_mapping map_reduce map_reduce_document_variable_name map_reduce_prompt map_rerank map_rerank_prompt prompt prompts qa_with_sources question_answering question_prompt rank_key reduce_llm refine refine_llm refine_llm_chain refine_prompt refine_prompts self str stuff stuff_prompt typing verbose

Python: /langchain/chains/qa_with_sources/map_reduce_prompt.py
  Variables: COMBINE_PROMPT EXAMPLE_PROMPT QUESTION_PROMPT combine_prompt_template question_prompt_template
  Usages: PromptTemplate input_variables langchain prompts template

Python: /langchain/chains/qa_with_sources/refine_prompts.py
  Variables: DEFAULT_REFINE_PROMPT DEFAULT_REFINE_PROMPT_TMPL DEFAULT_TEXT_QA_PROMPT DEFAULT_TEXT_QA_PROMPT_TMPL EXAMPLE_PROMPT
  Usages: PromptTemplate input_variables langchain prompts template

Python: /langchain/chains/qa_with_sources/retrieval.py
  Classes: RetrievalQAWithSourcesChain
  Methods: _aget_docs _get_docs _reduce_tokens_below_limit
  Variables: docs max_tokens_limit: num_docs question reduce_k_below_max_tokens: retriever: token_count tokens
  Usages: Any BaseQAWithSourcesChain BaseRetriever Dict Document Field List StuffDocumentsChain aget_relevant_documents base bool chains combine_documents combine_documents_chain doc docstore document exclude get_num_tokens get_relevant_documents inputs int isinstance langchain len llm llm_chain max_tokens_limit page_content pydantic qa_with_sources question_key reduce_k_below_max_tokens retriever schema self str stuff sum typing

Python: /langchain/chains/qa_with_sources/stuff_prompt.py
  Variables: EXAMPLE_PROMPT PROMPT template
  Usages: PromptTemplate input_variables langchain prompts

Python: /langchain/chains/qa_with_sources/vector_db.py
  Classes: VectorDBQAWithSourcesChain
  Methods: _aget_docs _chain_type _get_docs _reduce_tokens_below_limit raise_deprecation
  Variables: docs max_tokens_limit: num_docs question reduce_k_below_max_tokens: search_kwargs: token_count tokens vectorstore:
  Usages: Any BaseQAWithSourcesChain Dict Document Field List NotImplementedError StuffDocumentsChain VectorStore base bool chains cls combine_documents combine_documents_chain default_factory dict doc docstore document exclude get_num_tokens inputs int isinstance langchain len llm llm_chain max_tokens_limit page_content property pydantic qa_with_sources question_key reduce_k_below_max_tokens root_validator search_kwargs self similarity_search str stuff sum typing values vectorstore vectorstores warn warnings

Python: /langchain/chains/query_constructor/base.py
  Functions: _format_attribute_info _get_prompt load_query_constructor_chain
  Classes: StructuredQueryOutputParser
  Methods: from_components parse
  Variables: allowed_comparators allowed_keys allowed_operators ast_parse: ast_parser attribute_str examples expected_keys i_dict info_dicts info_dicts[i_dict.pop("name")] output_parser parsed parsed["filter"] parsed["query"] prefix prompt schema suffix
  Usages: Any AttributeInfo BaseLanguageModel BaseOutputParser BasePromptTemplate Callable Comparator DEFAULT_EXAMPLES DEFAULT_PREFIX DEFAULT_SCHEMA DEFAULT_SUFFIX EXAMPLES_WITH_LIMIT EXAMPLE_PROMPT Exception FewShotPromptTemplate LLMChain List Operator Optional OutputParserException SCHEMA_WITH_LIMIT Sequence StructuredQuery annotations ast_parse attribute_info attributes base_language bool chains classmethod cls content dict document_contents dumps enable_limit example_prompt format get get_parser indent info input_variables items join json kwargs langchain len list llm output_parsers parse_and_check_json_markdown parser pop query_constructor replace self str text typing

Python: /langchain/chains/query_constructor/ir.py
  Functions: _to_snake_case
  Classes: Comparator Comparison Expr FilterDirective Operation Operator StructuredQuery Visitor
  Methods: _validate_func accept visit_comparison visit_operation visit_structured_query
  Variables: AND EQ GT GTE LT LTE NOT OR allowed_comparators: allowed_operators: arguments: attribute: comparator: filter: limit: operator: query: snake_case value:
  Usages: ABC Any BaseModel Enum List Optional Sequence Union ValueError __class__ __name__ abc abstractmethod allowed_comparators allowed_operators annotations arguments attribute char comparator comparison enum enumerate filter func getattr int isinstance isupper limit lower name operation operator pydantic query self str structured_query typing value visitor

Python: /langchain/chains/query_constructor/parser.py
  Functions: get_parser
  Classes: QueryTransformer
  Methods: __init__ _match_func_name args false float func_call int list program string true v_args
  Variables: GRAMMAR Lark Transformer func self.allowed_comparators self.allowed_operators transformer
  Usages: AND Any Comparator Comparison FilterDirective ImportError OR Operation Operator Optional Sequence Union ValueError __version__ allowed_comparators allowed_operators arguments attribute bool chains comparator func_name inline isinstance item items kwargs langchain lark len object operator packaging parse parser query_constructor self set start str strip super tuple typing value version

Python: /langchain/chains/query_constructor/prompt.py
  Variables: DEFAULT_EXAMPLES DEFAULT_PREFIX DEFAULT_SCHEMA DEFAULT_SUFFIX EXAMPLES_WITH_LIMIT EXAMPLE_PROMPT EXAMPLE_PROMPT_TEMPLATE FULL_ANSWER NO_FILTER_ANSWER SCHEMA_WITH_LIMIT SONG_DATA_SOURCE WITH_LIMIT_ANSWER
  Usages: PromptTemplate input_variables langchain replace template

Python: /langchain/chains/query_constructor/schema.py
  Classes: AttributeInfo Config
  Variables: arbitrary_types_allowed description: frozen name: type:
  Usages: BaseModel description name pydantic str type

Python: /langchain/chains/question_answering/__init__.py
  Functions: _load_map_reduce_chain _load_map_rerank_chain _load_refine_chain _load_stuff_chain load_qa_chain
  Classes: LoadingCallable
  Methods: __call__
  Variables: _collapse_llm _combine_prompt _prompt _question_prompt _reduce_llm _refine_llm _refine_prompt collapse_chain combine_document_chain initial_chain llm_chain loader_mapping: map_chain reduce_chain refine_chain
  Usages: Any BaseCallbackManager BaseCombineDocumentsChain BaseLanguageModel BasePromptTemplate COMBINE_PROMPT_SELECTOR Callbacks LLMChain MapReduceDocumentsChain MapRerankDocumentsChain Mapping Optional PROMPT PROMPT_SELECTOR Protocol QUESTION_PROMPT_SELECTOR REFINE_PROMPT_SELECTOR RefineDocumentsChain StuffDocumentsChain ValueError answer_key base base_language bool callback_manager callbacks chain_type chains collapse_document_chain collapse_llm collapse_prompt combine_document_variable_name combine_documents combine_prompt document_variable_name get_prompt initial_llm_chain initial_response_name keys kwargs langchain llm loader_mapping manager map_reduce map_reduce_document_variable_name map_reduce_prompt map_rerank map_rerank_prompt prompt prompts question_answering question_prompt rank_key reduce_llm refine refine_llm refine_llm_chain refine_prompt refine_prompts self str stuff stuff_prompt typing verbose

Python: /langchain/chains/question_answering/map_reduce_prompt.py
  Variables: CHAT_COMBINE_PROMPT CHAT_QUESTION_PROMPT COMBINE_PROMPT COMBINE_PROMPT_SELECTOR QUESTION_PROMPT QUESTION_PROMPT_SELECTOR combine_prompt_template messages question_prompt_template system_template
  Usages: ChatPromptTemplate ConditionalPromptSelector HumanMessagePromptTemplate PromptTemplate SystemMessagePromptTemplate chains chat conditionals default_prompt from_messages from_template input_variables is_chat_model langchain prompt prompt_selector prompts template

Python: /langchain/chains/question_answering/map_rerank_prompt.py
  Variables: PROMPT output_parser prompt_template
  Usages: PromptTemplate RegexParser input_variables langchain output_keys output_parsers prompts regex template

Python: /langchain/chains/question_answering/refine_prompts.py
  Variables: CHAT_QUESTION_PROMPT CHAT_REFINE_PROMPT DEFAULT_REFINE_PROMPT DEFAULT_REFINE_PROMPT_TMPL DEFAULT_TEXT_QA_PROMPT DEFAULT_TEXT_QA_PROMPT_TMPL QUESTION_PROMPT_SELECTOR REFINE_PROMPT_SELECTOR chat_qa_prompt_template messages refine_template
  Usages: AIMessagePromptTemplate ChatPromptTemplate ConditionalPromptSelector HumanMessagePromptTemplate PromptTemplate SystemMessagePromptTemplate chains chat conditionals default_prompt from_messages from_template input_variables is_chat_model langchain prompt prompt_selector prompts template

Python: /langchain/chains/question_answering/stuff_prompt.py
  Variables: CHAT_PROMPT PROMPT PROMPT_SELECTOR messages prompt_template system_template
  Usages: ChatPromptTemplate ConditionalPromptSelector HumanMessagePromptTemplate PromptTemplate SystemMessagePromptTemplate chains chat conditionals default_prompt from_messages from_template input_variables is_chat_model langchain prompt_selector prompts template

Python: /langchain/chains/retrieval_qa/base.py
  Classes: BaseRetrievalQA Config RetrievalQA VectorDBQA
  Methods: _acall _aget_docs _call _chain_type _get_docs from_chain_type from_llm input_keys output_keys raise_deprecation validate_search_type
  Variables: _chain_type_kwargs _output_keys _prompt _run_manager allow_population_by_field_name answer arbitrary_types_allowed combine_documents_chain combine_documents_chain: docs document_prompt extra input_key: llm_chain output_key: question retriever: return_source_documents: search_kwargs: search_type search_type: vectorstore:
  Usages: Any AsyncCallbackManagerForChainRun BaseCombineDocumentsChain BaseLanguageModel BaseRetriever CallbackManagerForChainRun Chain Dict Document Extra Field LLMChain List NotImplementedError Optional PROMPT_SELECTOR PromptTemplate StuffDocumentsChain ValueError VectorStore abc abstractmethod aget_relevant_documents alias annotations arun base base_language bool callbacks chain_type chain_type_kwargs chains classmethod cls combine_documents default_factory dict document_variable_name exclude forbid get_child get_noop_manager get_prompt get_relevant_documents input_documents input_key input_variables inputs int kwargs langchain llm load_qa_chain manager max_marginal_relevance_search output_key prompt prompts property pydantic question_answering retriever return_source_documents root_validator run run_manager schema search_kwargs self similarity_search str stuff stuff_prompt template typing values vectorstore vectorstores warn warnings

Python: /langchain/chains/retrieval_qa/prompt.py
  Variables: PROMPT prompt_template
  Usages: PromptTemplate input_variables langchain prompts template

Python: /langchain/chains/router/__init__.py
  Variables: __all__
  Usages: LLMRouterChain MultiPromptChain MultiRetrievalQAChain MultiRouteChain RouterChain base chains langchain llm_router multi_prompt multi_retrieval_qa router

Python: /langchain/chains/router/base.py
  Classes: Config MultiRouteChain Route RouterChain
  Methods: _acall _call aroute input_keys output_keys route
  Variables: _run_manager arbitrary_types_allowed callbacks default_chain: destination: destination_chains: extra next_inputs: result route router_chain: silent_errors:
  Usages: ABC Any AsyncCallbackManagerForChainRun CallbackManagerForChainRun Callbacks Chain Dict Extra List Mapping NamedTuple Optional ValueError abc acall annotations base bool chains default_chain destination destination_chains forbid get_child get_noop_manager inputs langchain manager next_inputs on_text property pydantic router_chain run_manager self silent_errors str typing verbose

Python: /langchain/chains/router/embedding_router.py
  Classes: Config EmbeddingRouterChain
  Methods: _call from_names_and_descriptions input_keys
  Variables: _input arbitrary_types_allowed documents extra results routing_keys: vectorstore vectorstore:
  Usages: Any CallbackManagerForChainRun Dict Document Embeddings Extra List Optional RouterChain Sequence Tuple Type VectorStore annotations append base callbacks chains classmethod cls description descriptions docstore document embeddings forbid from_documents inputs join kwargs langchain manager metadata name names_and_descriptions page_content property pydantic router routing_keys run_manager self similarity_search str typing vectorstore_cls vectorstores

Python: /langchain/chains/router/llm_router.py
  Classes: LLMRouterChain RouterOutputParser
  Methods: _acall _call _validate_outputs from_llm input_keys parse validate_prompt
  Variables: _run_manager callbacks default_destination: expected_keys llm_chain llm_chain: next_inputs_inner_key: next_inputs_type: output parsed parsed["destination"] parsed["next_inputs"] prompt
  Usages: Any AsyncCallbackManagerForChainRun BaseLanguageModel BaseOutputParser BasePromptTemplate CallbackManagerForChainRun Dict Exception LLMChain List Optional OutputParserException RouterChain Type ValueError annotations apredict_and_parse base base_language cast chains classmethod cls default_destination dict get_child get_noop_manager inputs isinstance json kwargs langchain llm lower manager next_inputs_inner_key next_inputs_type output_parser output_parsers outputs parse_and_check_json_markdown predict_and_parse prompts property pydantic root_validator router run_manager schema self str strip super text typing values

Python: /langchain/chains/router/multi_prompt.py
  Classes: MultiPromptChain
  Methods: from_prompts output_keys
  Variables: _default_chain chain default_chain: destination_chains destination_chains: destination_chains[name] destinations destinations_str name prompt prompt_template router_chain router_chain: router_prompt router_template
  Usages: Any BaseLanguageModel ConversationChain Dict LLMChain LLMRouterChain List MULTI_PROMPT_ROUTER_TEMPLATE Mapping MultiRouteChain Optional PromptTemplate RouterChain RouterOutputParser annotations base base_language chains classmethod cls default_chain format from_llm input_variables join kwargs langchain llm llm_router multi_prompt_prompt output_key output_parser p_info prompt_infos prompts property router self str template typing

Python: /langchain/chains/router/multi_prompt_prompt.py
  Variables: MULTI_PROMPT_ROUTER_TEMPLATE

Python: /langchain/chains/router/multi_retrieval_prompt.py
  Variables: MULTI_RETRIEVAL_ROUTER_TEMPLATE

Python: /langchain/chains/router/multi_retrieval_qa.py
  Classes: MultiRetrievalQAChain
  Methods: from_retrievers output_keys
  Variables: _default_chain chain default_chain: destination_chains destination_chains: destination_chains[name] destinations destinations_str name prompt prompt_template retriever router_chain router_chain: router_prompt router_template
  Usages: Any BaseLanguageModel BaseRetrievalQA BaseRetriever Chain ChatOpenAI ConversationChain DEFAULT_TEMPLATE Dict LLMRouterChain List MULTI_RETRIEVAL_ROUTER_TEMPLATE Mapping MultiRouteChain Optional PromptTemplate RetrievalQA RouterOutputParser ValueError annotations base base_language chains chat_models classmethod cls conversation default_chain default_prompt default_retriever format from_llm get input_key input_variables join kwargs langchain llm llm_router multi_retrieval_prompt next_inputs_inner_key output_key output_parser prompts property r_info replace retrieval_qa retriever_infos router schema self str template typing

Python: /langchain/chains/sql_database/base.py
  Classes: Config SQLDatabaseChain SQLDatabaseSequentialChain
  Methods: _call _chain_type from_llm input_keys output_keys raise_deprecation
  Variables: INTERMEDIATE_STEPS_KEY _lowercased_table_names _run_manager _table_names arbitrary_types_allowed chain_result: chain_result[INTERMEDIATE_STEPS_KEY] checked_sql_command: database database: decider_chain decider_chain: exc.intermediate_steps extra final_result input_key: input_text intermediate_steps: llm: llm_chain llm_chain: llm_inputs llm_inputs["input"] new_inputs output_key: prompt prompt: query_checker_chain query_checker_inputs query_checker_prompt query_checker_prompt: result return_direct: return_intermediate_steps: sql_chain sql_chain: sql_cmd table_info table_names table_names_from_chain table_names_to_use top_k: use_query_checker: values["llm_chain"]
  Usages: Any BaseLanguageModel BasePromptTemplate CallbackManagerForChainRun Chain DECIDER_PROMPT Dict Exception Extra Field LLMChain List Optional PROMPT PromptTemplate QUERY_CHECKER SQLDatabase SQL_PROMPTS annotations append base base_language bool callbacks chain_result chains checked_sql_command classmethod cls color decider_prompt dialect end exc exclude forbid get get_child get_noop_manager get_table_info get_usable_table_names input_key input_variables inputs int intermediate_steps join kwargs langchain llm lower manager name on_text output_key pre predict predict_and_parse prompts property pydantic query_prompt return_direct return_intermediate_steps return_only_outputs root_validator run run_manager self sql_database str strip template tools top_k typing use_query_checker values verbose warn warnings

Python: /langchain/chains/sql_database/prompt.py
  Variables: CLICKHOUSE_PROMPT DECIDER_PROMPT DUCKDB_PROMPT GOOGLESQL_PROMPT MARIADB_PROMPT MSSQL_PROMPT MYSQL_PROMPT ORACLE_PROMPT POSTGRES_PROMPT PRESTODB_PROMPT PROMPT PROMPT_SUFFIX SQLITE_PROMPT SQL_PROMPTS _DECIDER_TEMPLATE _DEFAULT_TEMPLATE _clickhouse_prompt _duckdb_prompt _googlesql_prompt _mariadb_prompt _mssql_prompt _mysql_prompt _oracle_prompt _postgres_prompt _prestodb_prompt _sqlite_prompt
  Usages: CommaSeparatedListOutputParser PromptTemplate input_variables langchain list output_parser output_parsers prompt prompts template

Python: /langchain/chains/summarize/__init__.py
  Functions: _load_map_reduce_chain _load_refine_chain _load_stuff_chain load_summarize_chain
  Classes: LoadingCallable
  Methods: __call__
  Variables: _collapse_llm _reduce_llm _refine_llm collapse_chain combine_document_chain initial_chain llm_chain loader_mapping: map_chain reduce_chain refine_chain
  Usages: Any BaseCombineDocumentsChain BaseLanguageModel BasePromptTemplate LLMChain MapReduceDocumentsChain Mapping Optional PROMPT Protocol REFINE_PROMPT RefineDocumentsChain StuffDocumentsChain ValueError base base_language bool chain_type chains collapse_document_chain collapse_llm collapse_prompt combine_document_variable_name combine_documents combine_prompt document_variable_name initial_llm_chain initial_response_name keys kwargs langchain llm loader_mapping map_prompt map_reduce map_reduce_document_variable_name map_reduce_prompt prompt prompts question_prompt reduce_llm refine refine_llm refine_llm_chain refine_prompt refine_prompts self str stuff stuff_prompt summarize typing verbose

Python: /langchain/chains/summarize/map_reduce_prompt.py
  Variables: PROMPT prompt_template
  Usages: PromptTemplate input_variables langchain prompts template

Python: /langchain/chains/summarize/refine_prompts.py
  Variables: PROMPT REFINE_PROMPT REFINE_PROMPT_TMPL prompt_template
  Usages: PromptTemplate input_variables langchain prompts template

Python: /langchain/chains/summarize/stuff_prompt.py
  Variables: PROMPT prompt_template
  Usages: PromptTemplate input_variables langchain prompts template

Python: /langchain/document_loaders/blob_loaders/__init__.py
  Variables: __all__
  Usages: Blob BlobLoader FileSystemBlobLoader YoutubeAudioLoader blob_loaders document_loaders file_system langchain schema youtube_audio

Python: /langchain/document_loaders/blob_loaders/file_system.py
  Functions: _make_iterator
  Classes: FileSystemBlobLoader
  Methods: __init__ _with_tqdm _yield_paths count_matching_files yield_blobs
  Variables: T _path iterator num paths self.glob self.path self.show_progress self.suffixes
  Usages: Blob BlobLoader Callable ImportError Iterable Iterator Optional Path Sequence TypeError TypeVar Union auto blob_loaders bool document_loaders from_path glob int is_file isinstance iter iterable langchain length_func path pathlib schema self set show_progress str suffix suffixes total tqdm type typing

Python: /langchain/document_loaders/blob_loaders/schema.py
  Classes: Blob BlobLoader Config
  Methods: __repr__ as_bytes as_bytes_io as_string check_blob_is_valid from_data from_path source yield_blobs
  Variables: PathLike _mimetype arbitrary_types_allowed data: encoding: frozen mimetype: path: str_repr
  Usages: ABC Any BaseModel BufferedReader BytesIO Generator Iterable Mapping NotImplementedError Optional PurePath Union ValueError abc abstractmethod annotations bool bytes classmethod cls contextlib contextmanager data decode encode encoding guess_type isinstance mime_type mimetype mimetypes open path pathlib pre property pydantic read root_validator self str typing values

Python: /langchain/document_loaders/blob_loaders/youtube_audio.py
  Classes: YoutubeAudioLoader
  Methods: __init__ yield_blobs
  Variables: loader self.save_dir self.urls ydl_opts
  Usages: Blob BlobLoader FileSystemBlobLoader ImportError Iterable List TypeError ValueError YoutubeDL blob blob_loaders document_loaders download glob isinstance langchain list save_dir schema self str typing url urls ydl yt_dlp

Python: /langchain/document_loaders/parsers/__init__.py
  Variables: __all__
  Usages: BS4HTMLParser OpenAIWhisperParser PDFMinerParser PDFPlumberParser PyMuPDFParser PyPDFParser PyPDFium2Parser audio document_loaders html langchain parsers pdf

Python: /langchain/document_loaders/parsers/audio.py
  Classes: OpenAIWhisperParser
  Methods: lazy_parse
  Variables: audio chunk chunk_duration chunk_duration_ms file_obj file_obj.name transcript
  Usages: Audio AudioSegment BaseBlobParser Blob BytesIO Document ImportError Iterator ValueError base blob blob_loaders document_loaders enumerate export format from_file langchain len metadata name openai page_content path print pydub range read schema self source split_number text transcribe typing

Python: /langchain/document_loaders/parsers/generic.py
  Classes: MimeTypeBasedParser
  Methods: __init__ lazy_parse
  Variables: handler mimetype self.fallback_parser self.handlers
  Usages: BaseBlobParser Blob Document Iterator Mapping Optional ValueError base blob blob_loaders document_loaders fallback_parser handlers langchain schema self str typing

Python: /langchain/document_loaders/parsers/pdf.py
  Classes: PDFMinerParser PDFPlumberParser PyMuPDFParser PyPDFParser PyPDFium2Parser
  Methods: __init__ lazy_parse
  Variables: content doc metadata pdf_reader self.text_kwargs text text_page
  Usages: Any BaseBlobParser Blob Document ImportError Iterator Mapping Optional PdfDocument PdfReader ValueError as_bytes_io autoclose base blob blob_loaders close dict document_loaders enumerate extract_text file_path fitz get_text get_text_range get_textpage high_level int langchain len number open page page_content page_number pages pdf_file_obj pdfminer pdfplumber pypdf pypdfium2 schema self source str text_kwargs type typing

Python: /langchain/document_loaders/parsers/registry.py
  Functions: _get_default_parser get_parser
  Variables: _REGISTRY
  Usages: BaseBlobParser MimeTypeBasedParser PyMuPDFParser TextParser ValueError base document_loaders fallback_parser generic handlers langchain parser_name parsers pdf str txt

Python: /langchain/document_loaders/parsers/txt.py
  Classes: TextParser
  Methods: lazy_parse
  Usages: BaseBlobParser Blob Document Iterator as_string base blob blob_loaders document_loaders langchain metadata page_content schema self source typing

Python: /langchain/evaluation/agents/__init__.py
  Variables: __all__
  Usages: TrajectoryEvalChain agents evaluation langchain trajectory_eval_chain

Python: /langchain/evaluation/agents/trajectory_eval_chain.py
  Classes: TrajectoryEval TrajectoryEvalChain TrajectoryOutputParser
  Methods: _call _tools_description from_llm get_agent_trajectory input_keys output_keys parse
  Variables: agent_tools: eval_chain eval_chain: output_parser: parsed_output raw_output reasoning, reasoning: return_reasoning: score: score_str
  Usages: AgentAction Any BaseOutputParser BaseTool CallbackManagerForChainRun Chain ChatOpenAI Dict EVAL_CHAT_PROMPT LLMChain List NamedTuple Optional OutputParserException Sequence Tuple Union action agent_tools agents base bool callbacks chains char chat_models classmethod cls description enumerate evaluation inputs int isdigit isinstance join langchain llm manager name next output output_parser prompt property reasoning return_reasoning run run_manager schema score self split staticmethod steps str strip text tool tool_input tools trajectory_eval_prompt typing

Python: /langchain/evaluation/agents/trajectory_eval_prompt.py
  Variables: EVAL_CHAT_PROMPT EVAL_TEMPLATE EXAMPLE_INPUT EXAMPLE_OUTPUT
  Usages: AIMessage ChatPromptTemplate HumanMessage HumanMessagePromptTemplate SystemMessage chat content from_messages from_template langchain messages prompts schema

Python: /langchain/evaluation/qa/__init__.py
  Variables: __all__
  Usages: ContextQAEvalChain CotQAEvalChain QAEvalChain QAGenerateChain eval_chain evaluation generate_chain langchain

Python: /langchain/evaluation/qa/eval_chain.py
  Classes: ContextQAEvalChain CotQAEvalChain QAEvalChain
  Methods: _validate_input_vars evaluate from_llm
  Variables: expected_input_vars inputs
  Usages: Any BaseLanguageModel CONTEXT_PROMPT COT_PROMPT LLMChain List PROMPT PromptTemplate Sequence ValueError annotations answer_key apply base_language chains classmethod cls context_key dict enumerate eval_prompt evaluation example examples input_variables kwargs langchain llm prediction_key predictions prompt question_key self set str typing

Python: /langchain/evaluation/qa/eval_prompt.py
  Variables: CONTEXT_PROMPT COT_PROMPT PROMPT SQL_PROMPT context_template cot_template template
  Usages: PromptTemplate input_variables langchain prompts

Python: /langchain/evaluation/qa/generate_chain.py
  Classes: QAGenerateChain
  Methods: from_llm
  Usages: Any BaseLanguageModel LLMChain PROMPT annotations base_language chains classmethod cls evaluation generate_prompt kwargs langchain llm prompt typing

Python: /langchain/evaluation/qa/generate_prompt.py
  Variables: PROMPT output_parser template
  Usages: PromptTemplate RegexParser input_variables langchain output_keys output_parsers prompts regex

Python: /langchain/evaluation/run_evaluators/__init__.py
  Variables: __all__
  Usages: ChoicesOutputParser RunEvaluatorChain RunEvaluatorInputMapper RunEvaluatorOutputParser StringRunEvaluatorInputMapper base evaluation get_criteria_evaluator get_qa_evaluator implementations langchain run_evaluators

Python: /langchain/evaluation/run_evaluators/base.py
  Classes: RunEvaluatorChain RunEvaluatorInputMapper RunEvaluatorOutputParser
  Methods: _acall _call aevaluate_run evaluate_run input_keys map output_keys parse_chain_output
  Variables: _run_manager callbacks chain_input chain_output eval_chain: eval_chain_output_key: example: feedback feedback.evaluator_info[RUN_KEY] input_mapper: output_parser: result run: run_info text
  Usages: Any AsyncCallbackManagerForChainRun BaseOutputParser CallbackManagerForChainRun Chain Dict EvaluationResult Example LLMChain List Optional RUN_KEY Run RunEvaluator abc abstractmethod acall annotations base chains eval_chain eval_chain_output_key evaluator_info example get get_child get_noop_manager include_run_info input_mapper inputs langchain langchainplus_sdk llm manager output output_parser parse property run run_manager schema schemas self str typing

Python: /langchain/evaluation/run_evaluators/criteria_prompt.py
  Variables: PROMPT template
  Usages: PromptTemplate input_variables langchain prompts

Python: /langchain/evaluation/run_evaluators/implementations.py
  Functions: get_criteria_evaluator get_qa_evaluator
  Classes: ChoicesOutputParser Config StringRunEvaluatorInputMapper
  Methods: map parse
  Variables: COHERENCE_CRITERION CONCISENESS_CRITERION CONTROVERSIALITY_CRITERION CORRECTNESS_CRITERION CRIMINALITY_CRITERION HARMFULNESS_CRITERION HELPFULNESS_CRITERION INSENSITIVE_CRITERION MALICIOUSNESS_CRITERION MYSOGYNY_CRITERION RELEVANCE_CRITERION _QA_PROMPTS _SUPPORTED_CRITERIA answer_map: arbitrary_types_allowed choices_map: comment criteria criteria_str data eval_chain evaluation_name evaluation_name: input_map: input_mapper lines output_parser parser prediction_map: prompt prompt_ score value
  Usages: Any BaseLanguageModel BaseModel CRITERIA_PROMPT Dict EvaluationResult Example LLMChain Mapping Optional PROMPT PromptTemplate QAEvalChain QA_DEFAULT_PROMPT Run RunEvaluatorChain RunEvaluatorInputMapper RunEvaluatorOutputParser SQL_PROMPT Sequence Union ValueError answer_key answer_map base base_language chains choices_map criteria_prompt criterion eval_prompt evaluation evaluator example from_llm get input_key input_map inputs int isinstance items join key keys kwargs langchain langchainplus_sdk len llm outputs partial pop prediction_key prediction_map prompts pydantic run run_evaluators schemas self split str strip text typing update

Python: /langchain/experimental/autonomous_agents/__init__.py
  Variables: __all__
  Usages: AutoGPT BabyAGI agent autogpt autonomous_agents baby_agi experimental langchain

PythonNotebook: /langchain/experimental/client/tracing_datasets.ipynb
  Functions: arun
  Variables: agent chain_factory chain_results client conciseness_evaluator custom_criteria_evaluator dataset dataset_name eval_feedback eval_llm evaluation_session_name evaluators feedbacks helpfulness_evaluator inputs llm os.environ["LANGCHAIN_SESSION"] os.environ["LANGCHAIN_TRACING_V2"] qa_evaluator results runs tools
  Usages: AgentType ChatOpenAI Exception LangChainPlusClient ZERO_SHOT_REACT_DESCRIPTION aevaluate_run agents append arun_on_dataset asyncio chat_models concurrency_level create_dataset create_example dataset_id delete_dataset description environ error evaluation evaluator execution_order extend gather get_criteria_evaluator get_qa_evaluator initialize_agent input_example langchain langchainplus_sdk list_datasets list_runs llm_or_chain_factory load_tools name notebook outputs print run run_evaluators session_name set temperature tqdm verbose

Python: /langchain/experimental/generative_agents/__init__.py
  Variables: __all__
  Usages: GenerativeAgent GenerativeAgentMemory experimental generative_agent generative_agents langchain memory

Python: /langchain/experimental/generative_agents/generative_agent.py
  Classes: Config GenerativeAgent
  Methods: _clean_response _compute_agent_summary _generate_reaction _get_entity_action _get_entity_from_observation _parse_list chain generate_dialogue_response generate_reaction get_full_header get_summary summarize_related_memories
  Variables: age age: agent_summary_description arbitrary_types_allowed call_to_action_template consumed_tokens current_time current_time_str daily_summaries: entity_action entity_name farewell full_result kwargs: kwargs[self.memory.most_recent_memories_token_key] last_refreshed: lines llm: memory: name: now prompt reaction relevant_memories_str response_text result said_value self.last_refreshed self.summary since_refresh status: summary summary: summary_refresh_seconds: traits: verbose:
  Usages: Any BaseLanguageModel BaseModel Dict Field GenerativeAgentMemory LLMChain List Optional PromptTemplate Tuple add_memory_key agent_name agent_status base_language bool daily_summaries datetime default_factory dict entity experimental force_refresh format from_template generative_agents get_num_tokens int kwargs langchain last_refreshed line list llm memory most_recent_memories most_recent_memories_token_key name now_key observation prompts pydantic queries relevant_memories run save_context seconds self split staticmethod status str strftime strip sub suffix summary_refresh_seconds text traits typing verbose

Python: /langchain/experimental/generative_agents/memory.py
  Classes: GenerativeAgentMemory
  Methods: _format_memory_detail _get_insights_on_topic _get_memories_until_limit _get_topics_of_reflection _parse_list _score_memories_importance _score_memory_importance add_memories add_memory chain clear fetch_memories format_memories_detail format_memories_simple load_memory_variables memory_variables pause_to_reflect save_context
  Variables: add_memory_key: aggregate_importance: content created_time current_plan: document documents importance_score importance_scores importance_weight: insights lines llm: logger match max_tokens_limit: mem memory_list memory_retriever: most_recent_memories_key: most_recent_memories_token most_recent_memories_token_key: new_insights now now_key: observation_str observations prompt queries queries_key: reflecting: reflection_threshold: related_memories related_statements relevant_memories relevant_memories_key: relevant_memories_simple_key: result score scores scores_list self.aggregate_importance self.reflecting topics verbose:
  Usages: Any BaseLanguageModel BaseMemory Dict Document LLMChain List Optional PromptTemplate TimeWeightedVectorStoreRetriever __name__ add_documents add_memory_key aggregate_importance append base_language bool consumed_tokens current_plan current_time datetime doc enumerate extend float from_template get getLogger get_num_tokens get_relevant_documents group importance_weight info inputs insight int join langchain last_k len line llm logging max max_tokens_limit memory memory_content memory_retriever memory_stream metadata mock_now most_recent_memories_key most_recent_memories_token_key now_key observation outputs page_content prefix prompts property queries_key query range reflecting reflection_threshold relevant_memories_key relevant_memories_simple_key retrievers run schema search self split staticmethod str strftime strip sub text topic typing utils verbose

Python: /langchain/experimental/llms/__init__.py
  Variables: __all__
  Usages: JsonFormer RELLM experimental jsonformer_decoder langchain llms rellm_decoder

Python: /langchain/experimental/llms/jsonformer_decoder.py
  Functions: import_jsonformer
  Classes: JsonFormer
  Methods: _call check_jsonformer_installation
  Variables: debug: json_schema: jsonformer max_new_tokens: model pipeline text
  Usages: Any CallbackManagerForLLMRun Field HuggingFacePipeline ImportError Jsonformer List Optional TYPE_CHECKING Text2TextGenerationPipeline ValueError annotations bool callbacks cast cls debug default description dict dumps huggingface_pipeline int json json_schema kwargs langchain llms manager max_new_tokens max_number_tokens prompt pydantic root_validator run_manager self stop str tokenizer transformers typing values

Python: /langchain/experimental/llms/rellm_decoder.py
  Functions: import_rellm
  Classes: RELLM
  Methods: _call check_rellm_installation
  Variables: max_new_tokens: pipeline regex: rellm text
  Usages: Any CallbackManagerForLLMRun Field HuggingFacePipeline ImportError List Optional Pattern RegexPattern TYPE_CHECKING Text2TextGenerationPipeline ValueError annotations callbacks cast cls complete_re default description dict enforce_stop_tokens huggingface_pipeline int kwargs langchain llms manager max_new_tokens model prompt pydantic regex root_validator run_manager self stop str tokenizer transformers typing utils values

Python: /langchain/experimental/plan_and_execute/__init__.py
  Variables: __all__
  Usages: PlanAndExecute agent_executor chat_planner executors experimental langchain load_agent_executor load_chat_planner plan_and_execute planners

Python: /langchain/experimental/plan_and_execute/agent_executor.py
  Classes: PlanAndExecute
  Methods: _call input_keys output_keys
  Variables: _new_inputs executor: input_key: new_inputs output_key: plan planner: response step_container:
  Usages: Any BaseExecutor BasePlanner BaseStepContainer CallbackManagerForChainRun Chain Dict Field List ListStepContainer Optional add_step base callbacks chains default_factory executor executors experimental get_child get_final_response input_key inputs langchain manager on_text output_key plan_and_execute planner planners property pydantic run_manager schema self step step_container steps str typing value verbose

Python: /langchain/experimental/plan_and_execute/schema.py
  Classes: BaseStepContainer ListStepContainer Plan PlanOutputParser Step StepResponse
  Methods: add_step get_final_response get_steps parse
  Variables: response: steps: value:
  Usages: BaseModel BaseOutputParser Field List Tuple abc abstractmethod append default_factory langchain list pydantic response schema self step step_response steps str text typing value

Python: /langchain/indexes/prompts/entity_extraction.py
  Variables: ENTITY_EXTRACTION_PROMPT _DEFAULT_ENTITY_EXTRACTION_TEMPLATE
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/indexes/prompts/entity_summarization.py
  Variables: ENTITY_SUMMARIZATION_PROMPT _DEFAULT_ENTITY_SUMMARIZATION_TEMPLATE
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/indexes/prompts/knowledge_triplet_extraction.py
  Variables: KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT _DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE
  Usages: KG_TRIPLE_DELIMITER PromptTemplate graphs input_variables langchain networkx_graph prompt prompts template

Python: /langchain/memory/chat_message_histories/__init__.py
  Variables: __all__
  Usages: CassandraChatMessageHistory CosmosDBChatMessageHistory DynamoDBChatMessageHistory FileChatMessageHistory FirestoreChatMessageHistory MomentoChatMessageHistory MongoDBChatMessageHistory PostgresChatMessageHistory RedisChatMessageHistory SQLChatMessageHistory ZepChatMessageHistory cassandra chat_message_histories cosmos_db dynamodb file firestore langchain memory momento mongodb postgres redis sql zep

Python: /langchain/memory/chat_message_histories/cassandra.py
  Classes: CassandraChatMessageHistory
  Methods: __del__ __init__ _prepare_cassandra add_message clear messages
  Variables: DEFAULT_KEYSPACE_NAME DEFAULT_PASSWORD DEFAULT_PORT DEFAULT_TABLE_NAME DEFAULT_USERNAME items logger messages rows self.cluster: self.contact_points self.keyspace_name self.password self.port self.session self.session_id self.table_name self.username
  Usages: AuthenticationFailed BaseChatMessageHistory BaseMessage Cluster ImportError List OperationTimedOut PlainTextAuthProvider ReadFailure ReadTimeout Unavailable UnresolvableContactPoints ValueError WriteFailure WriteTimeout __name__ _message_to_dict auth_provider cassandra cluster connect contact_points dumps error execute getLogger history int json keyspace_name langchain loads logging message messages_from_dict password port property row schema self session session_id set_keyspace shutdown str table_name typing username uuid uuid4

Python: /langchain/memory/chat_message_histories/cosmos_db.py
  Classes: CosmosDBChatMessageHistory
  Methods: __enter__ __exit__ __init__ add_message clear load_messages prepare_cosmos upsert_messages
  Variables: database item logger self._client self._container self._container: self.conn_string self.cosmos_container self.cosmos_database self.cosmos_endpoint self.credential self.messages self.messages: self.session_id self.ttl self.user_id
  Usages: Any BaseChatMessageHistory BaseException BaseMessage ContainerProxy CosmosClient CosmosHttpResponseError ImportError List Optional PartitionKey TYPE_CHECKING TracebackType Type ValueError __name__ _client _container annotations append azure body conn_str conn_string connection_string cosmos cosmos_client_kwargs cosmos_container cosmos_database cosmos_endpoint create_container_if_not_exists create_database_if_not_exists credential default_ttl delete_item dict exc exc_type exc_val exceptions from_connection_string getLogger info int langchain len logging message messages messages_from_dict messages_to_dict partition_key read_item schema self session_id str traceback ttl types typing upsert_item url user_id

Python: /langchain/memory/chat_message_histories/dynamodb.py
  Classes: DynamoDBChatMessageHistory
  Methods: __init__ add_message clear messages
  Variables: _message client items logger messages response self.session_id self.table
  Usages: BaseChatMessageHistory BaseMessage ClientError Item Key List Optional Table __name__ _message_to_dict append boto3 botocore delete_item endpoint_url err error exceptions getLogger get_item langchain logging message messages_from_dict messages_to_dict property put_item resource schema self session_id str table table_name typing warning

Python: /langchain/memory/chat_message_histories/file.py
  Classes: FileChatMessageHistory
  Methods: __init__ add_message clear messages
  Variables: items logger messages self.file_path
  Usages: BaseChatMessageHistory BaseMessage List Path __name__ append dumps exists file_path getLogger json langchain loads logging message messages_from_dict messages_to_dict pathlib property read_text schema self str touch typing write_text

Python: /langchain/memory/chat_message_histories/firestore.py
  Classes: FirestoreChatMessageHistory
  Methods: __init__ add_message clear load_messages prepare_firestore upsert_messages
  Variables: data doc logger self._document self._document: self.collection_name self.firestore_client self.messages self.messages: self.session_id self.user_id
  Usages: BaseChatMessageHistory BaseMessage DocumentReference ImportError List Optional TYPE_CHECKING ValueError __name__ _document annotations append client cloud collection collection_name debug delete document exists firebase_admin firestore firestore_client get getLogger get_app google initialize_app langchain len logging message messages messages_from_dict messages_to_dict new_message schema self session_id set str to_dict typing user_id

Python: /langchain/memory/chat_message_histories/in_memory.py
  Classes: ChatMessageHistory
  Methods: add_message clear
  Variables: messages: self.messages
  Usages: BaseChatMessageHistory BaseMessage BaseModel List append langchain message messages pydantic schema self typing

Python: /langchain/memory/chat_message_histories/momento.py
  Functions: _ensure_cache_exists
  Classes: MomentoChatMessageHistory
  Methods: __init__ add_message clear from_client_params messages
  Variables: auth_token cache_client configuration create_cache_response credentials delete_response fetch_response item items push_response self.cache_client self.cache_name self.key self.ttl
  Usages: Any BaseChatMessageHistory BaseMessage CacheAlreadyExists CacheClient CacheDelete CacheListFetch CacheListPushBack CollectionTtl Configuration Configurations CreateCache CredentialProvider Error Exception Hit ImportError Laptop Miss Optional Success TYPE_CHECKING TypeError _message_to_dict annotations bool cache_name classmethod cls config create_cache datetime default_ttl delete dumps ensure_cache_exists from_cache_ttl from_string get_from_env inner_exception isinstance json key key_prefix kwargs langchain list list_fetch list_push_back loads message messages_from_dict momento property requests responses schema self session_id str timedelta ttl typing utils value_list_string

Python: /langchain/memory/chat_message_histories/mongodb.py
  Classes: MongoDBChatMessageHistory
  Methods: __init__ add_message clear messages
  Variables: DEFAULT_COLLECTION_NAME DEFAULT_DBNAME cursor items logger messages self.client: self.collection self.collection_name self.connection_string self.database_name self.db self.session_id
  Usages: BaseChatMessageHistory BaseMessage ConnectionFailure List MongoClient OperationFailure WriteError __name__ _message_to_dict client collection collection_name connection_string create_index database_name delete_many document dumps err error errors find getLogger insert_one json langchain loads logging message messages_from_dict property pymongo schema self session_id str typing

Python: /langchain/memory/chat_message_histories/postgres.py
  Classes: PostgresChatMessageHistory
  Methods: __del__ __init__ _create_table_if_not_exists add_message clear messages
  Variables: DEFAULT_CONNECTION_STRING create_table_query items logger messages query self.connection self.cursor self.session_id self.table_name
  Usages: BaseChatMessageHistory BaseMessage Identifier List OperationalError SQL __name__ _message_to_dict close commit connect connection connection_string cursor dict_row dumps error execute fetchall format getLogger json langchain logging message messages_from_dict property psycopg record row_factory rows schema self session_id sql str table_name typing

Python: /langchain/memory/chat_message_histories/redis.py
  Classes: RedisChatMessageHistory
  Methods: __init__ add_message clear key messages
  Variables: _items items logger messages self.key_prefix self.redis_client self.session_id self.ttl
  Usages: BaseChatMessageHistory BaseMessage ConnectionError ImportError List Optional Redis __name__ _message_to_dict decode delete dumps error exceptions expire from_url getLogger int json key_prefix langchain loads logging lpush lrange message messages_from_dict property redis redis_client schema self session_id str ttl typing url

Python: /langchain/memory/chat_message_histories/sql.py
  Functions: create_message_model
  Classes: Message SQLChatMessageHistory
  Methods: __init__ _create_table_if_not_exists add_message clear messages
  Variables: DynamicBase __tablename__ items jsonstr logger message messages result self.Message self.Session self.connection_string self.engine self.session_id self.table_name session_id
  Usages: BaseChatMessageHistory BaseMessage Column ImportError Integer List Session Text __name__ _message_to_dict add commit connection_string create_all create_engine declarative declarative_base delete dumps echo engine ext filter getLogger json langchain loads logging messages_from_dict metadata orm primary_key property query record schema self session sessionmaker sqlalchemy str table_name typing where

Python: /langchain/memory/chat_message_histories/zep.py
  Classes: ZepChatMessageHistory
  Methods: __init__ _get_memory add_message clear messages search zep_messages zep_summary
  Variables: logger messages: msg: payload: self.session_id self.zep_client zep_memory zep_memory: zep_message zep_message:
  Usages: AIMessage BaseChatMessageHistory BaseMessage Dict HumanMessage ImportError List Memory MemorySearchPayload MemorySearchResult Message NotFoundError Optional TYPE_CHECKING ValueError ZepClient __name__ add_memory annotations append base_url content delete_memory getLogger get_memory int isinstance langchain len limit logging message metadata msg payload property query role schema search_memory self session_id str summary text typing url warning zep_client zep_python

Python: /langchain/prompts/example_selector/__init__.py
  Variables: __all__
  Usages: LengthBasedExampleSelector MaxMarginalRelevanceExampleSelector SemanticSimilarityExampleSelector example_selector langchain length_based prompts semantic_similarity

Python: /langchain/prompts/example_selector/base.py
  Classes: BaseExampleSelector
  Methods: add_example select_examples
  Usages: ABC Any Dict List abc abstractmethod dict example input_variables self str typing

Python: /langchain/prompts/example_selector/length_based.py
  Functions: _get_length_based
  Classes: LengthBasedExampleSelector
  Methods: add_example calculate_example_text_lengths select_examples
  Variables: example_prompt example_prompt: example_text_lengths: examples examples: get_text_length get_text_length: inputs max_length: new_length remaining_length string_example string_examples
  Usages: BaseExampleSelector BaseModel Callable Dict List PromptTemplate always append base cls dict example example_selector example_text_lengths format input_variables int join langchain len max_length prompt prompts pydantic self split str text typing validator values

Python: /langchain/prompts/example_selector/ngram_overlap.py
  Functions: ngram_overlap_score
  Classes: NGramOverlapExampleSelector
  Methods: add_example check_dependencies select_examples
  Variables: arg_max example_prompt: examples examples: first_prompt_template_key hypotheses inputs references score score[arg_max] score[i] threshold:
  Usages: BaseExampleSelector BaseModel Dict ImportError List PromptTemplate SmoothingFunction ValueError abs append argmax auto_reweigh base bleu_score cls dict example example_prompt example_selector float input_variables langchain len list method1 nltk numpy pre prompt prompts pydantic range root_validator self sentence_bleu smoothing_function source split str threshold translate typing values

Python: /langchain/prompts/example_selector/semantic_similarity.py
  Functions: sorted_values
  Classes: Config MaxMarginalRelevanceExampleSelector SemanticSimilarityExampleSelector
  Methods: add_example from_examples select_examples
  Variables: arbitrary_types_allowed example_docs example_keys: examples extra fetch_k: ids input_keys: input_variables query string_example string_examples vectorstore vectorstore:
  Usages: Any BaseExampleSelector BaseModel Dict Embeddings Extra List Optional Type VectorStore add_texts annotations base classmethod cls dict embeddings example example_keys example_selector fetch_k forbid from_texts input_keys int join key langchain max_marginal_relevance_search metadata metadatas prompts pydantic self similarity_search sorted str typing val values vectorstore_cls vectorstore_cls_kwargs vectorstores

Python: /langchain/retrievers/document_compressors/__init__.py
  Variables: __all__
  Usages: CohereRerank DocumentCompressorPipeline EmbeddingsFilter LLMChainExtractor LLMChainFilter base chain_extract chain_filter cohere_rerank document_compressors embeddings_filter langchain retrievers

Python: /langchain/retrievers/document_compressors/base.py
  Classes: BaseDocumentCompressor Config DocumentCompressorPipeline
  Methods: acompress_documents compress_documents
  Variables: arbitrary_types_allowed documents transformers:
  Usages: ABC BaseDocumentTransformer BaseModel Document List Sequence Union ValueError _transformer abc abstractmethod atransform_documents isinstance langchain pydantic query schema self str transform_documents transformers typing

Python: /langchain/retrievers/document_compressors/chain_extract.py
  Functions: _get_default_chain_prompt default_get_input
  Classes: LLMChainExtractor NoOutputParser
  Methods: acompress_documents compress_documents from_llm parse
  Variables: _get_input _input _prompt cleaned_text compressed_docs get_input: llm_chain llm_chain: no_output_str: output output_parser outputs template
  Usages: Any BaseDocumentCompressor BaseLanguageModel BaseOutputParser Callable Dict Document LLMChain Optional PromptTemplate Sequence annotations append apredict_and_parse asyncio base base_language chain_extract_prompt classmethod cls dict doc document_compressors documents enumerate format gather get_input input_variables langchain len llm llm_chain_kwargs metadata no_output_str page_content predict_and_parse prompt prompt_template query retrievers schema self str strip text typing

Python: /langchain/retrievers/document_compressors/chain_extract_prompt.py
  Variables: prompt_template

Python: /langchain/retrievers/document_compressors/chain_filter.py
  Functions: _get_default_chain_prompt default_get_input
  Classes: LLMChainFilter
  Methods: acompress_documents compress_documents from_llm
  Variables: _input _prompt filtered_docs get_input: include_doc llm_chain llm_chain:
  Usages: Any BaseDocumentCompressor BaseLanguageModel BasePromptTemplate BooleanOutputParser Callable Dict Document LLMChain NotImplementedError Optional PromptTemplate Sequence append base base_language boolean chain_filter_prompt classmethod cls dict doc document_compressors documents get_input input_variables kwargs langchain llm output_parser output_parsers page_content predict_and_parse prompt prompt_template query retrievers schema self str template typing

Python: /langchain/retrievers/document_compressors/chain_filter_prompt.py
  Variables: prompt_template

Python: /langchain/retrievers/document_compressors/cohere_rerank.py
  Classes: CohereRerank Config
  Methods: acompress_documents compress_documents validate_environment
  Variables: _docs arbitrary_types_allowed client: cohere_api_key doc doc.metadata["relevance_score"] doc_list extra final_results model: results top_n: values["client"]
  Usages: BaseDocumentCompressor Client Dict Document Extra ImportError NotImplementedError Sequence TYPE_CHECKING annotations append base client cls cohere document_compressors documents forbid get_from_dict_or_env index int langchain len list metadata model page_content pre pydantic query relevance_score rerank retrievers root_validator schema self str top_n typing utils values

Python: /langchain/retrievers/document_compressors/embeddings_filter.py
  Classes: Config EmbeddingsFilter
  Methods: acompress_documents compress_documents validate_params
  Variables: arbitrary_types_allowed embedded_documents embedded_query embeddings: included_idxs similar_enough similarity similarity_fn: similarity_threshold: stateful_documents
  Usages: BaseDocumentCompressor Callable Dict Document Embeddings NotImplementedError Optional Sequence ValueError _get_embeddings_from_stateful_docs arange argsort base cls cosine_similarity document_compressors document_transformers documents embed_query embeddings float get_stateful_documents int langchain len math_utils numpy pydantic query retrievers root_validator schema self similarity_fn similarity_threshold str typing values where

Python: /langchain/retrievers/self_query/base.py
  Functions: _get_builtin_translator
  Classes: Config SelfQueryRetriever
  Methods: aget_relevant_documents from_llm get_relevant_documents validate_translator
  Variables: BUILTIN_TRANSLATORS: arbitrary_types_allowed chain_kwargs chain_kwargs[ docs inputs llm_chain llm_chain: new_kwargs["k"] new_query, search_kwargs search_kwargs: search_type: structured_query structured_query_translator structured_query_translator: values["structured_query_translator"] vectorstore: vectorstore_cls verbose:
  Usages: Any AttributeInfo BUILTIN_TRANSLATORS BaseLanguageModel BaseModel BaseRetriever Chroma ChromaTranslator Dict Document Field LLMChain List NotImplementedError Optional Pinecone PineconeTranslator Qdrant QdrantTranslator StructuredQuery Type ValueError VectorStore Visitor Weaviate WeaviateTranslator __class__ allowed_comparators allowed_operators base base_language bool callbacks cast chains chroma classmethod cls default_factory dict document_contents enable_limit isinstance kwargs langchain limit llm load_query_constructor_chain metadata_field_info metadata_key metadata_payload_key new_kwargs new_query pinecone pre predict_and_parse prep_inputs print pydantic qdrant query query_constructor retrievers root_validator schema search search_type self self_query str typing values vectorstore vectorstores verbose visit_structured_query weaviate

Python: /langchain/retrievers/self_query/chroma.py
  Classes: ChromaTranslator
  Methods: _format_func visit_comparison visit_operation visit_structured_query
  Variables: allowed_operators args kwargs
  Usages: AND Comparator Comparison Dict OR Operation Operator StructuredQuery Tuple Union Visitor _validate_func accept arg arguments attribute chains comparator comparison dict filter func langchain operation operator query query_constructor self str structured_query typing value

Python: /langchain/retrievers/self_query/pinecone.py
  Classes: PineconeTranslator
  Methods: _format_func visit_comparison visit_operation visit_structured_query
  Variables: allowed_operators args kwargs
  Usages: AND Comparator Comparison Dict OR Operation Operator StructuredQuery Tuple Union Visitor _validate_func accept arg arguments attribute chains comparator comparison dict filter func langchain operation operator query query_constructor self str structured_query typing value

Python: /langchain/retrievers/self_query/qdrant.py
  Classes: QdrantTranslator
  Methods: __init__ visit_comparison visit_operation visit_structured_query
  Variables: args attribute filter kwargs operator self.metadata_key
  Usages: AND Comparator Comparison EQ FieldCondition Filter ImportError MatchValue NOT OR Operation Operator Range StructuredQuery TYPE_CHECKING Tuple Visitor _validate_func accept annotations arg arguments chains comparator comparison dict http isinstance key langchain match metadata_key models must operation qdrant_client query query_constructor range rest self str structured_query typing value

Python: /langchain/retrievers/self_query/weaviate.py
  Classes: WeaviateTranslator
  Methods: _format_func visit_comparison visit_operation visit_structured_query
  Variables: allowed_comparators allowed_operators args kwargs map_dict
  Usages: AND Comparator Comparison Dict EQ OR Operation Operator StructuredQuery Tuple Union Visitor _validate_func accept arg arguments attribute chains comparator comparison dict filter func langchain operation operator query query_constructor self str structured_query typing value

Python: /langchain/tools/arxiv/tool.py
  Classes: ArxivQueryRun
  Methods: _arun _run
  Variables: api_wrapper: description name
  Usages: ArxivAPIWrapper AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Field NotImplementedError Optional api_wrapper arxiv base callbacks default_factory langchain manager pydantic query run run_manager self str tools typing utilities

Python: /langchain/tools/azure_cognitive_services/__init__.py
  Variables: __all__
  Usages: AzureCogsFormRecognizerTool AzureCogsImageAnalysisTool AzureCogsSpeech2TextTool AzureCogsText2SpeechTool azure_cognitive_services form_recognizer image_analysis langchain speech2text text2speech tools

Python: /langchain/tools/azure_cognitive_services/form_recognizer.py
  Classes: AzureCogsFormRecognizerTool
  Methods: _arun _document_analysis _format_document_analysis_result _parse_kv_pairs _parse_tables _run validate_environment
  Variables: _table _table[cell.row_index][cell.column_index] azure_cogs_endpoint azure_cogs_endpoint: azure_cogs_key azure_cogs_key: description doc_analysis_client: document_analysis_result document_src_type formatted_result key logger name poller rc, res_dict res_dict["content"] res_dict["key_value_pairs"] res_dict["tables"] result value values["doc_analysis_client"]
  Usages: Any AsyncCallbackManagerForToolRun AzureKeyCredential BaseTool CallbackManagerForToolRun Dict DocumentAnalysisClient Exception ImportError List NotImplementedError Optional RuntimeError ValueError __name__ annotations append azure azure_cognitive_services base begin_analyze_document begin_analyze_document_from_url callbacks cell cells cls column_count column_index content core credential credentials detect_file_src_type doc_analysis_client document document_path endpoint enumerate formrecognizer getLogger get_from_dict_or_env join key_value_pairs kv_pair kv_pairs langchain logging manager open pre pydantic query range replace root_validator row_count row_index run_manager self str table tables tools typing utils values

Python: /langchain/tools/azure_cognitive_services/image_analysis.py
  Classes: AzureCogsImageAnalysisTool
  Methods: _arun _format_image_analysis_result _image_analysis _run validate_environment
  Variables: analysis_options: azure_cogs_endpoint azure_cogs_endpoint: azure_cogs_key azure_cogs_key: description error_details formatted_result image_analysis_result image_analyzer image_src_type logger name res_dict res_dict["caption"] res_dict["objects"] res_dict["tags"] res_dict["text"] result values["analysis_options"] values["analysis_options"].features values["vision_service"] vision_service: vision_source
  Usages: ANALYZED Any AsyncCallbackManagerForToolRun BaseTool CAPTION CallbackManagerForToolRun Dict Exception ImageAnalysisErrorDetails ImageAnalysisFeature ImageAnalysisOptions ImageAnalysisResultReason ImageAnalyzer ImportError NotImplementedError OBJECTS Optional RuntimeError TAGS TEXT ValueError VisionServiceOptions VisionSource __name__ analysis_options analyze annotations append azure azure_cognitive_services base callbacks caption cls content detect_file_src_type endpoint features filename from_result getLogger get_from_dict_or_env image_path join key langchain len line lines logging manager message obj objects pre pydantic query reason root_validator run_manager sdk self str tag tags text tools typing url utils values vision vision_service

Python: /langchain/tools/azure_cognitive_services/speech2text.py
  Classes: AzureCogsSpeech2TextTool
  Methods: _arun _continuous_recognize _run _speech2text retrieve_cb stop_cb validate_environment
  Variables: audio_config audio_src_type azure_cogs_key azure_cogs_key: azure_cogs_region azure_cogs_region: description done logger name self.speech_config.speech_recognition_language speech_config: speech_language: speech_recognizer text tmp_audio_path values["speech_config"]
  Usages: Any AsyncCallbackManagerForToolRun AudioConfig BaseTool CallbackManagerForToolRun Dict Exception ImportError NotImplementedError Optional RuntimeError SpeechConfig SpeechRecognizer ValueError __name__ annotations audio_path azure azure_cognitive_services base callbacks canceled cls cognitiveservices connect detect_file_src_type download_audio_from_url evt filename getLogger get_from_dict_or_env langchain logging manager pre pydantic query recognized region result root_validator run_manager self session_stopped sleep speech speech_config speech_language speech_recognition_language speechsdk start_continuous_recognition_async stop_continuous_recognition_async str subscription time tools typing utils values

Python: /langchain/tools/azure_cognitive_services/text2speech.py
  Classes: AzureCogsText2SpeechTool
  Methods: _arun _run _text2speech validate_environment
  Variables: azure_cogs_key azure_cogs_key: azure_cogs_region azure_cogs_region: cancellation_details description logger name result self.speech_config.speech_synthesis_language speech_config: speech_file speech_language: speech_synthesizer stream values["speech_config"]
  Usages: Any AsyncCallbackManagerForToolRun AudioDataStream BaseTool CallbackManagerForToolRun Canceled CancellationReason Dict Error Exception ImportError NamedTemporaryFile NotImplementedError Optional ResultReason RuntimeError SpeechConfig SpeechSynthesizer SynthesizingAudioCompleted __name__ annotations audio_config azure base callbacks cls cognitiveservices debug delete error_details getLogger get_from_dict_or_env langchain logging manager mode pre pydantic query reason region root_validator run_manager save_to_wav_file self speak_text speech speech_config speech_language speech_synthesis_language speechsdk str subscription suffix tempfile text tools typing utils values

Python: /langchain/tools/azure_cognitive_services/utils.py
  Functions: detect_file_src_type download_audio_from_url
  Variables: ext parsed_url response
  Usages: NamedTemporaryFile audio_url chunk chunk_size delete file_path get isfile iter_content mode name netloc parse path raise_for_status requests scheme split str stream suffix tempfile urllib urlparse write

Python: /langchain/tools/bing_search/__init__.py
  Variables: __all__
  Usages: BingSearchResults BingSearchRun bing_search langchain tool tools

Python: /langchain/tools/bing_search/tool.py
  Classes: BingSearchResults BingSearchRun
  Methods: _arun _run
  Variables: api_wrapper: description name num_results:
  Usages: AsyncCallbackManagerForToolRun BaseTool BingSearchAPIWrapper CallbackManagerForToolRun NotImplementedError Optional api_wrapper base bing_search callbacks int langchain manager num_results query results run run_manager self str tools typing utilities

Python: /langchain/tools/brave_search/tool.py
  Classes: BraveSearch
  Methods: _arun _run from_api_key
  Variables: description name search_wrapper: wrapper
  Usages: Any AsyncCallbackManagerForToolRun BaseTool BraveSearchWrapper CallbackManagerForToolRun NotImplementedError Optional annotations api_key base brave_search callbacks classmethod cls dict kwargs langchain manager query run run_manager search_kwargs search_wrapper self str tools typing utilities

Python: /langchain/tools/ddg_search/__init__.py
  Variables: __all__
  Usages: DuckDuckGoSearchRun ddg_search langchain tool tools

Python: /langchain/tools/ddg_search/tool.py
  Functions: DuckDuckGoSearchTool
  Classes: DuckDuckGoSearchResults DuckDuckGoSearchRun
  Methods: _arun _run
  Variables: api_wrapper: description name num_results:
  Usages: Any AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun DeprecationWarning DuckDuckGoSearchAPIWrapper Field NotImplementedError Optional api_wrapper args base callbacks default_factory duckduckgo_search int kwargs langchain manager num_results pydantic query results run run_manager self str tools typing utilities warn warnings

Python: /langchain/tools/file_management/__init__.py
  Variables: __all__
  Usages: CopyFileTool DeleteFileTool FileSearchTool ListDirectoryTool MoveFileTool ReadFileTool WriteFileTool copy delete file_management file_search langchain list_dir move read tools write

Python: /langchain/tools/file_management/copy.py
  Classes: CopyFileTool FileCopyInput
  Methods: _arun _run
  Variables: args_schema: description: destination_path: destination_path_ name: source_path: source_path_
  Usages: AsyncCallbackManagerForToolRun BaseFileToolMixin BaseModel BaseTool CallbackManagerForToolRun Exception Field FileValidationError INVALID_PATH_TEMPLATE NotImplementedError Optional Type arg_name args_schema base callbacks copy2 description destination_path file_management follow_symlinks format get_relative_path langchain manager name pydantic run_manager self shutil source_path str tools typing utils value

Python: /langchain/tools/file_management/delete.py
  Classes: DeleteFileTool FileDeleteInput
  Methods: _arun _run
  Variables: args_schema: description: file_path: file_path_ name:
  Usages: AsyncCallbackManagerForToolRun BaseFileToolMixin BaseModel BaseTool CallbackManagerForToolRun Exception Field FileValidationError INVALID_PATH_TEMPLATE NotImplementedError Optional Type arg_name args_schema base callbacks description exists file_management file_path format get_relative_path langchain manager name pydantic remove run_manager self str tools typing utils value

Python: /langchain/tools/file_management/file_search.py
  Classes: FileSearchInput FileSearchTool
  Methods: _arun _run
  Variables: absolute_path args_schema: description: dir_path: dir_path_ matches name: pattern: relative_path
  Usages: AsyncCallbackManagerForToolRun BaseFileToolMixin BaseModel BaseTool CallbackManagerForToolRun Exception Field FileValidationError INVALID_PATH_TEMPLATE NotImplementedError Optional Type append arg_name args_schema base callbacks default description dir_path file_management filename filenames filter fnmatch format get_relative_path join langchain manager name path pattern pydantic relpath root run_manager self str tools typing utils value walk

Python: /langchain/tools/file_management/list_dir.py
  Classes: DirectoryListingInput ListDirectoryTool
  Methods: _arun _run
  Variables: args_schema: description: dir_path: dir_path_ entries name:
  Usages: AsyncCallbackManagerForToolRun BaseFileToolMixin BaseModel BaseTool CallbackManagerForToolRun Exception Field FileValidationError INVALID_PATH_TEMPLATE NotImplementedError Optional Type arg_name args_schema base callbacks default description dir_path file_management format get_relative_path join langchain listdir manager name pydantic run_manager self str tools typing utils value

Python: /langchain/tools/file_management/move.py
  Classes: FileMoveInput MoveFileTool
  Methods: _arun _run
  Variables: args_schema: description: destination_path: destination_path_ name: source_path: source_path_
  Usages: AsyncCallbackManagerForToolRun BaseFileToolMixin BaseModel BaseTool CallbackManagerForToolRun Exception Field FileValidationError INVALID_PATH_TEMPLATE NotImplementedError Optional Type arg_name args_schema base callbacks description destination_path exists file_management format get_relative_path langchain manager move name pydantic run_manager self shutil source_path str tools typing utils value

Python: /langchain/tools/file_management/read.py
  Classes: ReadFileInput ReadFileTool
  Methods: _arun _run
  Variables: args_schema: content description: file_path: name: read_path
  Usages: AsyncCallbackManagerForToolRun BaseFileToolMixin BaseModel BaseTool CallbackManagerForToolRun Exception Field FileValidationError INVALID_PATH_TEMPLATE NotImplementedError Optional Type arg_name args_schema base callbacks description encoding exists file_management file_path format get_relative_path langchain manager name open pydantic read run_manager self str tools typing utils value

Python: /langchain/tools/file_management/utils.py
  Functions: get_validated_relative_path is_relative_to
  Classes: BaseFileToolMixin FileValidationError
  Methods: get_relative_path
  Variables: INVALID_PATH_TEMPLATE full_path root root_dir:
  Usages: BaseModel Optional Path ValueError bool file_path path pathlib pydantic relative_to resolve root_dir self str sys typing user_path version_info

Python: /langchain/tools/file_management/write.py
  Classes: WriteFileInput WriteFileTool
  Methods: _arun _run
  Variables: append: args_schema: description: file_path: mode name: text: write_path
  Usages: AsyncCallbackManagerForToolRun BaseFileToolMixin BaseModel BaseTool CallbackManagerForToolRun Exception Field FileValidationError INVALID_PATH_TEMPLATE NotImplementedError Optional Type append arg_name args_schema base bool callbacks default description encoding exist_ok file_management file_path format get_relative_path langchain manager mkdir name open parent parents pydantic run_manager self str text tools typing utils value write

Python: /langchain/tools/gmail/__init__.py
  Variables: __all__
  Usages: GmailCreateDraft GmailGetMessage GmailGetThread GmailSearch GmailSendMessage create_draft get_gmail_credentials get_message get_thread gmail langchain search send_message tools utils

Python: /langchain/tools/gmail/base.py
  Classes: GmailBaseTool
  Methods: from_api_resource
  Variables: api_resource:
  Usages: BaseTool Field ImportError Resource TYPE_CHECKING annotations api_resource base build_resource_service classmethod cls default_factory discovery gmail googleapiclient langchain pydantic service tools typing utils

Python: /langchain/tools/gmail/create_draft.py
  Classes: CreateDraftSchema GmailCreateDraft
  Methods: _arun _prepare_draft_message _run
  Variables: args_schema: bcc: cc: create_message description: draft draft_message draft_message["Bcc"] draft_message["Cc"] draft_message["Subject"] draft_message["To"] encoded_message message: name: output subject: to:
  Usages: AsyncCallbackManagerForToolRun BaseModel CallbackManagerForToolRun EmailMessage Exception Field GmailBaseTool List NotImplementedError Optional Type api_resource args_schema as_bytes base base64 bcc body callbacks create decode description dict drafts email execute gmail join langchain manager message name pydantic run_manager self set_content str subject tools typing urlsafe_b64encode userId users

Python: /langchain/tools/gmail/get_message.py
  Classes: GmailGetMessage SearchArgsSchema
  Methods: _arun _run
  Variables: args_schema: body description: email_msg message_body message_data message_id: name: query raw_message sender subject
  Usages: AsyncCallbackManagerForToolRun BaseModel CallbackManagerForToolRun Dict Field GmailBaseTool NotImplementedError Optional Type api_resource args_schema base base64 callbacks clean_email_body description email execute format get get_payload gmail langchain manager message_from_bytes message_id messages name pydantic run_manager self str tools typing urlsafe_b64decode userId users utils

Python: /langchain/tools/gmail/get_thread.py
  Classes: GetThreadSchema GmailGetThread
  Methods: _arun _run
  Variables: args_schema: description: keys_to_keep messages name: query thread_data thread_data["messages"] thread_id:
  Usages: AsyncCallbackManagerForToolRun BaseModel CallbackManagerForToolRun Dict Field GmailBaseTool NotImplementedError Optional Type ValueError api_resource append args_schema base callbacks description dict execute get gmail isinstance langchain manager message name pydantic run_manager self str thread_id threads tools typing userId users

Python: /langchain/tools/gmail/search.py
  Classes: GmailSearch Resource SearchArgsSchema
  Methods: _arun _parse_messages _parse_threads _run
  Variables: MESSAGES THREADS args_schema: body description: email_msg max_results: message_body message_data message_id messages name: query: raw_message resource: results sender snippet subject thread["messages"] thread_data thread_id
  Usages: Any AsyncCallbackManagerForToolRun BaseModel CallbackManagerForToolRun Dict Enum Field GmailBaseTool List NotImplementedError Optional Type api_resource append args_schema base base64 callbacks clean_email_body default description email enum execute format get get_payload gmail int langchain list manager maxResults max_results message message_from_bytes name pydantic query resource run_manager self str thread threads tools typing urlsafe_b64decode userId users utils value

Python: /langchain/tools/gmail/send_message.py
  Classes: GmailSendMessage SendMessageSchema
  Methods: _arun _prepare_message _run
  Variables: bcc: cc: create_message description: encoded_message message: mime_message mime_message["Bcc"] mime_message["Cc"] mime_message["Subject"] mime_message["To"] name: send_message sent_message subject: to:
  Usages: Any AsyncCallbackManagerForToolRun BaseModel CallbackManagerForToolRun Dict Exception Field GmailBaseTool List MIMEMultipart MIMEText NotImplementedError Optional api_resource as_bytes attach base base64 bcc body callbacks decode description email error execute gmail join langchain manager message messages mime multipart name pydantic run_manager self send str subject text tools typing urlsafe_b64encode userId users

Python: /langchain/tools/gmail/utils.py
  Functions: build_resource_service clean_email_body get_gmail_credentials import_google import_googleapiclient_resource_builder import_installed_app_flow
  Variables: DEFAULT_CLIENT_SECRETS_FILE DEFAULT_CREDS_TOKEN_FILE DEFAULT_SCOPES InstalledAppFlow Request, body builder client_secrets_file credentials creds flow logger scopes soup token_file
  Usages: BeautifulSoup Credentials Exception ImportError List Optional Request Resource TYPE_CHECKING Tuple ValueError __name__ annotations auth bs4 build build_resource discovery error exists expired from_authorized_user_file from_client_secrets_file getLogger get_text google google_auth_oauthlib googleapiclient logging oauth2 open path port refresh refresh_token requests run_local_server service_name service_version str to_json token transport typing valid warning write

Python: /langchain/tools/google_places/__init__.py
  Variables: __all__
  Usages: GooglePlacesTool google_places langchain tool tools

Python: /langchain/tools/google_places/tool.py
  Classes: GooglePlacesSchema GooglePlacesTool
  Methods: _arun _run
  Variables: api_wrapper: args_schema: description name query:
  Usages: AsyncCallbackManagerForToolRun BaseModel BaseTool CallbackManagerForToolRun Field GooglePlacesAPIWrapper NotImplementedError Optional Type api_wrapper args_schema base callbacks default_factory google_places_api langchain manager pydantic query run run_manager self str tools typing utilities

Python: /langchain/tools/google_search/__init__.py
  Variables: __all__
  Usages: GoogleSearchResults GoogleSearchRun google_search langchain tool tools

Python: /langchain/tools/google_search/tool.py
  Classes: GoogleSearchResults GoogleSearchRun
  Methods: _arun _run
  Variables: api_wrapper: description name num_results:
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun GoogleSearchAPIWrapper NotImplementedError Optional api_wrapper base callbacks google_search int langchain manager num_results query results run run_manager self str tools typing utilities

Python: /langchain/tools/google_serper/__init__.py
  Variables: __all__
  Usages: GoogleSerperResults GoogleSerperRun google_serper langchain tool tools

Python: /langchain/tools/google_serper/tool.py
  Classes: GoogleSerperResults GoogleSerperRun
  Methods: _arun _run
  Variables: api_wrapper: description name
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Field GoogleSerperAPIWrapper Optional __str__ api_wrapper aresults arun base callbacks default_factory fields google_serper langchain manager pydantic query results run run_manager self str tools typing utilities

Python: /langchain/tools/graphql/tool.py
  Classes: BaseGraphQLTool Config
  Methods: _arun _run
  Variables: arbitrary_types_allowed description graphql_wrapper: name result
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun GraphQLAPIWrapper NotImplementedError Optional base callbacks dumps graphql graphql_wrapper indent json langchain manager run run_manager self str tool_input tools typing utilities

Python: /langchain/tools/human/__init__.py
  Variables: __all__
  Usages: HumanInputRun human langchain tool tools

Python: /langchain/tools/human/tool.py
  Functions: _print_func
  Classes: HumanInputRun
  Methods: _arun _run
  Variables: description input_func: name prompt_func:
  Usages: AsyncCallbackManagerForToolRun BaseTool Callable CallbackManagerForToolRun Field NotImplementedError Optional base callbacks default_factory input input_func langchain manager print prompt_func pydantic query run_manager self str text tools typing

Python: /langchain/tools/interaction/tool.py
  Functions: StdInInquireTool
  Usages: Any DeprecationWarning HumanInputRun args human kwargs langchain tool tools typing warn warnings

Python: /langchain/tools/jira/prompt.py
  Variables: JIRA_CATCH_ALL_PROMPT JIRA_GET_ALL_PROJECTS_PROMPT JIRA_ISSUE_CREATE_PROMPT JIRA_JQL_PROMPT

Python: /langchain/tools/jira/tool.py
  Classes: JiraAction
  Methods: _arun _run
  Variables: api_wrapper: description mode: name
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Field JiraAPIWrapper NotImplementedError Optional api_wrapper base callbacks default_factory instructions jira langchain manager mode pydantic run run_manager self str tools typing utilities

Python: /langchain/tools/json/tool.py
  Functions: _parse_input
  Classes: JsonGetValueTool JsonListKeysTool JsonSpec
  Methods: _arun _run from_file keys value
  Variables: _res description dict_ dict_: items max_value_length: name res spec: str_val val
  Usages: AsyncCallbackManagerForToolRun BaseModel BaseTool CallbackManagerForToolRun Dict Exception FileNotFoundError List Optional Path Union ValueError annotations base callbacks classmethod cls dict exists findall int isdigit isinstance json langchain len list loads manager max_value_length path pathlib pydantic read_text replace repr run_manager self spec str text tool_input tools typing

Python: /langchain/tools/metaphor_search/__init__.py
  Variables: __all__
  Usages: MetaphorSearchResults langchain metaphor_search tool tools

Python: /langchain/tools/metaphor_search/tool.py
  Classes: MetaphorSearchResults
  Methods: _arun _run
  Variables: api_wrapper: description name
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Dict Exception List MetaphorSearchAPIWrapper Optional Union api_wrapper base callbacks int langchain manager metaphor_search num_results query repr results results_async run_manager self str tools typing utilities

Python: /langchain/tools/openweathermap/__init__.py
  Variables: __all__
  Usages: OpenWeatherMapQueryRun langchain openweathermap tool tools

Python: /langchain/tools/openweathermap/tool.py
  Classes: OpenWeatherMapQueryRun
  Methods: _arun _run
  Variables: api_wrapper: description name
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Field NotImplementedError OpenWeatherMapAPIWrapper Optional api_wrapper base callbacks default_factory langchain location manager pydantic run run_manager self str tools typing utilities

Python: /langchain/tools/playwright/__init__.py
  Variables: __all__
  Usages: ClickTool CurrentWebPageTool ExtractHyperlinksTool ExtractTextTool GetElementsTool NavigateBackTool NavigateTool click current_page extract_hyperlinks extract_text get_elements langchain navigate navigate_back playwright tools

Python: /langchain/tools/playwright/base.py
  Functions: lazy_import_playwright_browsers
  Classes: BaseBrowserTool
  Methods: from_browser validate_browser_provided
  Variables: async_browser: sync_browser:
  Usages: AsyncBrowser BaseTool Browser ImportError Optional SyncBrowser TYPE_CHECKING Tuple Type ValueError annotations async_api async_browser base classmethod cls dict get langchain playwright pydantic root_validator sync_api sync_browser tools typing values

Python: /langchain/tools/playwright/click.py
  Classes: ClickTool ClickToolInput
  Methods: _arun _run _selector_effective
  Variables: args_schema: description: name: page playwright_strict: playwright_timeout: selector: selector_effective visible_only:
  Usages: AsyncCallbackManagerForToolRun BaseBrowserTool BaseModel CallbackManagerForToolRun Field Optional PlaywrightTimeoutError TimeoutError Type ValueError aget_current_page annotations args_schema async_api async_browser base bool callbacks click description float get_current_page langchain manager name playwright playwright_strict playwright_timeout pydantic run_manager selector self str strict sync_api sync_browser timeout tools typing utils visible_only

Python: /langchain/tools/playwright/current_page.py
  Classes: CurrentWebPageTool
  Methods: _arun _run
  Variables: args_schema: description: name: page
  Usages: AsyncCallbackManagerForToolRun BaseBrowserTool BaseModel CallbackManagerForToolRun Optional Type ValueError aget_current_page annotations args_schema async_browser base callbacks description get_current_page langchain manager name playwright pydantic run_manager self str sync_browser tools typing url utils

Python: /langchain/tools/playwright/extract_hyperlinks.py
  Classes: ExtractHyperlinksTool ExtractHyperlinksToolInput
  Methods: _arun _run check_bs_import scrape_page
  Variables: absolute_urls: anchors args_schema: base_url description: html_content links name: page soup
  Usages: Any AsyncCallbackManagerForToolRun BaseBrowserTool BaseModel BeautifulSoup CallbackManagerForToolRun Field ImportError Optional TYPE_CHECKING Type ValueError absolute_urls aget_current_page anchor annotations args_schema async_browser base bool bs4 callbacks cls content default description dict dumps find_all get get_current_page json langchain manager name parse playwright pydantic root_validator run_manager self staticmethod str sync_browser tools typing url urljoin urllib utils values

Python: /langchain/tools/playwright/extract_text.py
  Classes: ExtractTextTool
  Methods: _arun _run check_acheck_bs_importrgs
  Variables: args_schema: description: html_content name: page soup
  Usages: AsyncCallbackManagerForToolRun BaseBrowserTool BaseModel BeautifulSoup CallbackManagerForToolRun ImportError Optional Type ValueError aget_current_page annotations args_schema async_browser base bs4 callbacks cls content description dict get_current_page join langchain manager name playwright pydantic root_validator run_manager self str stripped_strings sync_browser text tools typing utils values

Python: /langchain/tools/playwright/get_elements.py
  Functions: _aget_elements _get_elements
  Classes: GetElementsTool GetElementsToolInput
  Methods: _arun _run
  Variables: args_schema: attributes: description: elements name: page result result[attribute] results selector: val val:
  Usages: AsyncCallbackManagerForToolRun AsyncPage BaseBrowserTool BaseModel CallbackManagerForToolRun Field List Optional Page Sequence SyncPage TYPE_CHECKING Type ValueError aget_current_page annotations append args_schema async_api async_browser attribute attributes base callbacks default_factory description dict dumps element ensure_ascii get_attribute get_current_page inner_text json langchain manager name playwright pydantic query_selector_all run_manager selector self str strip sync_api sync_browser tools typing utils

Python: /langchain/tools/playwright/navigate.py
  Classes: NavigateTool NavigateToolInput
  Methods: _arun _run
  Variables: args_schema: description: name: page response status url:
  Usages: AsyncCallbackManagerForToolRun BaseBrowserTool BaseModel CallbackManagerForToolRun Field Optional Type ValueError aget_current_page annotations args_schema async_browser base callbacks description get_current_page goto langchain manager name playwright pydantic run_manager self str sync_browser tools typing url utils

Python: /langchain/tools/playwright/navigate_back.py
  Classes: NavigateBackTool
  Methods: _arun _run
  Variables: args_schema: description: name: page response
  Usages: AsyncCallbackManagerForToolRun BaseBrowserTool BaseModel CallbackManagerForToolRun Optional Type ValueError aget_current_page annotations args_schema async_browser base callbacks description get_current_page go_back langchain manager name playwright pydantic run_manager self status str sync_browser tools typing url utils

Python: /langchain/tools/playwright/utils.py
  Functions: aget_current_page create_async_playwright_browser create_sync_playwright_browser get_current_page run_async
  Variables: T browser context event_loop
  Usages: Any AsyncBrowser AsyncPage Browser Coroutine Page SyncBrowser SyncPage TYPE_CHECKING TypeVar annotations async_api async_playwright asyncio bool chromium contexts coro get_event_loop headless launch new_context new_page pages playwright run_until_complete start sync_api sync_playwright typing

Python: /langchain/tools/powerbi/prompt.py
  Variables: BAD_REQUEST_RESPONSE DEFAULT_FEWSHOT_EXAMPLES QUESTION_TO_QUERY RETRY_RESPONSE SCHEMA_ERROR_RESPONSE UNAUTHORIZED_RESPONSE

Python: /langchain/tools/powerbi/tool.py
  Classes: Config InfoPowerBITool ListPowerBITool QueryPowerBITool
  Methods: _arun _check_cache _parse_output _run validate_llm_chain_input_variables
  Variables: arbitrary_types_allowed description examples: iterations llm_chain: logger max_iterations: name pbi_result powerbi: query result, self.session_cache[tool_input] session_cache: template:
  Usages: Any AsyncCallbackManagerForToolRun BAD_REQUEST_RESPONSE BaseTool CallbackManagerForToolRun DEFAULT_FEWSHOT_EXAMPLES Dict Exception Field LLMChain Optional PowerBIDataset QUESTION_TO_QUERY RETRY_RESPONSE Tuple ValueError __name__ aget_table_info apredict arun base cache callbacks chains cls command debug default_factory dict error examples exc exclude format get getLogger get_schemas get_table_info get_table_names info input_variables int join json_to_md kwargs langchain llm llm_chain logging manager max_iterations powerbi predict prompt pydantic result run run_manager schemas self session_cache split str tables template tool_input tools typing utilities validator

Python: /langchain/tools/pubmed/tool.py
  Classes: PubmedQueryRun
  Methods: _arun _run
  Variables: api_wrapper: description name
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Field NotImplementedError Optional PubMedAPIWrapper api_wrapper base callbacks default_factory langchain manager pupmed pydantic query run run_manager self str tools typing utilities

Python: /langchain/tools/python/tool.py
  Functions: _get_default_python_repl sanitize_input
  Classes: PythonAstREPLTool PythonREPLTool
  Methods: _arun _run validate_python_version
  Variables: description globals: io_buffer locals: module module_end module_end_str name python_repl: query ret sanitize_input: tree
  Usages: Any AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Dict Exception Field Module NotImplementedError Optional PythonREPL StringIO ValueError __name__ _globals _locals ast base body bool callbacks cls contextlib default_factory dict eval exec format getvalue globals langchain locals manager parse pre pydantic python_repl redirect_stdout root_validator run run_manager self str sub sys tools type type_ignores typing unparse utilities values version version_info

Python: /langchain/tools/requests/tool.py
  Functions: _clean_url _parse_input
  Classes: BaseRequestsTool RequestsDeleteTool RequestsGetTool RequestsPatchTool RequestsPostTool RequestsPutTool
  Methods: _arun _run
  Variables: data description name requests_wrapper:
  Usages: Any AsyncCallbackManagerForToolRun BaseModel BaseTool CallbackManagerForToolRun Dict Exception Optional TextRequestsWrapper adelete aget apatch apost aput base callbacks delete get json langchain loads manager patch post put pydantic repr requests requests_wrapper run_manager self str strip text tools typing url

Python: /langchain/tools/scenexplain/tool.py
  Classes: SceneXplainInput SceneXplainTool
  Methods: _arun _run
  Variables: api_wrapper: description name query:
  Usages: AsyncCallbackManagerForToolRun BaseModel BaseTool CallbackManagerForToolRun Field NotImplementedError Optional SceneXplainAPIWrapper api_wrapper base callbacks default_factory langchain manager pydantic query run run_manager scenexplain self str tools typing utilities

Python: /langchain/tools/searx_search/tool.py
  Classes: Config SearxSearchResults SearxSearchRun
  Methods: _arun _run
  Variables: description extra name num_results: wrapper:
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Extra Optional SearxSearchWrapper __str__ allow aresults arun base callbacks int langchain manager num_results pydantic query results run run_manager searx_search self str tools typing utilities wrapper

Python: /langchain/tools/shell/__init__.py
  Variables: __all__
  Usages: ShellTool langchain shell tool tools

Python: /langchain/tools/shell/tool.py
  Functions: _get_default_bash_processs _get_platform
  Classes: ShellInput ShellTool
  Methods: _arun _run _validate_commands
  Variables: args_schema: commands commands: description: name: process: system values["commands"]
  Usages: AsyncCallbackManagerForToolRun BaseModel BaseTool BashProcess CallbackManagerForToolRun Field List Optional Type Union args_schema asyncio base bash callbacks cls default_factory description dict get get_event_loop isinstance langchain list manager name platform process pydantic return_err_output root_validator run run_in_executor run_manager self str tools typing utilities values warn warnings

Python: /langchain/tools/sleep/tool.py
  Classes: SleepInput SleepTool
  Methods: _arun _run
  Variables: args_schema: description name sleep_time:
  Usages: AsyncCallbackManagerForToolRun BaseModel BaseTool CallbackManagerForToolRun Field Optional Type args_schema asleep asyncio base callbacks int langchain manager pydantic run_manager self sleep sleep_time str time tools typing

Python: /langchain/tools/spark_sql/prompt.py
  Variables: QUERY_CHECKER

Python: /langchain/tools/spark_sql/tool.py
  Classes: BaseSparkSQLTool Config InfoSparkSQLTool ListSparkSQLTool QueryCheckerTool QuerySparkSQLTool
  Methods: _arun _run initialize_llm_chain
  Variables: arbitrary_types_allowed db: description extra llm: llm_chain: name template: values["llm_chain"]
  Usages: Any AsyncCallbackManagerForToolRun BaseLanguageModel BaseModel BaseTool CallbackManagerForToolRun Dict Extra Field LLMChain NotImplementedError Optional PromptTemplate QUERY_CHECKER SparkSQL ValueError apredict base base_language callbacks chains cls exclude forbid get get_table_info_no_throw get_usable_table_names init input_variables join langchain llm llm_chain manager pre predict prompt prompts pydantic query root_validator run_manager run_no_throw self spark_sql split str table_name table_names template tool_input tools typing utilities values

Python: /langchain/tools/sql_database/prompt.py
  Variables: QUERY_CHECKER

Python: /langchain/tools/sql_database/tool.py
  Classes: BaseSQLDatabaseTool Config InfoSQLDatabaseTool ListSQLDatabaseTool QueryCheckerTool QuerySQLDataBaseTool
  Methods: _arun _run initialize_llm_chain
  Variables: arbitrary_types_allowed db: description extra llm: llm_chain: name template: values["llm_chain"]
  Usages: Any AsyncCallbackManagerForToolRun BaseLanguageModel BaseModel BaseTool CallbackManagerForToolRun Dict Extra Field LLMChain NotImplementedError Optional PromptTemplate QUERY_CHECKER SQLDatabase ValueError apredict base base_language callbacks chains cls dialect exclude forbid get get_table_info_no_throw get_usable_table_names init input_variables join langchain llm llm_chain manager pre predict prompt prompts pydantic query root_validator run_manager run_no_throw self split sql_database str table_name table_names template tool_input tools typing values

Python: /langchain/tools/steamship_image_generation/__init__.py
  Variables: __all__
  Usages: SteamshipImageGenerationTool langchain steamship_image_generation tool tools

Python: /langchain/tools/steamship_image_generation/tool.py
  Classes: ModelName SteamshipImageGenerationTool
  Methods: _arun _run validate_environment validate_size
  Variables: DALL_E STABLE_DIFFUSION SUPPORTED_IMAGE_SIZES blocks description image_generator model_name model_name: name return_urls: size size: steamship steamship: steamship_api_key task values["steamship"]
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun Dict Enum ImportError NotImplementedError Optional RuntimeError Steamship TYPE_CHECKING annotations api_key append_output_to_file bool callbacks cls config enum generate get_from_dict_or_env langchain len make_image_public manager output plugin_handle pre pydantic query return_urls root_validator run_manager self steamship_image_generation str text tools typing use_plugin utils value values wait

Python: /langchain/tools/steamship_image_generation/utils.py
  Functions: make_image_public
  Variables: filepath read_signed_url signed_url
  Usages: Block Bucket ImportError Operation PLUGIN_DATA READ Request SignedUrl Steamship TYPE_CHECKING ValueError WRITE annotations block bucket client create_signed_url data get_workspace operation raw signed_urls steamship str typing upload_to_signed_url utils uuid uuid4 workspace

Python: /langchain/tools/vectorstore/tool.py
  Functions: _create_description_from_template
  Classes: BaseVectorStoreTool Config VectorStoreQATool VectorStoreQAWithSourcesTool
  Methods: _arun _run get_description
  Variables: arbitrary_types_allowed chain llm: template: values["description"] vectorstore:
  Usages: Any AsyncCallbackManagerForToolRun BaseLanguageModel BaseModel BaseTool CallbackManagerForToolRun Dict Field NotImplementedError OpenAI Optional RetrievalQA RetrievalQAWithSourcesChain VectorStore as_retriever base base_language callbacks chains default_factory description dumps exclude format from_chain_type json langchain llm llms manager name openai pydantic query question_key retriever return_only_outputs run run_manager self staticmethod str temperature template tools typing values vectorstore vectorstores

Python: /langchain/tools/wikipedia/tool.py
  Classes: WikipediaQueryRun
  Methods: _arun _run
  Variables: api_wrapper: description name
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun NotImplementedError Optional WikipediaAPIWrapper api_wrapper base callbacks langchain manager query run run_manager self str tools typing utilities wikipedia

Python: /langchain/tools/wolfram_alpha/__init__.py
  Variables: __all__
  Usages: WolframAlphaQueryRun langchain tool tools wolfram_alpha

Python: /langchain/tools/wolfram_alpha/tool.py
  Classes: WolframAlphaQueryRun
  Methods: _arun _run
  Variables: api_wrapper: description name
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun NotImplementedError Optional WolframAlphaAPIWrapper api_wrapper base callbacks langchain manager query run run_manager self str tools typing utilities wolfram_alpha

Python: /langchain/tools/youtube/search.py
  Classes: YouTubeSearchTool
  Methods: _arun _run _search
  Variables: data description name num_results person results url_suffix_list values
  Usages: AsyncCallbackManagerForToolRun BaseTool CallbackManagerForToolRun NotImplementedError Optional YoutubeSearch callbacks int json langchain len loads manager query run_manager self split str to_json tools typing video youtube_search

Python: /langchain/tools/zapier/__init__.py
  Variables: __all__
  Usages: ZapierNLAListActions ZapierNLARunAction langchain tool tools zapier

Python: /langchain/tools/zapier/prompt.py
  Variables: BASE_ZAPIER_TOOL_PROMPT

Python: /langchain/tools/zapier/tool.py
  Classes: ZapierNLAListActions ZapierNLARunAction
  Methods: _arun _run set_name_description
  Variables: ZapierNLAListActions.__doc__ ZapierNLARunAction.__doc__ action_id: api_wrapper: base_prompt: description name necessary_fields params: params_schema params_schema: values["description"] values["name"] zapier_description zapier_description:
  Usages: Any AsyncCallbackManagerForToolRun BASE_ZAPIER_TOOL_PROMPT BaseTool CallbackManagerForToolRun Dict Field NotImplementedError Optional ValueError ZapierNLAWrapper __doc__ action_id all api_wrapper base base_prompt callbacks cls default_factory dict field format instructions keys langchain list list_as_str manager params prompt pydantic root_validator run run_as_str run_manager self str tools typing utilities values zapier

Python: /langchain/vectorstores/docarray/__init__.py
  Variables: __all__
  Usages: DocArrayHnswSearch DocArrayInMemorySearch docarray hnsw in_memory langchain vectorstores

Python: /langchain/vectorstores/docarray/base.py
  Functions: _check_docarray_import
  Classes: DocArrayDoc DocArrayIndex
  Methods: __init__ _get_doc_cls _similarity_search_with_relevance_scores add_texts doc_cls max_marginal_relevance_search similarity_search similarity_search_by_vector similarity_search_with_score
  Variables: da_version doc docs docs, embedding: embeddings ids: metadata: mmr_selected query_doc query_embedding result results self.doc_index self.embedding text:
  Usages: ABC Any BaseDoc BaseDocIndex Document Embeddings Field ImportError Iterable List NdArray NotImplementedError Optional TYPE_CHECKING Tuple Type ValueError VectorStore __version__ _schema abc abstract append array base dict doc_index docarray documents embed_documents embed_query embedding embeddings_params enumerate fetch_k find float ids idx index int kwargs lambda_mult langchain limit list maximal_marginal_relevance metadata metadatas numpy page_content property pydantic query schema score scores search_field self split staticmethod str text texts typing utils vectorstores zip

Python: /langchain/vectorstores/docarray/hnsw.py
  Classes: DocArrayHnswSearch
  Methods: from_params from_texts
  Variables: doc_cls doc_index store
  Usages: Any DocArrayIndex Embeddings HnswDocumentIndex List Literal M Optional ValueError _check_docarray_import _get_doc_cls add_texts allow_replace_deleted annotations base bool classmethod cls dict dim dist_metric docarray ef_construction embedding embeddings index int kwargs langchain max_elements metadatas n_dim num_threads space str texts typing vectorstores work_dir

Python: /langchain/vectorstores/docarray/in_memory.py
  Classes: DocArrayInMemorySearch
  Methods: from_params from_texts
  Variables: doc_cls doc_index store
  Usages: Any Dict DocArrayIndex Embeddings InMemoryExactNNIndex List Literal Optional _check_docarray_import _get_doc_cls add_texts annotations base classmethod cls docarray embedding embeddings index kwargs langchain metadatas metric space str texts typing vectorstores

Python: /tests/integration_tests/agent/test_csv_agent.py
  Functions: test_csv_agent_creation test_multi_csv test_single_csv
  Methods: csv csv_list
  Variables: agent df1 df2 filename filename1 filename2 random_data response result
  Usages: AgentExecutor DataFrame OpenAI TempPathFactory _pytest agents columns create_csv_agent fixture group isinstance langchain list llms mktemp numpy pandas pytest rand random run scope search str temperature tmp_path_factory tmpdir to_csv verbose

Python: /tests/integration_tests/agent/test_pandas_agent.py
  Functions: test_data_reading test_data_reading_no_df_in_prompt test_multi_df test_multi_df_no_df_in_prompt test_pandas_agent_creation
  Methods: df df_list
  Variables: agent df1 df2 df_list random_data response result
  Usages: AgentExecutor DataFrame OpenAI agents columns create_pandas_dataframe_agent fixture group include_df_in_prompt isinstance langchain list llms numpy pandas pytest rand random run scope search shape temperature verbose

Python: /tests/integration_tests/agent/test_powerbi_agent.py
  Functions: azure_installed
  Methods: test_daxquery
  Variables: DATASET_ID NUM_ROWS TABLE_NAME agent_executor fast_llm output smart_llm toolkit
  Usages: ChatOpenAI DefaultAzureCredential Exception PowerBIDataset PowerBIToolkit TokenCredential agent_toolkits agents azure bool chat_models core create_pbi_agent credential credentials dataset_id get_from_env identity langchain llm mark max_tokens model_name powerbi print pytest reason run skipif table_names temperature utilities utils verbose

Python: /tests/integration_tests/cache/test_gptcache.py
  Functions: init_gptcache_map init_gptcache_map_with_llm
  Methods: test_gptcache_caching
  Variables: cache_output cache_path gptcache_installed init_gptcache_map._i langchain.llm_cache llm llm_string params params["stop"]
  Usages: Any Cache Callable FakeLLM GPTCache Generation ImportError Union cache cache_obj clear data_manager data_path dict factory fake_llm generate get_data_manager get_prompt getattr gptcache init init_func isfile items langchain llm_cache llms lookup manager mark parametrize path pre pre_embedding_func processor pytest reason remove schema skipif sorted str tests text typing unit_tests update

Python: /tests/integration_tests/cache/test_momento_cache.py
  Functions: random_string test_invalid_ttl test_momento_cache_miss
  Methods: momento_cache test_momento_cache_hit
  Variables: cache_name client langchain.llm_cache llm llm_cache llm_generations llm_string params params["stop"] stub_llm_output
  Usages: CacheClient Configurations CredentialProvider FakeLLM Generation Iterator LLMResult Laptop MomentoCache ValueError annotations cache datetime default_ttl delete_cache dict fake_llm fixture from_environment_variable generate generation generation_info generations items langchain list llm_generations_i llm_output llms mark momento parametrize prompt_i prompt_i_generations prompts pytest raises schema scope seconds sorted str tests text timedelta ttl typing unit_tests update uuid uuid4 zip

Python: /tests/integration_tests/cache/test_redis_cache.py
  Functions: test_redis_cache test_redis_semantic_cache
  Variables: REDIS_TEST_URL expected_output langchain.llm_cache llm llm_string output params params["stop"]
  Usages: FakeEmbeddings FakeLLM Generation LLMResult Redis RedisCache RedisSemanticCache cache clear dict embedding fake_embeddings fake_llm flushall from_url generate generations integration_tests items langchain llm_cache llm_output llms print redis redis_ redis_url schema score_threshold sorted str tests text unit_tests update vectorstores

Python: /tests/integration_tests/callbacks/test_langchain_tracer.py
  Functions: test_trace_as_group test_trace_as_group_with_env_set test_tracing_context_manager test_tracing_sequential test_tracing_session_env_var test_tracing_v2_context_manager
  Methods: test_trace_as_group_async test_tracing_concurrent test_tracing_concurrent_bw_compat_environ test_tracing_context_manager_async test_tracing_v2_environment_variable
  Variables: agent aiosession async_tools chain llm os.environ["LANGCHAIN_HANDLER"] os.environ["LANGCHAIN_SESSION"] os.environ["LANGCHAIN_TRACING"] os.environ["LANGCHAIN_TRACING_V2"] prompt questions task tasks tools
  Usages: AgentType CHAT_ZERO_SHOT_REACT_DESCRIPTION ChatOpenAI ClientSession LLMChain OpenAI PromptTemplate ZERO_SHOT_REACT_DESCRIPTION agents aiohttp arun asyncio atrace_as_chain_group callbacks chains chat_models close create_task environ gather group_manager initialize_agent input_variables langchain llms load_tools manager mark product prompts pytest run session temperature template trace_as_chain_group tracing_enabled tracing_v2_enabled verbose

Python: /tests/integration_tests/callbacks/test_openai_callback.py
  Functions: test_openai_callback_agent
  Methods: test_openai_callback
  Variables: agent llm task tools total_tokens
  Usages: AgentType OpenAI ZERO_SHOT_REACT_DESCRIPTION agenerate agents asyncio callbacks completion_tokens create_task gather get_openai_callback initialize_agent langchain llms load_tools mark print prompt_tokens pytest range run temperature total_cost verbose

Python: /tests/integration_tests/callbacks/test_wandb_tracer.py
  Functions: test_tracing_context_manager test_tracing_sequential test_tracing_session_env_var
  Methods: test_tracing_concurrent test_tracing_context_manager_async
  Variables: agent aiosession async_tools llm os.environ["LANGCHAIN_WANDB_TRACING"] os.environ["WANDB_PROJECT"] questions task tasks tools
  Usages: AgentType ClientSession OpenAI ZERO_SHOT_REACT_DESCRIPTION agents aiohttp arun asyncio callbacks close create_task environ gather initialize_agent langchain llms load_tools manager mark pytest run temperature verbose wandb_tracing_enabled

Python: /tests/integration_tests/chains/test_graph_database.py
  Functions: test_connect_neo4j test_cypher_generating_run test_cypher_intermediate_steps test_cypher_return_direct test_cypher_top_k
  Variables: TOP_K chain context expected_context expected_output expected_query graph output password query url username
  Usages: GraphCypherQAChain Neo4jGraph OpenAI chains cypher environ from_llm get graph_qa graphs langchain len llms openai refresh_schema return_direct return_intermediate_steps run temperature top_k

Python: /tests/integration_tests/chains/test_memory.py
  Functions: test_summary_buffer_memory_buffer_only test_summary_buffer_memory_no_buffer_yet test_summary_buffer_memory_summary
  Variables: memory output
  Usages: ConversationSummaryBufferMemory FakeLLM buffer fake_llm langchain llm llms load_memory_variables max_token_limit memory_key save_context summary_buffer tests unit_tests

Python: /tests/integration_tests/chains/test_pal.py
  Functions: test_colored_object_prompt test_math_prompt
  Variables: llm output pal_chain question
  Usages: OpenAI PALChain base chains from_colored_object_prompt from_math_prompt langchain max_tokens pal run temperature

Python: /tests/integration_tests/chains/test_react.py
  Functions: test_react
  Variables: llm output question react
  Usages: OpenAI ReActChain Wikipedia agents base docstore langchain llms model_name openai run temperature wikipedia

Python: /tests/integration_tests/chains/test_retrieval_qa.py
  Functions: test_retrieval_qa_saving_loading
  Variables: docsearch documents embeddings file_path loader qa_loaded text_splitter texts
  Usages: CharacterTextSplitter Chroma OpenAI OpenAIEmbeddings Path RetrievalQA TextLoader as_retriever chains chunk_overlap chunk_size document_loaders from_documents from_llm langchain llm llms load load_chain loading openai pathlib retriever save split_documents tmp_path vectorstores

Python: /tests/integration_tests/chains/test_self_ask_with_search.py
  Functions: test_self_ask_with_search
  Variables: answer chain final_answer question
  Usages: GoogleSerperAPIWrapper OpenAI SelfAskWithSearchChain agents base google_serper input_key langchain llm llms openai output_key run search_chain self_ask_with_search split temperature utilities

Python: /tests/integration_tests/chains/test_sql_database.py
  Functions: test_sql_database_run test_sql_database_run_update test_sql_database_sequential_chain_intermediate_steps test_sql_database_sequential_chain_run
  Variables: db_chain engine expected_output expected_query expected_query_results metadata_obj output query query_results stmt user
  Usages: Column Integer MetaData OpenAI SQLDatabase SQLDatabaseChain SQLDatabaseSequentialChain String Table base chains conn connect create_all create_engine execute from_llm insert langchain llms nullable openai primary_key return_intermediate_steps run sql_database sqlalchemy temperature user_company user_id user_name values

Python: /tests/integration_tests/chat_models/test_anthropic.py
  Functions: test_anthropic_call test_anthropic_streaming test_anthropic_streaming_callback test_formatting
  Methods: test_anthropic_async_streaming_callback
  Variables: callback_handler callback_manager chat chat_messages chat_messages: message response result result:
  Usages: AIMessage BaseMessage CallbackManager ChatAnthropic ChatGeneration FakeCallbackHandler HumanMessage LLMResult List _convert_messages_to_prompt agenerate anthropic asyncio callbacks chat_models content fake_callback_handler generations isinstance langchain llm_streams manager mark model pytest schema str streaming tests text typing unit_tests verbose

Python: /tests/integration_tests/chat_models/test_google_palm.py
  Functions: test_chat_google_palm test_chat_google_palm_generate test_chat_google_palm_multiple_completions test_chat_google_palm_system_message
  Methods: test_async_chat_google_palm
  Variables: chat human_message message response system_message
  Usages: BaseMessage ChatGeneration ChatGooglePalm ChatResult HumanMessage LLMResult SystemMessage _generate agenerate asyncio chat_models content generate generation generations isinstance langchain len mark pytest schema str temperature text

Python: /tests/integration_tests/chat_models/test_openai.py
  Functions: test_chat_openai test_chat_openai_extra_kwargs test_chat_openai_generate test_chat_openai_invalid_streaming_params test_chat_openai_llm_output_contains_model_name test_chat_openai_model test_chat_openai_multiple_completions test_chat_openai_streaming test_chat_openai_streaming_llm_output_contains_model_name test_chat_openai_system_message
  Methods: test_async_chat_openai test_async_chat_openai_streaming
  Variables: callback_handler callback_manager chat human_message llm llm_result message response system_message
  Usages: BaseMessage CallbackManager ChatGeneration ChatOpenAI ChatResult FakeCallbackHandler HumanMessage LLMResult SystemMessage ValueError _generate agenerate asyncio callbacks chat_models content fake_callback_handler foo generate generation generations isinstance langchain len llm_output llm_streams manager mark max_tokens model model_kwargs model_name openai pytest raises schema str streaming temperature tests text unit_tests verbose

Python: /tests/integration_tests/chat_models/test_promptlayer_openai.py
  Functions: test_promptlayer_chat_openai test_promptlayer_chat_openai_generate test_promptlayer_chat_openai_invalid_streaming_params test_promptlayer_chat_openai_multiple_completions test_promptlayer_chat_openai_streaming test_promptlayer_chat_openai_system_message
  Methods: test_async_promptlayer_chat_openai test_async_promptlayer_chat_openai_streaming
  Variables: callback_handler callback_manager chat human_message message response system_message
  Usages: BaseMessage CallbackManager ChatGeneration ChatResult FakeCallbackHandler HumanMessage LLMResult PromptLayerChatOpenAI SystemMessage ValueError _generate agenerate asyncio callbacks chat_models content fake_callback_handler generate generation generations isinstance langchain len llm_streams manager mark max_tokens promptlayer_openai pytest raises schema str streaming temperature tests text unit_tests verbose

Python: /tests/integration_tests/chat_models/test_vertexai.py
  Functions: test_parse_chat_history_correct test_parse_chat_history_wrong_sequence test_vertexai_args_passed test_vertexai_single_call test_vertexai_single_call_failes_no_message test_vertexai_single_call_with_context
  Variables: answer chat context history message mock_response model prompt_params question raw_context response response_text send_message.return_value text_answer text_context text_question user_prompt
  Usages: AIMessage ChatVertexAI HumanMessage Mock SystemMessage ValueError _MessagePair _llm_type _model_id _parse_chat_history assert_called_once_with chat_models client content exc_info isinstance langchain len mock model_name patch pytest raises return_value schema send_message str system_message text unittest value vertexai

Python: /tests/integration_tests/document_loaders/test_arxiv.py
  Functions: assert_docs test_load_returns_full_set_of_metadata test_load_returns_limited_docs test_load_returns_no_result test_load_success
  Variables: docs expected_docs loader
  Usages: ArxivLoader Document List arxiv doc document_loaders issuperset langchain len load load_all_available_meta load_max_docs metadata page_content print query schema set typing

Python: /tests/integration_tests/document_loaders/test_bigquery.py
  Methods: test_bigquery_loader_metadata_columns test_bigquery_loader_no_options test_bigquery_loader_page_content_columns
  Variables: bigquery_installed docs loader
  Usages: BigQueryLoader ImportError bigquery cloud document_loaders google langchain len load mark metadata metadata_columns page_content page_content_columns pytest reason skipif

Python: /tests/integration_tests/document_loaders/test_bilibili.py
  Functions: test_bilibili_loader
  Variables: docs loader
  Usages: BiliBiliLoader document_loaders langchain len load metadata page_content

Python: /tests/integration_tests/document_loaders/test_blockchain.py
  Methods: test_get_all test_get_all_10sec_timeout test_get_nfts_invalid_contract test_get_nfts_polygon test_get_nfts_valid_contract test_get_nfts_with_pagination
  Variables: alchemyKeySet apiKey contract_address end_time max_alchemy_tokens result startToken start_time
  Usages: BlockchainDocumentLoader BlockchainType ETH_MAINNET POLYGON_MAINNET RuntimeError ValueError api_key blockchain blockchainType document_loaders environ error_NoNfts get_all_tokens langchain len load mark max_execution_time print pytest raises reason skipif str time value

Python: /tests/integration_tests/document_loaders/test_confluence.py
  Methods: test_confluence_pagination test_load_full_confluence_space test_load_single_confluence_page test_pass_confluence_kwargs
  Variables: confluence_installed docs loader
  Usages: Confluence ConfluenceLoader ImportError atlassian confluence confluence_kwargs document_loaders langchain len limit load mark max_pages metadata page_content page_ids pytest reason skipif space_key url verify_ssl

Python: /tests/integration_tests/document_loaders/test_csv_loader.py
  Functions: test_unstructured_csv_loader
  Variables: EXAMPLE_DIRECTORY docs file_path loader
  Usages: Path UnstructuredCSVLoader __file__ document_loaders join langchain len load parent path pathlib str

Python: /tests/integration_tests/document_loaders/test_dataframe.py
  Functions: test_load_converts_dataframe_columns_to_document_metadata test_load_returns_list_of_documents test_load_uses_page_content_column_to_create_document_text
  Methods: sample_data_frame
  Variables: data docs loader sample_data_frame
  Usages: DataFrame DataFrameLoader Document all columns doc document_loaders enumerate fixture isinstance langchain len list load loc metadata page_content page_content_column pandas pytest rename schema

Python: /tests/integration_tests/document_loaders/test_duckdb.py
  Methods: test_duckdb_loader_metadata_columns test_duckdb_loader_no_options test_duckdb_loader_page_content_columns
  Variables: docs duckdb_installed loader
  Usages: DuckDBLoader ImportError document_loaders duckdb duckdb_loader langchain len load metadata metadata_columns page_content page_content_columns skipIf unittest

Python: /tests/integration_tests/document_loaders/test_email.py
  Functions: test_outlook_message_loader
  Variables: docs file_path loader
  Usages: OutlookMessageLoader Path __file__ document_loaders langchain len load metadata page_content parent pathlib str

Python: /tests/integration_tests/document_loaders/test_embaas.py
  Methods: test_handle_request test_handle_request_exception test_load
  Variables: documents loader mock_handle_request.return_value
  Usages: Any Blob EMBAAS_DOC_API_URL EmbaasBlobLoader EmbaasLoader Exception MagicMock POST activate add blob blob_loaders data document_loaders embaas embaas_api_key file_path from_data json langchain len load metadata mock mock_handle_request object page_content params parse patch responses return_value status str typing unittest

Python: /tests/integration_tests/document_loaders/test_excel.py
  Functions: test_unstructured_excel_loader
  Variables: EXAMPLE_DIRECTORY docs file_path loader
  Usages: Path UnstructuredExcelLoader __file__ document_loaders join langchain len load parent path pathlib str

Python: /tests/integration_tests/document_loaders/test_facebook_chat.py
  Functions: test_facebook_chat_loader
  Variables: docs file_path loader
  Usages: FacebookChatLoader Path __file__ document_loaders langchain len load metadata page_content parent pathlib str

Python: /tests/integration_tests/document_loaders/test_fauna.py
  Classes: TestFaunaLoader
  Methods: setUp test_fauna_loader
  Variables: docs fauna_installed loader self.fauna_secret self.valid_fql_query self.valid_metadata_fields self.valid_page_content_field
  Usages: FaunaLoader ImportError TestCase doc document_loaders fauna fauna_secret langchain len load metadata metadata_fields page_content page_content_field query secret self skipIf unittest valid_fql_query valid_metadata_fields valid_page_content_field

Python: /tests/integration_tests/document_loaders/test_figma.py
  Functions: test_figma_file_loader
  Variables: ACCESS_TOKEN IDS KEY docs loader
  Usages: FigmaFileLoader document_loaders figma langchain len load

Python: /tests/integration_tests/document_loaders/test_gitbook.py
  Classes: TestGitbookLoader
  Methods: test_init test_load_multiple_pages test_load_single_page
  Variables: loader result
  Usages: GitbookLoader Optional __dict__ base_url bool document_loaders endswith expected_number_results expected_web_path gitbook int langchain len load load_all_paths mark parametrize print pytest self str typing web_page web_path

Python: /tests/integration_tests/document_loaders/test_github.py
  Functions: test_issues_load
  Variables: docs loader title titles
  Usages: GitHubIssuesLoader all creator doc document_loaders github langchain load metadata repo state

Python: /tests/integration_tests/document_loaders/test_ifixit.py
  Functions: test_ifixit_loader test_ifixit_loader_answers test_ifixit_loader_device test_ifixit_loader_teardown
  Variables: loader web_path
  Usages: IFixitLoader document_loaders ifixit langchain page_type

Python: /tests/integration_tests/document_loaders/test_joplin.py
  Functions: test_joplin_loader
  Variables: docs loader
  Usages: JoplinLoader document_loaders joplin langchain list load metadata page_content str type

Python: /tests/integration_tests/document_loaders/test_json_loader.py
  Functions: test_json_loader
  Variables: docs file_path loader
  Usages: JSONLoader Path __file__ document_loaders langchain len load page_content parent pathlib str

Python: /tests/integration_tests/document_loaders/test_mastodon.py
  Functions: test_mastodon_toots_loader
  Variables: docs loader
  Usages: MastodonTootsLoader document_loaders langchain len load mastodon_accounts metadata number_toots

Python: /tests/integration_tests/document_loaders/test_modern_treasury.py
  Functions: test_modern_treasury_loader
  Variables: documents modern_treasury_loader
  Usages: ModernTreasuryLoader document_loaders langchain len load modern_treasury

Python: /tests/integration_tests/document_loaders/test_odt.py
  Functions: test_unstructured_odt_loader
  Variables: docs file_path loader
  Usages: Path UnstructuredODTLoader __file__ document_loaders langchain len load parent pathlib str

Python: /tests/integration_tests/document_loaders/test_pdf.py
  Functions: test_mathpix_loader test_pdfminer_loader test_pdfminer_pdf_as_html_loader test_pymupdf_loader test_pypdf_loader test_pypdfium2_loader test_unstructured_pdf_loader
  Variables: docs file_path loader web_path
  Usages: MathpixPDFLoader PDFMinerLoader PDFMinerPDFasHTMLLoader Path PyMuPDFLoader PyPDFLoader PyPDFium2Loader UnstructuredPDFLoader __file__ document_loaders langchain len load page_content parent pathlib print str

Python: /tests/integration_tests/document_loaders/test_pyspark_dataframe_loader.py
  Functions: test_pyspark_loader_load_valid_data
  Variables: data expected_docs loader result spark
  Usages: Document PySparkDataFrameLoader SparkSession ascii_letters builder choice createDataFrame docstore document document_loaders getOrCreate langchain load metadata page_content page_content_column pyspark pyspark_dataframe randint random range spark_session sql string

Python: /tests/integration_tests/document_loaders/test_python.py
  Methods: test_python_loader
  Variables: docs file_path loader metadata
  Usages: Path PythonLoader __file__ document_loaders filename langchain len load mark parametrize parent pathlib pytest python str

Python: /tests/integration_tests/document_loaders/test_sitemap.py
  Functions: test_filter_sitemap test_local_sitemap test_sitemap test_sitemap_block test_sitemap_block_blocknum_default test_sitemap_block_does_not_exists test_sitemap_block_num_to_small test_sitemap_block_only_one test_sitemap_block_size_to_small test_sitemap_metadata test_sitemap_metadata_default test_sitemap_metadata_extraction
  Methods: sitemap_metadata_one sitemap_metadata_two
  Variables: documents file_path loader title
  Usages: Any Path SitemapLoader ValueError __file__ _content blocknum blocksize content dict document_loaders filter_urls find get_text langchain len load match meta meta_function metadata page_content parent pathlib pytest raises str typing

Python: /tests/integration_tests/document_loaders/test_slack.py
  Functions: test_slack_directory_loader test_slack_directory_loader_urls
  Variables: docs file_path loader workspace_url
  Usages: Path SlackDirectoryLoader __file__ doc document_loaders langchain len load metadata parent pathlib startswith str

Python: /tests/integration_tests/document_loaders/test_spreedly.py
  Functions: test_spreedly_loader
  Variables: access_token documents resource spreedly_loader
  Usages: SpreedlyLoader document_loaders langchain len load spreedly

Python: /tests/integration_tests/document_loaders/test_stripe.py
  Functions: test_stripe_loader
  Variables: documents stripe_loader
  Usages: StripeLoader document_loaders langchain len load stripe

Python: /tests/integration_tests/document_loaders/test_unstructured.py
  Functions: test_unstructured_api_file_io_loader test_unstructured_api_file_loader test_unstructured_api_file_loader_io_multiple_files test_unstructured_api_file_loader_multiple_files
  Variables: EXAMPLE_DOCS_DIRECTORY docs file_path file_paths files loader
  Usages: ExitStack Path UnstructuredAPIFileIOLoader UnstructuredAPIFileLoader __file__ api_key contextlib document_loaders enter_context file file_filename file_filenames join langchain len load mode open parent path pathlib stack str strategy

Python: /tests/integration_tests/document_loaders/test_url.py
  Functions: test_continue_on_failure_false test_continue_on_failure_true
  Variables: loader
  Usages: Exception UnstructuredURLLoader continue_on_failure document_loaders langchain load pytest raises

Python: /tests/integration_tests/document_loaders/test_url_playwright.py
  Functions: test_playwright_url_loader
  Variables: docs loader urls
  Usages: PlaywrightURLLoader continue_on_failure document_loaders headless langchain len load remove_selectors

Python: /tests/integration_tests/document_loaders/test_whatsapp_chat.py
  Functions: test_whatsapp_chat_loader
  Variables: docs file_path loader
  Usages: Path WhatsAppChatLoader __file__ document_loaders langchain len load metadata page_content parent pathlib str

Python: /tests/integration_tests/document_loaders/test_xml.py
  Functions: test_unstructured_xml_loader
  Variables: EXAMPLE_DIRECTORY docs file_path loader
  Usages: Path UnstructuredXMLLoader __file__ document_loaders join langchain len load parent path pathlib str

Python: /tests/integration_tests/embeddings/test_cohere.py
  Functions: test_cohere_embedding_documents test_cohere_embedding_query
  Variables: document documents embedding output
  Usages: CohereEmbeddings cohere embed_documents embed_query embeddings langchain len

Python: /tests/integration_tests/embeddings/test_dashscope.py
  Functions: test_dashscope_embedding_documents test_dashscope_embedding_documents_multiple test_dashscope_embedding_query test_dashscope_embedding_with_empty_string
  Variables: document documents embedding expected_output output
  Usages: DashScopeEmbeddings TextEmbedding __name__ allclose call dashscope embed_documents embed_query embeddings input langchain len model numpy text_type

Python: /tests/integration_tests/embeddings/test_deepinfra.py
  Functions: test_deepinfra_call
  Variables: deepinfra_emb
  Usages: DeepInfraEmbeddings embed_documents embed_query embeddings langchain len model_id

Python: /tests/integration_tests/embeddings/test_elasticsearch.py
  Functions: test_elasticsearch_embedding_documents test_elasticsearch_embedding_query
  Methods: model_id
  Variables: document documents embedding output
  Usages: ElasticsearchEmbeddings elasticsearch embed_documents embed_query embeddings fixture from_credentials langchain len pytest str

Python: /tests/integration_tests/embeddings/test_embaas.py
  Functions: test_embaas_embed_documents test_embaas_embed_query test_embaas_embed_query_instruction test_embaas_embed_query_model
  Methods: test_embaas_embed_documents_response
  Variables: embedding embeddings instruction model output text texts
  Usages: EMBAAS_API_URL EmbaasEmbeddings POST activate add embaas embed_documents embed_query json langchain len responses status

Python: /tests/integration_tests/embeddings/test_google_palm.py
  Functions: test_google_palm_embedding_documents test_google_palm_embedding_documents_multiple test_google_palm_embedding_query
  Variables: document documents embedding output
  Usages: GooglePalmEmbeddings embed_documents embed_query embeddings google_palm langchain len

Python: /tests/integration_tests/embeddings/test_huggingface.py
  Functions: test_huggingface_embedding_documents test_huggingface_embedding_query test_huggingface_instructor_embedding_documents test_huggingface_instructor_embedding_normalize test_huggingface_instructor_embedding_query
  Variables: document documents embedding encode_kwargs eps model_name norm output query
  Usages: HuggingFaceEmbeddings HuggingFaceInstructEmbeddings abs embed_documents embed_query embeddings huggingface langchain len sum

Python: /tests/integration_tests/embeddings/test_huggingface_hub.py
  Functions: test_huggingfacehub_embedding_documents test_huggingfacehub_embedding_invalid_repo test_huggingfacehub_embedding_query
  Variables: document documents embedding output
  Usages: HuggingFaceHubEmbeddings ValueError embed_documents embed_query embeddings langchain len pytest raises repo_id

Python: /tests/integration_tests/embeddings/test_jina.py
  Functions: test_jina_embedding_documents test_jina_embedding_query
  Variables: document documents embedding output
  Usages: JinaEmbeddings embed_documents embed_query embeddings jina langchain len

Python: /tests/integration_tests/embeddings/test_llamacpp.py
  Functions: get_model test_llamacpp_embedding_documents test_llamacpp_embedding_query
  Variables: conversion_script document documents embedding local_filename model_path model_url output tokenizer_url
  Usages: LlamaCppEmbeddings embed_documents embed_query embeddings exists langchain len llamacpp path request split str system urllib urlretrieve

Python: /tests/integration_tests/embeddings/test_modelscope_hub.py
  Functions: test_modelscope_embedding_documents test_modelscope_embedding_query
  Variables: document documents embedding output
  Usages: ModelScopeEmbeddings embed_documents embed_query embeddings langchain len modelscope_hub

Python: /tests/integration_tests/embeddings/test_mosaicml.py
  Functions: test_mosaicml_embedding_document_instruction test_mosaicml_embedding_documents test_mosaicml_embedding_documents_multiple test_mosaicml_embedding_endpoint test_mosaicml_embedding_query test_mosaicml_embedding_query_instruction
  Variables: document documents embedding output
  Usages: MosaicMLInstructorEmbeddings embed_documents embed_instruction embed_query embeddings endpoint_url langchain len mosaicml query_instruction

Python: /tests/integration_tests/embeddings/test_openai.py
  Functions: test_openai_embedding_documents test_openai_embedding_documents_multiple test_openai_embedding_query test_openai_embedding_with_empty_string
  Variables: document documents embedding embedding.embedding_ctx_length expected_output output
  Usages: Embedding OpenAIEmbeddings allclose chunk_size create embed_documents embed_query embedding_ctx_length embeddings input langchain len model numpy openai

Python: /tests/integration_tests/embeddings/test_self_hosted.py
  Functions: get_pipeline get_remote_instance inference_fn test_self_hosted_embedding_documents test_self_hosted_embedding_query test_self_hosted_huggingface_embedding_documents test_self_hosted_huggingface_embedding_query test_self_hosted_huggingface_instructor_embedding_documents test_self_hosted_huggingface_instructor_embedding_query
  Variables: document documents embedding gpu model model_id output query tokenizer
  Usages: Any AutoModelForCausalLM AutoTokenizer SelfHostedEmbeddings SelfHostedHuggingFaceEmbeddings SelfHostedHuggingFaceInstructEmbeddings cluster emb embed_documents embed_query embeddings from_pretrained hardware install_packages instance_type isinstance langchain len list model_load_fn name pipeline prompt runhouse str transformers typing use_spot

Python: /tests/integration_tests/embeddings/test_sentence_transformer.py
  Functions: test_sentence_transformer_db_query test_sentence_transformer_embedding_documents test_sentence_transformer_embedding_query
  Variables: docs documents embedding output query query_vector texts
  Usages: Chroma SentenceTransformerEmbeddings add_texts embed_documents embed_query embedding_function embeddings langchain len page_content sentence_transformer similarity_search_by_vector vectorstores

Python: /tests/integration_tests/embeddings/test_tensorflow_hub.py
  Functions: test_tensorflowhub_embedding_documents test_tensorflowhub_embedding_query
  Variables: document documents embedding output
  Usages: TensorflowHubEmbeddings embed_documents embed_query embeddings langchain len

Python: /tests/integration_tests/embeddings/test_vertexai.py
  Functions: test_embedding_documents test_embedding_query test_paginated_texts
  Variables: document documents model output
  Usages: VertexAIEmbeddings _llm_type _model_id client embed_documents embed_query embeddings langchain len model_name

HTML: /tests/integration_tests/examples/example-utf8.html
## Chase the red dot

HTML: /tests/integration_tests/examples/example.html
## Chase the red dot

File: /tests/integration_tests/examples/example.json

File: /tests/integration_tests/examples/facebook_chat.json

File: /tests/integration_tests/examples/factbook.xml

File: /tests/integration_tests/examples/sitemap.xml

File: /tests/integration_tests/examples/stanley-cups.csv

File: /tests/integration_tests/examples/whatsapp_chat.txt

Python: /tests/integration_tests/llms/test_ai21.py
  Functions: test_ai21_call test_ai21_call_experimental test_saving_loading_llm
  Variables: llm loaded_llm output
  Usages: AI21 Path ai21 file_path isinstance langchain llms load_llm loading maxTokens model pathlib save str tmp_path

Python: /tests/integration_tests/llms/test_aleph_alpha.py
  Functions: test_aleph_alpha_call
  Variables: llm output
  Usages: AlephAlpha aleph_alpha isinstance langchain llms maximum_tokens str

Python: /tests/integration_tests/llms/test_anthropic.py
  Functions: test_anthropic_call test_anthropic_streaming test_anthropic_streaming_callback
  Methods: test_anthropic_async_generate test_anthropic_async_streaming_callback
  Variables: callback_handler callback_manager generator llm output result
  Usages: Anthropic CallbackManager FakeCallbackHandler Generator LLMResult agenerate anthropic asyncio callbacks fake_callback_handler isinstance langchain llm_streams llms manager mark model pytest schema str stream streaming tests token typing unit_tests verbose

Python: /tests/integration_tests/llms/test_anyscale.py
  Functions: test_anyscale_call
  Variables: llm output
  Usages: Anyscale anyscale isinstance langchain llms str

Python: /tests/integration_tests/llms/test_aviary.py
  Functions: test_aviary_call
  Variables: llm output
  Usages: Aviary aviary isinstance langchain llms model str

Python: /tests/integration_tests/llms/test_banana.py
  Functions: test_banana_call
  Variables: llm output
  Usages: Banana bananadev isinstance langchain llms str

Python: /tests/integration_tests/llms/test_baseten.py
  Methods: test_baseten_call
  Variables: llm output
  Usages: Baseten baseten environ isinstance langchain llms login mark model pytest requires str

Python: /tests/integration_tests/llms/test_beam.py
  Functions: test_beam_call
  Variables: llm output
  Usages: Beam _call _deploy beam cpu gpu isinstance langchain llms max_length memory model_name name python_packages python_version str

Python: /tests/integration_tests/llms/test_cerebrium.py
  Functions: test_cerebriumai_call
  Variables: llm output
  Usages: CerebriumAI cerebriumai isinstance langchain llms max_length str

Python: /tests/integration_tests/llms/test_cohere.py
  Functions: test_cohere_call test_saving_loading_llm
  Variables: llm loaded_llm output
  Usages: Cohere Path assert_llm_equality cohere file_path integration_tests isinstance langchain llms load_llm loading max_tokens pathlib save str tests tmp_path utils

Python: /tests/integration_tests/llms/test_ctransformers.py
  Functions: test_ctransformers_call
  Variables: callback_handler config llm output
  Usages: CTransformers FakeCallbackHandler callbacks fake_callback_handler isinstance langchain len llm_streams llms model str tests unit_tests

Python: /tests/integration_tests/llms/test_deepinfra.py
  Functions: test_deepinfra_call
  Variables: llm output
  Usages: DeepInfra deepinfra isinstance langchain llms model_id str

Python: /tests/integration_tests/llms/test_forefrontai.py
  Functions: test_forefrontai_call
  Variables: llm output
  Usages: ForefrontAI forefrontai isinstance langchain length llms str

Python: /tests/integration_tests/llms/test_google_palm.py
  Functions: test_google_palm_call test_saving_loading_llm
  Variables: llm loaded_llm output
  Usages: GooglePalm Path file_path google_palm isinstance langchain llms load_llm loading max_output_tokens pathlib save str tmp_path

Python: /tests/integration_tests/llms/test_gooseai.py
  Functions: test_gooseai_call test_gooseai_call_fairseq test_gooseai_stop_valid
  Variables: first_llm first_output llm output query second_llm second_output
  Usages: GooseAI gooseai isinstance langchain llms max_tokens model_name stop str temperature

Python: /tests/integration_tests/llms/test_gpt4all.py
  Functions: _download_model test_gpt4all_inference
  Variables: llm local_filename model_path model_url output
  Usages: GPT4All exists isinstance langchain llms model path request split str urllib urlretrieve

Python: /tests/integration_tests/llms/test_huggingface_endpoint.py
  Functions: test_huggingface_endpoint_call_error test_saving_loading_endpoint_llm
  Methods: test_huggingface_endpoint_summarization test_huggingface_endpoint_text2text_generation test_huggingface_endpoint_text_generation
  Variables: llm loaded_llm output
  Usages: HuggingFaceEndpoint Path ValueError assert_llm_equality endpoint_url file_path huggingface_endpoint integration_tests isinstance langchain llms load_llm loading model_kwargs pathlib print pytest raises save skip str task tests tmp_path unittest utils

Python: /tests/integration_tests/llms/test_huggingface_hub.py
  Functions: test_huggingface_call_error test_huggingface_summarization test_huggingface_text2text_generation test_huggingface_text_generation test_saving_loading_llm
  Variables: llm loaded_llm output
  Usages: HuggingFaceHub Path ValueError assert_llm_equality file_path huggingface_hub integration_tests isinstance langchain llms load_llm loading model_kwargs pathlib pytest raises repo_id save str tests tmp_path utils

Python: /tests/integration_tests/llms/test_huggingface_pipeline.py
  Functions: test_huggingface_pipeline_text2text_generation test_huggingface_pipeline_text_generation test_init_with_pipeline test_saving_loading_llm text_huggingface_pipeline_summarization
  Variables: llm loaded_llm model model_id output pipe tokenizer
  Usages: AutoModelForCausalLM AutoTokenizer HuggingFacePipeline Path assert_llm_equality file_path from_model_id from_pretrained huggingface_pipeline integration_tests isinstance langchain llms load_llm loading max_new_tokens model_kwargs pathlib pipeline save str task tests tmp_path transformers utils

Python: /tests/integration_tests/llms/test_llamacpp.py
  Functions: get_model test_llamacpp_inference test_llamacpp_streaming test_llamacpp_streaming_callback
  Variables: MAX_TOKENS OFF_BY_ONE callback_handler conversion_script generator llm local_filename model_path model_url output stream_results_string tokenizer_url
  Usages: FakeCallbackHandler Generator LlamaCpp callbacks chunk exists fake_callback_handler isinstance langchain len llm_streams llms max_tokens path request split stop str stream strip system tests typing unit_tests urllib urlretrieve verbose

Python: /tests/integration_tests/llms/test_manifest.py
  Functions: test_manifest_wrapper
  Variables: llm manifest output
  Usages: Manifest ManifestWrapper client client_name langchain llm_kwargs llms

Python: /tests/integration_tests/llms/test_modal.py
  Functions: test_modal_call
  Variables: llm output
  Usages: Modal isinstance langchain llms modal str

Python: /tests/integration_tests/llms/test_mosaicml.py
  Functions: test_instruct_prompt test_mosaicml_endpoint_change test_mosaicml_extra_kwargs test_mosaicml_llm_call test_retry_logic test_short_retry_does_not_loop
  Variables: expected_prompt instruction llm new_url output prompt
  Usages: MosaicML PROMPT_FOR_GENERATION_FORMAT ValueError _transform_prompt endpoint_url format inject_instruction_format isinstance langchain len llms match model_kwargs mosaicml pytest raises retry_sleep split str

Python: /tests/integration_tests/llms/test_nlpcloud.py
  Functions: test_nlpcloud_call test_saving_loading_llm
  Variables: llm loaded_llm output
  Usages: NLPCloud Path assert_llm_equality file_path integration_tests isinstance langchain llms load_llm loading max_length nlpcloud pathlib save str tests tmp_path utils

Python: /tests/integration_tests/llms/test_openai.py
  Functions: test_openai_call test_openai_chat test_openai_chat_streaming test_openai_chat_streaming_callback test_openai_chat_wrong_class test_openai_extra_kwargs test_openai_llm_output_contains_model_name test_openai_model_param test_openai_modelname_to_contextsize_invalid test_openai_modelname_to_contextsize_valid test_openai_stop_error test_openai_stop_valid test_openai_streaming test_openai_streaming_best_of_error test_openai_streaming_call test_openai_streaming_callback test_openai_streaming_error test_openai_streaming_multiple_prompts_error test_openai_streaming_n_error test_saving_loading_llm
  Methods: test_chat_openai_get_num_tokens test_openai_async_generate test_openai_async_streaming_callback test_openai_chat_async_generate test_openai_chat_async_streaming_callback test_openai_get_num_tokens
  Variables: _CHAT_MODELS _EXPECTED_NUM_TOKENS _MODELS callback_handler callback_manager first_llm first_output generator llm llm_result loaded_llm output query result second_llm second_output
  Usages: CallbackManager ChatOpenAI FakeCallbackHandler Generator LLMResult OpenAI OpenAIChat Path ValueError agenerate asyncio best_of callbacks chat_models fake_callback_handler file_path foo generate get_num_tokens isinstance langchain llm_output llm_streams llms load_llm loading manager mark max_tokens model model_kwargs model_name modelname_to_contextsize models openai parametrize pathlib pytest raises save schema stop str stream streaming temperature tests tmp_path token typing unit_tests verbose

Python: /tests/integration_tests/llms/test_openlm.py
  Functions: test_openlm_call
  Variables: llm output
  Usages: OpenLM isinstance langchain llms max_tokens model_name openlm prompt str

Python: /tests/integration_tests/llms/test_petals.py
  Functions: test_gooseai_call
  Variables: llm output
  Usages: Petals isinstance langchain llms max_new_tokens petals str

Python: /tests/integration_tests/llms/test_pipelineai.py
  Functions: test_pipelineai_call
  Variables: llm output
  Usages: PipelineAI isinstance langchain llms pipelineai str

Python: /tests/integration_tests/llms/test_predictionguard.py
  Functions: test_predictionguard_call
  Variables: llm output
  Usages: PredictionGuard isinstance langchain llms model predictionguard str

Python: /tests/integration_tests/llms/test_promptlayer_openai.py
  Functions: test_promptlayer_openai_call test_promptlayer_openai_extra_kwargs test_promptlayer_openai_stop_error test_promptlayer_openai_stop_valid test_promptlayer_openai_streaming test_promptlayer_openai_streaming_error test_saving_loading_llm
  Variables: first_llm first_output generator llm loaded_llm output query second_llm second_output
  Usages: Generator Path PromptLayerOpenAI ValueError best_of file_path foo isinstance langchain llms load_llm loading max_tokens model_kwargs pathlib promptlayer_openai pytest raises save stop str stream temperature tmp_path token typing

Python: /tests/integration_tests/llms/test_propmptlayer_openai_chat.py
  Functions: test_promptlayer_openai_chat_call test_promptlayer_openai_chat_stop_error test_promptlayer_openai_chat_stop_valid test_saving_loading_llm
  Variables: first_llm first_output llm loaded_llm output query second_llm second_output
  Usages: Path PromptLayerOpenAIChat ValueError file_path isinstance langchain llms load_llm loading max_tokens pathlib promptlayer_openai pytest raises save stop str temperature tmp_path

Python: /tests/integration_tests/llms/test_replicate.py
  Functions: test_replicate_call
  Variables: llm output
  Usages: Replicate isinstance langchain llms replicate str

Python: /tests/integration_tests/llms/test_rwkv.py
  Functions: _download_model
  Methods: test_rwkv_inference
  Variables: llm local_filename model_path model_url output tokenizer_url
  Usages: RWKV exists filterwarnings isinstance langchain llms mark model path pytest request split str strategy tokens_path urllib urlretrieve warnings

Python: /tests/integration_tests/llms/test_self_hosted_llm.py
  Functions: get_remote_instance inference_fn load_pipeline test_init_with_local_pipeline test_init_with_pipeline_fn test_init_with_pipeline_path test_self_hosted_huggingface_pipeline_summarization test_self_hosted_huggingface_pipeline_text2text_generation test_self_hosted_huggingface_pipeline_text_generation
  Variables: gpu llm model model_id model_reqs output pipe pipeline tokenizer
  Usages: Any AutoModelForCausalLM AutoTokenizer List Optional SelfHostedHuggingFaceLLM SelfHostedPipeline blob cluster dumps from_pipeline from_pretrained hardware instance_type isinstance langchain llms max_new_tokens model_kwargs model_load_fn name path pickle prompt runhouse save stop str task transformers typing use_spot

Python: /tests/integration_tests/llms/test_stochasticai.py
  Functions: test_stochasticai_call
  Variables: llm output
  Usages: StochasticAI isinstance langchain llms stochasticai str

Python: /tests/integration_tests/llms/test_vertexai.py
  Functions: test_vertex_call
  Variables: llm output
  Usages: VertexAI _llm_type _model_id client isinstance langchain llms model_name str

Python: /tests/integration_tests/llms/test_writer.py
  Functions: test_writer_call
  Variables: llm output
  Usages: Writer isinstance langchain llms str writer

Python: /tests/integration_tests/llms/utils.py
  Functions: assert_llm_equality
  Variables: new_val val
  Usages: BaseLLM __fields__ base field getattr keys langchain llm llms loaded_llm type

Python: /tests/integration_tests/memory/test_cassandra.py
  Functions: test_memory_with_message_store
  Variables: contact_points memory message_history messages messages_json
  Usages: CassandraChatMessageHistory ConversationBufferMemory _message_to_dict add_ai_message add_user_message cassandra chat_memory chat_message_histories clear dumps environ json langchain memory_key msg return_messages schema session_id split

Python: /tests/integration_tests/memory/test_cosmos_db.py
  Functions: test_memory_with_message_store
  Variables: credential endpoint memory message_history messages messages_json
  Usages: ConversationBufferMemory CosmosDBChatMessageHistory _message_to_dict add_ai_message add_user_message chat_memory chat_message_histories clear cosmos_container cosmos_database cosmos_endpoint dumps environ json langchain memory_key msg prepare_cosmos return_messages schema session_id ttl user_id

Python: /tests/integration_tests/memory/test_firestore.py
  Functions: test_memory_with_message_store
  Variables: memory message_history messages messages_json
  Usages: ConversationBufferMemory FirestoreChatMessageHistory _message_to_dict add_ai_message add_user_message chat_memory chat_message_histories clear collection_name dumps json langchain memory_key msg return_messages schema session_id user_id

Python: /tests/integration_tests/memory/test_momento.py
  Functions: random_string test_memory_empty_on_new_session test_memory_with_message_store
  Methods: message_history
  Variables: cache_name chat_message_history client memory messages messages_json
  Usages: CacheClient Configurations ConversationBufferMemory CredentialProvider Iterator Laptop MomentoChatMessageHistory _message_to_dict add_ai_message add_user_message cache_client chat_memory chat_message_histories clear datetime default_ttl delete_cache dumps fixture from_environment_variable json langchain memory_key momento msg pytest return_messages schema scope seconds session_id str timedelta typing uuid uuid4

Python: /tests/integration_tests/memory/test_mongodb.py
  Functions: test_memory_with_message_store
  Variables: connection_string memory message_history messages messages_json
  Usages: ConversationBufferMemory MongoDBChatMessageHistory _message_to_dict add_ai_message add_user_message chat_memory chat_message_histories clear dumps environ json langchain memory_key msg return_messages schema session_id

Python: /tests/integration_tests/memory/test_redis.py
  Functions: test_memory_with_message_store
  Variables: memory message_history messages messages_json
  Usages: ConversationBufferMemory RedisChatMessageHistory _message_to_dict add_ai_message add_user_message chat_memory chat_message_histories clear dumps json langchain memory_key msg return_messages schema session_id ttl url

Python: /tests/integration_tests/prompts/test_ngram_overlap_example_selector.py
  Functions: test_ngram_overlap_score test_selector_add_example test_selector_threshold_more_than_one test_selector_threshold_zero test_selector_valid
  Methods: selector
  Variables: EXAMPLES check complete new_example none output prompts selector selector.threshold sentence some
  Usages: NGramOverlapExampleSelector PromptTemplate abs add_example example_prompt example_selector examples fixture input_variables langchain ngram_overlap ngram_overlap_score prompt pytest select_examples template threshold

Python: /tests/integration_tests/retrievers/test_arxiv.py
  Functions: assert_docs test_load_no_result test_load_success test_load_success_all_meta test_load_success_init_args
  Methods: retriever
  Variables: docs main_meta retriever retriever.load_all_available_meta retriever.load_max_docs
  Usages: ArxivRetriever Document List all_meta bool doc fixture get_relevant_documents issuperset langchain len load_all_available_meta load_max_docs metadata page_content pytest query retrievers schema set typing

Python: /tests/integration_tests/retrievers/test_azure_cognitive_search.py
  Functions: test_azure_cognitive_search_get_relevant_documents
  Methods: test_azure_cognitive_search_aget_relevant_documents
  Variables: documents retriever
  Usages: AzureCognitiveSearchRetriever Document aget_relevant_documents asyncio azure_cognitive_search doc get_relevant_documents isinstance langchain mark page_content pytest retrievers schema

Python: /tests/integration_tests/retrievers/test_contextual_compression.py
  Functions: test_contextual_compression_retriever_get_relevant_docs
  Variables: actual base_compressor base_retriever embeddings retriever texts
  Usages: Chroma ContextualCompressionRetriever EmbeddingsFilter OpenAIEmbeddings as_retriever contextual_compression document_compressors embedding from_texts get_relevant_documents langchain len page_content retrievers search_kwargs similarity_threshold vectorstores

Python: /tests/integration_tests/retrievers/test_merger_retriever.py
  Functions: test_merger_retriever_get_relevant_docs
  Variables: actual embeddings lotr retriever_a retriever_b texts_group_a texts_group_b
  Usages: Chroma MergerRetriever OpenAIEmbeddings as_retriever embedding from_texts get_relevant_documents langchain len merger_retriever page_content retrievers search_kwargs vectorstores

Python: /tests/integration_tests/retrievers/test_pupmed.py
  Functions: assert_docs test_load_no_result test_load_success test_load_success_all_meta test_load_success_init_args
  Methods: retriever
  Variables: docs main_meta retriever retriever.load_all_available_meta retriever.load_max_docs
  Usages: Document List PubMedRetriever all_meta bool doc fixture get_relevant_documents issuperset langchain len load_all_available_meta load_max_docs metadata page_content pytest query retrievers schema set typing

Python: /tests/integration_tests/retrievers/test_weaviate_hybrid_search.py
  Classes: TestWeaviateHybridSearchRetriever
  Methods: setup_class test_get_relevant_documents test_get_relevant_documents_with_filter test_get_relevant_documents_with_uuids weaviate_url
  Variables: client metadatas output retriever texts url uuids where_filter
  Usages: Client DEBUG Document Generator NAMESPACE_DNS Union ValueError WeaviateHybridSearchRetriever add_documents attributes autouse basicConfig classmethod cls delete_all docstore document enumerate fixture get_relevant_documents getenv hex ignore_localhost index_name langchain len level logging mark metadata page_content pytest range retrievers schema scope self str text text_key typing uuid uuid4 uuid5 vcr weaviate weaviate_hybrid_search

Python: /tests/integration_tests/retrievers/test_wikipedia.py
  Functions: assert_docs test_load_no_result test_load_success test_load_success_all_meta test_load_success_init_args
  Methods: retriever
  Variables: docs main_meta retriever retriever.load_all_available_meta
  Usages: Document List WikipediaRetriever all_meta bool doc fixture get_relevant_documents issuperset lang langchain len load_all_available_meta metadata page_content pytest retrievers schema set top_k_results typing

Python: /tests/integration_tests/utilities/test_arxiv.py
  Functions: _load_arxiv_from_universal_entry assert_docs test_load_arxiv_from_universal_entry test_load_arxiv_from_universal_entry_with_params test_load_returns_full_set_of_metadata test_load_returns_limited_docs test_load_returns_no_result test_load_success test_run_returns_no_result test_run_returns_several_docs test_run_success
  Methods: api_client
  Variables: api_client arxiv_tool docs expected_docs output params tools
  Usages: Any ArxivAPIWrapper BaseTool Document List agents api_wrapper base doc fixture isinstance issuperset kwargs langchain len load load_all_available_meta load_max_docs load_tools metadata page_content print pytest run schema set top_k_results typing utilities

Python: /tests/integration_tests/utilities/test_duckduckdgo_search_api.py
  Functions: ddg_installed
  Methods: test_ddg_search_tool
  Variables: keywords result tool
  Usages: DuckDuckGoSearchRun Exception bool ddg ddg_search duckduckgo_search langchain len mark print pytest reason skipif split tools

Python: /tests/integration_tests/utilities/test_googlesearch_api.py
  Functions: test_call test_no_result_call
  Variables: output search
  Usages: GoogleSearchAPIWrapper google_search langchain print run type utilities

Python: /tests/integration_tests/utilities/test_googleserper_api.py
  Functions: test_news_call test_results test_search_call
  Methods: test_async_call test_async_results
  Variables: output search
  Usages: GoogleSerperAPIWrapper aresults arun asyncio google_serper langchain lower mark pytest results run type utilities

Python: /tests/integration_tests/utilities/test_jira_api.py
  Functions: test_create_ticket test_getprojects test_search
  Variables: issue_string jira jql output
  Usages: JiraAPIWrapper langchain run utilities

Python: /tests/integration_tests/utilities/test_openweathermap.py
  Functions: test_openweathermap_api_wrapper
  Variables: weather weather_data
  Usages: OpenWeatherMapAPIWrapper langchain openweathermap run utilities

Python: /tests/integration_tests/utilities/test_powerbi_api.py
  Functions: azure_installed
  Methods: test_daxquery
  Variables: DATASET_ID NUM_ROWS TABLE_NAME numrows output powerbi
  Usages: DefaultAzureCredential Exception PowerBIDataset TokenCredential azure bool core credential credentials dataset_id get_from_env identity langchain mark print pytest reason run skipif str table_names utilities utils

Python: /tests/integration_tests/utilities/test_pupmed.py
  Functions: _load_pubmed_from_universal_entry assert_docs test_load_pupmed_from_universal_entry test_load_pupmed_from_universal_entry_with_params test_load_returns_full_set_of_metadata test_load_returns_limited_docs test_load_returns_no_result test_load_success test_run_returns_no_result test_run_returns_several_docs test_run_success
  Methods: api_client
  Variables: api_client docs expected_docs output params pupmed_tool tools
  Usages: Any BaseTool Document List PubMedAPIWrapper agents api_wrapper base doc fixture isinstance issuperset kwargs langchain len load load_all_available_meta load_docs load_max_docs load_tools metadata page_content print pytest run schema set top_k_results typing utilities

Python: /tests/integration_tests/utilities/test_serpapi.py
  Functions: test_call
  Variables: chain output
  Usages: SerpAPIWrapper langchain run utilities

Python: /tests/integration_tests/utilities/test_twilio.py
  Functions: test_call
  Variables: output twilio
  Usages: TwilioAPIWrapper langchain run utilities

Python: /tests/integration_tests/utilities/test_wikipedia_api.py
  Functions: assert_docs test_load_no_result test_load_success test_load_success_all_meta test_run_no_result test_run_success
  Methods: api_client
  Variables: api_client.load_all_available_meta docs main_meta output
  Usages: Document List WikipediaAPIWrapper all_meta bool doc fixture issuperset langchain len load load_all_available_meta metadata page_content pytest run schema set typing utilities

Python: /tests/integration_tests/utilities/test_wolfram_alpha_api.py
  Functions: test_call
  Variables: output search
  Usages: WolframAlphaAPIWrapper langchain run utilities wolfram_alpha

Python: /tests/integration_tests/vectorstores/conftest.py
  Methods: before_record_request before_record_response documents embedding_openai texts vcr_config
  Variables: documents os.environ["BUGGER_OFF"] os.environ["DEEPLAKE_DOWNLOAD_PATH"] os.environ["DEEPLAKE_PYTEST_ENABLED"] skipped_host text_splitter
  Usages: CharacterTextSplitter Document Generator List OpenAIEmbeddings Request TextLoader Union __file__ chunk_overlap chunk_size dict dirname doc document_loaders embeddings endswith environ fixture host join langchain load page_content path pytest request response schema scope split_documents startswith str typing vcr

Python: /tests/integration_tests/vectorstores/fake_embeddings.py
  Classes: ConsistentFakeEmbeddings FakeEmbeddings
  Methods: __init__ embed_documents embed_query
  Variables: fake_texts out_vectors self.known_texts: vector
  Usages: Embeddings List append base embeddings float index known_texts langchain len range self str text texts typing

Python: /tests/integration_tests/vectorstores/test_analyticdb.py
  Functions: test_analyticdb test_analyticdb_collection_with_metadata test_analyticdb_with_filter_distant_match test_analyticdb_with_filter_match test_analyticdb_with_filter_no_match test_analyticdb_with_metadatas test_analyticdb_with_metadatas_with_scores
  Classes: FakeEmbeddingsWithAdaDimension
  Methods: embed_documents embed_query
  Variables: ADA_TOKEN_COUNT CONNECTION_STRING collection docsearch metadatas output pgvector session texts
  Usages: AnalyticDB Document FakeEmbeddings List Session analyticdb cmetadata collection_metadata collection_name connect connection_string connection_string_from_db_params database docstore document driver embedding embedding_function environ fake_embeddings filter float from_texts get get_collection host int integration_tests langchain len metadata name orm page_content password port pre_delete_collection print range self similarity_search similarity_search_with_score sqlalchemy str tests text typing user vectorstores

Python: /tests/integration_tests/vectorstores/test_annoy.py
  Functions: test_annoy test_annoy_add_texts test_annoy_local_save_load test_annoy_search_not_found test_annoy_vector_sim test_annoy_vector_sim_by_index test_annoy_with_metadatas
  Variables: docsearch docsearch.docstore expected_docstore index_to_id loaded_docsearch metadatas output query_vec temp_dir texts
  Usages: Annoy Document FakeEmbeddings InMemoryDocstore NotImplementedError TemporaryDirectory ValueError __dict__ add_texts annoy docstore document embed_query fake_embeddings from_texts in_memory index index_to_docstore_id integration_tests langchain len load_local max_marginal_relevance_search_by_vector metadata name page_content pytest raises range save_local similarity_search similarity_search_by_index similarity_search_by_vector tempfile tests text vectorstores

Python: /tests/integration_tests/vectorstores/test_atlas.py
  Functions: test_atlas test_atlas_with_metadatas
  Variables: ATLAS_TEST_API_KEY docsearch metadatas output texts
  Usages: AtlasDB FakeEmbeddings api_key embedding fake_embeddings from_texts integration_tests langchain len metadata name page_content range reset_project_if_exists similarity_search str tests time vectorstores

Python: /tests/integration_tests/vectorstores/test_awadb.py
  Functions: test_awadb test_awadb_add_texts test_awadb_with_metadatas test_awadb_with_metadatas_with_scores
  Variables: docsearch metadatas output texts
  Usages: AwaDB Document FakeEmbeddings add_texts docstore document embedding fake_embeddings from_texts integration_tests langchain len metadata page_content range similarity_search similarity_search_with_score str table_name tests vectorstores

Python: /tests/integration_tests/vectorstores/test_azuresearch.py
  Functions: from_text_similarity_search_test test_semantic_hybrid_search
  Methods: similarity_search_test
  Variables: embeddings: index_name: model: openai.api_base openai.api_key openai.api_type openai.api_version res vector_store: vector_store_address: vector_store_password:
  Usages: AzureSearch OpenAIEmbeddings add_texts api_base api_key api_type api_version azure_search_endpoint azure_search_key azuresearch chunk_size dotenv embed_query embedding embedding_function embeddings fixture from_texts getenv index_name langchain len load_dotenv model openai pytest query semantic_configuration_name semantic_hybrid_search similarity_search sleep str texts time vector_store vector_store_address vector_store_password vectorstores

Python: /tests/integration_tests/vectorstores/test_chroma.py
  Functions: test_chroma test_chroma_mmr test_chroma_mmr_by_vector test_chroma_search_filter test_chroma_search_filter_with_scores test_chroma_update_document test_chroma_with_include_parameter test_chroma_with_metadatas test_chroma_with_metadatas_with_scores test_chroma_with_persistence
  Methods: test_chroma_async
  Variables: chroma_persist_dir collection_name docsearch document_id embedded_query embedding embeddings initial_content metadatas new_embedding old_embedding original_doc output texts updated_content updated_doc
  Usages: Chroma ConsistentFakeEmbeddings Document FakeEmbeddings _collection asimilarity_search asyncio delete_collection docstore document documents embed_documents embed_query embedding_function fake_embeddings filter format from_documents from_texts get ids include index integration_tests langchain len mark max_marginal_relevance_search max_marginal_relevance_search_by_vector metadata page_content peek persist persist_directory pytest range similarity_search similarity_search_with_score str tests text update_document vectorstores

Python: /tests/integration_tests/vectorstores/test_clickhouse.py
  Functions: test_clickhouse test_clickhouse_search_filter test_clickhouse_with_metadatas test_clickhouse_with_metadatas_with_relevance_scores test_clickhouse_with_persistence
  Methods: test_clickhouse_async
  Variables: config config.table docsearch metadatas output texts
  Usages: Clickhouse ClickhouseSettings Document FakeEmbeddings asimilarity_search asyncio docstore document drop embedding fake_embeddings format from_texts integration_tests langchain len mark metadata metadata_column page_content pytest range similarity_search similarity_search_with_relevance_scores str table tests text vectorstores where_str

Python: /tests/integration_tests/vectorstores/test_deeplake.py
  Functions: test_deeplake test_deeplake_overwrite_flag test_deeplake_with_metadatas test_deeplakewith_persistence test_delete_by_path test_delete_dataset_by_filter test_delete_dataset_by_ids test_max_marginal_relevance_search test_similarity_search test_similarity_search_by_vector test_similarity_search_with_filter test_similarity_search_with_score
  Methods: deeplake_datastore distance_metric
  Variables: dataset_path docsearch embeddings metadatas output output, path texts
  Usages: DeepLake Document FakeEmbeddings FixtureRequest data deeplake delete delete_dataset docstore document embed_documents embedding embedding_function exists fake_embeddings fetch_k filter fixture force_delete_by_path from_texts ids integration_tests langchain len max_marginal_relevance_search max_marginal_relevance_search_by_vector metadata overwrite page_content param params persist pytest range request score similarity_search similarity_search_by_vector similarity_search_with_score str tests vectorstores

Python: /tests/integration_tests/vectorstores/test_elasticsearch.py
  Classes: TestElasticsearch
  Methods: elasticsearch_url setup_class test_custom_index_add_documents test_custom_index_add_documents_to_exists_store test_custom_index_from_documents test_default_index_from_documents test_similarity_search_with_metadata test_similarity_search_with_ssl_verify test_similarity_search_without_metadata
  Variables: docsearch elastic_vector_search index_name index_names metadatas output search_result ssl_verify texts url
  Usages: DEBUG Document ElasticVectorSearch Elasticsearch FakeEmbeddings Generator List OpenAIEmbeddings Union ValueError add_documents autouse basicConfig classmethod cls delete docstore document documents elasticsearch embedding embedding_openai embeddings fake_embeddings fixture from_documents from_texts get getenv hex hosts ignore_localhost index indices integration_tests keys langchain len level logging mark metadata page_content print pytest range scope self similarity_search str tests typing uuid uuid4 vcr vectorstores

Python: /tests/integration_tests/vectorstores/test_faiss.py
  Functions: test_faiss test_faiss_add_texts test_faiss_add_texts_not_supported test_faiss_invalid_normalize_fn test_faiss_local_save_load test_faiss_search_not_found test_faiss_similarity_search_with_relevance_scores test_faiss_vector_sim test_faiss_with_metadatas test_faiss_with_metadatas_and_filter test_missing_normalize_score_fn
  Variables: docsearch docsearch.docstore expected_docstore faiss_instance faiss_instance.relevance_score_fn index_to_id metadatas new_docsearch output output, outputs query_vec temp_timestamp texts
  Usages: Document FAISS FakeEmbeddings InMemoryDocstore TemporaryDirectory ValueError Warning Wikipedia __dict__ add_texts datetime docstore document embed_query faiss fake_embeddings filter from_texts in_memory index index_to_docstore_id integration_tests langchain len load_local match math max_marginal_relevance_search_by_vector metadata page_content pytest raises range relevance_score_fn save_local score similarity_search similarity_search_by_vector similarity_search_with_relevance_scores sqrt strftime suffix temp_folder tempfile tests text utcnow vectorstores warns wikipedia

Python: /tests/integration_tests/vectorstores/test_hologres.py
  Functions: test_hologres test_hologres_embeddings test_hologres_with_filter_distant_match test_hologres_with_filter_match test_hologres_with_filter_no_match test_hologres_with_metadatas test_hologres_with_metadatas_with_scores
  Classes: FakeEmbeddingsWithAdaDimension
  Methods: embed_documents embed_query
  Variables: ADA_TOKEN_COUNT CONNECTION_STRING docsearch metadatas output text_embedding_pairs text_embeddings texts
  Usages: Document FakeEmbeddings Hologres List connection_string connection_string_from_db_params database docstore document embedding environ fake_embeddings filter float from_embeddings from_texts get hologres host int integration_tests langchain len list metadata page_content password port pre_delete_table range self similarity_search similarity_search_with_score str table_name tests text typing user vectorstores zip

Python: /tests/integration_tests/vectorstores/test_lancedb.py
  Functions: test_lancedb test_lancedb_add_texts
  Variables: embeddings result result_texts store table texts vectors
  Usages: FakeEmbeddings LanceDB add_texts connect create_table data doc embed_documents enumerate fake_embeddings idx integration_tests lancedb langchain mode page_content similarity_search tests text vectorstores

Python: /tests/integration_tests/vectorstores/test_milvus.py
  Functions: _milvus_from_texts test_milvus test_milvus_add_extra test_milvus_max_marginal_relevance_search test_milvus_no_drop test_milvus_with_score
  Variables: docs docsearch metadatas output scores texts
  Usages: Document FakeEmbeddings List Milvus Optional add_texts bool connection_args dict docstore document drop drop_old fake_embeddings fake_texts fetch_k from_texts integration_tests langchain len max_marginal_relevance_search metadata page_content range similarity_search similarity_search_with_score tests typing vectorstores

Python: /tests/integration_tests/vectorstores/test_mongodb_atlas.py
  Classes: TestMongoDBAtlasVectorSearch
  Methods: setup setup_class teardown_class test_from_documents test_from_texts test_from_texts_with_metadatas test_from_texts_with_metadatas_and_pre_filter
  Variables: CONNECTION_STRING DB_NAME, INDEX_NAME NAMESPACE TEST_CLIENT collection documents metadatas output texts vectorstore
  Usages: COLLECTION_NAME DB_NAME Document Embeddings MongoClient MongoDBAtlasVectorSearch TYPE_CHECKING annotations autouse base classmethod cls count_documents delete_many docstore document embedding_openai embeddings environ fixture from_documents from_texts get index_name langchain metadata mongodb_atlas page_content pre_filter pymongo pytest self similarity_search sleep split time typing vectorstores

Python: /tests/integration_tests/vectorstores/test_myscale.py
  Functions: test_myscale test_myscale_search_filter test_myscale_with_metadatas test_myscale_with_metadatas_with_relevance_scores test_myscale_with_persistence
  Methods: test_myscale_async
  Variables: config config.table docsearch metadatas output texts
  Usages: Document FakeEmbeddings MyScale MyScaleSettings asimilarity_search asyncio docstore document drop embedding fake_embeddings format from_texts integration_tests langchain len mark metadata metadata_column page_content pytest range similarity_search similarity_search_with_relevance_scores str table tests text vectorstores where_str

Python: /tests/integration_tests/vectorstores/test_opensearch.py
  Functions: test_add_text test_add_text_painless_scripting test_add_text_script_scoring test_appx_search_with_boolean_filter test_appx_search_with_lucene_filter test_opensearch test_opensearch_embedding_size_zero test_opensearch_invalid_search_type test_opensearch_painless_scripting test_opensearch_script_scoring test_opensearch_with_custom_field_name test_opensearch_with_custom_field_name_appx_false test_opensearch_with_custom_field_name_appx_true test_opensearch_with_metadatas test_similarity_search_with_score
  Variables: DEFAULT_OPENSEARCH_URL boolean_filter_val docids docsearch lucene_filter_val metadatas output pre_filter_val text_input texts
  Usages: Document FakeEmbeddings OpenSearchVectorSearch PAINLESS_SCRIPTING_SEARCH RuntimeError SCRIPT_SCORING_SEARCH ValueError add_texts boolean_filter docstore document engine fake_embeddings from_texts integration_tests is_appx_search langchain len lucene_filter metadata opensearch_url opensearch_vector_search page_content pre_filter pytest raises range search_type similarity_search similarity_search_with_score space_type subquery_clause tests text_field vector_field vectorstores

Python: /tests/integration_tests/vectorstores/test_pgvector.py
  Functions: test_pgvector test_pgvector_collection_with_metadata test_pgvector_embeddings test_pgvector_with_filter_distant_match test_pgvector_with_filter_in_set test_pgvector_with_filter_match test_pgvector_with_filter_no_match test_pgvector_with_metadatas test_pgvector_with_metadatas_with_scores
  Classes: FakeEmbeddingsWithAdaDimension
  Methods: embed_documents embed_query
  Variables: ADA_TOKEN_COUNT CONNECTION_STRING collection docsearch metadatas output pgvector session text_embedding_pairs text_embeddings texts
  Usages: Document FakeEmbeddings List PGVector Session cmetadata collection_metadata collection_name connect connection_string connection_string_from_db_params database docstore document driver embedding embedding_function environ fake_embeddings filter float from_embeddings from_texts get get_collection host int integration_tests langchain len list metadata name orm page_content password port pre_delete_collection range self similarity_search similarity_search_with_score sqlalchemy str tests text typing user vectorstores zip

Python: /tests/integration_tests/vectorstores/test_pinecone.py
  Functions: reset_pinecone
  Classes: TestPinecone
  Methods: setup setup_class teardown_class test_add_documents_with_ids test_from_existing_index_with_namespaces test_from_texts test_from_texts_with_metadatas test_from_texts_with_scores
  Variables: cls.index dimension docs docsearch ids ids_1 index: index_name index_stats metadatas namespace_name needs output page_contents scores sorted_documents texts texts_1 texts_2 unique_id
  Usages: Document Index List OpenAIEmbeddings Pinecone _namespace_name all api_key autouse classmethod cls content create_index delete delete_all delete_index describe_index_stats docstore document embedding embedding_openai embeddings environ environment fixture from_existing_index from_texts get hex importlib index init insert key keys langchain len list_indexes mark metadata name namespace page_content pinecone pytest range reload self set similarity_search similarity_search_with_score sorted str typing uuid uuid4 vcr vectorstores

Python: /tests/integration_tests/vectorstores/test_qdrant.py
  Functions: test_qdrant_from_texts_stores_duplicated_texts test_qdrant_similarity_search_filters_with_qdrant_filters test_qdrant_similarity_search_with_relevance_score_no_threshold test_qdrant_similarity_search_with_relevance_score_with_threshold test_qdrant_similarity_search_with_relevance_score_with_threshold_and_filter test_qdrant_stores_duplicated_texts
  Methods: test_qdrant_add_documents test_qdrant_add_texts_returns_all_ids test_qdrant_add_texts_stores_ids test_qdrant_embedding_interface test_qdrant_embedding_interface_raises test_qdrant_from_texts_stores_ids test_qdrant_max_marginal_relevance_search test_qdrant_similarity_search test_qdrant_similarity_search_filters test_qdrant_with_metadatas
  Variables: client collection_name docsearch docsearch: ids kwargs metadatas negative_filter new_texts output positive_filter qdrant_filter returned_ids score_threshold stored_ids texts vec_store
  Usages: CONTENT_KEY COSINE Callable ConsistentFakeEmbeddings Distance Document Embeddings FieldCondition Filter METADATA_KEY MatchAny MatchValue Optional Qdrant QdrantClient TemporaryDirectory ValueError VectorParams add_documents add_texts all any base batch_size content content_payload_key count distance docstore document embed_query embedding_function embeddings fake_embeddings fetch_k filter first from_texts http int integration_tests key langchain len location mark match max_marginal_relevance_search metadata metadata_payload_key models must page_content parametrize path point pytest qdrant_client raises range recreate_collection rest round score scroll second set similarity_search similarity_search_with_relevance_scores size str tempfile tests tmpdir typing value vectors_config vectorstores zip

Python: /tests/integration_tests/vectorstores/test_redis.py
  Functions: drop test_cosine test_ip test_l2 test_redis test_redis_add_texts_to_existing test_redis_from_documents test_redis_from_existing test_redis_from_texts_return_keys test_redis_new_vector
  Methods: texts
  Variables: COSINE_SCORE EUCLIDEAN_SCORE IP_SCORE TEST_INDEX_NAME TEST_REDIS_URL TEST_RESULT TEST_SINGLE_RESULT TEST_SINGLE_WITH_METADATA_RESULT docs docsearch docsearch, docsearch2 output
  Usages: Document FakeEmbeddings List Redis abs add_texts approx bool delete_documents distance_metric docstore document drop_index fake_embeddings fixture from_documents from_existing_index from_texts from_texts_return_keys index_name integration_tests keys langchain len metadata page_content pytest redis redis_url score similarity_search similarity_search_with_score str tests typing vectorstores

Python: /tests/integration_tests/vectorstores/test_singlestoredb.py
  Functions: drop
  Classes: NormilizedFakeEmbeddings
  Methods: embed_documents embed_query normalize test_singlestoredb test_singlestoredb_add_texts_to_existing test_singlestoredb_from_documents test_singlestoredb_from_existing test_singlestoredb_new_vector texts
  Variables: TEST_RESULT TEST_SINGLESTOREDB_URL TEST_SINGLE_RESULT TEST_SINGLE_WITH_METADATA_RESULT docs docsearch docsearch2 output singlestoredb_installed table_name
  Usages: Document FakeEmbeddings ImportError List SingleStoreDB add_texts autocommit conn connect cursor docstore document execute fake_embeddings fixture float from_documents from_texts host integration_tests langchain linalg mark metadata norm numpy page_content pytest reason self similarity_search singlestoredb skipif str super tests text typing vector vectorstores

Python: /tests/integration_tests/vectorstores/test_tair.py
  Functions: test_tair
  Variables: docsearch output texts
  Usages: Document FakeEmbeddings Tair docstore document fake_embeddings from_texts integration_tests langchain page_content similarity_search tair tair_url tests vectorstores

Python: /tests/integration_tests/vectorstores/test_vectara.py
  Functions: get_abbr test_vectara_add_documents
  Variables: docsearch: first_letters new_texts output texts words
  Usages: Document FakeEmbeddings Vectara add_documents docsearch docstore document embedding fake_embeddings from_texts integration_tests join langchain metadata metadatas n_sentence_context page_content similarity_search split str tests vectara vectorstores word

Python: /tests/integration_tests/vectorstores/test_weaviate.py
  Classes: TestWeaviate
  Methods: setup_class test_add_texts_with_given_embedding test_add_texts_with_given_uuids test_max_marginal_relevance_search test_max_marginal_relevance_search_by_vector test_max_marginal_relevance_search_with_filter test_similarity_search_with_metadata test_similarity_search_with_metadata_and_additional test_similarity_search_with_metadata_and_filter test_similarity_search_with_uuids test_similarity_search_without_metadata weaviate_url
  Variables: client docsearch embedding foo_embedding metadatas output standard_ranking texts url uuids where_filter
  Usages: Client DEBUG Document FakeEmbeddings Generator NAMESPACE_DNS OpenAIEmbeddings Union ValueError Weaviate add_texts additional autouse basicConfig classmethod cls delete_all docstore document embed_query embedding_openai embeddings fake_embeddings fetch_k fixture from_texts getenv ignore_localhost integration_tests lambda_mult langchain len level logging mark max_marginal_relevance_search max_marginal_relevance_search_by_vector metadata openai page_content pytest range schema scope self similarity_search similarity_search_by_vector str tests text typing uuid uuid5 vcr vectorstores weaviate

Python: /tests/integration_tests/vectorstores/test_zilliz.py
  Functions: _zilliz_from_texts test_zilliz test_zilliz_add_extra test_zilliz_max_marginal_relevance_search test_zilliz_no_drop test_zilliz_with_score
  Variables: docs docsearch metadatas output scores texts
  Usages: Document FakeEmbeddings List Optional Zilliz add_texts bool connection_args dict docstore document drop drop_old fake_embeddings fake_texts fetch_k from_texts integration_tests langchain len max_marginal_relevance_search metadata page_content range similarity_search similarity_search_with_score tests typing vectorstores

Python: /tests/mock_servers/robot/server.py
  Functions: custom_openapi
  Classes: Cautiousness Direction PublicCues SecretPassPhrase StateItems Style WalkInput
  Methods: ask_for_help ask_for_passphrase get_state goto recycle walk
  Variables: PASS_PHRASE PORT _ROBOT_LOCATION _ROBOT_LOCATION["x"] _ROBOT_LOCATION["y"] _ROBOT_LOCATION["z"] _ROBOT_STATE _ROBOT_STATE["cautiousness"] _ROBOT_STATE["destruct"] _ROBOT_STATE["direction"] _ROBOT_STATE["speed"] _ROBOT_STATE["style"] _ROBOT_STATE["walking"] app app.openapi app.openapi_schema casual cautiousness cue: destruct direction direction: east energetic high jumping location low medium normal north openapi_schema openapi_schema["servers"] origins other_commands: other_cues: public: pw: response south speed speed: state state[field.value] style style_or_cautiousness: walking west
  Usages: Any BaseModel CORSMiddleware Dict Enum FastAPI Field HTTPException List Optional Query Union __name__ add_middleware alias allow_credentials allow_headers allow_methods allow_origins bool cors cue delete description detail enum fastapi field fields float get get_openapi host int isinstance middleware openapi other_commands other_cues password port post public pydantic query routes run said_please status_code str style_or_cautiousness title typing utils uuid uuid4 uvicorn value version walk_input

Python: /tests/unit_tests/agents/test_agent.py
  Functions: _get_agent test_agent_bad_action test_agent_lookup_tool test_agent_stopped_early test_agent_tool_return_direct test_agent_tool_return_direct_in_intermediate_steps test_agent_with_callbacks test_agent_with_new_prefix_suffix
  Classes: FakeListLLM
  Methods: _call _identifying_params _llm_type
  Variables: action, agent bad_action_name fake_llm handler1 handler2 output prefix prompt_str resp responses responses: suffix tool tools
  Usages: AgentExecutor AgentType Any CallbackManagerForLLMRun FakeCallbackHandler LLM List Mapping Optional Tool ZERO_SHOT_REACT_DESCRIPTION _action_intput action agent_kwargs agents base callbacks chain_ends chain_starts description ends endswith errors fake_callback_handler func hasattr initialize_agent int kwargs langchain len llm llm_chain llm_ends llm_starts llms lookup_tool manager max_execution_time max_iterations name print prompt property return_direct return_intermediate_steps run run_manager self starts startswith stop str template tests text tool_ends tool_starts typing unit_tests verbose

Python: /tests/unit_tests/agents/test_mrkl.py
  Functions: get_action_and_input test_bad_action_input_line test_bad_action_line test_from_chains test_get_action_and_input test_get_action_and_input_newline test_get_action_and_input_newline_after_keyword test_get_action_and_input_sql_query test_get_action_and_input_whitespace test_get_final_answer test_get_final_answer_multiline test_get_final_answer_new_line test_valid_action_and_answer_raises_exception
  Variables: action, agent chain_configs expected_template expected_tool_names expected_tools_prompt llm_output output prompt
  Usages: AgentAction FORMAT_INSTRUCTIONS FakeLLM MRKLOutputParser OutputParserException PREFIX PromptTemplate SUFFIX Tool Tuple ZeroShotAgent action action_input agents base description e_info fake_llm format from_llm_and_tools func isinstance join langchain llm_chain llms mrkl name observation output_parser parse prompts pytest raises return_values schema str template tests text tool tool_input tool_names tools typing unit_tests value

Python: /tests/unit_tests/agents/test_public_api.py
  Functions: test_public_api
  Variables: _EXPECTED
  Usages: __all__ agents agents_all langchain sorted

Python: /tests/unit_tests/agents/test_react.py
  Functions: test_predict_until_observation_normal test_react_chain test_react_chain_bad_action
  Classes: FakeDocstore FakeListLLM
  Methods: _call _identifying_params _llm_type search
  Variables: _FAKE_PROMPT _PAGE_CONTENT agent bad_action_name document expected_output fake_llm output outputs react_chain responses responses: tools
  Usages: AgentAction Any CallbackManagerForLLMRun Docstore Document LLM List Mapping Optional PromptTemplate ReActChain ReActDocstoreAgent Tool Union agents base callbacks description docstore from_llm_and_tools func input input_variables int kwargs langchain llm llms manager name page_content plan prompt prompts property react run run_manager schema self stop str template typing

Python: /tests/unit_tests/agents/test_serialization.py
  Functions: test_mrkl_serialization
  Variables: agent file
  Usages: AgentType FakeListLLM Path TemporaryDirectory ZERO_SHOT_REACT_DESCRIPTION agent_types agents fake initialize initialize_agent langchain llms load_agent pathlib responses save_agent tempdir tempfile verbose

Python: /tests/unit_tests/agents/test_sql.py
  Functions: test_create_sql_agent
  Variables: agent_executor llm queries toolkit
  Usages: FakeLLM SQLDatabase SQLDatabaseToolkit agent_toolkits agents create_sql_agent fake_llm from_uri langchain llms run sequential_responses sql_database tests unit_tests

Python: /tests/unit_tests/agents/test_tools.py
  Functions: test_load_tools_with_callback_manager_raises_deprecation_warning test_load_tools_with_callbacks_is_called test_tool_no_args_specified_assumes_str
  Methods: ambiguous_function test_single_input_agent_raises_error_on_structured_tool the_tool
  Variables: callback_manager callbacks expected_args result some_tool tools
  Usages: Agent Any ChatAgent ConversationalAgent ConversationalChatAgent DeprecationWarning FakeCallbackHandler MagicMock Mock ReActDocstoreAgent ReActTextWorldAgent SelfAskWithSearchAgent Tool Type ValueError ZeroShotAgent __name__ agent agent_cls agents args bar base chat conversational conversational_chat description fake_callback_handler foo from_llm_and_tools func kwargs langchain len load_tools mark match mock mrkl name parametrize patch pytest raises react return_value run self_ask_with_search str tests text tool tool_ends tool_starts typing unit_tests unittest warns

Python: /tests/unit_tests/agents/test_types.py
  Classes: TestTypes
  Methods: test_confirm_full_coverage
  Usages: AGENT_TO_CLASS AgentType TestCase agent_types agents assertEqual keys langchain list self types unittest

Python: /tests/unit_tests/callbacks/fake_callback_handler.py
  Classes: BaseFakeCallbackHandler BaseFakeCallbackHandlerMixin FakeAsyncCallbackHandler FakeCallbackHandler FakeCallbackHandlerWithChatStart
  Methods: __deepcopy__ ignore_agent ignore_chain ignore_llm on_agent_action on_agent_action_common on_agent_finish on_agent_finish_common on_chain_end on_chain_end_common on_chain_error on_chain_error_common on_chain_start on_chain_start_common on_chat_model_start on_chat_model_start_common on_llm_end on_llm_end_common on_llm_error on_llm_error_common on_llm_new_token on_llm_new_token_common on_llm_start on_llm_start_common on_text on_text_common on_tool_end on_tool_end_common on_tool_error on_tool_error_common on_tool_start on_tool_start_common
  Variables: agent_actions: agent_ends: chain_ends: chain_starts: chat_model_starts: ends: errors: ignore_agent_: ignore_chain_: ignore_chat_model_: ignore_llm_: llm_ends: llm_starts: llm_streams: starts: text: tool_ends: tool_starts:
  Usages: Any AsyncCallbackHandler BaseCallbackHandler BaseMessage BaseModel Dict List Optional UUID agent_actions agent_ends all args base bool callbacks chain chain_ends chain_starts chat_model_starts dict ends errors ignore_agent_ ignore_chain_ ignore_chat_model_ ignore_llm_ int isinstance itertools kwargs langchain llm_ends llm_starts llm_streams memo messages parent_run_id print property pydantic run_id schema self serialized starts str text tool_ends tool_starts typing uuid

Python: /tests/unit_tests/callbacks/test_callback_manager.py
  Functions: _check_num_calls _test_callback_manager _test_callback_manager_async test_callback_manager test_callback_manager_configure test_callback_manager_inheritance test_ignore_agent test_ignore_chain test_ignore_llm
  Methods: test_async_callback_manager test_async_callback_manager_sync_handler
  Variables: async_configured_manager async_local_callbacks callback_manager1 callback_manager2 child_manager child_manager2 configured_manager handler1 handler1, handler2 handler3 inheritable_callbacks: local_callbacks: manager run_manager run_manager_chain run_manager_tool
  Usages: AgentAction AgentFinish AsyncCallbackManager BaseCallbackHandler BaseFakeCallbackHandler CallbackManager Exception FakeAsyncCallbackHandler FakeCallbackHandler LLMResult List StdOutCallbackHandler Tuple add_handler asyncio base callbacks chain_ends chain_starts configure ends errors fake_callback_handler generations get_child handler handler4 handlers ignore_agent_ ignore_chain_ ignore_llm_ inherit inheritable_callbacks inheritable_handlers isinstance langchain len llm_ends llm_starts llm_streams local_callbacks log mark on_agent_action on_agent_finish on_chain_end on_chain_error on_chain_start on_llm_end on_llm_error on_llm_new_token on_llm_start on_text on_tool_end on_tool_error on_tool_start pytest return_values schema set_handlers starts stdout tests text tool tool_ends tool_input tool_starts typing unit_tests verbose

Python: /tests/unit_tests/callbacks/test_openai_info.py
  Functions: test_on_llm_end test_on_llm_end_custom_model test_on_llm_end_finetuned_model
  Methods: handler
  Variables: response
  Usages: BaseOpenAI LLMResult OpenAICallbackHandler __fields__ callbacks completion_tokens default fixture generations langchain llm_output llms on_llm_end openai prompt_tokens pytest schema successful_requests total_cost total_tokens

Python: /tests/unit_tests/chains/test_api.py
  Functions: test_api_question
  Classes: FakeRequestsChain
  Methods: fake_llm_api_chain get test_api_data
  Variables: TEST_API_DOCS TEST_API_RESPONSE TEST_API_SUMMARY TEST_QUESTION TEST_URL api_answer_chain api_docs api_request_chain api_response_prompt api_url_query_prompt fake_llm output output: queries question requests_wrapper
  Usages: APIChain API_RESPONSE_PROMPT API_URL_PROMPT Any FakeLLM LLMChain TextRequestsWrapper api api_response api_url base chains dict dumps fixture format json kwargs langchain llm llms prompt pytest requests run self str tests typing unit_tests url

Python: /tests/unit_tests/chains/test_base.py
  Functions: test_bad_inputs test_bad_outputs test_correct_call test_multiple_output_keys_error test_run_arg_with_memory test_run_args_and_kwargs_error test_run_info test_run_kwargs test_run_kwargs_error test_run_multiple_args_error test_run_single_arg test_run_with_callback test_single_input_correct test_single_input_error
  Classes: FakeChain FakeMemory
  Methods: _call clear input_keys load_memory_variables memory_variables output_keys save_context
  Variables: be_correct: chain handler output the_input_keys: the_output_keys:
  Usages: Any BaseMemory CallbackManagerForChainRun Chain Dict FakeCallbackHandler List Optional RUN_KEY ValueError bar base baz be_correct bool callbacks chains ends errors fake_callback_handler foo include_run_info inputs langchain manager memory outputs property pytest raises run run_manager schema self starts str tests the_input_keys the_output_keys typing unit_tests

Python: /tests/unit_tests/chains/test_combine_documents.py
  Functions: _fake_combine_docs_func _fake_docs_len_func test__collapse_docs_metadata test__collapse_docs_no_metadata test__collapse_docs_one_doc test__split_list_double_doc test__split_list_long_pair_doc test__split_list_long_single_doc test__split_list_single_doc test__split_list_works_correctly test_format_doc_missing_metadata test_format_doc_with_metadata
  Variables: doc doc_list docs expected_metadata expected_output expected_result metadata1 metadata2 output prompt
  Usages: Any Document List PromptTemplate ValueError _collapse_docs _split_list_of_docs base chains combine_documents docstore document format_document input_variables int join kwargs langchain len map_reduce metadata page_content pytest raises str template typing

Python: /tests/unit_tests/chains/test_constitutional_ai.py
  Functions: test_critique_parsing
  Variables: TEXT_ONE TEXT_THREE TEXT_TWO critique
  Usages: ConstitutionalChain _parse_critique base chains constitutional_ai langchain strip text

Python: /tests/unit_tests/chains/test_conversation.py
  Functions: test_conversation_chain_errors_bad_prompt test_conversation_chain_errors_bad_variable test_conversation_chain_works test_memory_ai_prefix test_memory_human_prefix
  Methods: test_clearing_conversation_memory test_conversation_memory
  Variables: bad_inputs bad_outputs chain good_inputs good_outputs llm memory prompt
  Usages: BaseMemory ConversationBufferMemory ConversationBufferWindowMemory ConversationChain ConversationSummaryMemory FakeLLM PromptTemplate ValueError ai_prefix base buffer buffer_window chains clear conversation fake_llm human_prefix input_key input_variables langchain llms load_memory_variables mark memory_key parametrize prompts pytest raises run save_context schema summary template tests unit_tests

Python: /tests/unit_tests/chains/test_graph_qa.py
  Functions: test_backticks test_no_backticks
  Variables: output query
  Usages: chains cypher extract_cypher graph_qa langchain

Python: /tests/unit_tests/chains/test_hyde.py
  Functions: test_hyde_from_llm test_hyde_from_llm_with_multiple_n
  Classes: FakeEmbeddings FakeLLM
  Methods: _agenerate _generate _llm_type embed_documents embed_query
  Variables: embedding
  Usages: Any AsyncCallbackManagerForLLMRun BaseLLM CallbackManagerForLLMRun Embeddings Generation HypotheticalDocumentEmbedder LLMResult List Optional PROMPT_MAP base callbacks chains embeddings float from_llm generations hyde int key kwargs langchain list llms manager numpy prompts property random range run_manager schema self stop str text texts typing uniform

Python: /tests/unit_tests/chains/test_llm.py
  Functions: test_missing_inputs test_predict_and_parse test_predict_method test_valid_call
  Classes: FakeOutputParser
  Methods: fake_llm_chain parse test_serialization
  Variables: chain file llm loaded_chain output prompt
  Usages: BaseOutputParser Dict FakeLLM LLMChain List PromptTemplate TemporaryDirectory Union ValueError bar chains fake_llm fixture foo input_variables langchain llms load_chain loading mock output_key output_parser patch predict predict_and_parse prompts pytest queries raises save schema self split str temp_dir tempfile template tests text typing unit_tests unittest

Python: /tests/unit_tests/chains/test_llm_bash.py
  Functions: test_get_code test_get_code_lines_mixed_blocks test_get_code_lines_simple_nested_ticks test_parsing_error
  Methods: output_parser test_simple_question
  Variables: _SAMPLE_CODE _SAMPLE_CODE_2_LINES code code_lines fake_llm fake_llm_bash_chain output prompt queries question text
  Usages: BashOutputParser FakeLLM LLMBashChain OutputParserException _PROMPT_TEMPLATE base chains fixture format from_llm input_key langchain llm_bash llms mark output_key parse platform pytest raises reason run schema skipif startswith strip sys tests unit_tests

Python: /tests/unit_tests/chains/test_llm_checker.py
  Functions: test_simple_question
  Methods: fake_llm_checker_chain
  Variables: fake_llm output queries question
  Usages: FakeLLM LLMCheckerChain _CHECK_ASSERTIONS_TEMPLATE _CREATE_DRAFT_ANSWER_TEMPLATE _LIST_ASSERTIONS_TEMPLATE _REVISED_ANSWER_TEMPLATE assertions base chains checked_assertions fixture format from_llm input_key langchain llm_checker llms output_key prompt pytest run statement tests unit_tests

Python: /tests/unit_tests/chains/test_llm_math.py
  Functions: test_complex_question test_error test_simple_question
  Methods: fake_llm_math_chain
  Variables: complex_question fake_llm output queries question
  Usages: FakeLLM LLMMathChain ValueError _PROMPT_TEMPLATE base chains fixture format from_llm input_key langchain llm_math llms output_key prompt pytest raises run tests unit_tests

Python: /tests/unit_tests/chains/test_llm_summarization_checker.py
  Functions: test_simple_text
  Methods: fake_llm_summarization_checker_chain
  Variables: fake_llm output queries question
  Usages: ARE_ALL_TRUE_PROMPT CHECK_ASSERTIONS_PROMPT CREATE_ASSERTIONS_PROMPT FakeLLM LLMSummarizationCheckerChain REVISED_SUMMARY_PROMPT assertions base chains checked_assertions fixture format from_llm input_key langchain llm_summarization_checker llms output_key pytest run summary tests unit_tests

Python: /tests/unit_tests/chains/test_memory.py
  Functions: test_simple_memory
  Methods: test_readonly_memory
  Variables: memory output read_only_memory
  Usages: BaseMemory ConversationBufferMemory ConversationBufferWindowMemory ConversationSummaryMemory FakeLLM ReadOnlySharedMemory SimpleMemory chains conversation fake_llm langchain llm llms load_memory_variables mark memories memory_key memory_variables parametrize pytest save_context schema tests unit_tests

Python: /tests/unit_tests/chains/test_natbot.py
  Functions: test_proper_inputs test_variable_key_naming
  Classes: FakeLLM
  Methods: _call _identifying_params _llm_type
  Variables: browser_content nat_bot_chain output url
  Usages: Any CallbackManagerForLLMRun LLM List Mapping NatBotChain Optional base callbacks chains execute from_llm input_browser_content_key input_url_key kwargs langchain len llms manager natbot objective output_key prompt property run_manager self stop str typing

Python: /tests/unit_tests/chains/test_sequential.py
  Functions: test_multi_input_errors test_multi_output_errors test_sequential_bad_outputs test_sequential_missing_inputs test_sequential_overlapping_inputs test_sequential_usage_memory test_sequential_usage_multiple_inputs test_sequential_usage_multiple_outputs test_sequential_usage_single_inputs test_sequential_valid_outputs test_simple_sequential_functionality
  Classes: FakeChain
  Methods: _call input_keys output_keys
  Variables: chain chain_1 chain_2 expected_output input_variables: memory output output_variables: outputs outputs[var] variables
  Usages: CallbackManagerForChainRun Chain Dict List Optional SequentialChain SimpleMemory SimpleSequentialChain ValueError base callbacks chains input_variables inputs join langchain manager memories output_variables property pytest raises return_only_outputs run_manager self sequential simple str typing var

Python: /tests/unit_tests/chains/test_transform.py
  Functions: dummy_transform test_tranform_chain test_transform_chain_bad_inputs
  Variables: expected_response input_dict outputs outputs["greeting"] response transform_chain
  Usages: Dict TransformChain ValueError chains input_variables inputs langchain output_variables pytest raises str transform typing

Python: /tests/unit_tests/chat_models/test_google_palm.py
  Functions: test_chat_google_raises_with_invalid_temperature test_chat_google_raises_with_invalid_top_k test_chat_google_raises_with_invalid_top_p test_messages_to_prompt_dict_raises_with_example_after_real test_messages_to_prompt_dict_raises_with_mismatched_examples test_messages_to_prompt_dict_raises_with_misordered_examples test_messages_to_prompt_dict_raises_with_misplaced_system_message test_messages_to_prompt_dict_with_valid_messages
  Variables: expected result
  Usages: AIMessage ChatGooglePalm ChatGooglePalmError HumanMessage SystemMessage ValueError _messages_to_prompt_dict chat_models content example google_api_key google_palm importorskip langchain pytest raises schema str temperature top_k top_p

Python: /tests/unit_tests/client/test_runner_utils.py
  Methods: mock_arun_chain mock_list_examples mock_read_dataset test__get_messages_invalid test__get_messages_valid test__get_prompts_invalid test__get_prompts_valid test_arun_on_dataset test_run_chat_model_all_formats test_run_llm_all_formats
  Variables: _CREATED_AT _EXAMPLE_MESSAGE _TENANT_ID _VALID_MESSAGES _VALID_PROMPTS chain client dataset examples expected llm num_repetitions results uuids
  Usages: Any BaseLanguageModel Chain Dataset Dict Example FakeChatModel FakeLLM InputFormatError LangChainPlusClient List MagicMock MonkeyPatch UUID Union _get_messages _get_prompts api_key api_url args arun_on_dataset asyncio base base_language chains concurrency_level created_at dataset_id dataset_name datetime description example fake_chat_model fake_llm inputs int kwargs langchain langchainplus_sdk llm_or_chain llm_or_chain_factory llms mark mock monkeypatch n_repetitions name new object outputs owner_id parametrize patch pytest raises range run_llm runner_utils schemas session_name str tenant_id tests tracer typing unit_tests unittest uuid uuid4 uuid_

File: /tests/unit_tests/data/prompt_file.txt

Python: /tests/unit_tests/docstore/test_arbitrary_fn.py
  Functions: test_document_found
  Variables: docstore dummy_dict output
  Usages: DocstoreFn Document arbitrary_fn isinstance langchain page_content schema search

Python: /tests/unit_tests/docstore/test_inmemory.py
  Functions: test_adding_document test_adding_document_already_exists test_document_found test_document_not_found
  Variables: _dict bar_output docstore foo_output new_dict output
  Usages: Document InMemoryDocstore ValueError add document in_memory isinstance langchain page_content pytest raises search

Python: /tests/unit_tests/document_loaders/test_base.py
  Functions: test_base_blob_parser
  Classes: MyParser
  Methods: lazy_parse
  Variables: docs parser
  Usages: BaseBlobParser Blob Document Iterator base blob blob_loaders data document_loaders isinstance langchain len page_content parse schema self typing

Python: /tests/unit_tests/document_loaders/test_bibtex.py
  Methods: test_load_file_pattern test_load_load_extra_metadata test_load_max_content_chars test_load_success
  Variables: BIBTEX_EXAMPLE_FILE doc docs loader
  Usages: BibtexLoader Path __file__ bibtex document_loaders file_path file_pattern langchain len load load_extra_metadata mark max_content_chars metadata page_content parent pathlib pytest requires set str

Python: /tests/unit_tests/document_loaders/test_bshtml.py
  Methods: test_bs_html_loader test_bs_html_loader_non_utf8
  Variables: EXAMPLES HERE content docs file_path loader metadata
  Usages: BSHTMLLoader Path UnicodeDecodeError __file__ bool document_loaders flags get_text_separator html_bs langchain len load mark open_encoding page_content parent pathlib platform pytest raises reason requires skipif startswith str sys utf8_mode

Python: /tests/unit_tests/document_loaders/test_confluence.py
  Classes: TestConfluenceLoader
  Methods: _get_mock_confluence_loader _get_mock_page _get_mock_page_restrictions mock_confluence test_confluence_loader_initialization test_confluence_loader_initialization_from_env test_confluence_loader_load_data_by_page_ids test_confluence_loader_load_data_by_space_id test_confluence_loader_load_data_invalid_args
  Variables: CONFLUENCE_URL MOCK_API_TOKEN MOCK_SPACE_KEY MOCK_USERNAME confluence_loader confluence_loader.confluence documents mock_confluence.get_all_pages_from_space.return_value mock_confluence.get_all_restrictions_for_content.side_effect mock_confluence.get_page_by_id.side_effect mock_page_ids
  Usages: ConfluenceLoader Dict Document MagicMock ValueError all api_key assert_called_once_with assert_called_with call_count cloud confluence cql dict doc docstore document document_loaders fixture get_all_pages_by_label get_all_pages_from_space get_all_restrictions_for_content get_page_by_id get_page_child_by_type isinstance langchain len load mark match max_pages mock page_content page_id page_ids password patch pytest raises requires return_value self side_effect space_key str typing unittest url username

Python: /tests/unit_tests/document_loaders/test_csv_loader.py
  Classes: TestCSVLoader
  Methods: _get_csv_file_path test_csv_loader_load_empty_file test_csv_loader_load_single_column_file test_csv_loader_load_single_row_file test_csv_loader_load_valid_data
  Variables: expected_docs expected_docs: file_path loader result
  Usages: CSVLoader Document Path __file__ csv_loader docstore document document_loaders file_name langchain list load metadata page_content parent pathlib resolve self str

Python: /tests/unit_tests/document_loaders/test_detect_encoding.py
  Methods: test_loader_detect_encoding test_loader_detect_encoding_timeout
  Variables: docs file_path files loader loader_detect_encoding path
  Usages: DirectoryLoader Path RuntimeError TextLoader TimeoutError UnicodeDecodeError __file__ detect_file_encodings document_loaders glob helpers langchain len list load loader_cls loader_kwargs mark open parent pathlib pytest raises reason requires skip str timeout tmpdir write

Python: /tests/unit_tests/document_loaders/test_directory.py
  Functions: test_raise_error_if_path_is_not_directory test_raise_error_if_path_not_exist
  Variables: loader
  Usages: DirectoryLoader FileNotFoundError ValueError __file__ document_loaders langchain load pytest raises str value

Python: /tests/unit_tests/document_loaders/test_evernote_loader.py
  Classes: TestEverNoteLoader
  Methods: example_notebook_path test_loademptynotebook_emptylistreturned test_loadnotebook_eachnotehasexpectedcontentwithleadingandtrailingremoved test_loadnotebook_eachnotehasexpectedmetadata test_loadnotebook_eachnoteisindividualdocument test_loadnotebookwithconflictingsourcemetadatatag_sourceoffilepreferred test_loadnotebookwithimage_notehasplaintextonlywithresourcesremoved test_loadnotewithemptycontent_emptydocumentcontent test_loadnotewithmissingcontenttag_emptylistreturned test_loadnotewithnometadata_documentreturnedwithsourceonly test_returnsingledocument_loadnotebook_eachnoteiscombinedinto1document test_returnsingledocument_loadnotebook_notecontentiscombinedinto1document
  Variables: content_note1 content_note2 current_dir documents loader metadata_note1 metadata_note2 note
  Usages: EverNoteLoader Path __file__ document_loaders isinstance join keys langchain len load mark metadata notebook_name page_content parent path pathlib pytest requires self staticmethod str struct_time time tm_mday tm_mon tm_year

Python: /tests/unit_tests/document_loaders/test_generic_loader.py
  Functions: test__init__ test_from_filesystem_classmethod test_from_filesystem_classmethod_with_glob test_from_filesystem_using_default_parser
  Classes: AsIsParser
  Methods: lazy_parse test_from_filesystem_classmethod_show_progress toy_dir
  Variables: docs loader other_dir some_dir
  Usages: BaseBlobParser Blob Document FileSystemBlobLoader Generator GenericLoader Iterator Path TemporaryDirectory as_string base blob blob_loaders document_loaders fixture from_filesystem generic glob hidden_file join langchain len load makedirs mark nested_file open page_content parser path pathlib pytest requires schema self show_progress str suffixes temp_dir tempfile test_html test_txt typing write

Python: /tests/unit_tests/document_loaders/test_github.py
  Functions: test_initialization test_invalid_initialization test_load test_parse_issue test_url
  Variables: document documents expected_document issue loader
  Usages: Document GitHubIssuesLoader MagicMock MockerFixture ValueError access_token assignee creator direction docstore document_loaders github headers invalid json label labels langchain links load mentioned metadata milestone mocker page_content parse_issue patch pytest pytest_mock raises repo return_value since sort state url

Python: /tests/unit_tests/document_loaders/test_json_loader.py
  Methods: test_load_invalid_test_content test_load_valid_bool_content test_load_valid_dict_content test_load_valid_numeric_content test_load_valid_string_content
  Variables: expected_docs file_path loader mock_csv_reader mock_csv_reader.return_value result
  Usages: Document JSONLoader MockerFixture ValueError docstore document document_loaders jq_schema json_loader langchain load mark metadata mock_open mocker page_content patch pytest pytest_mock raises requires return_value text_content

Python: /tests/unit_tests/document_loaders/test_psychic.py
  Classes: TestPsychicLoader
  Methods: _get_mock_document _get_mock_psychic_loader mock_connector_id mock_psychic test_psychic_loader_initialization test_psychic_loader_load_data
  Variables: MOCK_API_KEY MOCK_CONNECTION_ID MOCK_CONNECTOR_ID documents mock_psychic.get_documents.return_value psychic_loader psychic_loader.psychic
  Usages: Dict Document MagicMock PsychicLoader all api_key assert_called_once_with call_count connection_id connector_id doc docstore document document_loaders fixture get_documents isinstance langchain len load mark mock page_content patch psychic pytest requires return_value secret_key self str typing unittest uri

Python: /tests/unit_tests/document_loaders/test_readthedoc.py
  Methods: test_custom test_div_role_main test_empty test_main_id_main_content
  Variables: PARENT_DIR documents loader
  Usages: Path ReadTheDocsLoader __file__ custom_html_tag document_loaders langchain len load mark page_content parent pathlib pytest readthedocs requires

Python: /tests/unit_tests/document_loaders/test_telegram.py
  Functions: test_telegram_chat_file_loader
  Methods: test_telegram_channel_loader_parsing
  Variables: docs file_path loader
  Usages: Path TelegramChatApiLoader TelegramChatFileLoader __file__ document_loaders langchain len load mark metadata page_content parent pathlib print pytest requires str

Python: /tests/unit_tests/document_loaders/test_trello.py
  Functions: card_list_to_objects list_to_objects
  Classes: MockBoard TestTrelloLoader
  Methods: __init__ get_cards list_lists mock_trello_client test_complete_text_and_metadata test_empty_board test_partial_text_and_metadata
  Variables: TRELLO_CARDS_QA TRELLO_LISTS boards card["checklists"] card["labels"] cards_qa_objs documents list_objs mock_trello_client.return_value.list_boards.return_value self.cards self.id self.lists self.name soup texts trello_loader
  Usages: Any BeautifulSoup Optional TestCase TrelloLoader api_key assertEqual assertFalse assertTrue bs4 card card_filter cards collections dict dict_list document_loaders extra_metadata find_all fixture from_credentials get include_card_name include_checklist include_comments isinstance keys langchain len list list_boards lists load mark metadata mock name namedtuple page_content patch pytest requires return_value self str text token trello typing unittest usefixtures

Python: /tests/unit_tests/document_loaders/test_web_base.py
  Classes: TestWebBaseLoader
  Methods: test_respect_user_specified_user_agent
  Variables: header_template loader url user_specified_user_agent
  Usages: WebBaseLoader document_loaders headers langchain self session web_base

Python: /tests/unit_tests/document_loaders/test_youtube.py
  Methods: test_video_id_extraction
  Usages: YoutubeLoader document_loaders expected_video_id extract_video_id langchain mark parametrize pytest str youtube_url

File: /tests/unit_tests/examples/example-non-utf8.txt

File: /tests/unit_tests/examples/example-utf8.txt

Python: /tests/unit_tests/llms/fake_chat_model.py
  Classes: FakeChatModel
  Methods: _agenerate _call _identifying_params _llm_type
  Variables: generation message output_str
  Usages: AIMessage Any AsyncCallbackManagerForLLMRun BaseMessage CallbackManagerForLLMRun ChatGeneration ChatResult List Mapping Optional SimpleChatModel base callbacks chat_models content generations kwargs langchain manager messages property run_manager schema self stop str typing

Python: /tests/unit_tests/llms/fake_llm.py
  Classes: FakeLLM
  Methods: _call _get_next_response_in_sequence _identifying_params _llm_type check_queries_required
  Variables: queries queries: response response_index: self.response_index sequential_responses:
  Usages: Any CallbackManagerForLLMRun LLM List Mapping Optional ValueError always base bool callbacks cast cls get int keys kwargs langchain list llms manager prompt property pydantic response_index run_manager self sequential_responses stop str typing validator values

Python: /tests/unit_tests/llms/test_base.py
  Functions: test_caching test_custom_caching
  Classes: FulltextLLMCache
  Variables: Base __tablename__ cache_output engine expected_cache_output expected_generations expected_output idx langchain.llm_cache llm llm_string output params params["stop"] prompt response
  Usages: Column FakeLLM Generation ImportError InMemoryCache Integer LLMResult SQLAlchemyCache Sequence String cache create_engine declarative declarative_base dict ext fake_llm generate generations items langchain llm_cache llm_output llms lookup nullable orm primary_key schema sorted sqlalchemy str tests text unit_tests update

Python: /tests/unit_tests/llms/test_callbacks.py
  Functions: test_chat_model_with_v1_callbacks test_chat_model_with_v2_callbacks test_llm_with_callbacks
  Variables: handler llm output
  Usages: FakeCallbackHandler FakeCallbackHandlerWithChatStart FakeChatModel FakeLLM HumanMessage callbacks chat_model_starts content ends errors fake_callback_handler fake_chat_model fake_llm langchain llm_ends llm_starts llms schema starts tests unit_tests verbose

Python: /tests/unit_tests/llms/test_loading.py
  Methods: test_saving_loading_round_trip
  Variables: fake_llm loaded_llm
  Usages: FakeLLM Path file_path langchain llms load_llm loading mock patch pathlib save tests tmp_path unit_tests unittest

Python: /tests/unit_tests/llms/test_utils.py
  Functions: test_enforce_stop_tokens test_enforce_stop_tokens_none
  Variables: output text
  Usages: enforce_stop_tokens langchain llms utils

Python: /tests/unit_tests/load/test_dump.py
  Functions: test_person
  Classes: NotSerializable Person SpecialPerson
  Methods: lc_attributes lc_secrets lc_serializable test_serialize_llmchain test_serialize_llmchain_chat test_serialize_llmchain_with_non_serializable_arg test_serialize_openai_llm
  Variables: another_secret: another_visible: chain llm llm.temperature prompt secret: you_can_see_me:
  Usages: Any ChatOpenAI ChatPromptTemplate Dict HumanMessagePromptTemplate LLMChain LangChainTracer OpenAI PromptTemplate Serializable another_secret another_visible bool callbacks chains chat chat_models client dump dumps from_messages from_template langchain llms load mark model openai openai_api_key pretty prompts property pytest requires secret self serializable snapshot str temperature tracers typing you_can_see_me

Python: /tests/unit_tests/load/test_load.py
  Classes: NotSerializable
  Methods: test_load_llmchain test_load_llmchain_with_non_serializable_arg test_load_openai_llm
  Variables: chain chain2 chain_string llm llm2 llm_string prompt
  Usages: LLMChain NotImplementedError OpenAI PromptTemplate chains client dump dumps from_template isinstance langchain llms load loads mark model openai openai_api_key pretty prompts pytest raises requires secrets_map temperature

Python: /tests/unit_tests/memory/test_combined_memory.py
  Functions: test_basic_functionality test_repeated_memory_var
  Methods: example_memory
  Variables: combined_memory example_1 example_2 example_3
  Usages: CombinedMemory ConversationBufferMemory List ValueError clear fixture langchain load_memory_variables memories memory memory_key memory_variables pytest raises save_context typing

Python: /tests/unit_tests/output_parsers/test_base_output_parser.py
  Functions: non_abstract_subclasses test_all_subclasses_implement_unique_type
  Methods: test_subclass_implements_type
  Variables: _NON_ABSTRACT_PARSERS _PARSERS_TO_SKIP _to_skip dups subclasses types
  Usages: ABC BaseOutputParser List NotImplementedError Optional Set Type __name__ __subclasses__ _type abc append cls count extend fail getattr langchain mark parametrize pytest schema set subclass to_skip typing

Python: /tests/unit_tests/output_parsers/test_boolean_parser.py
  Functions: test_boolean_output_parser_parse
  Variables: parser result
  Usages: BooleanOutputParser ValueError boolean langchain output_parsers parse

Python: /tests/unit_tests/output_parsers/test_combining_parser.py
  Functions: test_combining_dict_result
  Variables: DEF_EXPECTED_RESULT DEF_README combining_parser parsers result_dict
  Usages: CombiningOutputParser RegexParser ResponseSchema StructuredOutputParser combining default_output_key description langchain name output_keys output_parsers parse regex response_schemas structured

Python: /tests/unit_tests/output_parsers/test_datetime_parser.py
  Functions: test_datetime_output_parser_parse
  Variables: date datestr parser parser.format result
  Usages: AssertionError DatetimeOutputParser datetime day format hour langchain minute month now output_parsers parse second sleep strftime time year

Python: /tests/unit_tests/output_parsers/test_enum_parser.py
  Functions: test_enum_output_parser_parse
  Classes: Colors
  Variables: BLUE GREEN RED parser result
  Usages: Enum EnumOutputParser OutputParserException enum langchain output_parsers parse schema

Python: /tests/unit_tests/output_parsers/test_json.py
  Methods: test_parse_json
  Variables: GOOD_JSON JSON_WITH_NEW_LINES JSON_WITH_NEW_LINES_EVERYWHERE JSON_WITH_NEW_LINES_INSIDE NO_TICKS NO_TICKS_WHITE_SPACE TEST_CASES TEXT_AFTER TEXT_BEFORE TEXT_BEFORE_AND_AFTER TICKS_WITH_NEW_LINES_EVERYWHERE parsed
  Usages: json json_string langchain mark output_parsers parametrize parse_json_markdown pytest str

Python: /tests/unit_tests/output_parsers/test_list_parser.py
  Functions: test_multiple_items test_single_item
  Variables: parser
  Usages: CommaSeparatedListOutputParser langchain list output_parsers parse

Python: /tests/unit_tests/output_parsers/test_pydantic_parser.py
  Functions: test_pydantic_output_parser test_pydantic_output_parser_fail
  Classes: Actions TestModel
  Variables: CREATE DEF_EXPECTED_RESULT DEF_RESULT DEF_RESULT_FAIL DELETE SEARCH TestModel.__test__ UPDATE action: action_input: additional_fields: for_new_lines: pydantic_parser: result
  Usages: BaseModel Enum Field Optional OutputParserException PydanticOutputParser __test__ action action_input additional_fields default description enum for_new_lines langchain output_parsers parse print pydantic pydantic_object pydantic_parser schema str typing

Python: /tests/unit_tests/output_parsers/test_regex_dict.py
  Functions: test_regex_dict_result
  Variables: DEF_EXPECTED_RESULT DEF_OUTPUT_KEY_TO_FORMAT DEF_README regex_dict_parser result_dict
  Usages: RegexDictParser langchain no_update_value output_key_to_format output_parsers parse print regex_dict

Python: /tests/unit_tests/output_parsers/test_structured_parser.py
  Functions: test_parse
  Variables: expected_result parser response_schemas result text
  Usages: OutputParserException ResponseSchema StructuredOutputParser description from_response_schemas langchain name output_parsers parse schema

Python: /tests/unit_tests/prompts/test_chat.py
  Functions: create_chat_prompt_template create_messages test_chat_prompt_template test_chat_prompt_template_from_messages test_chat_prompt_template_with_messages test_create_chat_prompt_template_from_template test_create_chat_prompt_template_from_template_partial test_message_prompt_template_from_template_file
  Variables: actual ai_message_prompt chat_message_prompt chat_prompt_template expected expected_prompt human_message_prompt messages output_prompt prompt prompt_template prompt_value prompt_value_messages string system_message_prompt
  Usages: AIMessagePromptTemplate BaseMessagePromptTemplate ChatMessagePromptTemplate ChatPromptTemplate ChatPromptValue HumanMessage HumanMessagePromptTemplate List Path PromptTemplate SystemMessagePromptTemplate __file__ bar chat content context foo format format_prompt from_messages from_template from_template_file input_variables isinstance langchain len parent partial_variables pathlib prompts role schema sorted template to_messages to_string typing

Python: /tests/unit_tests/prompts/test_few_shot.py
  Functions: test_few_shot_functionality test_partial test_partial_init_func test_partial_init_string test_prompt_extra_input_variables test_prompt_jinja2_extra_input_variables test_prompt_jinja2_functionality test_prompt_jinja2_missing_input_variables test_prompt_missing_input_variables test_suffix_only
  Methods: example_jinja2_prompt
  Variables: EXAMPLE_PROMPT example_template examples expected_output input_variables new_output new_prompt output prefix prompt suffix template
  Usages: Dict FewShotPromptTemplate List PromptTemplate Tuple ValueError bar content example_prompt example_separator few_shot fixture foo format langchain new_content partial partial_variables prompts pytest raises str template_format typing

Python: /tests/unit_tests/prompts/test_few_shot_with_templates.py
  Functions: test_prompttemplate_prefix_suffix
  Variables: EXAMPLE_PROMPT examples expected_output output prefix prompt suffix
  Usages: FewShotPromptWithTemplates PromptTemplate content example_prompt example_separator few_shot_with_templates format input_variables langchain new_content prompts template

Python: /tests/unit_tests/prompts/test_length_based_example_selector.py
  Functions: test_selector_add_example test_selector_trims_all_examples test_selector_trims_one_example test_selector_valid
  Methods: selector
  Variables: EXAMPLES long_question longest_question new_example output prompts selector short_question
  Usages: LengthBasedExampleSelector PromptTemplate add_example example_prompt example_selector examples fixture input_variables langchain length_based max_length prompt pytest select_examples template

Python: /tests/unit_tests/prompts/test_loading.py
  Functions: test_loading_few_shot_prompt_example_prompt test_loading_few_shot_prompt_from_json test_loading_few_shot_prompt_from_yaml test_loading_few_shot_prompt_when_examples_in_config test_loading_from_JSON test_loading_from_YAML test_loading_with_output_parser test_loading_with_template_as_file test_saving_loading_round_trip
  Methods: change_directory
  Variables: expected_prompt expected_template few_shot_prompt loaded_prompt origin prompt simple_prompt
  Usages: FewShotPromptTemplate Iterator Path PromptTemplate RegexParser absolute chdir contextlib contextmanager example_prompt examples few_shot file_path input_variables langchain load_prompt loading output_keys output_parser output_parsers pathlib prefix prompts regex save suffix template tmp_path typing

Python: /tests/unit_tests/prompts/test_pipeline_prompt.py
  Functions: test_get_input_variables test_multi_variable_pipeline test_partial_with_chat_prompts test_simple_pipeline
  Variables: output pipeline_prompt prompt_a prompt_b
  Usages: ChatPromptTemplate MessagesPlaceholder PipelinePromptTemplate PromptTemplate bar baz chat content final_prompt foo format format_prompt from_template input_variables langchain messages pipeline pipeline_prompts prompt prompts to_messages variable_name

Python: /tests/unit_tests/prompts/test_prompt.py
  Functions: test_partial test_partial_init_func test_partial_init_string test_prompt_extra_input_variables test_prompt_from_examples_valid test_prompt_from_file test_prompt_from_jinja2_template test_prompt_from_template test_prompt_invalid_template_format test_prompt_jinja2_extra_input_variables test_prompt_jinja2_missing_input_variables test_prompt_jinja2_wrong_input_variables test_prompt_missing_input_variables test_prompt_valid test_prompt_wrong_input_variables
  Variables: example_separator examples expected_prompt input_variables input_variables: new_prompt new_result prefix prompt prompt_from_examples prompt_from_template result suffix template template_file
  Usages: PromptTemplate ValueError foo format from_examples from_file from_template langchain list partial partial_variables prompts pytest raises template_format

Python: /tests/unit_tests/prompts/test_utils.py
  Functions: test_sorted_vals
  Variables: expected_response test_dict
  Usages: example_selector langchain prompts semantic_similarity sorted_values

Python: /tests/unit_tests/retrievers/test_tfidf.py
  Methods: test_from_documents test_from_texts test_from_texts_with_tfidf_params
  Variables: input_docs input_texts tfidf_retriever
  Usages: Document TFIDFRetriever docs documents from_documents from_texts langchain len mark page_content pytest requires retrievers schema shape texts tfidf tfidf_array tfidf_params toarray

Python: /tests/unit_tests/retrievers/test_time_weighted_retriever.py
  Functions: _get_example_memories test__get_hours_passed test_add_documents test_get_combined_score test_get_relevant_documents test_get_salient_docs
  Classes: MockVectorStore
  Methods: _similarity_search_with_relevance_scores aadd_texts add_texts from_documents from_texts similarity_search time_weighted_retriever
  Variables: added_documents combined_score current_time docs_and_scores document documents expected_hours_passed expected_score hours_passed metadatas query relevant_documents texts time1 time2 vector_salience vectorstore
  Usages: Any Document Embeddings Iterable List NotImplementedError Optional TimeWeightedVectorStoreRetriever Tuple Type VectorStore _get_combined_score _get_hours_passed add_documents approx base classmethod cls datetime decay_rate dict doc embedding embeddings fixture float get_relevant_documents get_salient_docs int isinstance kwargs langchain len list memory_stream metadata page_content pytest range retrievers schema self str typing vectorstores

Python: /tests/unit_tests/retrievers/test_zep.py
  Functions: _test_documents
  Methods: search_results test_zep_retriever_aget_relevant_documents test_zep_retriever_get_relevant_documents zep_retriever
  Variables: documents: mock_zep_client.asearch_memory.return_value mock_zep_client.search_memory.return_value mock_zep_client: search_result zep zep.zep_client
  Usages: Document List MemorySearchResult Message MockerFixture TYPE_CHECKING ZepClient ZepRetriever aget_relevant_documents annotations asearch_memory asyncio autospec copy deepcopy dist document documents enumerate fixture get get_relevant_documents langchain len mark message metadata mock_zep_client mocker page_content parse_obj patch pytest pytest_mock query requires result retrievers return_value schema search_memory session_id summary typing url zep_client zep_python

Python: /tests/unit_tests/tools/test_base.py
  Functions: test_args_kwargs_filtered test_base_tool_inheritance_base_schema test_create_tool_keyword_args test_create_tool_positional_args test_decorated_function_schema_equivalent test_decorator_with_specified_schema test_empty_args_decorator test_exception_handling_bool test_exception_handling_callable test_exception_handling_non_tool_exception test_exception_handling_str test_forward_ref_annotated_base_tool_accepted test_misannotated_base_tool_raises_error test_missing_docstring test_named_tool_decorator test_named_tool_decorator_return_direct test_structured_args test_structured_args_decorator_no_infer_schema test_structured_single_str_decorator_no_infer_schema test_structured_tool_from_function test_structured_tool_from_function_docstring test_structured_tool_lambda_multi_args_schema test_structured_tool_types_parsed test_subclass_annotated_base_tool_accepted test_tool_lambda_args_schema test_tool_partial_function_args_schema test_tool_with_kwargs test_unannotated_base_tool_raises_error test_unnamed_decorator test_unnamed_tool_decorator_return_direct
  Classes: SomeBaseModel SomeEnum _FakeExceptionTool _ForwardRefAnnotatedTool _MisAnnotatedTool _MockSchema _MockSimpleTool _MockStructuredTool _SingleArgToolWithKwargs _UnAnnotatedTool _VarArgToolWithKwargs
  Methods: _arun _run _test_func empty_tool_input foo func search_api structured_tool structured_tool_input test_async_exception_handling_bool test_async_exception_handling_callable test_async_exception_handling_non_tool_exception test_async_exception_handling_str test_create_async_tool tool_func unstructured_tool_input
  Variables: A B _tool actual arg1: arg2: arg3: args args_schema args_schema: description exception: expected expected_args expected_result foo: handling name prefix result simple_tool structured_api structured_tool test_tool tool tool2
  Usages: Any AssertionError AsyncCallbackManagerForToolRun BaseModel BaseTool CallbackManagerForToolRun Enum Exception NotImplementedError Optional SchemaAnnotationError StructuredTool Tool ToolException Type Union ValueError __doc__ agents arg1 arg2 arg3 arg_0 arg_1 arun asyncio bar base baz bool callbacks coroutine datetime dict dumps enum exception float from_function functools handle_tool_error infer_schema int is_single_input isinstance issubclass json kwargs langchain loads manager mark match opt_arg other_arg partial ping pydantic pytest query raises return_direct run run_manager schema self some_arg some_base_model some_enum str strip tool_input tools typing value

Python: /tests/unit_tests/tools/test_exported.py
  Functions: _get_tool_classes test_tool_names_unique
  Variables: _EXCLUDE duplicated_names names results tool_class tool_classes
  Usages: BaseTool List StructuredTool Type __all__ __fields__ append base bool count default getattr isinstance issubclass langchain name skip_tools_without_default_names sorted tool_class_name tool_cls tools tools_all type typing

Python: /tests/unit_tests/tools/test_json.py
  Functions: test_json_spec_from_file test_json_spec_keys test_json_spec_value test_json_spec_value_max_length
  Variables: path spec
  Usages: JsonSpec Path dict_ from_file json keys langchain max_value_length pathlib tmp_path tool tools value write_text

Python: /tests/unit_tests/tools/test_public_api.py
  Functions: test_public_api
  Variables: _EXPECTED
  Usages: __all__ langchain public_api sorted tools

Python: /tests/unit_tests/tools/test_signatures.py
  Functions: get_non_abstract_subclasses
  Methods: test_all_subclasses_accept_run_manager
  Variables: params pattern run_func subclasses to_skip
  Usages: BaseBrowserTool BaseTool GmailBaseTool List Type __name__ __subclasses__ _arun _run annotation append base bool cls compile default extend getattr gmail inspect langchain mark parameters parametrize playwright pytest search signature startswith str subclass tools typing

Python: /tests/unit_tests/tools/test_zapier.py
  Functions: test_custom_base_prompt test_custom_base_prompt_fail test_default_base_prompt
  Variables: base_prompt tool
  Usages: BASE_ZAPIER_TOOL_PROMPT ValueError ZapierNLARunAction ZapierNLAWrapper action_id api_wrapper description format keys langchain list params params_schema prompt pytest raises str tools utilities zapier zapier_description zapier_nla_api_key

Python: /tests/unit_tests/utilities/test_graphql.py
  Methods: test_run
  Variables: MOCK_RESPONSE TEST_ENDPOINT expected_result graphql_wrapper query result
  Usages: GraphQLAPIWrapper POST activate add custom_headers dumps graphql graphql_endpoint indent json langchain mark pytest requires responses run status utilities

Python: /tests/unit_tests/utilities/test_loading.py
  Functions: test_failed_request test_invalid_prefix test_invalid_suffix test_non_hub_path
  Methods: loader mocked_responses test_success
  Variables: body file_contents lc_path_prefix loader path ref result valid_suffixes
  Usages: DEFAULT_REF Iterable Mock Path RequestsMock URL_BASE ValueError assert_not_called autouse compile content_type dumps file_path fixture format get json langchain loading mark match mock parametrize parse pathlib pytest raises read_text responses rsps status str try_load_from_hub typing unittest urljoin urllib utilities

Python: /tests/unit_tests/vectorstores/test_sklearn.py
  Methods: test_sklearn test_sklearn_mmr test_sklearn_mmr_by_vector test_sklearn_with_metadatas test_sklearn_with_metadatas_with_scores test_sklearn_with_persistence
  Variables: doc, docsearch embedded_query embeddings metadatas output persist_path texts
  Usages: FakeEmbeddings Path SKLearnVectorStore doc embed_query fake_embeddings fetch_k from_texts integration_tests langchain len mark max_marginal_relevance_search max_marginal_relevance_search_by_vector metadata page_content pathlib persist pytest range requires score serializer similarity_search similarity_search_with_relevance_scores str tests tmpdir vectorstores

Python: /tests/unit_tests/vectorstores/test_utils.py
  Functions: test_maximal_marginal_relevance test_maximal_marginal_relevance_lambda_one test_maximal_marginal_relevance_lambda_zero test_maximal_marginal_relevance_query_dim
  Variables: actual embedding_list expected first query_embedding query_embedding_2d second
  Usages: array lambda_mult langchain maximal_marginal_relevance numpy random reshape size tolist utils vectorstores zeros

# Agent Types
## `zero-shot-react-description`
## `react-docstore`
## `self-ask-with-search`
### `conversational-react-description`

PythonNotebook: /docs/modules/agents/agents/custom_agent.ipynb
  Classes: FakeAgent
  Methods: aplan input_keys plan
  Variables: agent agent_executor search tools
  Usages: AgentAction AgentExecutor AgentFinish Any BaseSingleActionAgent List OpenAI SerpAPIWrapper Tool Tuple Union agents description from_agent_and_tools func intermediate_steps kwargs langchain log name property return_direct run schema self str tool tool_input typing verbose

PythonNotebook: /docs/modules/agents/agents/custom_agent_with_tool_retrieval.ipynb
  Functions: fake_func get_tools
  Classes: CustomOutputParser CustomPromptTemplate
  Methods: format parse
  Variables: ALL_TOOLS action action_input agent agent_executor docs fake_tools intermediate_steps kwargs["agent_scratchpad"] kwargs["tool_names"] kwargs["tools"] llm llm_chain match output_parser prompt regex retriever search search_tool template template: thoughts tool_names tools tools_getter: vector_store
  Usages: AgentAction AgentExecutor AgentFinish AgentOutputParser Callable DOTALL Document FAISS LLMChain LLMSingleActionAgent List OpenAI OpenAIEmbeddings SerpAPIWrapper StringPromptTemplate Tool Union ValueError agents allowed_tools as_retriever description embeddings enumerate from_agent_and_tools from_documents func get_relevant_documents group inp input_variables join kwargs langchain llm_output log metadata name observation page_content pop prompts query range return_values run schema self split stop str strip temperature tool tool_input tools_getter typing vectorstores verbose

PythonNotebook: /docs/modules/agents/agents/custom_llm_agent.ipynb
  Classes: CustomOutputParser CustomPromptTemplate
  Methods: format parse
  Variables: action action_input agent agent_executor intermediate_steps kwargs["agent_scratchpad"] kwargs["tool_names"] kwargs["tools"] llm llm_chain match memory output_parser prompt prompt_with_history regex search template template: template_with_history thoughts tool_names tools tools:
  Usages: AgentAction AgentExecutor AgentFinish AgentOutputParser ConversationBufferWindowMemory DOTALL LLMChain LLMSingleActionAgent List OpenAI SerpAPIWrapper StringPromptTemplate Tool Union ValueError agents allowed_tools description from_agent_and_tools func group input_variables join kwargs langchain llm_output log name observation pop prompts return_values run schema self split stop str strip temperature tool tool_input typing verbose

PythonNotebook: /docs/modules/agents/agents/custom_llm_chat_agent.ipynb
  Classes: CustomOutputParser CustomPromptTemplate
  Methods: format_messages parse
  Variables: OPENAI_API_KEY SERPAPI_API_KEY action action_input agent agent_executor formatted intermediate_steps kwargs["agent_scratchpad"] kwargs["tool_names"] kwargs["tools"] llm llm_chain match output_parser prompt regex search template template: thoughts tool_names tools tools:
  Usages: AgentAction AgentExecutor AgentFinish AgentOutputParser BaseChatPromptTemplate ChatOpenAI DOTALL HumanMessage LLMChain LLMSingleActionAgent List SerpAPIWrapper Tool Union ValueError agents allowed_tools chat_models content description format from_agent_and_tools func getpass google group input_variables install join kwargs langchain llm_output log name observation openai openai_api_key pop prompts results return_values run schema self serpapi_api_key split stop str strip temperature tool tool_input typing verbose

PythonNotebook: /docs/modules/agents/agents/custom_mrkl_agent.ipynb
  Variables: agent agent_executor llm_chain prefix prompt search suffix tool_names tools
  Usages: AgentExecutor LLMChain OpenAI SerpAPIWrapper Tool ZeroShotAgent agents allowed_tools create_prompt description from_agent_and_tools func input input_variables langchain language llm name print run temperature template tool verbose

PythonNotebook: /docs/modules/agents/agents/custom_multi_action_agent.ipynb
  Functions: random_word
  Classes: FakeAgent
  Methods: aplan input_keys plan
  Variables: agent agent_executor search tools
  Usages: AgentAction AgentExecutor AgentFinish Any BaseMultiActionAgent List OpenAI SerpAPIWrapper Tool Tuple Union agents description from_agent_and_tools func intermediate_steps kwargs langchain len log name print property query return_values run schema self str tool tool_input typing verbose

PythonNotebook: /docs/modules/agents/tools/custom_tools.ipynb
  Functions: _handle_error post_message search_tool1 search_tool2
  Classes: CalculatorInput CustomCalculatorTool CustomSearchTool SearchInput SearchSchema
  Methods: _arun _run post_message search_api
  Variables: agent args_schema: description engine: gl: hl: llm llm_math_chain name query: question: result search search_tool3 search_wrapper tool tools tools[0].name
  Usages: AgentType AsyncCallbackManagerForToolRun BaseModel BaseTool CallbackManagerForToolRun ChatOpenAI Field LLMMathChain NotImplementedError OpenAI Optional SerpAPIWrapper StructuredTool Tool ToolException Type ZERO_SHOT_REACT_DESCRIPTION agents append args args_schema body callbacks chat_models dict engine error from_function func handle_tool_error initialize_agent json langchain llms load_tools manager parameters params post pydantic query question requests return_direct run run_manager schema self status_code str temperature text typing url verbose

# Getting Started
## List of Tools

PythonNotebook: /docs/modules/agents/tools/human_approval.ipynb
  Functions: _approve _should_check
  Variables: agent callbacks llm msg resp tool tools
  Usages: AgentType HumanApprovalCallbackHandler OpenAI ShellTool ZERO_SHOT_REACT_DESCRIPTION _input agents approve bool dict get initialize_agent input langchain llms load_tools lower print run serialized_obj should_check str temperature

PythonNotebook: /docs/modules/agents/tools/multi_input_tool.ipynb
  Functions: multiplier parsing_multiplier
  Variables: agent_executor llm mrkl os.environ["LANGCHAIN_TRACING"] tool tools
  Usages: AgentType OpenAI STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION StructuredTool Tool ZERO_SHOT_REACT_DESCRIPTION agent agents description environ float from_function func initialize_agent int langchain llms name run split string temperature verbose

PythonNotebook: /docs/modules/agents/tools/tool_input_validation.ipynb
  Classes: ToolInputSchema
  Methods: validate_query
  Variables: _APPROVED_DOMAINS agent answer domain llm tool url url:
  Usages: AgentType Any BaseModel Dict Field OpenAI RequestsGetTool TextRequestsWrapper ValueError ZERO_SHOT_REACT_DESCRIPTION agents args_schema cls dev extract initialize_agent install langchain llms null print pydantic requests requests_wrapper root_validator run sorted str temperature tldextract tools typing values verbose

PythonNotebook: /docs/modules/callbacks/examples/argilla.ipynb
  Variables: agent argilla_callback callbacks dataset llm os.environ["ARGILLA_API_KEY"] os.environ["ARGILLA_API_URL"] os.environ["OPENAI_API_KEY"] prompt_template synopsis_chain template test_prompts tools
  Usages: AgentType ArgillaCallbackHandler FeedbackDataset LLMChain OpenAI PromptTemplate RatingQuestion RuntimeError StdOutCallbackHandler TextField TextQuestion ZERO_SHOT_REACT_DESCRIPTION __version__ agents api_key api_url apply argilla chains dataset_name description environ fields generate guidelines init initialize_agent input_variables install langchain llms load_tools name openai packaging parse parse_version prompt prompts push_to_argilla questions required run temperature upgrade values version

PythonNotebook: /docs/modules/chains/examples/api.ipynb
  Variables: chain chain_new headers listen_api_key llm os.environ['TMDB_BEARER_TOKEN']
  Usages: APIChain API_RESPONSE_PROMPT OPEN_METEO_DOCS OpenAI PODCAST_DOCS PromptTemplate TMDB_DOCS api chains environ from_llm_and_api_docs langchain llms open_meteo_docs podcast_docs prompt prompts run temperature tmdb_docs verbose

PythonNotebook: /docs/modules/chains/examples/constitutional_chain.ipynb
  Variables: constitutional_chain ethical_principle evil_qa_chain evil_qa_prompt good_qa_chain good_qa_prompt llm master_yoda_principle principles qa_chain qa_prompt query
  Usages: ConstitutionalChain ConstitutionalPrinciple LLMChain OpenAI PRINCIPLES PromptTemplate base chain chains constitutional_ai constitutional_principles critique_request from_llm get_principles input_variables langchain llms models name prompt prompts question return_intermediate_steps revision_request run temperature template verbose

PythonNotebook: /docs/modules/chains/examples/flare.ipynb
  Classes: SerperSearchRetriever
  Methods: __init__ aget_relevant_documents get_relevant_documents
  Variables: flare langchain.verbose llm os.environ["SERPER_API_KEY"] query retriever self.search
  Usages: BaseRetriever ChatOpenAI Document FlareChain GoogleSerperAPIWrapper NotImplemented OpenAI OpenAIEmbeddings chains chat_models embeddings environ from_llm langchain llms max_generation_len min_prob numpy page_content run schema search self str temperature utilities verbose

PythonNotebook: /docs/modules/chains/examples/graph_cypher_qa.ipynb
  Variables: chain graph result
  Usages: ChatOpenAI GraphCypherQAChain Neo4jGraph chains chat_models from_llm get_schema graphs langchain password print query refresh_schema return_direct return_intermediate_steps run temperature top_k url username verbose

PythonNotebook: /docs/modules/chains/examples/graph_nebula_qa.ipynb
  Variables: chain graph
  Usages: CREATE ChatOpenAI EDGE EXISTS IF INDEX INSERT NOT NebulaGraph NebulaGraphQAChain ON SPACE TAG USE VALUES VERTEX acted_in address birthdate chains chat_models fixed_string from_llm get_schema graphs install ipython langchain load_ext movie movie_index name nebula ngql partition_num password person person_index pip port print replica_factor root run session_pool_size space string temperature user username verbose vid_type

PythonNotebook: /docs/modules/chains/examples/llm_bash.ipynb
  Variables: PROMPT _PROMPT_TEMPLATE bash_chain llm persistent_process text
  Usages: BashOutputParser BashProcess LLMBashChain OpenAI PromptTemplate bash bash_process chains from_llm input_variables langchain llm_bash llms output_parser persistent prompt prompts run temperature template utilities verbose

PythonNotebook: /docs/modules/chains/examples/llm_checker.ipynb
  Variables: checker_chain llm text
  Usages: LLMCheckerChain OpenAI chains from_llm langchain llms run temperature verbose

PythonNotebook: /docs/modules/chains/examples/llm_math.ipynb
  Variables: llm llm_math
  Usages: LLMMathChain OpenAI from_llm langchain run temperature verbose

PythonNotebook: /docs/modules/chains/examples/llm_requests.ipynb
  Variables: PROMPT chain inputs question template
  Usages: LLMChain LLMRequestsChain OpenAI PromptTemplate chains input_variables langchain llm llm_chain llms prompt prompts replace temperature

PythonNotebook: /docs/modules/chains/examples/llm_summarization_checker.ipynb
  Variables: checker_chain llm text
  Usages: LLMSummarizationCheckerChain OpenAI chains from_llm langchain llms max_checks run temperature verbose

PythonNotebook: /docs/modules/chains/examples/moderation.ipynb
  Classes: CustomModeration
  Methods: _moderate
  Variables: chain custom_moderation error_str inputs llm_chain moderation_chain moderation_chain.input_key moderation_chain.output_key moderation_chain_error new_input prompt setup text
  Usages: LLMChain OpenAI OpenAIModerationChain PromptTemplate SequentialChain SimpleSequentialChain chains dict error input_key input_variables langchain llm llms model_name output_key prompts results return_only_outputs run self str temperature template

PythonNotebook: /docs/modules/chains/examples/multi_prompt_router.ipynb
  Variables: chain math_template physics_template prompt_infos
  Usages: MultiPromptChain OpenAI chains from_prompts langchain llms print router run verbose

PythonNotebook: /docs/modules/chains/examples/multi_retrieval_qa_router.ipynb
  Variables: chain personal_retriever personal_texts pg_docs pg_retriever retriever_infos sou_docs sou_retriever
  Usages: FAISS MultiRetrievalQAChain OpenAI OpenAIEmbeddings TextLoader as_retriever chains document_loaders embeddings from_documents from_retrievers from_texts langchain llms load_and_split print router run vectorstores verbose

File: /docs/modules/chains/examples/openai_openapi.yaml

PythonNotebook: /docs/modules/chains/examples/openapi.ipynb
  Variables: chain llm operation output spec
  Usages: APIOperation OpenAI OpenAPIEndpointChain OpenAPISpec Requests chains from_api_operation from_openapi_spec from_url langchain llms raw_response requests return_intermediate_steps tools verbose

PythonNotebook: /docs/modules/chains/examples/pal.ipynb
  Variables: llm pal_chain question result
  Usages: OpenAI PALChain chains from_colored_object_prompt from_math_prompt langchain max_tokens return_intermediate_steps run temperature verbose

PythonNotebook: /docs/modules/chains/examples/sqlite.ipynb
  Functions: _parse_example
  Variables: PROMPT QUERY YAML_EXAMPLES _DEFAULT_TEMPLATE _example _example[answer_key] _example[sql_cmd_key] _example[table_info_key] answer_key chain custom_table_info db_chain device_id example example: example_prompt example_selector examples_dict few_shot_prompt final_answer_key input_key llm local_chain local_embeddings local_llm model model_id pipe result sql_cmd_key sql_result_key steps table_info_key tokenizer yaml_example
  Usages: AutoModelForCausalLM AutoModelForSeq2SeqLM AutoTokenizer Chroma Dict Exception FewShotPromptTemplate GPT2TokenizerFast HuggingFaceEmbeddings HuggingFacePipeline OpenAI PROMPT_SUFFIX PromptTemplate RuntimeError SQLDatabase SQLDatabaseChain SQLDatabaseSequentialChain SemanticSimilarityExampleSelector _sqlite_prompt allow_unicode any chains chromadb cuda device dict dump embeddings endswith exc from_examples from_llm from_pretrained from_uri get half huggingface include_tables input_variables install intermediate_steps is_available isinstance langchain len logging max_length min model_name oetry pip pipeline prefix print prompt prompts pyyaml return_intermediate_steps run safe_load sample_rows_in_table_info semantic_similarity sql_database step str suffix table_info task temperature template top_k torch transformers typing use_query_checker vectorstores verbose warn yaml

PythonNotebook: /docs/modules/chains/generic/async_chain.ipynb
  Functions: async_generate generate_concurrently generate_serially
  Variables: chain elapsed llm prompt resp tasks
  Usages: LLMChain OpenAI PromptTemplate arun asyncio chains gather input_variables langchain llms perf_counter print product prompts range run temperature template time

PythonNotebook: /docs/modules/chains/generic/custom_chain.ipynb
  Classes: Config MyCustomChain
  Methods: _acall _call _chain_type input_keys output_keys
  Variables: arbitrary_types_allowed chain extra llm: output_key: prompt: prompt_value response
  Usages: Any AsyncCallbackManagerForChainRun BaseLanguageModel BasePromptTemplate CallbackManagerForChainRun Chain ChatOpenAI Dict Extra List Optional PromptTemplate StdOutCallbackHandler agenerate_prompt annotations base base_language callbacks chains chat_models forbid format_prompt from_template generate_prompt generations get_child input_variables inputs langchain llm manager on_text openai output_key prompt prompts property pydantic run run_manager self stdout str text typing

PythonNotebook: /docs/modules/chains/generic/from_hub.ipynb
  Variables: chain documents embeddings loader query text_splitter texts vectorstore
  Usages: CharacterTextSplitter Chroma OpenAI OpenAIEmbeddings TextLoader VectorDBQA chains chunk_overlap chunk_size document_loaders from_documents langchain load load_chain openai run split_documents vectorstores

File: /docs/modules/chains/generic/llm.json

PythonNotebook: /docs/modules/chains/generic/llm_chain.ipynb
  Variables: input_list llm llm_chain output_parser prompt prompt_template template
  Usages: CommaSeparatedListOutputParser LLMChain OpenAI PromptTemplate adjective apply from_string from_template generate input_variables langchain output_parsers predict predict_and_parse product subject temperature

File: /docs/modules/chains/generic/llm_chain.json

File: /docs/modules/chains/generic/llm_chain_separate.json

File: /docs/modules/chains/generic/prompt.json

PythonNotebook: /docs/modules/chains/generic/router.ipynb
  Variables: chain default_chain destination_chains destination_chains[name] destinations destinations_str llm math_template name names_and_descriptions physics_template prompt prompt_infos prompt_template router_chain router_prompt router_template
  Usages: Chroma CohereEmbeddings ConversationChain EmbeddingRouterChain LLMChain LLMRouterChain MULTI_PROMPT_ROUTER_TEMPLATE MultiPromptChain OpenAI PromptTemplate RouterOutputParser chains embedding_router embeddings format from_llm from_names_and_descriptions input_variables join langchain llm_router llms multi_prompt_prompt output_key output_parser p_info print prompts router routing_keys run template vectorstores verbose

PythonNotebook: /docs/modules/chains/generic/sequential_chains.ipynb
  Variables: llm overall_chain prompt_template review review_chain social_chain synopsis_chain template
  Usages: LLMChain OpenAI PromptTemplate SequentialChain SimpleMemory SimpleSequentialChain chains input_variables langchain llms memories memory output_key output_variables print prompt prompts run temperature verbose

PythonNotebook: /docs/modules/chains/generic/serialization.ipynb
  Variables: chain config llm_chain prompt template
  Usages: LLMChain OpenAI PromptTemplate chains dump indent input_variables json langchain llm llm_chain_separate load_chain open run save temperature verbose

PythonNotebook: /docs/modules/chains/generic/transformation.ipynb
  Functions: transform_func
  Variables: llm_chain prompt sequential_chain shortened_text state_of_the_union template text transform_chain
  Usages: LLMChain OpenAI PromptTemplate SimpleSequentialChain TransformChain chains dict input_variables inputs join langchain llm llms open output_variables prompts read run split transform

PythonNotebook: /docs/modules/chains/index_examples/analyze_document.ipynb
  Variables: llm qa_chain qa_document_chain state_of_the_union summarize_document_chain summary_chain
  Usages: AnalyzeDocumentChain OpenAI chain_type chains combine_docs_chain input_document langchain load_qa_chain load_summarize_chain open question question_answering read run summarize temperature

PythonNotebook: /docs/modules/chains/index_examples/chat_vector_db.ipynb
  Functions: get_chat_history
  Variables: chain chat_history doc_chain documents embeddings llm loader memory query question_generator res result streaming_llm text_splitter vectordbkwargs vectorstore
  Usages: CONDENSE_QUESTION_PROMPT CharacterTextSplitter ChatOpenAI Chroma ConversationBufferMemory ConversationalRetrievalChain LLMChain OpenAI OpenAIEmbeddings QA_PROMPT StreamingStdOutCallbackHandler TextLoader append as_retriever callbacks chain_type chains chat_models chunk_overlap chunk_size combine_docs_chain condense_question_llm conversational_retrieval document_loaders from_documents from_llm human inputs join langchain llms load load_qa_chain load_qa_with_sources_chain memory_key model openai prompt prompts qa_with_sources question_answering retriever return_messages return_source_documents split_documents str streaming streaming_stdout temperature vectorstores

PythonNotebook: /docs/modules/chains/index_examples/graph_qa.ipynb
  Variables: all_text chain graph index_creator loaded_graph text
  Usages: GraphIndexCreator GraphQAChain NetworkxEntityGraph OpenAI TextLoader chains document_loaders from_gml from_llm from_text get_triples indexes join langchain llm llms open read run split temperature verbose write_to_gml

PythonNotebook: /docs/modules/chains/index_examples/hyde.ipynb
  Variables: base_embeddings docs docsearch embeddings llm llm_chain multi_llm prompt prompt_template query result state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter Chroma HypotheticalDocumentEmbedder LLMChain OpenAI OpenAIEmbeddings PromptTemplate best_of chains chunk_overlap chunk_size embed_query from_llm from_texts input_variables langchain llms open page_content print prompts read similarity_search split_text template vectorstores

PythonNotebook: /docs/modules/chains/index_examples/qa_with_sources.ipynb
  Variables: COMBINE_PROMPT PROMPT QUESTION_PROMPT chain combine_prompt_template docs docsearch embeddings output_parser prompt_template query question_prompt question_prompt_template question_template refine_prompt refine_template result state_of_the_union template text_splitter texts
  Usages: CharacterTextSplitter Chroma CohereEmbeddings Document ElasticVectorSearch OpenAI OpenAIEmbeddings PromptTemplate RegexParser chain_type chains chunk_overlap chunk_size cohere combine_prompt docstore document elastic_vector_search from_texts input_variables langchain len llms load_qa_with_sources_chain metadata_keys metadatas open openai output_keys output_parsers prompt prompts qa_with_sources range read regex return_intermediate_steps return_only_outputs similarity_search split_text str temperature vectorstores

PythonNotebook: /docs/modules/chains/index_examples/question_answering.ipynb
  Variables: COMBINE_PROMPT PROMPT QUESTION_PROMPT chain combine_prompt_template docs docsearch embeddings initial_qa_prompt initial_qa_template output_parser prompt_template query question_prompt_template refine_prompt refine_prompt_template results state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter Chroma Document OpenAI OpenAIEmbeddings PromptTemplate RegexParser VectorstoreIndexCreator as_retriever chain_type chains chunk_overlap chunk_size combine_prompt docstore document from_texts get_relevant_documents indexes input_documents input_variables langchain len llms load_qa_chain metadatas open openai output_keys output_parsers prompt prompts question question_answering question_prompt range read regex return_intermediate_steps return_map_steps return_only_outputs return_refine_steps run split_text str temperature template vectorstore vectorstores

PythonNotebook: /docs/modules/chains/index_examples/summarize.ipynb
  Variables: MAP_PROMPT PROMPT REDUCE_PROMPT chain code combine_documents docs generative_result_reduce_chain llm map_llm_chain map_reduce map_template_string prompt_template reduce_llm_chain reduce_template_string refine_prompt refine_template state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter Document LLMChain MapReduceChain MapReduceDocumentsChain OpenAI PromptTemplate StuffDocumentsChain chain_type chains chunk_overlap chunk_size combine_document_chain combine_documents_chain combine_prompt docstore document document_variable_name input_text input_variables langchain llm_chain load_summarize_chain map_prompt mapreduce open page_content prompt prompts question question_prompt read return_intermediate_steps return_only_outputs run separator split_text stuff summarize temperature template

PythonNotebook: /docs/modules/chains/index_examples/vector_db_qa.ipynb
  Variables: PROMPT chain_type_kwargs docsearch documents embeddings loader prompt_template qa_chain query result text_splitter texts
  Usages: CharacterTextSplitter Chroma OpenAI OpenAIEmbeddings PromptTemplate RetrievalQA TextLoader as_retriever chain_type chains chunk_overlap chunk_size combine_documents_chain document_loaders from_chain_type from_documents input_variables langchain llm llms load load_qa_chain openai prompts question_answering retriever return_source_documents run split_documents temperature template vectorstores

PythonNotebook: /docs/modules/chains/index_examples/vector_db_qa_with_sources.ipynb
  Variables: chain docsearch embeddings qa_chain state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter Chroma CohereEmbeddings ElasticVectorSearch OpenAI OpenAIEmbeddings RetrievalQAWithSourcesChain as_retriever chain_type chains chunk_overlap chunk_size cohere combine_documents_chain elastic_vector_search from_chain_type from_texts langchain len load_qa_with_sources_chain metadatas open openai qa_with_sources range read retriever return_only_outputs split_text temperature vectorstores

PythonNotebook: /docs/modules/chains/index_examples/vector_db_text_generation.ipynb
  Functions: generate_blog_post get_github_docs
  Variables: PROMPT chain docs git_sha github_url inputs llm markdown_files prompt_template relative_path repo_path search_index source_chunks sources splitter
  Usages: CharacterTextSplitter Chroma Document LLMChain OpenAI OpenAIEmbeddings Path PromptTemplate TemporaryDirectory append apply chains check_call check_output chunk chunk_overlap chunk_size cwd decode doc docstore document embeddings from_documents glob input_variables langchain list llms markdown_file metadata open openai page_content pathlib print prompt prompts read relative_to repo_name repo_owner requests separator shell similarity_search source split_text strip subprocess temperature tempfile template text_splitter topic vectorstores

PythonNotebook: /docs/modules/indexes/text_splitters/getting_started.ipynb
  Variables: state_of_the_union text_splitter texts
  Usages: RecursiveCharacterTextSplitter add_start_index chunk_overlap chunk_size create_documents langchain len length_function open print read

PythonNotebook: /docs/modules/indexes/vectorstores/getting_started.ipynb
  Variables: docs docsearch documents embeddings query state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter Chroma OpenAIEmbeddings add_texts chunk_overlap chunk_size create_documents from_documents from_texts langchain metadatas open openai page_content print read similarity_search split_text vectorstores

PythonNotebook: /docs/modules/memory/examples/adding_memory.ipynb
  Variables: llm_chain memory prompt template
  Usages: ConversationBufferMemory LLMChain OpenAI PromptTemplate human_input input_variables langchain llm memory_key predict verbose

PythonNotebook: /docs/modules/memory/examples/adding_memory_chain_multiple_inputs.ipynb
  Variables: chain docs docsearch embeddings memory prompt query state_of_the_union template text_splitter texts
  Usages: CharacterTextSplitter Chroma CohereEmbeddings ConversationBufferMemory Document ElasticVectorSearch OpenAI OpenAIEmbeddings PromptTemplate buffer chain_type chains chunk_overlap chunk_size cohere docstore document elastic_vector_search from_texts input_key input_variables langchain len llms load_qa_chain memory_key metadatas open openai print prompts question_answering range read return_only_outputs similarity_search split_text temperature vectorstores

PythonNotebook: /docs/modules/memory/examples/agent_with_memory.ipynb
  Variables: agent agent_chain agent_without_memory llm_chain memory prefix prompt search suffix tools
  Usages: AgentExecutor ConversationBufferMemory GoogleSearchAPIWrapper LLMChain OpenAI Tool ZeroShotAgent agents create_prompt description from_agent_and_tools func input input_variables langchain llm memory_key name run temperature utilities verbose

PythonNotebook: /docs/modules/memory/examples/agent_with_memory_in_db.ipynb
  Variables: agent agent_chain agent_without_memory llm_chain memory message_history prefix prompt search suffix tools
  Usages: AgentExecutor ChatMessageHistory ConversationBufferMemory GoogleSearchAPIWrapper LLMChain OpenAI RedisChatMessageHistory Tool ZeroShotAgent agents chat_memory chat_message_histories create_prompt description from_agent_and_tools func input input_variables langchain llm memory_key name run session_id temperature ttl url utilities verbose

PythonNotebook: /docs/modules/memory/examples/cassandra_chat_message_history.ipynb
  Variables: contact_points message_history
  Usages: CassandraChatMessageHistory add_ai_message add_user_message langchain memory messages session_id

PythonNotebook: /docs/modules/memory/examples/conversational_customization.ipynb
  Variables: PROMPT conversation llm template
  Usages: ConversationBufferMemory ConversationChain OpenAI PromptTemplate ai_prefix chains human_prefix input input_variables langchain llms memory predict prompt prompts temperature verbose

PythonNotebook: /docs/modules/memory/examples/custom_memory.ipynb
  Classes: SpacyEntityMemory
  Methods: clear load_memory_variables memory_variables save_context
  Variables: conversation doc ent_str entities entities: llm memory_key: nlp prompt self.entities self.entities[ent_str] template text
  Usages: Any BaseMemory BaseModel ConversationChain Dict List OpenAI PromptTemplate dict ent ents input input_variables inputs join keys langchain list load memory memory_key outputs predict prompts property pydantic schema self spacy str temperature typing verbose

PythonNotebook: /docs/modules/memory/examples/dynamodb_chat_message_history.ipynb
  Variables: agent_chain dynamodb history llm memory message_history python_repl table tools
  Usages: AgentType AttributeDefinitions BillingMode CHAT_CONVERSATIONAL_REACT_DESCRIPTION ChatOpenAI ConversationBufferMemory DynamoDBChatMessageHistory KeySchema PythonREPL TableName Tool add_ai_message add_user_message agent agents boto3 chat_memory chat_message_histories chat_models client create_table description endpoint_url func get_waiter getpass initialize_agent input item_count langchain memory_key messages meta name print resource return_messages run session_id table_name temperature utilities verbose wait

PythonNotebook: /docs/modules/memory/examples/entity_memory_with_sqlite.ipynb
  Variables: conversation entity_store llm memory
  Usages: ConversationChain ConversationEntityMemory ENTITY_MEMORY_CONVERSATION_TEMPLATE OpenAI SQLiteEntityStore chains entity get langchain llms prompt run temperature verbose

PythonNotebook: /docs/modules/memory/examples/momento_chat_message_history.ipynb
  Variables: cache_name history session_id ttl
  Usages: MomentoChatMessageHistory add_ai_message add_user_message datetime days from_client_params langchain memory messages timedelta

PythonNotebook: /docs/modules/memory/examples/mongodb_chat_message_history.ipynb
  Variables: connection_string message_history
  Usages: MongoDBChatMessageHistory add_ai_message add_user_message langchain memory messages session_id

PythonNotebook: /docs/modules/memory/examples/motorhead_memory.ipynb
  Variables: llm_chain memory prompt template
  Usages: LLMChain MotorheadMemory OpenAI PromptTemplate init input_variables langchain llm memory_key motorhead_memory run session_id url verbose

PythonNotebook: /docs/modules/memory/examples/motorhead_memory_managed.ipynb
  Variables: llm_chain memory prompt template
  Usages: LLMChain MotorheadMemory OpenAI PromptTemplate api_key client_id init input_variables langchain llm memory_key motorhead_memory run session_id verbose

PythonNotebook: /docs/modules/memory/examples/multiple_memory.ipynb
  Variables: PROMPT _DEFAULT_TEMPLATE conv_memory conversation llm memory summary_memory
  Usages: CombinedMemory ConversationBufferMemory ConversationChain ConversationSummaryMemory OpenAI PromptTemplate chains input_key input_variables langchain llms memories memory_key prompt prompts run temperature template verbose

PythonNotebook: /docs/modules/memory/examples/postgres_chat_message_history.ipynb
  Variables: history
  Usages: PostgresChatMessageHistory add_ai_message add_user_message connection_string langchain memory messages session_id

PythonNotebook: /docs/modules/memory/examples/redis_chat_message_history.ipynb
  Variables: history
  Usages: RedisChatMessageHistory add_ai_message add_user_message langchain memory messages

PythonNotebook: /docs/modules/memory/examples/zep_memory.ipynb
  Functions: print_messages
  Variables: ZEP_API_URL agent_chain ddg llm memory search_results session_id test_history tools zep_chat_history
  Usages: AIMessage AgentType CONVERSATIONAL_REACT_DESCRIPTION ConversationBufferMemory DuckDuckGoSearchRun HumanMessage OpenAI ZepChatMessageHistory agent agents append chat_memory chat_message_histories content dist dotenv initialize_agent input langchain load_dotenv memory_key message messages msg print run schema search str temperature to_dict url uuid uuid4 verbose zep_messages zep_summary

PythonNotebook: /docs/modules/memory/types/buffer.ipynb
  Variables: conversation llm memory
  Usages: ConversationBufferMemory ConversationChain OpenAI chains input langchain llms load_memory_variables predict return_messages save_context temperature verbose

PythonNotebook: /docs/modules/memory/types/buffer_window.ipynb
  Variables: conversation_with_summary memory
  Usages: ConversationBufferWindowMemory ConversationChain OpenAI chains input langchain llm llms load_memory_variables predict return_messages save_context temperature verbose

PythonNotebook: /docs/modules/memory/types/entity_summary_memory.ipynb
  Variables: _input conversation llm memory
  Usages: Any BaseModel ConversationChain ConversationEntityMemory Dict ENTITY_MEMORY_CONVERSATION_TEMPLATE List OpenAI chains entity_store input langchain llms load_memory_variables pprint predict prompt pydantic return_messages save_context store temperature typing verbose

PythonNotebook: /docs/modules/memory/types/kg.ipynb
  Variables: conversation_with_kg llm memory prompt template
  Usages: ConversationChain ConversationKGMemory OpenAI PromptTemplate chains get_current_entities get_knowledge_triplets input input_variables langchain llms load_memory_variables predict prompts return_messages save_context temperature verbose

PythonNotebook: /docs/modules/memory/types/summary.ipynb
  Variables: conversation_with_summary history llm memory messages previous_summary
  Usages: ChatMessageHistory ConversationChain ConversationSummaryMemory OpenAI add_ai_message add_user_message buffer chains chat_memory from_messages input langchain llms load_memory_variables predict predict_new_summary return_messages save_context temperature verbose

PythonNotebook: /docs/modules/memory/types/summary_buffer.ipynb
  Variables: conversation_with_summary llm memory messages previous_summary
  Usages: ConversationChain ConversationSummaryBufferMemory OpenAI chains chat_memory input langchain llms load_memory_variables max_token_limit predict predict_new_summary return_messages save_context verbose

PythonNotebook: /docs/modules/memory/types/token_buffer.ipynb
  Variables: conversation_with_summary llm memory
  Usages: ConversationChain ConversationTokenBufferMemory OpenAI chains input langchain llms load_memory_variables max_token_limit predict return_messages save_context verbose

PythonNotebook: /docs/modules/memory/types/vectorstore_retriever_memory.ipynb
  Variables: PROMPT _DEFAULT_TEMPLATE conversation_with_summary embedding_fn embedding_size index llm memory retriever vectorstore
  Usages: ConversationChain FAISS InMemoryDocstore IndexFlatL2 OpenAI OpenAIEmbeddings PromptTemplate VectorStoreRetrieverMemory as_retriever chains datetime dict docstore embed_query embeddings faiss input input_variables langchain llms load_memory_variables openai predict print prompt prompts save_context search_kwargs temperature template vectorstores verbose

PythonNotebook: /docs/modules/models/chat/getting_started.ipynb
  Variables: batch_messages chain chat chat_prompt human_message_prompt human_template messages prompt resp result system_message_prompt template
  Usages: AIMessage AIMessagePromptTemplate ChatOpenAI ChatPromptTemplate HumanMessage HumanMessagePromptTemplate LLMChain PromptTemplate StreamingStdOutCallbackHandler SystemMessage SystemMessagePromptTemplate callbacks chat_models content format_prompt from_messages from_template generate input_language input_variables langchain llm llm_output output_language prompts run schema streaming streaming_stdout temperature text to_messages

File: /docs/modules/models/chat/how_to_guides.rst

File: /docs/modules/models/chat/integrations.rst

PythonNotebook: /docs/modules/models/llms/getting_started.ipynb
  Variables: llm llm_result
  Usages: OpenAI best_of generate generations get_num_tokens langchain len llm_output llms model_name

File: /docs/modules/models/llms/how_to_guides.rst

File: /docs/modules/models/llms/integrations.rst

PythonNotebook: /docs/modules/prompts/output_parsers/getting_started.ipynb
  Classes: Joke
  Methods: question_ends_with_question_mark
  Variables: _input joke_query model model_name output parser prompt punchline: setup: temperature
  Usages: BaseModel ChatOpenAI ChatPromptTemplate Field HumanMessagePromptTemplate List OpenAI PromptTemplate PydanticOutputParser ValueError chat_models cls description field format_prompt get_format_instructions input_variables langchain llms output_parsers parse partial_variables prompts punchline pydantic pydantic_object query setup str template to_string typing validator

File: /docs/modules/prompts/output_parsers/how_to_guides.rst

# Getting Started
## What is a prompt template?
# -> I want you to act as a naming consultant for new companies.
# -> What is a good name for a company that makes colorful socks?
## Create a prompt template
# An example prompt with no input variables
# -> "Tell me a joke."
# An example prompt with one input variable
# -> "Tell me a funny joke."
# An example prompt with multiple input variables
# -> "Tell me a funny joke about chickens."
# -> ['adjective', 'content']
# -> Tell me a funny joke about chickens.
## Template formats
# Make sure jinja2 is installed before running this
# -> Tell me a funny joke about chickens.
## Validate template
## Serialize prompt template
## Pass few shot examples to a prompt template
# First, create the list of few shot examples.
# Next, we specify the template to format the examples we have provided.
# We use the `PromptTemplate` class for this.
# Finally, we create the `FewShotPromptTemplate` object.
# We can now generate a prompt using the `format` method.
# -> Give the antonym of every input
# -> 
# -> Word: happy
# -> Antonym: sad
# ->
# -> Word: tall
# -> Antonym: short
# ->
# -> Word: big
# -> Antonym: 
## Select examples for a prompt template
# These are a lot of examples of a pretend task of creating antonyms.
# We'll use the `LengthBasedExampleSelector` to select the examples.
# We can now use the `example_selector` to create a `FewShotPromptTemplate`.
# We can now generate a prompt using the `format` method.
# -> Give the antonym of every input
# ->
# -> Word: happy
# -> Antonym: sad
# ->
# -> Word: tall
# -> Antonym: short
# ->
# -> Word: energetic
# -> Antonym: lethargic
# ->
# -> Word: sunny
# -> Antonym: gloomy
# ->
# -> Word: windy
# -> Antonym: calm
# ->
# -> Word: big
# -> Antonym:
# -> Give the antonym of every input
# -> Word: happy
# -> Antonym: sad
# ->
# -> Word: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else
# -> Antonym:

File: /docs/modules/prompts/prompt_templates/how_to_guides.rst

PythonNotebook: /docs/modules/utils/examples/gmail.ipynb
  Variables: command gmail_agent llm messages output
  Usages: OpenAI agent_toolkits agents base create_gmail_agent gmail json langchain llms loads message print run sender_name verbose

Python: /langchain/agents/agent_toolkits/azure_cognitive_services/__init__.py
  Variables: __all__
  Usages: AzureCognitiveServicesToolkit agent_toolkits agents azure_cognitive_services langchain toolkit

Python: /langchain/agents/agent_toolkits/azure_cognitive_services/toolkit.py
  Classes: AzureCognitiveServicesToolkit
  Methods: get_tools
  Variables: tools
  Usages: AzureCogsFormRecognizerTool AzureCogsImageAnalysisTool AzureCogsSpeech2TextTool AzureCogsText2SpeechTool BaseTool BaseToolkit List agent_toolkits agents annotations append azure_cognitive_services base langchain platform self startswith sys typing

Python: /langchain/agents/agent_toolkits/csv/base.py
  Functions: create_csv_agent
  Variables: _kwargs
  Usages: AgentExecutor Any BaseLanguageModel ImportError List Optional Union ValueError agent agent_toolkits agents append base base_language create_pandas_dataframe_agent dict isinstance item kwargs langchain list llm pandas pandas_kwargs path read_csv str type typing

Python: /langchain/agents/agent_toolkits/file_management/__init__.py
  Variables: __all__
  Usages: FileManagementToolkit agent_toolkits agents file_management langchain toolkit

Python: /langchain/agents/agent_toolkits/file_management/toolkit.py
  Classes: FileManagementToolkit
  Methods: get_tools validate_tools
  Variables: _FILE_TOOLS __all__ allowed_tools root_dir: selected_tools selected_tools: tool_cls tools:
  Usages: BaseTool BaseToolkit CopyFileTool DeleteFileTool FileSearchTool List ListDirectoryTool MoveFileTool Optional ReadFileTool ValueError WriteFileTool __fields__ agent_toolkits agents annotations append base cls copy default delete dict file_management file_search get keys langchain list list_dir move pydantic read root_dir root_validator self str tool tool_name tools typing values write

Python: /langchain/agents/agent_toolkits/gmail/toolkit.py
  Classes: Config GmailToolkit
  Methods: get_tools
  Variables: SCOPES api_resource: arbitrary_types_allowed
  Usages: BaseTool BaseToolkit Field GmailCreateDraft GmailGetMessage GmailGetThread GmailSearch GmailSendMessage ImportError List Resource TYPE_CHECKING agent_toolkits agents annotations api_resource base build_resource_service create_draft default_factory discovery get_message get_thread gmail googleapiclient langchain pydantic search self send_message tools typing utils

Python: /langchain/agents/agent_toolkits/jira/toolkit.py
  Classes: JiraToolkit
  Methods: from_jira_api_wrapper get_tools
  Variables: actions tools tools:
  Usages: BaseTool BaseToolkit JiraAPIWrapper JiraAction List action agent_toolkits agents api_wrapper base classmethod cls description jira jira_api_wrapper langchain list mode name self tool typing utilities

Python: /langchain/agents/agent_toolkits/json/base.py
  Functions: create_json_agent
  Variables: agent llm_chain prompt tool_names tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLanguageModel Dict FORMAT_INSTRUCTIONS JSON_PREFIX JSON_SUFFIX JsonToolkit LLMChain List Optional ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base base_language bool callback_manager callbacks chains create_prompt format_instructions from_agent_and_tools get_tools input_variables json kwargs langchain llm mrkl name prefix str suffix tool toolkit typing verbose

Python: /langchain/agents/agent_toolkits/json/prompt.py
  Variables: JSON_PREFIX JSON_SUFFIX

Python: /langchain/agents/agent_toolkits/json/toolkit.py
  Classes: JsonToolkit
  Methods: get_tools
  Variables: spec:
  Usages: BaseTool BaseToolkit JsonGetValueTool JsonListKeysTool JsonSpec List agent_toolkits agents annotations base json langchain self spec tool tools typing

Python: /langchain/agents/agent_toolkits/nla/tool.py
  Classes: NLATool
  Methods: from_llm_and_method from_open_api_endpoint_chain
  Variables: api_operation chain description expanded_name
  Usages: APIOperation Any BaseLanguageModel OpenAPIEndpointChain OpenAPISpec Optional Requests Tool agents api api_models api_title base_language bool chains classmethod cls from_api_operation from_openapi_spec func info kwargs langchain llm method name openapi openapi_utils operation_id path replace requests return_intermediate_steps run spec str title tools typing utils verbose

Python: /langchain/agents/agent_toolkits/nla/toolkit.py
  Classes: NLAToolkit
  Methods: _get_http_operation_tools from_llm_and_ai_plugin from_llm_and_ai_plugin_url from_llm_and_spec from_llm_and_url get_tools
  Variables: endpoint_tool http_operation_tools nla_tools: plugin spec
  Usages: AIPlugin Any BaseLanguageModel BaseTool BaseToolkit Field List NLATool OpenAPISpec Optional Requests Sequence agent_toolkits agents ai_plugin ai_plugin_url annotations api append base base_language bool classmethod cls from_llm_and_method from_url get_methods_for_path kwargs langchain list llm method nla nla_tools open_api_url openapi openapi_utils path paths pydantic requests self staticmethod str tool tools typing url utils verbose

Python: /langchain/agents/agent_toolkits/openapi/base.py
  Functions: create_openapi_agent
  Variables: agent llm_chain prompt tool_names tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLanguageModel Dict FORMAT_INSTRUCTIONS LLMChain List OPENAPI_PREFIX OPENAPI_SUFFIX OpenAPIToolkit Optional ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base base_language bool callback_manager callbacks chains create_prompt early_stopping_method float format_instructions from_agent_and_tools get_tools input_variables int kwargs langchain llm max_execution_time max_iterations mrkl name openapi prefix return_intermediate_steps str suffix tool toolkit typing verbose

Python: /langchain/agents/agent_toolkits/openapi/planner.py
  Functions: _create_api_controller_agent _create_api_controller_tool _create_api_planner_tool _get_default_llm_chain _get_default_llm_chain_factory create_openapi_agent
  Classes: RequestsDeleteToolWithParsing RequestsGetToolWithParsing RequestsPatchToolWithParsing RequestsPostToolWithParsing
  Methods: _arun _create_and_run_api_controller_agent _run
  Variables: MAX_RESPONSE_LENGTH agent base_url chain data data_params description docs docs_str endpoint_descriptions endpoint_docs_by_name endpoint_names get_llm_chain llm_chain: matches name pattern post_llm_chain prompt response response_length: tool tools tools:
  Usages: API_CONTROLLER_PROMPT API_CONTROLLER_TOOL_DESCRIPTION API_CONTROLLER_TOOL_NAME API_ORCHESTRATOR_PROMPT API_PLANNER_PROMPT API_PLANNER_TOOL_DESCRIPTION API_PLANNER_TOOL_NAME AgentExecutor Any BaseCallbackManager BaseLanguageModel BasePromptTemplate BaseRequestsTool BaseTool Callable Dict Field JSONDecodeError LLMChain List NotImplementedError OpenAI Optional PARSING_DELETE_PROMPT PARSING_GET_PROMPT PARSING_PATCH_PROMPT PARSING_POST_PROMPT PromptTemplate REQUESTS_DELETE_TOOL_DESCRIPTION REQUESTS_GET_TOOL_DESCRIPTION REQUESTS_PATCH_TOOL_DESCRIPTION REQUESTS_POST_TOOL_DESCRIPTION ReadOnlySharedMemory ReducedOpenAPISpec RequestsWrapper Tool ValueError ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools api_docs api_spec api_url base base_language bool callback_manager callbacks chains default_factory delete dump endpoint_name endpoints findall format from_agent_and_tools func functools get input_variables instructions int join json kwargs langchain llm llm_chain llms loads memory method mrkl openai openapi params partial partial_variables patch plan_str planner_prompt post predict prompts pydantic requests requests_wrapper response_length route run self servers shared_memory spec split str strip template text typing verbose yaml

Python: /langchain/agents/agent_toolkits/openapi/planner_prompt.py
  Variables: API_CONTROLLER_PROMPT API_CONTROLLER_TOOL_DESCRIPTION API_CONTROLLER_TOOL_NAME API_ORCHESTRATOR_PROMPT API_PLANNER_PROMPT API_PLANNER_TOOL_DESCRIPTION API_PLANNER_TOOL_NAME PARSING_DELETE_PROMPT PARSING_GET_PROMPT PARSING_PATCH_PROMPT PARSING_POST_PROMPT REQUESTS_DELETE_TOOL_DESCRIPTION REQUESTS_GET_TOOL_DESCRIPTION REQUESTS_PATCH_TOOL_DESCRIPTION REQUESTS_POST_TOOL_DESCRIPTION
  Usages: PromptTemplate input_variables langchain prompt prompts template

Python: /langchain/agents/agent_toolkits/openapi/prompt.py
  Variables: DESCRIPTION OPENAPI_PREFIX OPENAPI_SUFFIX

Python: /langchain/agents/agent_toolkits/openapi/spec.py
  Functions: dereference_refs reduce_openapi_spec
  Classes: ReducedOpenAPISpec
  Methods: _dereference_refs _retrieve_ref_path reduce_endpoint_docs
  Variables: components description: endpoints endpoints: obj_out: obj_out[k] out out["description"] out["parameters"] out["responses"] servers:
  Usages: Any Dict List RuntimeError Tuple Union bool component dataclass dataclasses dereference description dict docs frozen full_spec get isinstance items list name obj obj_out operation operation_name parameter path route servers spec spec_obj split stop str typing upper

Python: /langchain/agents/agent_toolkits/openapi/toolkit.py
  Classes: OpenAPIToolkit RequestsToolkit
  Methods: from_llm get_tools
  Variables: json_agent json_agent: json_agent_tool request_toolkit requests_wrapper:
  Usages: AgentExecutor Any BaseLanguageModel BaseTool BaseToolkit DESCRIPTION JsonSpec JsonToolkit List RequestsDeleteTool RequestsGetTool RequestsPatchTool RequestsPostTool RequestsPutTool TextRequestsWrapper Tool agent agent_toolkits agents annotations base base_language classmethod cls create_json_agent description func json json_spec kwargs langchain llm name openapi prompt requests requests_wrapper run self spec tool toolkit tools typing

Python: /langchain/agents/agent_toolkits/pandas/base.py
  Functions: _get_multi_prompt _get_prompt_and_tools _get_single_prompt create_pandas_dataframe_agent
  Variables: agent df_locals df_locals[f"df{i dfs_head include_df_head include_dfs_head input_variables llm_chain num_dfs partial_prompt prefix prompt prompt, suffix_to_use tool_names tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLanguageModel BasePromptTemplate DataFrame Dict ImportError LLMChain List MULTI_DF_PREFIX Optional PREFIX PythonAstREPLTool SUFFIX_NO_DF SUFFIX_WITH_DF SUFFIX_WITH_MULTI_DF Tuple ValueError ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base base_language bool callback_manager callbacks chains create_prompt dataframe df_head dfs early_stopping_method enumerate float from_agent_and_tools head include_df_in_prompt int isinstance item join kwargs langchain len list llm locals max_execution_time max_iterations mrkl name pandas partial prompts python return_intermediate_steps str suffix to_markdown tool type typing verbose

Python: /langchain/agents/agent_toolkits/pandas/prompt.py
  Variables: MULTI_DF_PREFIX PREFIX SUFFIX_NO_DF SUFFIX_WITH_DF SUFFIX_WITH_MULTI_DF

Python: /langchain/agents/agent_toolkits/playwright/__init__.py
  Variables: __all__
  Usages: PlayWrightBrowserToolkit agent_toolkits agents langchain playwright toolkit

Python: /langchain/agents/agent_toolkits/playwright/toolkit.py
  Classes: Config PlayWrightBrowserToolkit
  Methods: from_browser get_tools validate_imports_and_browser_provided
  Variables: arbitrary_types_allowed async_browser: extra sync_browser: tool_classes: tools
  Usages: AsyncBrowser BaseBrowserTool BaseTool BaseToolkit Browser ClickTool CurrentWebPageTool Extra ExtractHyperlinksTool ExtractTextTool GetElementsTool ImportError List NavigateBackTool NavigateTool Optional SyncBrowser TYPE_CHECKING Type ValueError agent_toolkits agents annotations async_api async_browser base cast classmethod click cls current_page dict extract_hyperlinks extract_text forbid get get_elements langchain lazy_import_playwright_browsers navigate navigate_back playwright pydantic root_validator self sync_api sync_browser tool_classes tool_cls typing values

Python: /langchain/agents/agent_toolkits/powerbi/base.py
  Functions: create_pbi_agent
  Variables: agent toolkit tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLanguageModel Dict FORMAT_INSTRUCTIONS LLMChain List Optional POWERBI_PREFIX POWERBI_SUFFIX PowerBIDataset PowerBIToolkit ValueError ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base base_language bool callback_manager callbacks chains create_prompt examples format format_instructions from_agent_and_tools get_tools input_variables int kwargs langchain llm llm_chain mrkl name powerbi prefix prompt str suffix tool top_k typing utilities verbose

Python: /langchain/agents/agent_toolkits/powerbi/chat_base.py
  Functions: create_pbi_chat_agent
  Variables: agent toolkit tools
  Usages: AgentExecutor AgentOutputParser Any BaseCallbackManager BaseChatMemory BaseChatModel ConversationBufferMemory ConversationalChatAgent Dict List Optional POWERBI_CHAT_PREFIX POWERBI_CHAT_SUFFIX PowerBIDataset PowerBIToolkit ValueError agent_executor_kwargs agent_toolkits agents base bool callback_manager callbacks chat_memory chat_models conversational_chat examples format from_agent_and_tools from_llm_and_tools get_tools human_message input_variables int kwargs langchain llm memory memory_key output_parser powerbi prefix prompt return_messages str suffix system_message top_k typing utilities verbose

Python: /langchain/agents/agent_toolkits/powerbi/prompt.py
  Variables: POWERBI_CHAT_PREFIX POWERBI_CHAT_SUFFIX POWERBI_PREFIX POWERBI_SUFFIX

Python: /langchain/agents/agent_toolkits/powerbi/toolkit.py
  Classes: Config PowerBIToolkit
  Methods: get_tools
  Variables: arbitrary_types_allowed callback_manager: chain examples: llm: max_iterations: powerbi:
  Usages: BaseCallbackManager BaseLanguageModel BaseTool BaseToolkit Field InfoPowerBITool LLMChain List ListPowerBITool Optional PowerBIDataset PromptTemplate QUESTION_TO_QUERY QueryPowerBITool agent_toolkits agents base base_language callback_manager callbacks chains examples exclude input_variables int langchain llm llm_chain max_iterations powerbi prompt prompts pydantic self str template tool tools typing utilities

Python: /langchain/agents/agent_toolkits/python/base.py
  Functions: create_python_agent
  Variables: agent llm_chain prompt tool_names tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLanguageModel Dict LLMChain Optional PREFIX PythonREPLTool ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base base_language bool callback_manager callbacks chains create_prompt from_agent_and_tools kwargs langchain llm mrkl name prefix python str tool typing verbose

Python: /langchain/agents/agent_toolkits/python/prompt.py
  Variables: PREFIX

Python: /langchain/agents/agent_toolkits/spark/base.py
  Functions: _validate_spark_connect_df _validate_spark_df create_spark_dataframe_agent
  Variables: agent input_variables llm_chain partial_prompt prompt tool_names tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLLM DataFrame Dict ImportError LLMChain List Optional PREFIX PythonAstREPLTool SUFFIX SparkConnectDataFrame SparkLocalDataFrame ValueError ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base bool callback_manager callbacks chains connect create_prompt dataframe early_stopping_method first float from_agent_and_tools int isinstance kwargs langchain llm llms locals max_execution_time max_iterations mrkl name partial prefix pyspark python return_intermediate_steps spark sql str suffix tool typing verbose

Python: /langchain/agents/agent_toolkits/spark/prompt.py
  Variables: PREFIX SUFFIX

Python: /langchain/agents/agent_toolkits/spark_sql/base.py
  Functions: create_spark_sql_agent
  Variables: agent llm_chain prefix prompt tool_names tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLanguageModel Dict FORMAT_INSTRUCTIONS LLMChain List Optional SQL_PREFIX SQL_SUFFIX SparkSQLToolkit ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base base_language bool callback_manager callbacks chains create_prompt early_stopping_method float format format_instructions from_agent_and_tools get_tools input_variables int kwargs langchain llm max_execution_time max_iterations mrkl name spark_sql str suffix tool toolkit top_k typing verbose

Python: /langchain/agents/agent_toolkits/spark_sql/prompt.py
  Variables: SQL_PREFIX SQL_SUFFIX

Python: /langchain/agents/agent_toolkits/spark_sql/toolkit.py
  Classes: Config SparkSQLToolkit
  Methods: get_tools
  Variables: arbitrary_types_allowed db: llm:
  Usages: BaseLanguageModel BaseTool BaseToolkit Field InfoSparkSQLTool List ListSparkSQLTool QueryCheckerTool QuerySparkSQLTool SparkSQL agent_toolkits agents base base_language exclude langchain llm pydantic self spark_sql tool tools typing utilities

Python: /langchain/agents/agent_toolkits/sql/base.py
  Functions: create_sql_agent
  Variables: agent llm_chain prefix prompt tool_names tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLanguageModel Dict FORMAT_INSTRUCTIONS LLMChain List Optional SQLDatabaseToolkit SQL_PREFIX SQL_SUFFIX ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base base_language bool callback_manager callbacks chains create_prompt dialect early_stopping_method float format format_instructions from_agent_and_tools get_tools input_variables int kwargs langchain llm max_execution_time max_iterations mrkl name sql str suffix tool toolkit top_k typing verbose

Python: /langchain/agents/agent_toolkits/sql/prompt.py
  Variables: SQL_PREFIX SQL_SUFFIX

Python: /langchain/agents/agent_toolkits/sql/toolkit.py
  Classes: Config SQLDatabaseToolkit
  Methods: dialect get_tools
  Variables: arbitrary_types_allowed db: info_sql_database_tool_description llm: query_sql_database_tool_description
  Usages: BaseLanguageModel BaseTool BaseToolkit Field InfoSQLDatabaseTool List ListSQLDatabaseTool QueryCheckerTool QuerySQLDataBaseTool SQLDatabase agent_toolkits agents base base_language description exclude langchain llm property pydantic self sql_database str tool tools typing

Python: /langchain/agents/agent_toolkits/vectorstore/base.py
  Functions: create_vectorstore_agent create_vectorstore_router_agent
  Variables: agent llm_chain prompt tool_names tools
  Usages: AgentExecutor Any BaseCallbackManager BaseLanguageModel Dict LLMChain Optional PREFIX ROUTER_PREFIX VectorStoreRouterToolkit VectorStoreToolkit ZeroShotAgent agent_executor_kwargs agent_toolkits agents allowed_tools base base_language bool callback_manager callbacks chains create_prompt from_agent_and_tools get_tools kwargs langchain llm mrkl name prefix str tool toolkit typing vectorstore verbose

Python: /langchain/agents/agent_toolkits/vectorstore/prompt.py
  Variables: PREFIX ROUTER_PREFIX

Python: /langchain/agents/agent_toolkits/vectorstore/toolkit.py
  Classes: Config VectorStoreInfo VectorStoreRouterToolkit VectorStoreToolkit
  Methods: get_tools
  Variables: arbitrary_types_allowed description description: llm: name: qa_tool qa_with_sources_tool tools: vectorstore: vectorstore_info: vectorstores:
  Usages: BaseLanguageModel BaseModel BaseTool BaseToolkit Field List OpenAI VectorStore VectorStoreQATool VectorStoreQAWithSourcesTool agent_toolkits agents append base base_language default_factory exclude get_description langchain llm llms name openai pydantic self str temperature tool tools typing vectorstore vectorstore_info vectorstores

Python: /langchain/agents/agent_toolkits/zapier/toolkit.py
  Classes: ZapierToolkit
  Methods: from_zapier_nla_wrapper get_tools
  Variables: actions tools tools:
  Usages: BaseTool BaseToolkit List ZapierNLARunAction ZapierNLAWrapper action action_id agent_toolkits agents api_wrapper base classmethod cls langchain list params_schema self tool typing utilities zapier zapier_description zapier_nla_wrapper

Python: /langchain/chains/api/openapi/chain.py
  Classes: OpenAPIEndpointChain _ParamMapping
  Methods: _call _construct_path _extract_body_params _extract_query_params _get_output deserialize_json_input from_api_operation from_url_and_method input_keys output_keys
  Variables: _answer _api_arguments _requests _run_manager answer api_arguments api_operation: api_request_chain: api_response: api_response_chain: args: body_params body_params: body_params[param] instructions instructions_key: intermediate_steps intermediate_steps["request_args"] intermediate_steps["response_text"] max_text_length: method method_str operation output_key: param_mapping param_mapping: path path_params: query_params query_params: query_params[param] request_args requests: requests_chain response_chain response_text return_intermediate_steps:
  Usages: APIOperation APIRequesterChain APIResponderChain Any BaseLanguageModel BaseModel CallbackManagerForChainRun Callbacks Chain Dict Exception Field LLMChain List NamedTuple Optional Requests Response alias annotations api api_models api_operation api_request_chain api_response api_response_chain args base base_language base_url bool callbacks cast chains classmethod cls color default_factory dict end exclude from_llm from_llm_and_typescript from_openapi_url get_child get_noop_manager getattr inputs instructions_key int json kwargs langchain len llm loads manager max_text_length on_text openapi output output_key param path_params pop predict_and_parse property pydantic raw_response reason replace requests response return_intermediate_steps run_manager self serialized_args spec_url startswith status_code str text to_typescript tools typescript_definition typing upper utils value verbose

Python: /langchain/chains/api/openapi/prompts.py
  Variables: REQUEST_TEMPLATE RESPONSE_TEMPLATE

Python: /langchain/chains/api/openapi/requests_chain.py
  Classes: APIRequesterChain APIRequesterOutputParser
  Methods: _load_json_block _type from_llm_and_typescript parse
  Variables: json_match message_match output_parser prompt
  Usages: Any BaseLanguageModel BaseOutputParser DOTALL JSONDecodeError LLMChain PromptTemplate REQUEST_TEMPLATE api base_language bool chains classmethod cls dumps group input_variables json kwargs langchain llm llm_output loads openapi partial_variables prompts property schema search self serialized_block str strict strip template typescript_definition typing verbose

Python: /langchain/chains/api/openapi/response_chain.py
  Classes: APIResponderChain APIResponderOutputParser
  Methods: _load_json_block _type from_llm parse
  Variables: json_match output_parser prompt response_content
  Usages: Any BaseLanguageModel BaseOutputParser DOTALL JSONDecodeError LLMChain PromptTemplate RESPONSE_TEMPLATE ValueError api base_language bool chains classmethod cls get group input_variables json kwargs langchain llm llm_output loads openapi prompts property schema search self serialized_block str strict strip template typing verbose

File: /langchain/chains/llm_summarization_checker/prompts/are_all_true_prompt.txt

File: /langchain/chains/llm_summarization_checker/prompts/check_facts.txt

File: /langchain/chains/llm_summarization_checker/prompts/create_facts.txt

File: /langchain/chains/llm_summarization_checker/prompts/revise_summary.txt

Python: /langchain/document_loaders/parsers/html/__init__.py
  Variables: __all__
  Usages: BS4HTMLParser bs4 document_loaders html langchain parsers

Python: /langchain/document_loaders/parsers/html/bs4.py
  Classes: BS4HTMLParser
  Methods: __init__ lazy_parse
  Variables: logger metadata: self.bs_kwargs self.get_text_separator soup text title
  Usages: Any BaseBlobParser BeautifulSoup Blob Dict Document ImportError Iterator Union ValueError __name__ as_bytes_io base blob blob_loaders bs4 bs_kwargs docstore document document_loaders features getLogger get_text get_text_separator kwargs langchain logging metadata page_content self source str string typing

Python: /langchain/experimental/autonomous_agents/autogpt/agent.py
  Classes: AutoGPT
  Methods: __init__ from_llm_and_tools run
  Variables: action assistant_reply chain feedback human_feedback_tool loop_count memory_to_add observation prompt result self.ai_name self.chain self.feedback_tool self.full_message_history: self.memory self.next_action_count self.output_parser self.tools tool tools user_input
  Usages: AIMessage AutoGPTOutputParser AutoGPTPrompt BaseAutoGPTOutputParser BaseChatModel BaseMessage BaseTool Document Exception FINISH_NAME HumanInputRun HumanMessage LLMChain List Optional SystemMessage ValidationError VectorStoreRetriever __name__ add_documents ai_name ai_role annotations append args autogpt autonomous_agents base bool chains chat_models classmethod cls content experimental feedback_tool full_message_history get_num_tokens goals human human_in_the_loop input_variables langchain llm memory messages name next_action_count output_parser page_content parse print prompt_generator pydantic schema self str token_counter type typing vectorstores

Python: /langchain/experimental/autonomous_agents/autogpt/memory.py
  Classes: AutoGPTMemory
  Methods: _get_prompt_input_key load_memory_variables memory_variables
  Variables: docs input_key query retriever:
  Usages: Any BaseChatMemory Dict Field List VectorStoreRetriever base chat_memory exclude get_prompt_input_key get_relevant_documents inputs langchain memory messages property pydantic retriever self str typing vectorstores

Python: /langchain/experimental/autonomous_agents/autogpt/output_parser.py
  Functions: preprocess_json_input
  Classes: AutoGPTAction AutoGPTOutputParser BaseAutoGPTOutputParser
  Methods: parse
  Variables: args: corrected_str name: parsed preprocessed_text
  Usages: BaseOutputParser Dict Exception JSONDecodeError KeyError NamedTuple TypeError abc abstractmethod args input_str json langchain loads name schema self str strict sub text typing

Python: /langchain/experimental/autonomous_agents/autogpt/prompt.py
  Classes: AutoGPTPrompt
  Methods: construct_full_prompt format_messages
  Variables: ai_name: ai_role: base_prompt content_format full_prompt historical_messages historical_messages: input_message memory: memory_message message_tokens messages: previous_messages prompt_start relevant_docs relevant_memory relevant_memory_tokens send_token_limit: time_prompt token_counter: tools: used_tokens
  Usages: Any BaseChatPromptTemplate BaseMessage BaseModel BaseTool Callable HumanMessage List SystemMessage VectorStoreRetriever ai_name ai_role append autogpt autonomous_agents base chat content doc enumerate experimental get_prompt get_relevant_documents goal goals int kwargs langchain memory message messages page_content prompt_generator prompts pydantic schema self send_token_limit str strftime sum time token_counter tools typing vectorstores

Python: /langchain/experimental/autonomous_agents/autogpt/prompt_generator.py
  Functions: get_prompt
  Classes: PromptGenerator
  Methods: __init__ _generate_command_string _generate_numbered_list add_constraint add_performance_evaluation add_resource add_tool generate_prompt_string
  Variables: FINISH_NAME command_strings finish_args finish_description finish_string formatted_response_format output prompt_generator prompt_string self.commands: self.constraints: self.performance_evaluation: self.resources: self.response_format
  Usages: BaseTool List append args base commands constraint constraints description dumps enumerate evaluation indent item item_type items join json langchain len list name performance_evaluation resource resources response_format self str tool tools typing

Python: /langchain/experimental/autonomous_agents/baby_agi/__init__.py
  Variables: __all__
  Usages: BabyAGI TaskCreationChain TaskExecutionChain TaskPrioritizationChain autonomous_agents baby_agi experimental langchain task_creation task_execution task_prioritization

Python: /langchain/experimental/autonomous_agents/baby_agi/baby_agi.py
  Classes: BabyAGI Config
  Methods: _call _get_top_tasks add_task execute_task from_llm get_next_task input_keys output_keys print_next_task print_task_list print_task_result prioritize_tasks
  Variables: arbitrary_types_allowed context execution_chain execution_chain: first_task incomplete_tasks max_iterations: new_tasks next_task_id num_iters objective prioritized_task_list response result result_id results self.task_list task task_creation_chain task_creation_chain: task_id task_id_counter: task_list: task_name task_names task_parts task_prioritization_chain task_prioritization_chain: this_task_id vectorstore:
  Usages: Any BaseLanguageModel BaseModel CallbackManagerForChainRun Chain Dict Field List Optional TaskCreationChain TaskExecutionChain TaskPrioritizationChain VectorStore add_texts append autonomous_agents baby_agi base base_language bool callbacks chains classmethod cls collections default_factory deque experimental get ids init inputs int item join kwargs langchain len list llm manager max_iterations metadata metadatas new_task popleft print property pydantic query run run_manager self similarity_search split str strip task_creation task_description task_execution task_execution_chain task_id_counter task_list task_prioritization task_string texts typing update vectorstore vectorstores verbose

Python: /langchain/experimental/autonomous_agents/baby_agi/task_creation.py
  Classes: TaskCreationChain
  Methods: from_llm
  Variables: prompt task_creation_template
  Usages: BaseLanguageModel LLMChain PromptTemplate base_language bool classmethod cls input_variables langchain llm template verbose

Python: /langchain/experimental/autonomous_agents/baby_agi/task_execution.py
  Classes: TaskExecutionChain
  Methods: from_llm
  Variables: execution_template prompt
  Usages: BaseLanguageModel LLMChain PromptTemplate base_language bool classmethod cls input_variables langchain llm template verbose

Python: /langchain/experimental/autonomous_agents/baby_agi/task_prioritization.py
  Classes: TaskPrioritizationChain
  Methods: from_llm
  Variables: prompt task_prioritization_template
  Usages: BaseLanguageModel LLMChain PromptTemplate base_language bool classmethod cls input_variables langchain llm template verbose

Python: /langchain/experimental/plan_and_execute/executors/agent_executor.py
  Functions: load_agent_executor
  Variables: HUMAN_MESSAGE_TEMPLATE TASK_PREFIX agent agent_executor input_variables template
  Usages: AgentExecutor BaseLanguageModel BaseTool ChainExecutor List StructuredChatAgent agents append base base_language bool chain executors experimental from_agent_and_tools from_llm_and_tools human_message_template include_task_in_prompt langchain llm plan_and_execute structured_chat tools typing verbose

Python: /langchain/experimental/plan_and_execute/executors/base.py
  Classes: BaseExecutor ChainExecutor
  Methods: astep step
  Variables: chain: response
  Usages: Any BaseModel Callbacks Chain StepResponse abc abstractmethod arun base callbacks chain chains dict experimental inputs kwargs langchain manager plan_and_execute pydantic run schema self typing

Python: /langchain/experimental/plan_and_execute/planners/base.py
  Classes: BasePlanner LLMPlanner
  Methods: aplan plan
  Variables: llm_chain: llm_response output_parser: stop:
  Usages: Any BaseModel Callbacks LLMChain List Optional Plan PlanOutputParser abc abstractmethod arun callbacks chains dict experimental inputs kwargs langchain llm llm_chain manager output_parser parse plan_and_execute pydantic run schema self stop typing

Python: /langchain/experimental/plan_and_execute/planners/chat_planner.py
  Functions: load_chat_planner
  Classes: PlanningOutputParser
  Methods: parse
  Variables: SYSTEM_PROMPT llm_chain prompt_template steps
  Usages: BaseLanguageModel ChatPromptTemplate HumanMessagePromptTemplate LLMChain LLMPlanner Plan PlanOutputParser Step SystemMessage base base_language chains content experimental from_messages from_template langchain llm output_parser plan_and_execute planners prompt prompts schema self split stop str system_prompt text value

Python: /langchain/tools/openapi/utils/api_models.py
  Classes: APIOperation APIProperty APIPropertyBase APIPropertyLocation APIRequestBody APIRequestBodyProperty
  Methods: _cast_schema_list_type _format_nested_properties _get_properties_from_parameters _get_schema _get_schema_type _get_schema_type_for_array _get_schema_type_for_enum _process_array_schema _process_object_schema _process_supported_media_type _validate_content _validate_location body_params from_openapi_spec from_openapi_url from_parameter from_request_body from_schema from_str is_supported_location path_params query_params to_typescript ts_type_from_python
  Variables: COOKIE HEADER INVALID_LOCATION_TEMPL PATH PRIMITIVE_TYPES QUERY SCHEMA_TYPE SUPPORTED_LOCATIONS _SUPPORTED_MEDIA_TYPES api_request_body api_request_body_properties array_type base_url: default: default_val description description: description_str formatted_params formatted_props formatted_request_body_props items location location: logger media_type: method: name: nested_props operation operation_id operation_id: operation_name param_name parameters params path: prop_desc prop_name prop_required prop_schema prop_type properties properties: ref_name references_used references_used: request_body request_body: required: required_properties required_props schema schema_type schema_type, schema_type: spec type: type_ typescript_definition
  Usages: Any BaseModel Dict Enum Field HTTPVerb List MediaType NotImplementedError OpenAPISpec Optional Parameter Reference RequestBody Schema Sequence Tuple Type Union ValueError __members__ __name__ alias append base_url bool classmethod cls content default enum extend float format from_url get getLogger get_cleaned_operation_id get_operation get_parameters_for_operation get_referenced_schema get_request_body_for_operation indent int isinstance issubclass join langchain list loc logging media_type media_type_obj media_type_schema method name openapi openapi_schema_pydantic openapi_utils param param_in param_schema parameter path paths prop property pydantic ref required self spec_url split staticmethod str strip summary tools tuple type typing utils value warning

Python: /langchain/tools/openapi/utils/openapi_utils.py
  Classes: HTTPVerb OpenAPISpec
  Methods: _alert_unsupported_spec _components_strict _get_path_strict _get_referenced_parameter _get_referenced_request_body _get_root_referenced_parameter _get_root_referenced_request_body _get_root_referenced_schema _parameters_strict _paths_strict _request_bodies_strict _schemas_strict base_url from_file from_spec_dict from_str from_text from_url get_cleaned_operation_id get_methods_for_path get_operation get_parameters_for_operation get_referenced_schema get_request_body_for_operation parse_obj
  Variables: DELETE GET HEAD OPTIONS PATCH POST PUT TRACE item keys logger new_obj openapi_version operation operation_id operation_obj parameter parameters path path_ path_item ref_name request_bodies request_body response results schema schemas spec_dict swagger_version warning_message
  Usages: Components Dict Enum FileNotFoundError JSONDecodeError List OpenAPI Operation Optional Parameter Path PathItem Paths Reference RequestBody Schema Union ValidationError ValueError __members__ __name__ append classmethod cls components copy deepcopy dict enum error errors exists get getLogger getattr isinstance json key loads logging lstrip method obj open openapi_schema_pydantic operationId pathlib paths pop property pydantic read ref replace requestBodies requestBody requests safe_load self servers split staticmethod str sub super text typing url value verb warning yaml

Python: /tests/integration_tests/document_loaders/parsers/test_pdf_parsers.py
  Functions: _assert_with_parser test_pdfminer_parser test_pdfplumber_parser test_pymupdf_loader test_pypdf_parser test_pypdfium2_parser
  Variables: HELLO_PDF LAYOUT_PARSER_PAPER_PDF blob doc_generator docs metadata page_content
  Usages: BaseBlobParser Blob Iterator PDFMinerParser PDFPlumberParser Path PyMuPDFParser PyPDFParser PyPDFium2Parser __file__ base blob_loaders bool document_loaders from_path isinstance langchain lazy_parse len list parent parser parsers pathlib pdf splits_by_page startswith str typing

Python: /tests/integration_tests/retrievers/document_compressors/test_base.py
  Functions: test_document_compressor_pipeline
  Variables: actual docs embeddings pipeline_filter redundant_filter relevant_filter splitter texts
  Usages: CharacterTextSplitter Document DocumentCompressorPipeline EmbeddingsFilter EmbeddingsRedundantFilter OpenAIEmbeddings chunk_overlap chunk_size compress_documents document_compressors document_transformers join langchain len page_content retrievers schema separator similarity_threshold text_splitter transformers

Python: /tests/integration_tests/retrievers/document_compressors/test_chain_extract.py
  Functions: test_llm_chain_extractor test_llm_chain_extractor_empty test_llm_construction_with_kwargs
  Variables: actual compressor doc expected_not_returned expected_returned llm_chain_kwargs texts
  Usages: ChatOpenAI Document LLMChainExtractor all chat_models compress_documents document_compressors from_llm join langchain len llm_chain page_content retrievers schema verbose

Python: /tests/integration_tests/retrievers/document_compressors/test_chain_filter.py
  Functions: test_llm_chain_filter
  Variables: actual docs relevant_filter texts
  Usages: ChatOpenAI Document LLMChainFilter chat_models compress_documents document_compressors from_llm intersection langchain len llm page_content retrievers schema set

Python: /tests/integration_tests/retrievers/document_compressors/test_cohere_reranker.py
  Functions: test_cohere_reranker_init
  Usages: CohereRerank cohere_rerank document_compressors langchain retrievers

Python: /tests/integration_tests/retrievers/document_compressors/test_embeddings_filter.py
  Functions: test_embeddings_filter test_embeddings_filter_with_state
  Variables: actual docs docs[-1].state embedded_query embeddings query relevant_filter state texts
  Usages: Document EmbeddingsFilter OpenAIEmbeddings _DocumentWithState compress_documents document_compressors document_transformers embed_query intersection langchain len numpy page_content retrievers schema set similarity_threshold zeros

Python: /tests/integration_tests/vectorstores/docarray/test_hnsw.py
  Functions: test_add_texts test_from_texts test_sim_search_with_score_for_ip_metric
  Methods: test_max_marginal_relevance_search test_sim_search test_sim_search_all_configurations test_sim_search_by_vector test_sim_search_with_score texts
  Variables: docsearch embedding hnsw_vec_store metadatas out_doc, output texts
  Usages: DocArrayHnswSearch Document FakeEmbeddings List M Path add_texts allow_replace_deleted atol dist_metric doc_index docarray ef_construction fake_embeddings fetch_k fixture from_params from_texts index integration_tests isclose langchain len mark max_elements max_marginal_relevance_search metadata metric n_dim num_docs num_threads numpy out_doc out_score page_content parametrize pathlib pytest range result schema similarity_search similarity_search_by_vector similarity_search_with_score str tests tmp_path typing vectorstores work_dir

Python: /tests/integration_tests/vectorstores/docarray/test_in_memory.py
  Functions: test_add_texts test_from_texts
  Methods: test_max_marginal_relevance_search test_sim_search test_sim_search_by_vector test_sim_search_with_score texts
  Variables: docsearch embedding expected_score in_memory_vec_store metadatas out_doc, output texts
  Usages: DocArrayInMemorySearch Document FakeEmbeddings List Path add_texts atol doc_index docarray fake_embeddings fetch_k fixture from_params from_texts integration_tests isclose isinstance langchain len mark max_marginal_relevance_search metadata metric num_docs numpy out_doc out_score page_content parametrize pathlib pytest range schema similarity_search similarity_search_by_vector similarity_search_with_score str tests tmp_path typing vectorstores

File: /tests/integration_tests/vectorstores/docker-compose/elasticsearch.yml

File: /tests/integration_tests/vectorstores/docker-compose/weaviate.yml

File: /tests/integration_tests/vectorstores/fixtures/sharks.txt

Python: /tests/unit_tests/callbacks/tracers/test_base_tracer.py
  Classes: FakeTracer
  Methods: __init__ _persist_run test_tracer_chain_run test_tracer_chain_run_on_error test_tracer_chat_model_run test_tracer_llm_run test_tracer_llm_run_errors_no_start test_tracer_llm_run_on_error test_tracer_multiple_llm_runs test_tracer_nested_run test_tracer_nested_runs_on_error test_tracer_tool_run test_tracer_tool_run_on_error
  Variables: SERIALIZED SERIALIZED_CHAT chain_uuid compare_run exception llm_uuid1 llm_uuid2 llm_uuid3 manager num_runs run_manager self.runs: tool_uuid tracer uuid
  Usages: BaseTracer CallbackManager Exception LLMResult List Run TracerException action annotations append base callbacks child_execution_order child_runs datetime dict end_time error execution_order extra freeze_time freezegun generations handlers input input_str inputs langchain llm_output messages name on_chain_end on_chain_error on_chain_start on_chat_model_start on_llm_end on_llm_error on_llm_start on_tool_end on_tool_error on_tool_start output outputs parent_run_id prompts pytest raises range repr response run run_id run_type runs schema schemas self serialized start_time str super tracers typing utcnow uuid4

Python: /tests/unit_tests/callbacks/tracers/test_langchain_v1.py
  Functions: _persist_session load_default_session load_session new_session
  Classes: FakeTracer
  Methods: __init__ _persist_run _persist_session lang_chain_tracer_v1 load_default_session load_session new_session sample_tracer_session_v1 test_convert_run test_tracer_chain_run test_tracer_chain_run_on_error test_tracer_chat_model_run test_tracer_llm_run test_tracer_llm_run_errors_no_start test_tracer_llm_run_on_error test_tracer_multiple_llm_runs test_tracer_nested_run test_tracer_nested_runs_on_error test_tracer_tool_run test_tracer_tool_run_on_error
  Variables: SERIALIZED SERIALIZED_CHAT TEST_SESSION_ID chain_run chain_uuid compare_run converted_chain_run converted_llm_run converted_tool_run exception expected_chain_run expected_llm_run expected_tool_run lang_chain_tracer_v1.session llm_run llm_uuid1 llm_uuid2 llm_uuid3 manager num_runs run run_manager self.runs: tool_run tool_uuid tracer tracer.load_default_session uuid
  Usages: BaseTracer CallbackManager ChainRun Exception LLMResult LLMRun LangChainTracerV1 List MonkeyPatch Optional Run RunTypeEnum ToolRun TracerException TracerSessionV1 TracerSessionV1Base Union _convert_to_v1_run action annotations append base callbacks chain child_chain_runs child_execution_order child_llm_runs child_runs child_tool_runs context datetime dict end_time error execution_order extra fixture freeze_time freezegun generations handlers input_str inputs isinstance langchain langchain_v1 llm llm_output messages monkeypatch name on_chain_end on_chain_error on_chain_start on_chat_model_start on_llm_end on_llm_error on_llm_start on_tool_end on_tool_error on_tool_start output outputs parent_run_id parent_uuid prompts pytest raises range repr response run_id run_type runs schema schemas self serialized session session_id session_name setenv start_time str super tool tool_input tracers typing utcnow uuid4

Python: /tests/unit_tests/chains/query_constructor/test_parser.py
  Functions: _test_parse_value test_parse_comparison test_parse_disallowed_comparator test_parse_disallowed_operator test_parse_nested_operation test_parse_operation
  Methods: test_parse_bool_value test_parse_float_value test_parse_int_value test_parse_invalid_grammar test_parse_list_value test_parse_string_value test_parser_unpack_single_arg_operation
  Variables: DEFAULT_PARSER _not _or actual comp eq1 eq2 eq3 eq4 expected parsed parser
  Usages: AND Any Comparator Comparison EQ GTE LT NOT OR Operation Operator UnexpectedToken ValueError allowed_comparators allowed_operators arg arguments attribute cast chains comparator exceptions float get_parser input int langchain lark list lower mark operator parametrize parse pytest query_constructor raises replace str typing value

File: /tests/unit_tests/data/prompts/prompt_extra_args.json

File: /tests/unit_tests/data/prompts/prompt_missing_args.json

File: /tests/unit_tests/data/prompts/simple_prompt.json

Python: /tests/unit_tests/document_loaders/blob_loaders/test_filesystem_blob_loader.py
  Methods: test_file_names_exist test_show_progress toy_dir
  Variables: blobs expected_filenames file_names loader other_dir some_dir
  Usages: FileSystemBlobLoader Generator Path Sequence TemporaryDirectory blob blob_loaders count_matching_files document_loaders fixture glob hidden_file join langchain len list makedirs mark nested_file open parametrize path pathlib pytest relative_filename relative_filenames requires sorted str suffixes temp_dir tempfile test_html test_txt typing write yield_blobs

Python: /tests/unit_tests/document_loaders/blob_loaders/test_public_api.py
  Functions: test_public_api
  Usages: __all__ blob_loaders document_loaders langchain sorted

Python: /tests/unit_tests/document_loaders/blob_loaders/test_schema.py
  Functions: test_blob_from_pure_path test_blob_from_str_data test_blob_from_str_path test_blob_initialization_validator test_blob_initialized_with_binary_data test_blob_loader test_blob_mimetype_from_str_data
  Classes: TestLoader
  Methods: get_temp_file test_mime_type_inference yield_blobs
  Variables: blob content data mimetype path str_path
  Usages: Blob BlobLoader Generator Iterable NamedTemporaryFile Optional Path PathLike ValueError as_bytes as_bytes_io as_string blob_loaders bool bytes bytes_io contextlib contextmanager delete document_loaders encoding expected_mime_type from_data from_path guess_type isinstance langchain list mark match mime_type name parametrize pathlib pytest raises read remove schema self source str suffix temp_file temp_path tempfile typing write

Python: /tests/unit_tests/document_loaders/parsers/test_generic.py
  Classes: FirstCharParser SecondCharParser TestMimeBasedParser ThirdCharParser
  Methods: lazy_parse test_with_fallback_parser test_without_fallback_parser
  Variables: blob doc docs parser
  Usages: BaseBlobParser Blob Document Iterator MimeTypeBasedParser ValueError as_string base blob_loaders data document_loaders fallback_parser generic handlers langchain len match mimetype page_content parse parsers pytest raises schema self typing

Python: /tests/unit_tests/document_loaders/parsers/test_html_parsers.py
  Methods: test_bs_html_loader
  Variables: EXAMPLES HERE blob content docs file_path metadata parser
  Usages: BS4HTMLParser Blob Path __file__ blob_loaders document_loaders from_path get_text_separator html isinstance langchain lazy_parse len list mark page_content parent parsers pathlib pytest requires str

Python: /tests/unit_tests/document_loaders/parsers/test_pdf_parsers.py
  Functions: _assert_with_parser
  Methods: test_pdfminer_parser test_pymupdf_loader test_pypdf_parser test_pypdfium2_parser
  Variables: blob doc_generator docs metadata page_content
  Usages: BaseBlobParser Blob HELLO_PDF Iterator LAYOUT_PARSER_PAPER_PDF PDFMinerParser PyMuPDFParser PyPDFParser PyPDFium2Parser base blob_loaders bool data document_loaders from_path isinstance langchain lazy_parse len list mark parser parsers pdf pytest requires splits_by_page startswith str tests typing

Python: /tests/unit_tests/document_loaders/parsers/test_public_api.py
  Functions: test_parsers_public_api_correct
  Usages: __all__ document_loaders langchain parsers set

File: /tests/unit_tests/document_loaders/sample_documents/bibtex.bib

File: /tests/unit_tests/document_loaders/sample_documents/empty_export.enex

File: /tests/unit_tests/document_loaders/sample_documents/sample_notebook.enex

File: /tests/unit_tests/document_loaders/sample_documents/sample_notebook_2.enex

File: /tests/unit_tests/document_loaders/sample_documents/sample_notebook_emptynote.enex

File: /tests/unit_tests/document_loaders/sample_documents/sample_notebook_missingcontenttag.enex

File: /tests/unit_tests/document_loaders/sample_documents/sample_notebook_missingmetadata.enex

File: /tests/unit_tests/document_loaders/test_docs/telegram.json

File: /tests/unit_tests/document_loaders/test_docs/telegram_channel.json

Python: /tests/unit_tests/evaluation/qa/test_eval_chain.py
  Methods: test_context_eval_chain test_eval_chain
  Variables: example fake_qa_eval_chain outputs prediction
  Usages: ContextQAEvalChain CotQAEvalChain FakeLLM QAEvalChain Type chain_cls eval_chain evaluate evaluation fake_llm from_llm langchain llms mark parametrize platform pytest reason skipif startswith sys tests typing unit_tests

File: /tests/unit_tests/load/__snapshots__/test_dump.ambr

Python: /tests/unit_tests/memory/chat_message_histories/test_file.py
  Functions: test_add_messages test_clear_messages test_multiple_sessions
  Methods: file_chat_message_history
  Variables: expected_content file_chat_message_history file_path messages second_session_chat_message_history
  Usages: AIMessage FileChatMessageHistory Generator HumanMessage Path TemporaryDirectory add_ai_message add_user_message chat_message_histories clear content fixture isinstance langchain len memory pathlib pytest schema str temp_dir tempfile typing

Python: /tests/unit_tests/memory/chat_message_histories/test_sql.py
  Functions: test_add_messages test_clear_messages test_multiple_sessions
  Methods: sql_histories
  Variables: con_str file_path message_history messages other_history sql_history,
  Usages: AIMessage HumanMessage Path SQLChatMessageHistory Tuple add_ai_message add_user_message chat_message_histories clear connection_string content fixture isinstance langchain len memory param params pathlib pytest request schema session_id sql_history table_name tmp_path typing

Python: /tests/unit_tests/memory/chat_message_histories/test_zep.py
  Methods: test_add_ai_message test_add_user_message test_append test_clear test_messages test_search zep_chat
  Variables: mock_memory: mock_zep_client: result zep_chat.zep_client zep_chat.zep_client.get_memory.return_value zep_chat:
  Usages: AIMessage ANY HumanMessage Memory Message MockerFixture Summary TYPE_CHECKING ZepChatMessageHistory ZepClient add_ai_message add_memory add_message add_user_message assert_called_once assert_called_once_with autospec chat_message_histories clear content delete_memory fixture get_memory isinstance langchain len limit mark memory messages metadata mock_memory mock_zep_client mocker patch pytest pytest_mock requires return_value role schema search search_memory summary typing zep_client zep_python

Python: /tests/unit_tests/retrievers/self_query/test_pinecone.py
  Functions: test_visit_comparison test_visit_operation
  Variables: DEFAULT_TRANSLATOR actual comp expected
  Usages: AND Comparator Comparison EQ LT Operation Operator PineconeTranslator arguments attribute chains comparator langchain operator pinecone query_constructor retrievers self_query value visit_comparison visit_operation

Python: /tests/unit_tests/tools/file_management/test_copy.py
  Functions: test_copy_file test_copy_file_errs_outside_root_dir test_copy_file_with_root_dir
  Variables: destination_file result source_file tool
  Usages: CopyFileTool INVALID_PATH_TEMPLATE Path TemporaryDirectory arg_name copy exists file_management format langchain pathlib read_text root_dir run str temp_dir tempfile tools utils value write_text

Python: /tests/unit_tests/tools/file_management/test_file_search.py
  Functions: test_file_search test_file_search_errs_outside_root_dir test_file_search_with_root_dir
  Variables: file_1 file_2 matches result tool
  Usages: FileSearchTool INVALID_PATH_TEMPLATE Path TemporaryDirectory arg_name file_management file_search format langchain len name pathlib root_dir run split temp_dir tempfile tools utils value write_text

Python: /tests/unit_tests/tools/file_management/test_list_dir.py
  Functions: test_list_directory test_list_directory_errs_outside_root_dir test_list_directory_with_root_dir
  Variables: entries file_1 file_2 result tool
  Usages: INVALID_PATH_TEMPLATE ListDirectoryTool Path TemporaryDirectory arg_name file_management format langchain list_dir pathlib root_dir run set split temp_dir tempfile tools utils value write_text

Python: /tests/unit_tests/tools/file_management/test_move.py
  Functions: test_move_file test_move_file_errs_outside_root_dir test_move_file_with_root_dir
  Variables: destination_file result source_file tool
  Usages: INVALID_PATH_TEMPLATE MoveFileTool Path TemporaryDirectory arg_name exists file_management format langchain move pathlib read_text root_dir run str temp_dir tempfile tools utils value write_text

Python: /tests/unit_tests/tools/file_management/test_read.py
  Functions: test_read_file test_read_file_with_root_dir
  Variables: result tool
  Usages: Path ReadFileTool TemporaryDirectory file_management langchain open pathlib read root_dir run str temp_dir tempfile tools write

Python: /tests/unit_tests/tools/file_management/test_toolkit.py
  Functions: test_file_toolkit_get_tools test_file_toolkit_get_tools_with_selection test_file_toolkit_invalid_tool test_file_toolkit_root_dir
  Variables: root_dirs tool_names toolkit tools
  Usages: BaseTool FileManagementToolkit TemporaryDirectory ValueError agent_toolkits agents all base file_management get_tools hasattr isinstance langchain len name pytest raises root_dir selected_tools temp_dir tempfile tool

Python: /tests/unit_tests/tools/file_management/test_utils.py
  Functions: test_get_validated_relative_path test_get_validated_relative_path_errs_for_symlink_outside_root test_get_validated_relative_path_errs_on_absolute test_get_validated_relative_path_errs_on_parent_dir test_get_validated_relative_path_for_symlink_inside_root
  Variables: expected matches outside_path result root symlink_path target_path target_path_ user_path
  Usages: FileValidationError Path TemporaryDirectory __file__ file_management get_validated_relative_path langchain match parent pathlib pytest raises resolve symlink_to temp_dir tempfile tools unlink utils

Python: /tests/unit_tests/tools/file_management/test_write.py
  Functions: test_write_file test_write_file_errs_outside_root_dir test_write_file_with_root_dir
  Variables: file_path result tool
  Usages: INVALID_PATH_TEMPLATE Path TemporaryDirectory WriteFileTool arg_name exists file_management format langchain pathlib read_text root_dir run str temp_dir tempfile tools utils value write

Python: /tests/unit_tests/tools/openapi/test_api_models.py
  Functions: _get_paths_and_methods_from_spec_dictionary _get_test_specs http_paths_and_methods test_api_request_body_from_request_body_with_ref test_api_request_body_from_request_body_with_schema test_api_request_body_property_from_schema
  Methods: raw_spec test_parse_api_operations
  Variables: _DIR api_request_body api_request_body_property bar_prop expected_sub_properties foo_prop http_paths_and_methods media_type parsed_spec raw_spec.components request_body schema spec spec_name test_specs_dir valid_methods
  Usages: APIOperation APIRequestBody APIRequestBodyProperty AssertionError Components Exception HTTPVerb Info Iterable List MediaType OpenAPISpec Path Reference RequestBody Schema Tuple __file__ api_models append components content default description dict file files fixture from_file from_openapi_spec from_request_body from_schema info items json langchain len load mark method name open openapi openapi_schema_pydantic openapi_utils parametrize parent path path_item path_name pathlib properties pytest read ref references_used required root safe_load schemas startswith str suffix test_spec title tools type typing utils value verb version walk yaml

Python: /tests/unit_tests/tools/powerbi/test_powerbi.py
  Functions: test_power_bi_can_be_imported
  Usages: PowerBIDataset PowerBIToolkit QueryPowerBITool agent_toolkits agents create_pbi_agent langchain powerbi tool tools utilities

Python: /tests/unit_tests/tools/python/test_python.py
  Functions: test_python_repl_print test_python_repl_tool_single_input test_sanitize_input
  Methods: test_python_ast_repl_one_line_exception test_python_ast_repl_one_line_print test_python_ast_repl_one_line_return test_python_ast_repl_print test_python_ast_repl_raise_exception test_python_ast_repl_return test_python_ast_repl_tool_single_input test_repl_print_python_backticks
  Variables: actual arr data expected expected_outputs program query tool
  Usages: PythonAstREPLTool PythonREPLTool array int is_single_input langchain locals mark numpy pytest python reason run sanitize_input skipif strip sys tools version_info

Python: /tests/unit_tests/tools/requests/test_tool.py
  Functions: test_parse_input test_requests_delete_tool test_requests_get_tool test_requests_patch_tool test_requests_post_tool test_requests_put_tool
  Classes: _MockTextRequestsWrapper
  Methods: adelete aget apatch apost aput delete get mock_requests_wrapper patch post put
  Variables: expected_output input_text tool
  Usages: Any Dict RequestsDeleteTool RequestsGetTool RequestsPatchTool RequestsPostTool RequestsPutTool TextRequestsWrapper _parse_input arun asyncio data fixture kwargs langchain pytest requests requests_wrapper run staticmethod str tools typing url

Python: /tests/unit_tests/tools/shell/test_shell.py
  Functions: test_shell_input_validation test_shell_tool_init test_shell_tool_run test_shell_tool_run_str
  Methods: test_shell_tool_arun
  Variables: result shell_input shell_tool test_commands
  Usages: ShellInput ShellTool _arun _run args_schema asyncio catch_warnings commands description isinstance langchain len list mark message name process pytest record shell str strip tool tools warnings

PythonNotebook: /docs/modules/agents/agent_executors/examples/agent_vectorstore.ipynb
  Variables: agent doc_path docs docsearch documents embeddings llm loader relevant_parts ruff ruff_db ruff_texts state_of_union text_splitter texts tools
  Usages: AgentType BaseTool CharacterTextSplitter Chroma LLMMathChain OpenAI OpenAIEmbeddings Path RetrievalQA SerpAPIWrapper TextLoader Tool WebBaseLoader ZERO_SHOT_REACT_DESCRIPTION absolute agents append as_retriever chain_type chains chunk_overlap chunk_size collection_name description document_loaders from_chain_type from_documents func initialize_agent langchain llms load name openai parts pathlib retriever return_direct run split_documents str temperature vectorstores verbose

PythonNotebook: /docs/modules/agents/agent_executors/examples/async_agent.ipynb
  Variables: agent elapsed llm questions tasks tools
  Usages: AgentType ClientSession LangChainTracer OpenAI StdOutCallbackHandler ZERO_SHOT_REACT_DESCRIPTION agents aiohttp arun asyncio callbacks gather initialize_agent langchain llms load_tools perf_counter print run stdout temperature time tracers verbose

PythonNotebook: /docs/modules/agents/agent_executors/examples/chatgpt_clone.ipynb
  Variables: chatgpt_chain docker_input output prompt template
  Usages: ConversationBufferWindowMemory ConversationChain LLMChain OpenAI PromptTemplate human_input input_variables langchain llm memory predict print temperature verbose

PythonNotebook: /docs/modules/agents/agent_executors/examples/handle_parsing_errors.ipynb
  Functions: _handle_error
  Variables: mrkl search tools
  Usages: AGENT_TO_CLASS AgentType CHAT_ZERO_SHOT_REACT_DESCRIPTION ChatOpenAI LLMMathChain OpenAI SQLDatabase SQLDatabaseChain SerpAPIWrapper Tool agent agents chat_models description error func handle_parsing_errors initialize_agent langchain name run str temperature types verbose

PythonNotebook: /docs/modules/agents/agent_executors/examples/intermediate_steps.ipynb
  Variables: agent llm response tools
  Usages: AgentType OpenAI ZERO_SHOT_REACT_DESCRIPTION agents dumps indent initialize_agent json langchain llms load_tools model_name print return_intermediate_steps temperature verbose

PythonNotebook: /docs/modules/agents/agent_executors/examples/max_iterations.ipynb
  Variables: adversarial_prompt agent llm tools
  Usages: AgentType OpenAI Tool ZERO_SHOT_REACT_DESCRIPTION agents description early_stopping_method func initialize_agent langchain llms load_tools max_iterations name run temperature verbose

PythonNotebook: /docs/modules/agents/agent_executors/examples/max_time_limit.ipynb
  Variables: adversarial_prompt agent llm tools
  Usages: AgentType OpenAI Tool ZERO_SHOT_REACT_DESCRIPTION agents description early_stopping_method func initialize_agent langchain llms load_tools max_execution_time name run temperature verbose

PythonNotebook: /docs/modules/agents/agent_executors/examples/sharedmemory_for_tools.ipynb
  Variables: agent agent_chain llm_chain memory prefix prompt readonlymemory search suffix summry_chain template tools
  Usages: AgentExecutor ConversationBufferMemory GoogleSearchAPIWrapper LLMChain OpenAI PromptTemplate ReadOnlySharedMemory Tool ZeroShotAgent agents buffer create_prompt description from_agent_and_tools func input input_variables langchain llm memory_key name print run temperature utilities verbose

PythonNotebook: /docs/modules/agents/agents/examples/chat_conversation_agent.ipynb
  Variables: OPENAI_API_KEY SERPAPI_API_KEY agent_chain llm memory search tools
  Usages: AgentType CHAT_CONVERSATIONAL_REACT_DESCRIPTION ChatOpenAI ConversationBufferMemory SerpAPIWrapper Tool agent agents chat_models description func getpass google initialize_agent input install langchain memory_key name openai openai_api_key results return_messages run serpapi_api_key temperature utilities verbose

PythonNotebook: /docs/modules/agents/agents/examples/conversational_agent.ipynb
  Variables: agent_chain llm memory search tools
  Usages: AgentType CONVERSATIONAL_REACT_DESCRIPTION ConversationBufferMemory OpenAI SerpAPIWrapper Tool agent agents description func initialize_agent input langchain memory_key name run temperature utilities verbose

PythonNotebook: /docs/modules/agents/agents/examples/mrkl.ipynb
  Variables: db_chain llm llm_math_chain mrkl search tools
  Usages: AgentType LLMMathChain OpenAI SQLDatabase SQLDatabaseChain SerpAPIWrapper Tool ZERO_SHOT_REACT_DESCRIPTION agent agents description from_llm from_uri func initialize_agent langchain name run temperature verbose

PythonNotebook: /docs/modules/agents/agents/examples/mrkl_chat.ipynb
  Variables: db_chain llm llm1 llm_math_chain mrkl search tools
  Usages: AgentType CHAT_ZERO_SHOT_REACT_DESCRIPTION ChatOpenAI LLMMathChain OpenAI SQLDatabase SQLDatabaseChain SerpAPIWrapper Tool agent agents chat_models description from_llm from_uri func initialize_agent langchain name run temperature verbose

PythonNotebook: /docs/modules/agents/agents/examples/react.ipynb
  Variables: docstore llm question react tools
  Usages: AgentType DocstoreExplorer OpenAI REACT_DOCSTORE Tool Wikipedia agent agents base description func initialize_agent langchain lookup model_name name run search temperature verbose

PythonNotebook: /docs/modules/agents/agents/examples/self_ask_with_search.ipynb
  Variables: llm search self_ask_with_search tools
  Usages: AgentType OpenAI SELF_ASK_WITH_SEARCH SerpAPIWrapper Tool agent agents description func initialize_agent langchain name run temperature verbose

PythonNotebook: /docs/modules/agents/agents/examples/structured_chat.ipynb
  Variables: agent_chain async_browser browser_toolkit chat_history llm memory os.environ["LANGCHAIN_TRACING"] response tools
  Usages: AgentType ChatOpenAI ConversationBufferMemory MessagesPlaceholder PlayWrightBrowserToolkit STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION agent agent_kwargs agent_toolkits agents apply arun chat_models create_async_playwright_browser create_sync_playwright_browser environ from_browser get_tools initialize_agent input langchain memory_key nest_asyncio playwright print prompts return_messages temperature utils variable_name verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/azure_cognitive_services.ipynb
  Variables: agent audio audio_file llm os.environ["AZURE_COGS_ENDPOINT"] os.environ["AZURE_COGS_KEY"] os.environ["AZURE_COGS_REGION"] os.environ["OPENAI_API_KEY"] toolkit
  Usages: AgentType Audio AzureCognitiveServicesToolkit IPython OpenAI STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION agent_toolkits agents display environ get_tools initialize_agent langchain name run temperature tool tools verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/csv.ipynb
  Variables: agent
  Usages: OpenAI agents create_csv_agent langchain llms run temperature verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/gmail.ipynb
  Variables: agent api_resource credentials llm toolkit tools
  Usages: AgentType GmailToolkit OpenAI STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION agent_toolkits agents api auth beautifulsoup4 build_resource_service client client_secrets_file dev get_gmail_credentials get_tools gmail google httplib2 initialize_agent install langchain null oauthlib python run scopes temperature token_file upgrade utils

PythonNotebook: /docs/modules/agents/toolkits/examples/jira.ipynb
  Variables: agent jira llm os.environ["JIRA_API_TOKEN"] os.environ["JIRA_INSTANCE_URL"] os.environ["JIRA_USERNAME"] os.environ["OPENAI_API_KEY"] toolkit
  Usages: AgentType JiraAPIWrapper JiraToolkit OpenAI ZERO_SHOT_REACT_DESCRIPTION agent_toolkits agents api atlassian environ from_jira_api_wrapper get_tools initialize_agent install langchain llms pip python run temperature utilities verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/json.ipynb
  Variables: data json_agent_executor json_spec json_toolkit
  Usages: AgentExecutor FullLoader JsonSpec JsonToolkit LLMChain Loader OpenAI TextRequestsWrapper agent_toolkits agents chains create_json_agent dict_ json langchain llm llms load max_value_length open openai requests run spec temperature tool toolkit tools verbose yaml

File: /docs/modules/agents/toolkits/examples/openai_openapi.yml

PythonNotebook: /docs/modules/agents/toolkits/examples/openapi.ipynb
  Functions: construct_spotify_auth_headers count_tokens
  Variables: access_token data enc endpoints headers https://raw.githubusercontent.com/APIs-guru/openapi-directory/main/APIs/spotify.com/1.0.0/openapi.yaml https://raw.githubusercontent.com/openai/openai-openapi/master/openapi.yaml https://www.klarna.com/us/shopping/public/openai/v0/api-docs json_spec klarna_api_spec llm openai_agent openai_api_spec openai_requests_wrapper openapi_agent_executor openapi_toolkit raw_klarna_api_spec raw_openai_api_spec raw_spotify_api_spec requests_wrapper scopes spotify_agent spotify_api_spec user_query
  Usages: APIs FullLoader JsonSpec Loader OpenAI OpenAPIToolkit RequestsWrapper TextRequestsWrapper agent_toolkits agents api com create_openapi_agent dict dict_ directory docs dump encode encoding_for_model from_llm get getenv githubusercontent guru https items join json keys klarna klarna_openapi langchain len list llms load main master max_value_length model_name open openai openai_openapi openapi operation operations planner prompt_for_user_token public raw raw_spec reduce_openapi_spec requests route run scope shopping spec spotify spotify_openapi spotipy temperature tiktoken tool toolkit tools util verbose www yaml

PythonNotebook: /docs/modules/agents/toolkits/examples/openapi_nla.ipynb
  Variables: klarna_toolkit llm mrkl natural_language_api_tools natural_language_tools openapi_format_instructions requests speak_toolkit spoonacular_api_key spoonacular_toolkit user_input
  Usages: APIOperation AgentType LLMChain List NLAToolkit OpenAI OpenAPISpec Optional PromptTemplate Requests Tool ZERO_SHOT_REACT_DESCRIPTION agent agent_kwargs agent_toolkits agents chains from_llm_and_url get_tools headers initialize_agent langchain len llms max_text_length max_tokens print prompts run temperature tools typing verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/pandas.ipynb
  Variables: agent df1 df1["Age"]
  Usages: OpenAI agents copy create_pandas_dataframe_agent fillna langchain llms mean pandas read_csv run temperature verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/playwright.ipynb
  Variables: agent_chain async_browser get_elements_tool llm navigate_tool result toolkit tools tools_by_name
  Usages: AgentType ChatAnthropic PlayWrightBrowserToolkit STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION agent agent_toolkits agents apply arun chat_models create_async_playwright_browser create_sync_playwright_browser from_browser get_tools initialize_agent langchain name nest_asyncio playwright print temperature tool utils verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/powerbi.ipynb
  Variables: agent_executor fast_llm few_shots smart_llm toolkit
  Usages: AgentExecutor ChatOpenAI DefaultAzureCredential PowerBIDataset PowerBIToolkit agent_toolkits agents azure chat_models create_pbi_agent credential dataset_id examples identity langchain llm max_tokens model_name powerbi run table_names temperature utilities verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/python.ipynb
  Variables: agent_executor
  Usages: OpenAI PythonREPL PythonREPLTool agent_toolkits agents create_python_agent langchain llm llms max_tokens openai python run temperature tool tools verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/spark.ipynb
  Variables: agent csv_file_path org.apache.spark:spark-connect_2 os.environ["OPENAI_API_KEY"] spark
  Usages: OpenAI SparkSession agents apache builder connect connect_2 create_spark_dataframe_agent csv environ getOrCreate header inferSchema langchain llm llms master org packages pyspark read remote run sbin server show sql start stop temperature verbose

PythonNotebook: /docs/modules/agents/toolkits/examples/spark_sql.ipynb
  Variables: agent_executor csv_file_path llm schema spark spark_sql table toolkit
  Usages: ChatOpenAI SparkSQL SparkSQLToolkit SparkSession agent_toolkits agents builder chat_models create_spark_sql_agent csv getOrCreate header inferSchema langchain pyspark read run saveAsTable show sql temperature utilities verbose write

PythonNotebook: /docs/modules/agents/toolkits/examples/sql_database.ipynb
  Variables: agent_executor toolkit
  Usages: AgentExecutor OpenAI SQLDatabase SQLDatabaseToolkit agent_toolkits agents create_sql_agent from_uri langchain llm llms openai run sql_database temperature verbose

File: /docs/modules/agents/toolkits/examples/titanic.csv

File: /docs/modules/agents/toolkits/examples/titanic_age_fillna.csv

PythonNotebook: /docs/modules/agents/toolkits/examples/vectorstore.ipynb
  Variables: agent_executor docs documents embeddings llm loader router_toolkit ruff_store ruff_texts ruff_vectorstore_info state_of_union_store text_splitter texts toolkit vectorstore_info
  Usages: CharacterTextSplitter Chroma OpenAI OpenAIEmbeddings TextLoader VectorDBQA VectorStoreInfo VectorStoreRouterToolkit VectorStoreToolkit WebBaseLoader agent_toolkits agents chunk_overlap chunk_size collection_name create_vectorstore_agent create_vectorstore_router_agent description document_loaders from_documents langchain load name openai run split_documents temperature vectorstore vectorstores verbose

PythonNotebook: /docs/modules/agents/tools/examples/apify.ipynb
  Variables: apify index loader os.environ["APIFY_API_TOKEN"] os.environ["OPENAI_API_KEY"] query result
  Usages: ApifyWrapper Document VectorstoreIndexCreator actor_id base call_actor dataset_mapping_function document_loaders environ from_loaders indexes item langchain metadata page_content print query_with_sources run_input utilities

PythonNotebook: /docs/modules/agents/tools/examples/arxiv.ipynb
  Variables: agent_chain arxiv docs llm tools
  Usages: AgentType ArxivAPIWrapper ChatOpenAI ZERO_SHOT_REACT_DESCRIPTION agent agents chat_models initialize_agent install langchain load_tools run temperature utilities verbose

PythonNotebook: /docs/modules/agents/tools/examples/awslambda.ipynb
  Variables: agent llm tools
  Usages: AgentType OpenAI ZERO_SHOT_REACT_DESCRIPTION agents awslambda_tool_description awslambda_tool_name boto3 dev function_name initialize_agent install langchain load_tools null run temperature verbose

PythonNotebook: /docs/modules/agents/tools/examples/bash.ipynb
  Variables: llm self_ask_with_search shell_tool shell_tool.description
  Usages: AgentType CHAT_ZERO_SHOT_REACT_DESCRIPTION ChatOpenAI ShellTool agent agents args chat_models description initialize_agent langchain print replace run temperature tools verbose

PythonNotebook: /docs/modules/agents/tools/examples/bing_search.ipynb
  Variables: os.environ["BING_SEARCH_URL"] os.environ["BING_SUBSCRIPTION_KEY"] search
  Usages: BingSearchAPIWrapper environ langchain results run utilities

PythonNotebook: /docs/modules/agents/tools/examples/brave_search.ipynb
  Variables: api_key tool
  Usages: BraveSearch from_api_key langchain run search_kwargs tools

PythonNotebook: /docs/modules/agents/tools/examples/chatgpt_plugins.ipynb
  Variables: agent_chain llm tool tools
  Usages: AIPluginTool AgentType ChatOpenAI ZERO_SHOT_REACT_DESCRIPTION agent agents chat_models from_plugin_url initialize_agent langchain load_tools run temperature verbose

PythonNotebook: /docs/modules/agents/tools/examples/ddg.ipynb
  Variables: search
  Usages: DuckDuckGoSearchRun langchain run tools

PythonNotebook: /docs/modules/agents/tools/examples/filesystem.ipynb
  Variables: read_tool, toolkit tools working_directory
  Usages: CopyFileTool DeleteFileTool FileManagementToolkit ListDirectoryTool MoveFileTool ReadFileTool TemporaryDirectory WriteFileTool agent_toolkits agents file_management get_tools langchain list_tool name read_tool root_dir run selected_tools str tempfile write_tool

PythonNotebook: /docs/modules/agents/tools/examples/google_places.ipynb
  Variables: os.environ["GPLACES_API_KEY"] places
  Usages: GooglePlacesTool environ langchain run tools

PythonNotebook: /docs/modules/agents/tools/examples/google_search.ipynb
  Functions: top5_results
  Variables: os.environ["GOOGLE_API_KEY"] os.environ["GOOGLE_CSE_ID"] search tool
  Usages: GoogleSearchAPIWrapper Tool description environ func langchain name query results run tools utilities

PythonNotebook: /docs/modules/agents/tools/examples/google_serper.ipynb
  Variables: llm os.environ["SERPER_API_KEY"] os.environ['OPENAI_API_KEY'] results search self_ask_with_search tools
  Usages: AgentType GoogleSerperAPIWrapper OpenAI SELF_ASK_WITH_SEARCH Tool agent agents description environ func initialize_agent langchain llms name openai pprint run tbs temperature type utilities verbose

PythonNotebook: /docs/modules/agents/tools/examples/gradio_tools.ipynb
  Variables: agent llm local_file_path memory output tools
  Usages: ConversationBufferMemory Image ImageCaptioningTool OpenAI PIL StableDiffusionPromptGeneratorTool StableDiffusionTool TextToVideoTool agents display gradio_tools initialize_agent input langchain llms memory_key open run temperature verbose

PythonNotebook: /docs/modules/agents/tools/examples/graphql.ipynb
  Variables: agent graphql_fields llm suffix tools
  Usages: AgentType GraphQLAPIWrapper OpenAI ZERO_SHOT_REACT_DESCRIPTION agents dev gql graphql_endpoint httpx initialize_agent install langchain load_tools null pip run temperature utilities verbose

PythonNotebook: /docs/modules/agents/tools/examples/huggingface_tools.ipynb
  Variables: tool
  Usages: agents description dev huggingface_hub install langchain load_huggingface_tool name null print run transformers upgrade

PythonNotebook: /docs/modules/agents/tools/examples/human_tools.ipynb
  Functions: get_input
  Variables: agent_chain contents line llm math_llm tool tools
  Usages: AgentType ChatOpenAI EOFError HumanInputRun OpenAI ZERO_SHOT_REACT_DESCRIPTION agent agents append chat_models initialize_agent input input_func join langchain llms load_tools print run str temperature verbose

PythonNotebook: /docs/modules/agents/tools/examples/ifttt.ipynb
  Variables: key tool url
  Usages: IFTTTWebhook description environ ifttt langchain name run tools

PythonNotebook: /docs/modules/agents/tools/examples/metaphor_search.ipynb
  Variables: agent_chain async_browser extract_text llm metaphor_tool navigate_tool os.environ["METAPHOR_API_KEY"] search toolkit tools tools_by_name
  Usages: AgentType ChatOpenAI MetaphorSearchAPIWrapper MetaphorSearchResults PlayWrightBrowserToolkit STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION agent agent_toolkits agents api_wrapper chat_models create_async_playwright_browser environ from_browser get_tools initialize_agent keys langchain model_name name playwright print results run temperature tool utilities utils verbose

PythonNotebook: /docs/modules/agents/tools/examples/openweathermap.ipynb
  Variables: agent_chain llm os.environ["OPENAI_API_KEY"] os.environ["OPENWEATHERMAP_API_KEY"] tools weather weather_data
  Usages: AgentType OpenAI OpenWeatherMapAPIWrapper ZERO_SHOT_REACT_DESCRIPTION agent agents environ initialize_agent langchain llms load_tools print run temperature utilities verbose

PythonNotebook: /docs/modules/agents/tools/examples/pubmed.ipynb
  Variables: tool
  Usages: PubmedQueryRun langchain run tools

PythonNotebook: /docs/modules/agents/tools/examples/python.ipynb
  Variables: python_repl repl_tool
  Usages: PythonREPL Tool agents description func langchain name run utilities

PythonNotebook: /docs/modules/agents/tools/examples/requests.ipynb
  Variables: requests requests_tools
  Usages: TextRequestsWrapper agents get langchain load_tools requests_wrapper utilities

PythonNotebook: /docs/modules/agents/tools/examples/sceneXplain.ipynb
  Variables: agent llm memory os.environ["SCENEX_API_KEY"] output tool tools
  Usages: ConversationBufferMemory OpenAI SceneXplainTool agents environ initialize_agent input langchain llms load_tools memory_key print run temperature verbose

PythonNotebook: /docs/modules/agents/tools/examples/search_tools.ipynb
  Variables: agent llm tools
  Usages: AgentType OpenAI ZERO_SHOT_REACT_DESCRIPTION agents initialize_agent langchain llms load_tools run searx_host temperature verbose

PythonNotebook: /docs/modules/agents/tools/examples/searx_search.ipynb
  Variables: results search
  Usages: SearxSearchWrapper categories engines filter langchain language list num_results pprint run searx_host time_range utilities

PythonNotebook: /docs/modules/agents/tools/examples/serpapi.ipynb
  Variables: params repl_tool search
  Usages: SerpAPIWrapper Tool agents description func langchain name run utilities

PythonNotebook: /docs/modules/agents/tools/examples/twilio.ipynb
  Variables: twilio
  Usages: TwilioAPIWrapper langchain run utilities

PythonNotebook: /docs/modules/agents/tools/examples/wikipedia.ipynb
  Variables: wikipedia
  Usages: WikipediaAPIWrapper install langchain run utilities

PythonNotebook: /docs/modules/agents/tools/examples/wolfram_alpha.ipynb
  Variables: os.environ["WOLFRAM_ALPHA_APPID"] wolfram
  Usages: WolframAlphaAPIWrapper environ install langchain pip run utilities wolfram_alpha wolframalpha

PythonNotebook: /docs/modules/agents/tools/examples/youtube.ipynb
  Variables: tool
  Usages: YouTubeSearchTool langchain run tools

PythonNotebook: /docs/modules/agents/tools/examples/zapier.ipynb
  Functions: nla_gmail nla_slack
  Variables: GMAIL_SEARCH_INSTRUCTIONS SLACK_HANDLE action actions agent gmail_chain instructions llm os.environ["OPENAI_API_KEY"] os.environ["ZAPIER_NLA_API_KEY"] overall_chain prompt_template reply_chain slack_chain template toolkit zapier
  Usages: AgentType LLMChain OpenAI PromptTemplate SimpleSequentialChain TransformChain ZERO_SHOT_REACT_DESCRIPTION ZapierNLARunAction ZapierNLAWrapper ZapierToolkit action_id agent_toolkits agents chains environ from_zapier_nla_wrapper get get_tools initialize_agent input_variables inputs langchain list llms next output_variables params_schema prompt prompts run startswith temperature tool tools transform utilities verbose zapier_description

PythonNotebook: /docs/modules/indexes/document_loaders/examples/airbyte_json.ipynb
  Variables: data
  Usages: AirbyteJSONLoader airbyte_local document_loaders json_data langchain load loader page_content print tmp

PythonNotebook: /docs/modules/indexes/document_loaders/examples/airtable.ipynb
  Variables: api_key base_id docs loader table_id
  Usages: AirtableLoader document_loaders eval install langchain len load page_content pip pyairtable

PythonNotebook: /docs/modules/indexes/document_loaders/examples/alibaba_cloud_maxcompute.ipynb
  Variables: ACCESS_ID SECRET_ACCESS_KEY base_query data endpoint loader project
  Usages: MaxComputeLoader access_id document_loaders from_params install langchain load metadata metadata_columns page_content page_content_columns print pyodps secret_access_key

PythonNotebook: /docs/modules/indexes/document_loaders/examples/apify_dataset.ipynb
  Variables: data index loader query result
  Usages: ApifyDatasetLoader Document VectorstoreIndexCreator base dataset_id dataset_item dataset_mapping_function docstore document document_loaders from_loaders indexes item langchain load metadata page_content print query_with_sources

PythonNotebook: /docs/modules/indexes/document_loaders/examples/arxiv.ipynb
  Variables: docs
  Usages: ArxivLoader document_loaders langchain len load load_max_docs metadata page_content query

PythonNotebook: /docs/modules/indexes/document_loaders/examples/audio.ipynb
  Variables: audio_file_path docs loader
  Usages: GenericLoader OpenAIWhisperParser document_loaders from_filesystem generic glob langchain load parser parsers

PythonNotebook: /docs/modules/indexes/document_loaders/examples/aws_s3_directory.ipynb
  Variables: loader
  Usages: S3DirectoryLoader document_loaders langchain load prefix

PythonNotebook: /docs/modules/indexes/document_loaders/examples/aws_s3_file.ipynb
  Variables: loader
  Usages: S3FileLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/azlyrics.ipynb
  Variables: data loader
  Usages: AZLyricsLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/azure_blob_storage_container.ipynb
  Variables: loader
  Usages: AzureBlobStorageContainerLoader conn_str container document_loaders langchain load prefix

PythonNotebook: /docs/modules/indexes/document_loaders/examples/azure_blob_storage_file.ipynb
  Variables: loader
  Usages: AzureBlobStorageFileLoader blob_name conn_str container document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/bibtex.ipynb
  Variables: bibtex_text docs
  Usages: BibtexLoader document_loaders file langchain load metadata open page_content print request urllib urlretrieve write

PythonNotebook: /docs/modules/indexes/document_loaders/examples/bilibili.ipynb
  Variables: loader
  Usages: BiliBiliLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/blackboard.ipynb
  Variables: documents loader
  Usages: BlackboardLoader bbrouter blackboard_course_url document_loaders langchain load load_all_recursively

PythonNotebook: /docs/modules/indexes/document_loaders/examples/blockchain.ipynb
  Variables: alchemyApiKey blockchainLoader blockchainType contractAddress nfts
  Usages: BlockchainDocumentLoader BlockchainType ETH_MAINNET POLYGON_MAINNET api_key blockchain contract_address document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/chatgpt_loader.ipynb
  Variables: loader
  Usages: ChatGPTLoader chatgpt document_loaders langchain load log_file num_logs

PythonNotebook: /docs/modules/indexes/document_loaders/examples/college_confidential.ipynb
  Variables: data loader
  Usages: CollegeConfidentialLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/confluence.ipynb
  Variables: documents loader
  Usages: ConfluenceLoader api_key document_loaders include_attachments langchain limit load max_pages space_key token url username

PythonNotebook: /docs/modules/indexes/document_loaders/examples/conll-u.ipynb
  Variables: document loader
  Usages: CoNLLULoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/copypaste.ipynb
  Variables: doc metadata text
  Usages: Document docstore document langchain page_content

PythonNotebook: /docs/modules/indexes/document_loaders/examples/csv.ipynb
  Variables: data docs loader
  Usages: CSVLoader UnstructuredCSVLoader csv_args csv_loader document_loaders file_path langchain load metadata mode print source_column

PythonNotebook: /docs/modules/indexes/document_loaders/examples/diffbot.ipynb
  Variables: loader urls
  Usages: DiffbotLoader api_token document_loaders environ get langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/discord.ipynb
  Variables: csv_exists expected_csv_path loader path
  Usages: DiscordChatLoader append axis concat discord document_loaders header ignore_index index_col input isfile join langchain listdir load pandas print read_csv sort user_id_col

PythonNotebook: /docs/modules/indexes/document_loaders/examples/docugami.ipynb
  Variables: DOCUGAMI_API_KEY EXCLUDE_KEYS chain_response docs document_content_description documents embedding llm loader metadata_field_info qa_chain retriever vectordb
  Usages: AttributeInfo Chroma DocugamiLoader Document OpenAI OpenAIEmbeddings RetrievalQA SelfQueryRetriever as_retriever base chain_type chains chromadb description docset_id document_ids document_loaders embeddings environ from_chain_type from_documents from_llm get install key langchain llms load lower lxml metadata name oetry openai pip query_constructor retrievers return_source_documents run schema self_query temperature tiktoken type vectorstores verbose

PythonNotebook: /docs/modules/indexes/document_loaders/examples/duckdb.ipynb
  Variables: data loader
  Usages: DuckDBLoader Nationals Payroll Reds Team csv document_loaders example file langchain load metadata_columns page_content_columns print

PythonNotebook: /docs/modules/indexes/document_loaders/examples/email.ipynb
  Variables: data loader
  Usages: OutlookMessageLoader UnstructuredEmailLoader document_loaders langchain load mode

PythonNotebook: /docs/modules/indexes/document_loaders/examples/embaas.ipynb
  Variables: blob blob_loader documents embaas_api_key file_loader os.environ["EMBAAS_API_KEY"]
  Usages: Blob EmbaasBlobLoader EmbaasLoader blob_loaders document_loaders embaas environ file_path from_path langchain load params print

PythonNotebook: /docs/modules/indexes/document_loaders/examples/epub.ipynb
  Variables: data loader
  Usages: UnstructuredEPubLoader document_loaders langchain load mode

PythonNotebook: /docs/modules/indexes/document_loaders/examples/evernote.ipynb
  Variables: loader
  Usages: EverNoteLoader document_loaders langchain load load_single_document

PythonNotebook: /docs/modules/indexes/document_loaders/examples/excel.ipynb
  Variables: docs loader
  Usages: UnstructuredExcelLoader document_loaders langchain load mode

PythonNotebook: /docs/modules/indexes/document_loaders/examples/facebook_chat.ipynb
  Variables: loader
  Usages: FacebookChatLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/fauna.ipynb
  Variables: docs field loader query secret
  Usages: FaunaLoader document_loaders fauna langchain lazy_load print value

PythonNotebook: /docs/modules/indexes/document_loaders/examples/figma.ipynb
  Functions: generate_code
  Variables: chat_prompt conversation figma_doc_retriever figma_loader gpt_4 human_message_prompt human_prompt_template index relevant_nodes response system_message_prompt system_prompt_template
  Usages: AIMessagePromptTemplate CharacterTextSplitter ChatOpenAI ChatPromptTemplate ConversationBufferWindowMemory ConversationChain FigmaFileLoader HumanMessagePromptTemplate LLMChain SystemMessagePromptTemplate VectorstoreIndexCreator as_retriever chains chat chat_models context document_loaders environ figma format_prompt from_loaders from_messages from_template get get_relevant_documents human_input indexes langchain memory model_name prompts temperature text text_splitter to_messages vectorstore

PythonNotebook: /docs/modules/indexes/document_loaders/examples/file_directory.ipynb
  Variables: doc_sources docs loader path text_loader_kwargs
  Usages: DirectoryLoader PythonLoader TextLoader doc document_loaders glob install langchain len load loader_cls loader_kwargs metadata pip show_progress silent_errors tqdm use_multithreading

PythonNotebook: /docs/modules/indexes/document_loaders/examples/git.ipynb
  Variables: branch data loader repo
  Usages: GitLoader GitPython Repo clone_from clone_url document_loaders endswith file_filter file_path git head install langchain len load print reference repo_path to_path

PythonNotebook: /docs/modules/indexes/document_loaders/examples/gitbook.ipynb
  Variables: all_pages_data loader page_data
  Usages: GitbookLoader document_loaders langchain len load load_all_paths print

PythonNotebook: /docs/modules/indexes/document_loaders/examples/github.ipynb
  Variables: ACCESS_TOKEN docs loader
  Usages: GitHubIssuesLoader access_token creator document_loaders getpass include_prs langchain load metadata page_content print repo

PythonNotebook: /docs/modules/indexes/document_loaders/examples/google_bigquery.ipynb
  Variables: ALIASED_QUERY BASE_QUERY data loader
  Usages: BigQueryLoader document_loaders langchain load metadata_columns page_content_columns print

PythonNotebook: /docs/modules/indexes/document_loaders/examples/google_cloud_storage_directory.ipynb
  Variables: loader
  Usages: GCSDirectoryLoader bucket document_loaders langchain load prefix project_name

PythonNotebook: /docs/modules/indexes/document_loaders/examples/google_cloud_storage_file.ipynb
  Variables: loader
  Usages: GCSFileLoader blob bucket document_loaders langchain load project_name

PythonNotebook: /docs/modules/indexes/document_loaders/examples/google_drive.ipynb
  Variables: docs loader
  Usages: GoogleDriveLoader api auth client document_loaders file_types folder_id google httplib2 install langchain load oauthlib python recursive upgrade

PythonNotebook: /docs/modules/indexes/document_loaders/examples/gutenberg.ipynb
  Variables: data loader
  Usages: GutenbergLoader document_loaders langchain load metadata page_content

PythonNotebook: /docs/modules/indexes/document_loaders/examples/hacker_news.ipynb
  Variables: data loader
  Usages: HNLoader document_loaders langchain load metadata page_content

PythonNotebook: /docs/modules/indexes/document_loaders/examples/html.ipynb
  Variables: data loader
  Usages: BSHTMLLoader UnstructuredHTMLLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/hugging_face_dataset.ipynb
  Variables: data dataset_name index loader name page_content_column query result
  Usages: HuggingFaceDatasetLoader VectorstoreIndexCreator document_loaders from_loaders hugging_face_dataset indexes langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/ifixit.ipynb
  Variables: data loader
  Usages: IFixitLoader document_loaders langchain load load_suggestions

PythonNotebook: /docs/modules/indexes/document_loaders/examples/image.ipynb
  Variables: data loader
  Usages: UnstructuredImageLoader document_loaders image langchain load mode

PythonNotebook: /docs/modules/indexes/document_loaders/examples/image_captions.ipynb
  Variables: index list_docs list_image_urls loader query
  Usages: Image ImageCaptionLoader PIL VectorstoreIndexCreator convert document_loaders from_loaders get indexes langchain load open path_images raw requests stream

PythonNotebook: /docs/modules/indexes/document_loaders/examples/imsdb.ipynb
  Variables: data loader
  Usages: IMSDbLoader document_loaders langchain load metadata page_content

PythonNotebook: /docs/modules/indexes/document_loaders/examples/iugu.ipynb
  Variables: index iugu_doc_retriever iugu_loader
  Usages: IuguLoader VectorstoreIndexCreator as_retriever document_loaders from_loaders indexes langchain vectorstore

PythonNotebook: /docs/modules/indexes/document_loaders/examples/joplin.ipynb
  Variables: docs loader
  Usages: JoplinLoader access_token document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/json.ipynb
  Functions: metadata_func
  Variables: data file_path loader metadata["sender_name"] metadata["source"] metadata["timestamp_ms"] source
  Usages: JSONLoader Path content_key dict document_loaders get index join jq_schema json langchain load loads metadata pathlib pprint read_text record split

PythonNotebook: /docs/modules/indexes/document_loaders/examples/jupyter_notebook.ipynb
  Variables: loader
  Usages: NotebookLoader document_loaders include_outputs langchain load max_output_length remove_newline

PythonNotebook: /docs/modules/indexes/document_loaders/examples/markdown.ipynb
  Variables: data loader markdown_path
  Usages: UnstructuredMarkdownLoader document_loaders langchain load mode

PythonNotebook: /docs/modules/indexes/document_loaders/examples/mastodon.ipynb
  Variables: documents loader
  Usages: MastodonTootsLoader doc document_loaders langchain load mastodon_accounts number_toots page_content print

PythonNotebook: /docs/modules/indexes/document_loaders/examples/mediawikidump.ipynb
  Variables: documents loader
  Usages: MWDumpLoader com document_loaders encoding gdedrouas git github https install langchain len load mediawiki mwparserfromhell mwtypes mwxml print python updates_schema_0 utilities xml_format_0

PythonNotebook: /docs/modules/indexes/document_loaders/examples/microsoft_powerpoint.ipynb
  Variables: data loader
  Usages: UnstructuredPowerPointLoader document_loaders langchain load mode

PythonNotebook: /docs/modules/indexes/document_loaders/examples/microsoft_word.ipynb
  Variables: data loader
  Usages: Docx2txtLoader UnstructuredWordDocumentLoader document_loaders docx2txt install langchain load mode

PythonNotebook: /docs/modules/indexes/document_loaders/examples/modern_treasury.ipynb
  Variables: index modern_treasury_doc_retriever modern_treasury_loader
  Usages: ModernTreasuryLoader VectorstoreIndexCreator as_retriever document_loaders from_loaders indexes langchain vectorstore

PythonNotebook: /docs/modules/indexes/document_loaders/examples/notion.ipynb
  Variables: docs loader
  Usages: NotionDirectoryLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/notiondb.ipynb
  Variables: DATABASE_ID NOTION_TOKEN docs loader
  Usages: NotionDBLoader database_id document_loaders getpass integration_token langchain load print request_timeout_sec

PythonNotebook: /docs/modules/indexes/document_loaders/examples/obsidian.ipynb
  Variables: docs loader
  Usages: ObsidianLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/odt.ipynb
  Variables: docs loader
  Usages: UnstructuredODTLoader document_loaders langchain load mode

PythonNotebook: /docs/modules/indexes/document_loaders/examples/pandas_dataframe.ipynb
  Variables: loader
  Usages: DataFrameLoader document_loaders head langchain load page_content_column pandas read_csv

PythonNotebook: /docs/modules/indexes/document_loaders/examples/pdf.ipynb
  Variables: content cur_fs cur_idx cur_text data docs faiss_index loader metadata os.environ['OPENAI_API_KEY'] pages semantic_snippets semantic_snippets[cur_idx].metadata['content_font'] snippets soup
  Usages: BeautifulSoup Document FAISS MathpixPDFLoader OnlinePDFLoader OpenAIEmbeddings PDFMinerLoader PDFMinerPDFasHTMLLoader PDFPlumberLoader PyMuPDFLoader PyPDFDirectoryLoader PyPDFLoader PyPDFium2Loader UnstructuredPDFLoader append bs4 doc docstore document document_loaders embeddings environ find find_all findall from_documents get getpass install int langchain load load_and_split max mode openai page_content print pypdf similarity_search str text update vectorstores

PythonNotebook: /docs/modules/indexes/document_loaders/examples/psychic.ipynb
  Variables: chain docsearch documents embeddings google_drive_loader text_splitter texts
  Usages: CharacterTextSplitter Chroma ConnectorId OpenAI OpenAIEmbeddings PsychicLoader RetrievalQAWithSourcesChain api_key as_retriever chain_type chains chunk_overlap chunk_size connection_id connector_id document_loaders from_chain_type from_documents gdrive install langchain llms load oetry openai pip psychicapi retriever return_only_outputs run split_documents temperature value vectorstores

PythonNotebook: /docs/modules/indexes/document_loaders/examples/pyspark_dataframe.ipynb
  Variables: loader spark
  Usages: PySparkDataFrameLoader SparkSession builder csv document_loaders getOrCreate header langchain load page_content_column pyspark read sql

PythonNotebook: /docs/modules/indexes/document_loaders/examples/readthedocs_documentation.ipynb
  Variables: docs loader
  Usages: ReadTheDocsLoader document_loaders features langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/reddit.ipynb
  Variables: documents loader
  Usages: RedditPostsLoader categories client_id client_secret document_loaders langchain load mode number_posts search_queries user_agent

PythonNotebook: /docs/modules/indexes/document_loaders/examples/roam.ipynb
  Variables: docs loader
  Usages: RoamLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/sitemap.ipynb
  Functions: remove_nav_and_header_elements
  Variables: docs documents header_elements loader nav_elements sitemap_loader sitemap_loader.requests_kwargs sitemap_loader.requests_per_second
  Usages: BeautifulSoup SitemapLoader apply beautifulsoup4 bs4 content decompose document_loaders element filter_urls find_all get_text install is_local langchain load nest_asyncio parsing_function pip requests_kwargs requests_per_second sitemap str web_path

PythonNotebook: /docs/modules/indexes/document_loaders/examples/slack.ipynb
  Variables: LOCAL_ZIPFILE SLACK_WORKSPACE_URL docs loader
  Usages: SlackDirectoryLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/snowflake.ipynb
  Variables: QUERY snowflake_documents snowflake_loader
  Usages: SNOWFLAKE_ACCOUNT SNOWFLAKE_DATABASE SNOWFLAKE_PASS SNOWFLAKE_ROLE SNOWFLAKE_SCHEMA SNOWFLAKE_USER SNOWFLAKE_WAREHOUSE SnowflakeLoader account connector database document_loaders install langchain load metadata_columns password pip print python query role schema settings snowflake snowflakeLoader user warehouse

PythonNotebook: /docs/modules/indexes/document_loaders/examples/spreedly.ipynb
  Variables: index spreedly_doc_retriever spreedly_loader
  Usages: SpreedlyLoader VectorstoreIndexCreator as_retriever document_loaders environ from_loaders get_relevant_documents indexes langchain vectorstore

PythonNotebook: /docs/modules/indexes/document_loaders/examples/stripe.ipynb
  Variables: index stripe_doc_retriever stripe_loader
  Usages: StripeLoader VectorstoreIndexCreator as_retriever document_loaders from_loaders indexes langchain vectorstore

PythonNotebook: /docs/modules/indexes/document_loaders/examples/subtitle.ipynb
  Variables: docs loader
  Usages: SRTLoader document_loaders install langchain load page_content pysrt

PythonNotebook: /docs/modules/indexes/document_loaders/examples/telegram.ipynb
  Variables: loader
  Usages: TelegramChatApiLoader TelegramChatFileLoader api_hash api_id chat_entity document_loaders langchain load user_name

PythonNotebook: /docs/modules/indexes/document_loaders/examples/tomarkdown.ipynb
  Variables: api_key docs loader
  Usages: ToMarkdownLoader document_loaders from_api_key langchain load page_content print url

PythonNotebook: /docs/modules/indexes/document_loaders/examples/toml.ipynb
  Variables: loader rule
  Usages: TomlLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/trello.ipynb
  Variables: API_KEY TOKEN documents loader
  Usages: TrelloLoader api_key card_filter document_loaders extra_metadata from_credentials getpass include_card_name include_checklist include_comments langchain load metadata page_content print token

PythonNotebook: /docs/modules/indexes/document_loaders/examples/twitter.ipynb
  Variables: documents loader
  Usages: TwitterTweetLoader document_loaders from_bearer_token langchain load number_tweets oauth2_bearer_token twitter_users

PythonNotebook: /docs/modules/indexes/document_loaders/examples/unstructured_file.ipynb
  Variables: docs filenames https://raw.githubusercontent.com/Unstructured-IO/unstructured/main/example-docs/layout-parser-paper.pdf loader
  Usages: IO P Unstructured UnstructuredAPIFileLoader UnstructuredFileLoader api_key com document_loaders example file_path get githubusercontent https install langchain layout layoutmodels layoutparser load main mode page_content paper parser pdf raw strategy tesseract unstructured

PythonNotebook: /docs/modules/indexes/document_loaders/examples/url.ipynb
  Variables: data loader urls
  Usages: PlaywrightURLLoader SeleniumURLLoader UnstructuredURLLoader document_loaders install langchain laywright load remove_selectors

PythonNotebook: /docs/modules/indexes/document_loaders/examples/weather.ipynb
  Variables: OPENWEATHERMAP_API_KEY documents loader
  Usages: WeatherDataLoader document_loaders from_params getpass langchain load openweathermap_api_key

PythonNotebook: /docs/modules/indexes/document_loaders/examples/web_base.ipynb
  Variables: data docs loader loader.default_parser loader.requests_per_second
  Usages: WebBaseLoader aload apply default_parser document_loaders install langchain load nest_asyncio requests_per_second

PythonNotebook: /docs/modules/indexes/document_loaders/examples/whatsapp_chat.ipynb
  Variables: loader
  Usages: WhatsAppChatLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/wikipedia.ipynb
  Variables: docs
  Usages: WikipediaLoader document_loaders langchain len load load_max_docs metadata page_content query

PythonNotebook: /docs/modules/indexes/document_loaders/examples/xml.ipynb
  Variables: docs loader
  Usages: UnstructuredXMLLoader document_loaders langchain load

PythonNotebook: /docs/modules/indexes/document_loaders/examples/youtube_audio.ipynb
  Variables: combined_docs docs embeddings loader qa_chain query save_dir splits text text_splitter urls vectordb
  Usages: ChatOpenAI FAISS GenericLoader OpenAIEmbeddings OpenAIWhisperParser RecursiveCharacterTextSplitter RetrievalQA YoutubeAudioLoader as_retriever blob_loaders chain_type chains chat_models chunk_overlap chunk_size doc document_loaders from_chain_type from_texts generic install join langchain llm load model_name page_content parsers pip pydub retriever run split_text temperature vectorstores youtube_audio yt_dlp

PythonNotebook: /docs/modules/indexes/document_loaders/examples/youtube_transcript.ipynb
  Variables: google_api_client loader youtube_loader_channel youtube_loader_ids
  Usages: GoogleApiClient GoogleApiYoutubeLoader Path YoutubeLoader add_video_info captions_language channel_name credentials_path document_loaders from_youtube_url langchain language load pathlib translation video_ids

PythonNotebook: /docs/modules/indexes/retrievers/examples/arxiv.ipynb
  Variables: OPENAI_API_KEY chat_history docs model os.environ["OPENAI_API_KEY"] questions result retriever
  Usages: ArxivRetriever ChatOpenAI ConversationalRetrievalChain append chains chat_models environ from_llm get_relevant_documents getpass langchain load_max_docs metadata model_name page_content print query question retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/aws_kendra_index_retriever.ipynb
  Variables: kclient retriever
  Usages: AwsKendraIndexRetriever boto3 client get_relevant_documents kendraindex langchain region_name retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/azure_cognitive_search.ipynb
  Variables: os.environ["AZURE_COGNITIVE_SEARCH_API_KEY"] os.environ["AZURE_COGNITIVE_SEARCH_INDEX_NAME"] os.environ["AZURE_COGNITIVE_SEARCH_SERVICE_NAME"] retriever
  Usages: AzureCognitiveSearchRetriever content_key environ get_relevant_documents langchain retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/chatgpt-plugin.ipynb
  Functions: write_json
  Variables: data loader os.environ['OPENAI_API_KEY'] results retriever
  Usages: CSVLoader ChatGPTPluginRetriever Document List bearer_token csv_loader doc docstore document document_loaders documents dump environ file_path get_relevant_documents getpass indent json langchain load open page_content path retrievers str typing url

PythonNotebook: /docs/modules/indexes/retrievers/examples/chroma_self_query.ipynb
  Variables: docs document_content_description embeddings llm metadata_field_info os.environ['OPENAI_API_KEY'] retriever vectorstore
  Usages: AttributeInfo Chroma Document OpenAI OpenAIEmbeddings SelfQueryRetriever base chains description enable_limit environ from_documents from_llm get_relevant_documents getpass langchain llms metadata name openai page_content query_constructor retrievers schema self_query temperature type vectorstores verbose

PythonNotebook: /docs/modules/indexes/retrievers/examples/cohere-reranker.ipynb
  Functions: pretty_print_docs
  Variables: chain compressed_docs compression_retriever compressor docs documents llm os.environ['COHERE_API_KEY'] os.environ['OPENAI_API_KEY'] query retriever text_splitter texts
  Usages: CohereRerank ContextualCompressionRetriever FAISS OpenAI OpenAIEmbeddings RecursiveCharacterTextSplitter RetrievalQA TextLoader as_retriever base_compressor base_retriever chains chunk_overlap chunk_size document_compressors document_loaders embeddings enumerate environ from_chain_type from_documents get_relevant_documents getpass join langchain llms load page_content print retrievers search_kwargs split_documents temperature vectorstores

PythonNotebook: /docs/modules/indexes/retrievers/examples/contextual-compression.ipynb
  Functions: pretty_print_docs
  Variables: _filter compressed_docs compression_retriever compressor docs documents embeddings embeddings_filter llm pipeline_compressor redundant_filter relevant_filter retriever splitter text_splitter texts
  Usages: CharacterTextSplitter ContextualCompressionRetriever DocumentCompressorPipeline EmbeddingsFilter EmbeddingsRedundantFilter FAISS LLMChainExtractor LLMChainFilter OpenAI OpenAIEmbeddings TextLoader as_retriever base_compressor base_retriever chunk_overlap chunk_size document_compressors document_loaders document_transformers enumerate from_documents from_llm get_relevant_documents join langchain llms load page_content print retrievers separator similarity_threshold split_documents temperature transformers vectorstores

PythonNotebook: /docs/modules/indexes/retrievers/examples/databerry.ipynb
  Variables: retriever
  Usages: DataberryRetriever datastore_url get_relevant_documents langchain retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/elastic_search_bm25.ipynb
  Variables: elasticsearch_url result retriever
  Usages: ElasticSearchBM25Retriever add_texts create get_relevant_documents langchain retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/knn.ipynb
  Variables: result retriever
  Usages: KNNRetriever OpenAIEmbeddings embeddings from_texts get_relevant_documents langchain retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/merger_retriever.ipynb
  Variables: ABS_PATH DB_DIR all_mini client_settings compression_retriever db_all db_multi_qa filter filter_embeddings lotr multi_qa_mini pipeline retriever_all retriever_multi_qa
  Usages: Chroma ContextualCompressionRetriever DocumentCompressorPipeline EmbeddingsRedundantFilter HuggingFaceEmbeddings MergerRetriever OpenAIEmbeddings Settings __file__ abspath anonymized_telemetry as_retriever base_compressor base_retriever chroma_db_impl chromadb collection_name config dirname document_compressors document_transformers embedding_function embeddings join langchain merger_retriever model_name path persist_directory retrievers search_kwargs search_type transformers vectorstores

PythonNotebook: /docs/modules/indexes/retrievers/examples/metal.ipynb
  Variables: API_KEY CLIENT_ID INDEX_ID metal retriever
  Usages: Metal MetalRetriever get_relevant_documents index langchain metal_sdk params retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/pinecone_hybrid_search.ipynb
  Variables: api_key bm25_encoder embeddings env index index_name os.environ['OPENAI_API_KEY'] os.environ['PINECONE_API_KEY'] os.environ['PINECONE_ENVIRONMENT'] result retriever
  Usages: BM25Encoder Index OpenAIEmbeddings PineconeHybridSearchRetriever add_texts create_index default dimension enviroment environ get_relevant_documents getenv getpass init langchain metadata_config metric name pinecone pinecone_text pod_type retrievers sparse sparse_encoder whoami

PythonNotebook: /docs/modules/indexes/retrievers/examples/pubmed.ipynb
  Variables: retriever
  Usages: PubMedRetriever get_relevant_documents langchain retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/qdrant_self_query.ipynb
  Variables: docs document_content_description embeddings llm metadata_field_info retriever vectorstore
  Usages: AttributeInfo Document OpenAI OpenAIEmbeddings Qdrant SelfQueryRetriever base chains collection_name description enable_limit from_documents from_llm get_relevant_documents langchain llms location metadata name openai page_content query_constructor retrievers schema self_query temperature type vectorstores verbose

PythonNotebook: /docs/modules/indexes/retrievers/examples/self_query.ipynb
  Variables: docs document_content_description embeddings llm metadata_field_info retriever vectorstore
  Usages: AttributeInfo Document OpenAI OpenAIEmbeddings Pinecone SelfQueryRetriever api_key base chains create_index description dimension enable_limit environ environment from_documents from_llm get_relevant_documents index_name init langchain llms metadata name openai page_content pinecone query_constructor retrievers schema self_query temperature type vectorstores verbose

PythonNotebook: /docs/modules/indexes/retrievers/examples/svm.ipynb
  Variables: os.environ['OPENAI_API_KEY'] result retriever
  Usages: OpenAIEmbeddings SVMRetriever embeddings environ from_texts get_relevant_documents getpass langchain retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/tf_idf.ipynb
  Variables: result retriever
  Usages: Document TFIDFRetriever from_documents from_texts get_relevant_documents langchain page_content retrievers schema

PythonNotebook: /docs/modules/indexes/retrievers/examples/time_weighted_vectorstore.ipynb
  Variables: embedding_size embeddings_model index retriever vectorstore yesterday
  Usages: Document FAISS InMemoryDocstore IndexFlatL2 OpenAIEmbeddings TimeWeightedVectorStoreRetriever add_documents datetime days decay_rate docstore embed_query embeddings faiss get_relevant_documents langchain metadata mock_now now page_content print retrievers schema timedelta utils vectorstores

PythonNotebook: /docs/modules/indexes/retrievers/examples/vectorstore.ipynb
  Variables: docs documents embeddings loader retriever text_splitter texts
  Usages: CharacterTextSplitter FAISS OpenAIEmbeddings TextLoader as_retriever chunk_overlap chunk_size document_loaders from_documents get_relevant_documents langchain len load search_kwargs search_type split_documents vectorstores

PythonNotebook: /docs/modules/indexes/retrievers/examples/vespa.ipynb
  Variables: retriever vespa_app vespa_content_field vespa_query_body
  Usages: Vespa VespaRetriever application get_relevant_documents langchain retrievers url vespa vespa_retriever

PythonNotebook: /docs/modules/indexes/retrievers/examples/weaviate-hybrid.ipynb
  Variables: WEAVIATE_URL client docs retriever
  Usages: AuthApiKey Client Document WeaviateHybridSearchRetriever add_documents additional_headers api_key auth_client_secret get_relevant_documents getenv index_name langchain metadata page_content retrievers schema text_key url weaviate weaviate_hybrid_search where_filter

PythonNotebook: /docs/modules/indexes/retrievers/examples/weaviate_self_query.ipynb
  Variables: docs document_content_description embeddings llm metadata_field_info retriever vectorstore
  Usages: AttributeInfo Document OpenAI OpenAIEmbeddings SelfQueryRetriever Weaviate base chains description enable_limit from_documents from_llm get_relevant_documents langchain llms metadata name openai page_content query_constructor retrievers schema self_query temperature type vectorstores verbose weaviate_url

PythonNotebook: /docs/modules/indexes/retrievers/examples/wikipedia.ipynb
  Variables: OPENAI_API_KEY chat_history docs model os.environ["OPENAI_API_KEY"] questions result retriever
  Usages: ChatOpenAI ConversationalRetrievalChain WikipediaRetriever append chains chat_models environ from_llm get_relevant_documents getpass langchain metadata model_name page_content print query question retrievers

PythonNotebook: /docs/modules/indexes/retrievers/examples/zep_memorystore.ipynb
  Variables: ZEP_API_URL session_id test_history zep_chat_history zep_retriever
  Usages: AIMessage HumanMessage ZepChatMessageHistory ZepRetriever aget_relevant_documents append chat_message_histories content get_relevant_documents langchain memory msg retrievers schema str top_k url uuid uuid4

PythonNotebook: /docs/modules/indexes/text_splitters/examples/character_text_splitter.ipynb
  Variables: documents metadatas state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter chunk_overlap chunk_size create_documents langchain len length_function open print read separator split_text

PythonNotebook: /docs/modules/indexes/text_splitters/examples/code_splitter.ipynb
  Variables: JS_CODE PYTHON_CODE html_docs html_splitter html_text js_docs js_splitter latex_docs latex_splitter latex_text markdown_text md_docs md_splitter python_docs python_splitter
  Usages: JS Language MARKDOWN PYTHON RecursiveCharacterTextSplitter chunk_overlap chunk_size create_documents from_language get_separators_for_language langchain language text_splitter value

PythonNotebook: /docs/modules/indexes/text_splitters/examples/huggingface_length_function.ipynb
  Variables: state_of_the_union text_splitter texts tokenizer
  Usages: CharacterTextSplitter GPT2TokenizerFast chunk_overlap chunk_size from_huggingface_tokenizer from_pretrained langchain open print read split_text transformers

PythonNotebook: /docs/modules/indexes/text_splitters/examples/markdown_header_metadata.ipynb
  Variables: chunked_docs headers_to_split_on markdown_document markdown_splitter
  Usages: MarkdownHeaderTextSplitter chunk langchain print return_each_line split_text text_splitter

PythonNotebook: /docs/modules/indexes/text_splitters/examples/nltk.ipynb
  Variables: state_of_the_union text_splitter texts
  Usages: NLTKTextSplitter chunk_size langchain open print read split_text

PythonNotebook: /docs/modules/indexes/text_splitters/examples/recursive_text_splitter.ipynb
  Variables: state_of_the_union text_splitter texts
  Usages: RecursiveCharacterTextSplitter chunk_overlap chunk_size create_documents langchain len length_function open print read split_text

PythonNotebook: /docs/modules/indexes/text_splitters/examples/sentence_transformer_token_splitter.ipynb
  Variables: count_start_and_stop_tokens splitter text text_chunks text_to_split text_token_count token_multiplier
  Usages: SentenceTransformersTokenTextSplitter chunk_overlap count_tokens langchain maximum_tokens_per_chunk print split_text text_splitter

PythonNotebook: /docs/modules/indexes/text_splitters/examples/spacy.ipynb
  Variables: state_of_the_union text_splitter texts
  Usages: SpacyTextSplitter chunk_size langchain open print read split_text

PythonNotebook: /docs/modules/indexes/text_splitters/examples/tiktoken.ipynb
  Variables: state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter chunk_overlap chunk_size from_tiktoken_encoder langchain open print read split_text

PythonNotebook: /docs/modules/indexes/text_splitters/examples/tiktoken_splitter.ipynb
  Variables: state_of_the_union text_splitter texts
  Usages: TokenTextSplitter chunk_overlap chunk_size langchain open print read split_text

PythonNotebook: /docs/modules/indexes/vectorstores/examples/analyticdb.ipynb
  Variables: connection_string docs documents embeddings loader query text_splitter vector_db
  Usages: AnalyticDB CharacterTextSplitter OpenAIEmbeddings TextLoader chunk_overlap chunk_size connection_string_from_db_params database document_loaders driver environ from_documents get host int langchain load openai page_content password port print similarity_search split_documents user vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/annoy.ipynb
  Variables: data db_manually docs docstore documents embeddings embeddings_func embs index index_to_docstore_id loaded_vector_store loader metadata metadatas metric motorbike_emb query some_docstore_id text_splitter texts vector_store vector_store_from_docs vector_store_from_embeddings vector_store_v2
  Usages: Annoy AnnoyIndex CharacterTextSplitter Document HuggingFaceEmbeddings InMemoryDocstore TextLoader _dict add_item annoy append build chunk_overlap chunk_size doc document document_loaders emb embed_documents embed_query enumerate from_documents from_embeddings from_texts in_memory langchain len list load load_local n_jobs n_trees page_content print range save_local similarity_search similarity_search_by_vector similarity_search_with_score similarity_search_with_score_by_index similarity_search_with_score_by_vector split_documents str text uuid uuid4 vectorstores zip

PythonNotebook: /docs/modules/indexes/vectorstores/examples/atlas.ipynb
  Variables: ATLAS_TEST_API_KEY documents loader text_splitter texts
  Usages: AtlasDB OpenAIEmbeddings SpacyTextSplitter TextLoader api_key description doc document_loaders download embeddings en_core_web_sm extend from_texts index_kwargs install langchain load name nomic openai page_content project separator spacy split split_documents str strip time vectorstores wait_for_project_lock ython3

PythonNotebook: /docs/modules/indexes/vectorstores/examples/awadb.ipynb
  Variables: awadb_client docs documents loader query ret text_splitter
  Usages: AwaDB CharacterTextSplitter Client Load TextLoader added automatically awadb chunk_overlap chunk_size data document document_loaders from_documents install langchain load page_content persists print similarity_search similarity_search_with_score split_documents success table vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/azuresearch.ipynb
  Variables: docs documents embeddings: https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/ index_name: loader model: openai.api_base openai.api_key openai.api_type openai.api_version text_splitter vector_store: vector_store_address: vector_store_password:
  Usages: AzureSearch BaseRetriever CharacterTextSplitter OpenAIEmbeddings TextLoader _packaging a20230509004 add_documents api_base api_key api_type api_version azure azure_search_endpoint azure_search_key azuresearch chunk_overlap chunk_size com dev document_loaders dotenv embed_query embedding_function embeddings encoding for https identity index index_name install json langchain load load_dotenv model openai page_content pkgs print public pypi python query schema sdk search search_type similarity_search simple split_documents str url vector_store vector_store_address vector_store_password vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/chroma.ipynb
  Variables: OPENAI_API_KEY docs document_id documents embedding embeddings initial_content loader new_db original_doc os.environ["OPENAI_API_KEY"] output persist_directory query retriever text_splitter updated_content updated_doc vectordb
  Usages: CharacterTextSplitter Chroma Document OpenAIEmbeddings TextLoader as_retriever chromadb chunk_overlap chunk_size collection_name docstore document document_loaders embedding_function environ from_documents get_relevant_documents getpass ids install langchain load metadata openai page_content persist print search_type similarity_search similarity_search_with_score split_documents update_document vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/clickhouse.ipynb
  Variables: d.metadata docs docsearch documents embeddings loader meta nofile os.environ['OPENAI_API_KEY'] output query settings text_splitter
  Usages: CharacterTextSplitter Clickhouse ClickhouseSettings OpenAIEmbeddings TextLoader chunk_overlap chunk_size clickhouse config connect dist docker document_loaders drop enumerate environ from_documents getpass install langchain load metadata metadata_column name openai p9000 page_content print run schema server similarity_search similarity_search_with_relevance_scores split_documents str table ulimit vectorstores where_str

PythonNotebook: /docs/modules/indexes/vectorstores/examples/deeplake.ipynb
  Variables: d.metadata['year'] dataset_path destination docs documents embedding embeddings embeds loader os.environ['ACTIVELOOP_TOKEN'] os.environ['OPENAI_API_KEY'] query source text_splitter username
  Usages: CharacterTextSplitter DeepLake OpenAIChat OpenAIEmbeddings RetrievalQA TextLoader add_documents as_retriever chain_type chains chunk_overlap chunk_size creds deepcopy deeplake delete_dataset dest distance_metric document_loaders embedding_function environ filter force_delete_by_path from_chain_type from_documents getpass install langchain llm llms load max_marginal_relevance_search metadata model numpy openai overwrite page_content print randint random read_only retriever run similarity_search split_documents src summary tiktoken vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/docarray_hnsw.ipynb
  Variables: docs documents embeddings query text_splitter
  Usages: CharacterTextSplitter DocArrayHnswSearch OpenAIEmbeddings TextLoader chunk_overlap chunk_size document_loaders from_documents langchain load n_dim openai page_content print rmtree shutil similarity_search similarity_search_with_score split_documents vectorstores work_dir

PythonNotebook: /docs/modules/indexes/vectorstores/examples/docarray_in_memory.ipynb
  Variables: docs documents embeddings query text_splitter
  Usages: CharacterTextSplitter DocArrayInMemorySearch OpenAIEmbeddings TextLoader chunk_overlap chunk_size document_loaders from_documents langchain load openai page_content print similarity_search similarity_search_with_score split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/elasticsearch.ipynb
  Variables: dims docs documents embeddings es_cloud_id es_connection es_password es_user hybrid_result knn_result knn_search loader model_id new_texts os.environ['OPENAI_API_KEY'] query query_embedding query_text test_index text_splitter texts
  Usages: CharacterTextSplitter ElasticKnnSearch ElasticVectorSearch Elasticsearch ElasticsearchEmbeddings OpenAIEmbeddings TextLoader add_texts basic_auth chunk_overlap chunk_size dim_count document_loaders elastic_vector_search elasticsearch elasticsearch_url embed_query embedding environ fields from_credentials from_documents from_es_connection from_texts getpass hosts index_name install keys knn_hybrid_search langchain len load openai page_content print query_vector similarity_search source split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/faiss.ipynb
  Variables: db1 db2 docs docs_and_scores documents embedding_vector embeddings list_of_documents loader new_db os.environ['OPENAI_API_KEY'] query results results_with_scores text_splitter
  Usages: CharacterTextSplitter Document FAISS OpenAIEmbeddings TextLoader _dict chunk_overlap chunk_size cpu dict doc docstore document_loaders embed_query environ faiss fetch_k filter from_documents from_texts getpass install langchain load load_local max_marginal_relevance_search merge_from metadata openai page page_content print save_local schema score similarity_search similarity_search_by_vector similarity_search_with_score split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/hologres.ipynb
  Variables: connection_string docs documents embeddings loader query text_splitter vector_db
  Usages: CharacterTextSplitter Hologres OpenAIEmbeddings TextLoader chunk_overlap chunk_size connection_string_from_db_params database document_loaders environ from_documents get host int langchain load openai page_content password port print similarity_search split_documents table_name user vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/lancedb.ipynb
  Variables: docs docsearch documents embeddings loader os.environ['OPENAI_API_KEY'] query table
  Usages: CharacterTextSplitter LanceDB OpenAIEmbeddings TextLoader connect connection create_table data document_loaders embed_query environ from_documents getpass install lancedb langchain load mode page_content print similarity_search split_documents text_splitter vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/matchingengine.ipynb
  Variables: BUCKET_URI CREATE_VPC DEPLOYED_INDEX_ID DIMENSIONS DISPLAY_NAME EMBEDDING_DIR PEERING_RANGE_NAME PROJECT_ID PROJECT_NUMBER REGION VPC_NETWORK VPC_NETWORK_FULL embeddings initial_config model module_url my_index my_index_endpoint tcp:22 tcp:3389 texts vector_store
  Usages: MatchingEngine MatchingEngineIndex MatchingEngineIndexEndpoint VPC_PEERING add_texts addresses aiplatform all allow approximate_neighbors_count auto bgp cloud com compute config connect contents_delta_uri create create_tree_ah_index data deploy_index deployed_index_id deployed_indexes description dimensions display_name distance_measure_type dump endpoint_id file filter firewall float format from_components gcloud gcs_bucket_uri global google googleapis gsutil hub icmp index index_id init install internal json langchain length list load location mode network networks numpy open peerings prefix priority project project_id projects purpose ranges rdp region regional routing rules service servicenetworking services set similarity_search source ssh staging_bucket subnet sutil tcp tensorflow tensorflow_hub tensorflow_text text vectorstores vpc

PythonNotebook: /docs/modules/indexes/vectorstores/examples/milvus.ipynb
  Variables: docs documents embeddings loader os.environ['OPENAI_API_KEY'] query text_splitter vector_db
  Usages: CharacterTextSplitter Milvus OpenAIEmbeddings TextLoader chunk_overlap chunk_size connection_args document_loaders environ from_documents getpass install langchain load openai page_content pymilvus similarity_search split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/mongodb_atlas_vector_search.ipynb
  Variables: MONGODB_ATLAS_CLUSTER_URI MONGODB_ATLAS_URI OPENAI_API_KEY client collection collection_name db_name docs docsearch documents embeddings index_name loader os.environ['OPENAI_API_KEY'] query text_splitter vectorStore
  Usages: CharacterTextSplitter MongoClient MongoDBAtlasVectorSearch OpenAIEmbeddings TextLoader chunk_overlap chunk_size document_loaders environ from_documents getpass install langchain load openai page_content print pymongo similarity_search split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/myscale.ipynb
  Variables: d.metadata docs docsearch documents embeddings loader meta os.environ['OPENAI_API_KEY'] output query text_splitter
  Usages: CharacterTextSplitter MyScale MyScaleSettings OpenAIEmbeddings TextLoader chunk_overlap chunk_size clickhouse connect dist document_loaders drop enumerate environ from_documents getpass install langchain load metadata metadata_column openai page_content print similarity_search similarity_search_with_relevance_scores split_documents str vectorstores where_str

PythonNotebook: /docs/modules/indexes/vectorstores/examples/opensearch.ipynb
  Variables: docs docsearch documents embeddings filter loader os.environ['OPENAI_API_KEY'] query text_splitter
  Usages: CharacterTextSplitter OpenAIEmbeddings OpenSearchVectorSearch TextLoader chunk_overlap chunk_size document_loaders ef_construction embedding_function engine environ from_documents getpass index_name install is_appx_search langchain load metadata_field openai opensearch opensearch_url page_content pre_filter print search_type similarity_search space_type split_documents text_field vector_field vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/pgvector.ipynb
  Variables: CONNECTION_STRING DEFAULT_DISTANCE_STRATEGY api_key collection_name connection_string data db1 docs docs_with_score: documents embedding embeddings loader os.environ['OPENAI_API_KEY'] query retriever store text_splitter
  Usages: COSINE CharacterTextSplitter DistanceStrategy Document EUCLIDEAN List OpenAIEmbeddings PGVector TextLoader Tuple as_retriever binary chunk_overlap chunk_size connection_string_from_db_params database distance_strategy doc docs_with_score docstore document document_loaders dotenv driver embedding_function environ float from_documents from_existing_index get getpass host install int langchain load load_dotenv openai openai_api_key page_content password pgvector port pre_delete_collection print psycopg2 score similarity_search_with_score split_documents tiktoken typing user vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/pinecone.ipynb
  Variables: PINECONE_API_KEY PINECONE_ENV docs docsearch documents embeddings index_name loader os.environ['OPENAI_API_KEY'] query text_splitter
  Usages: CharacterTextSplitter OpenAIEmbeddings Pinecone TextLoader api_key chunk_overlap chunk_size client document_loaders environ environment from_documents getpass init install langchain load openai page_content pinecone print similarity_search split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/qdrant.ipynb
  Variables: api_key client docs document, documents embeddings found_docs loader os.environ['OPENAI_API_KEY'] qdrant query retriever text_splitter url
  Usages: CharacterTextSplitter OpenAIEmbeddings Qdrant QdrantClient TextLoader as_retriever chunk_overlap chunk_size collection_name content_payload_key doc document document_loaders enumerate environ fetch_k from_documents get_relevant_documents getpass install langchain load location max_marginal_relevance_search metadata_payload_key openai page_content path prefer_grpc print qdrant_client score search_type similarity_search similarity_search_with_score split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/redis.ipynb
  Variables: docs documents embeddings loader os.environ['OPENAI_API_KEY'] query rds results retriever text_splitter
  Usages: CharacterTextSplitter OpenAIEmbeddings Redis TextLoader add_texts as_retriever chunk_overlap chunk_size document_loaders environ from_documents from_existing_index get_relevant_documents getpass index_name install langchain load page_content print redis redis_url search_type similarity_search split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/singlestoredb.ipynb
  Variables: docs docsearch documents embeddings loader os.environ['OPENAI_API_KEY'] os.environ['SINGLESTOREDB_URL'] query text_splitter
  Usages: CharacterTextSplitter OpenAIEmbeddings SingleStoreDB TextLoader chunk_overlap chunk_size document_loaders environ from_documents getpass install langchain load openai page_content print similarity_search singlestoredb split_documents table_name vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/sklearn.ipynb
  Variables: docs documents embeddings loader os.environ['OPENAI_API_KEY'] persist_path query text_splitter vector_store vector_store2
  Usages: CharacterTextSplitter OpenAIEmbeddings SKLearnVectorStore TextLoader chunk_overlap chunk_size document_loaders embedding environ from_documents getpass gettempdir install join langchain learn load openai page_content pandas path persist pip print pyarrow remove scikit serializer similarity_search split_documents tempfile vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/supabase.ipynb
  Variables: docs documents embeddings loader matched_docs os.environ['OPENAI_API_KEY'] os.environ['SUPABASE_SERVICE_KEY'] os.environ['SUPABASE_URL'] query retriever supabase: supabase_key supabase_url text_splitter vector_store
  Usages: CharacterTextSplitter Client OpenAIEmbeddings SupabaseVectorStore TextLoader as_retriever chunk_overlap chunk_size client create_client document_loaders dotenv enumerate environ from_documents get get_relevant_documents getpass install langchain load load_dotenv openai page_content print search_type similarity_search similarity_search_with_relevance_scores split_documents supabase vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/tair.ipynb
  Variables: docs documents embeddings loader query tair_url text_splitter vector_store
  Usages: CharacterTextSplitter FakeEmbeddings Tair TextLoader chunk_overlap chunk_size document_loaders drop_index fake from_documents langchain load similarity_search size split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/tigris.ipynb
  Variables: docs documents embeddings found_docs loader os.environ['OPENAI_API_KEY'] os.environ['TIGRIS_CLIENT_ID'] os.environ['TIGRIS_CLIENT_SECRET'] os.environ['TIGRIS_PROJECT'] query result text_splitter vector_store
  Usages: CharacterTextSplitter OpenAIEmbeddings TextLoader Tigris chunk_overlap chunk_size doc document_loaders environ from_documents getpass index_name install langchain load openai openapi print pydantic schema score similarity_search similarity_search_with_score split_documents tigrisdb tiktoken vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/typesense.ipynb
  Variables: docs docsearch documents embeddings found_docs loader os.environ['OPENAI_API_KEY'] query retriever text_splitter
  Usages: CharacterTextSplitter OpenAIEmbeddings TextLoader Typesense as_retriever chunk_overlap chunk_size document_loaders environ from_documents get_relevant_documents getpass install langchain load openai openapi page_content print pydantic schema similarity_search split_documents tiktoken typesense typesense_client_params vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/vectara.ipynb
  Variables: docs document, documents embeddings found_docs loader os.environ['OPENAI_API_KEY'] query retriever text_splitter vectara
  Usages: CharacterTextSplitter OpenAIEmbeddings TextLoader Vectara as_retriever chunk_overlap chunk_size document document_loaders embedding environ from_documents get_relevant_documents getpass langchain load n_sentence_context openai page_content print score similarity_search similarity_search_with_score split_documents vectorstores

PythonNotebook: /docs/modules/indexes/vectorstores/examples/weaviate.ipynb
  Variables: WEAVIATE_URL chain docs docsearch documents embeddings loader os.environ["OPENAI_API_KEY"] os.environ["WEAVIATE_API_KEY"] query retriever state_of_the_union text_splitter texts
  Usages: CharacterTextSplitter OpenAI OpenAIEmbeddings RetrievalQAWithSourcesChain TextLoader Weaviate as_retriever by_text chain_type chains chunk_overlap chunk_size client document_loaders environ from_chain_type from_documents from_texts get_relevant_documents getpass install langchain len load metadatas open openai page_content print range read return_only_outputs search_type similarity_search similarity_search_with_score split_documents split_text temperature vectorstores weaviate weaviate_url

PythonNotebook: /docs/modules/indexes/vectorstores/examples/zilliz.ipynb
  Variables: ZILLIZ_CLOUD_PASSWORD ZILLIZ_CLOUD_URI ZILLIZ_CLOUD_USERNAME docs documents embeddings loader os.environ['OPENAI_API_KEY'] query text_splitter vector_db
  Usages: CharacterTextSplitter Milvus OpenAIEmbeddings TextLoader chunk_overlap chunk_size connection_args document_loaders environ from_documents getpass install langchain load openai page_content pymilvus similarity_search split_documents vectorstores

PythonNotebook: /docs/modules/models/chat/examples/few_shot_examples.ipynb
  Variables: chain chat chat_prompt example_ai example_human human_message_prompt human_template system_message_prompt template
  Usages: AIMessage AIMessagePromptTemplate ChatOpenAI ChatPromptTemplate HumanMessage HumanMessagePromptTemplate LLMChain PromptTemplate SystemMessage SystemMessagePromptTemplate additional_kwargs chat_models from_messages from_template langchain llm prompt prompts run schema temperature

PythonNotebook: /docs/modules/models/chat/examples/streaming.ipynb
  Variables: chat resp
  Usages: ChatOpenAI HumanMessage StreamingStdOutCallbackHandler callbacks chat_models content langchain schema streaming streaming_stdout temperature

PythonNotebook: /docs/modules/models/chat/integrations/anthropic.ipynb
  Variables: chat messages
  Usages: AIMessage AIMessagePromptTemplate CallbackManager ChatAnthropic ChatPromptTemplate HumanMessage HumanMessagePromptTemplate StreamingStdOutCallbackHandler SystemMessage SystemMessagePromptTemplate agenerate callback_manager callbacks chat_models content langchain manager prompts schema streaming streaming_stdout verbose

PythonNotebook: /docs/modules/models/chat/integrations/azure_chat_openai.ipynb
  Variables: API_KEY BASE_URL DEPLOYMENT_NAME model
  Usages: AzureChatOpenAI HumanMessage chat_models content deployment_name langchain openai_api_base openai_api_key openai_api_type openai_api_version schema

PythonNotebook: /docs/modules/models/chat/integrations/google_vertex_ai_palm.ipynb
  Variables: chat chat_prompt human_message_prompt human_template messages system_message_prompt template
  Usages: ChatPromptTemplate ChatVertexAI HumanMessage HumanMessagePromptTemplate SystemMessage SystemMessagePromptTemplate chat_models content format_prompt from_messages from_template input_language langchain output_language prompts schema text to_messages

PythonNotebook: /docs/modules/models/chat/integrations/openai.ipynb
  Variables: chat chat_prompt human_message_prompt human_template messages system_message_prompt template
  Usages: AIMessage AIMessagePromptTemplate ChatOpenAI ChatPromptTemplate HumanMessage HumanMessagePromptTemplate SystemMessage SystemMessagePromptTemplate chat_models content format_prompt from_messages from_template input_language langchain output_language prompts schema temperature text to_messages

PythonNotebook: /docs/modules/models/chat/integrations/promptlayer_chatopenai.ipynb
  Variables: chat chat_results os.environ["PROMPTLAYER_API_KEY"] pl_request_id
  Usages: HumanMessage PromptLayerChatOpenAI chat_models content environ generate generation_info generations install langchain pip pl_tags promptlayer request_id res return_pl_id schema score track

PythonNotebook: /docs/modules/models/llms/examples/async_llm.ipynb
  Functions: async_generate generate_concurrently generate_serially
  Variables: elapsed llm resp tasks
  Usages: OpenAI agenerate asyncio gather generate generations langchain llms perf_counter print range temperature text time

PythonNotebook: /docs/modules/models/llms/examples/custom_llm.ipynb
  Classes: CustomLLM
  Methods: _call _identifying_params _llm_type
  Variables: llm
  Usages: Any CallbackManagerForLLMRun LLM List Mapping Optional ValueError base callbacks int langchain llms manager print prompt property run_manager self stop str typing

PythonNotebook: /docs/modules/models/llms/examples/fake_llm.ipynb
  Variables: agent llm responses tools
  Usages: AgentType FakeListLLM ZERO_SHOT_REACT_DESCRIPTION agents fake initialize_agent langchain llms load_tools run verbose

PythonNotebook: /docs/modules/models/llms/examples/human_input_llm.ipynb
  Variables: agent llm tools
  Usages: AgentType HumanInputLLM ZERO_SHOT_REACT_DESCRIPTION agents human initialize_agent install langchain llms load_tools pip print prompt prompt_func run verbose wikipedia

File: /docs/modules/models/llms/examples/llm.json

File: /docs/modules/models/llms/examples/llm.yaml

PythonNotebook: /docs/modules/models/llms/examples/llm_caching.ipynb
  Functions: get_hashed_name init_gptcache
  Classes: FulltextLLMCache
  Variables: Base __table_args__ __tablename__ cache_name chain docs engine hashed_llm idx langchain.llm_cache llm no_cache_llm prompt prompt_tsv response state_of_the_union text_splitter texts ttl
  Usages: Cache CharacterTextSplitter Column Computed Document GPTCache InMemoryCache Index Integer MapReduceChain MomentoCache OpenAI OpenAIEmbeddings Redis RedisCache RedisSemanticCache SQLAlchemyCache SQLiteCache Sequence String TSVectorType adapter api best_of cache cache_obj chain_type chains create_engine data_dir data_manager database_path datetime days declarative declarative_base docstore document embedding embeddings encode ext factory from_client_params get_prompt gptcache hashlib hexdigest init init_similar_cache langchain llm_cache llms load_summarize_chain manager manager_factory mapreduce model_name name nullable open page_content persisted postgresql_using pre pre_embedding_func primary_key processor read redis redis_ redis_url reduce_llm run sha256 split_text sqlalchemy sqlalchemy_utils sqlite str summarize time timedelta

PythonNotebook: /docs/modules/models/llms/examples/llm_serialization.ipynb
  Variables: llm
  Usages: OpenAI json langchain llms load_llm loading save yaml

PythonNotebook: /docs/modules/models/llms/examples/streaming_llm.ipynb
  Variables: chat llm resp
  Usages: ChatAnthropic ChatOpenAI HumanMessage OpenAI StreamingStdOutCallbackHandler callbacks chat_models content generate langchain llms schema streaming streaming_stdout temperature

PythonNotebook: /docs/modules/models/llms/examples/token_usage_tracking.ipynb
  Variables: agent llm response result result2 tools
  Usages: AgentType OpenAI ZERO_SHOT_REACT_DESCRIPTION agents best_of callbacks completion_tokens get_openai_callback initialize_agent langchain llms load_tools model_name print prompt_tokens run temperature total_cost total_tokens verbose

PythonNotebook: /docs/modules/models/llms/integrations/ai21.ipynb
  Variables: AI21_API_KEY llm llm_chain prompt question template
  Usages: AI21 LLMChain PromptTemplate ai21 ai21_api_key getpass input_variables install langchain llms run

PythonNotebook: /docs/modules/models/llms/integrations/aleph_alpha.ipynb
  Variables: ALEPH_ALPHA_API_KEY llm llm_chain prompt question template
  Usages: AlephAlpha LLMChain PromptTemplate aleph aleph_alpha_api_key alpha client getpass input_variables install langchain llms maximum_tokens model run stop_sequences

PythonNotebook: /docs/modules/models/llms/integrations/anyscale.ipynb
  Methods: send_query
  Variables: futures llm llm_chain os.environ["ANYSCALE_SERVICE_ROUTE"] os.environ["ANYSCALE_SERVICE_TOKEN"] os.environ["ANYSCALE_SERVICE_URL"] prompt prompt_list question resp results template
  Usages: ANYSCALE_SERVICE_ROUTE ANYSCALE_SERVICE_TOKEN ANYSCALE_SERVICE_URL Anyscale LLMChain PromptTemplate environ get input_variables langchain llms ray remote run

PythonNotebook: /docs/modules/models/llms/integrations/aviary.ipynb
  Variables: llm result
  Usages: Aviary aviary_token aviary_url environ langchain llms model predict print

PythonNotebook: /docs/modules/models/llms/integrations/azure_openai_example.ipynb
  Variables: llm os.environ["OPENAI_API_BASE"] os.environ["OPENAI_API_KEY"] os.environ["OPENAI_API_TYPE"] os.environ["OPENAI_API_VERSION"]
  Usages: AzureOpenAI deployment_name environ install langchain llms model_name openai print

PythonNotebook: /docs/modules/models/llms/integrations/banana.ipynb
  Variables: llm llm_chain os.environ["BANANA_API_KEY"] prompt question template
  Usages: Banana LLMChain PromptTemplate banana dev environ getpass input_variables install langchain llms model_key run

PythonNotebook: /docs/modules/models/llms/integrations/baseten.ipynb
  Variables: link_one link_three link_two menu_maker prompt wizardlm
  Usages: Baseten LLMChain PromptTemplate SimpleSequentialChain baseten chains input_variables install langchain llm llms login model run template verbose

PythonNotebook: /docs/modules/models/llms/integrations/beam.ipynb
  Variables: beam_client_id beam_client_secret https://raw.githubusercontent.com/slai-labs/get-beam/main/get-beam.sh llm os.environ['BEAM_CLIENT_ID'] os.environ['BEAM_CLIENT_SECRET'] response
  Usages: Beam _call _deploy beam clientId clientSecret com configure cpu eam environ get githubusercontent gpu https install labs langchain llms main max_length memory model_name name print python_packages python_version raw sSfL sdk slai subprocess url verbose

PythonNotebook: /docs/modules/models/llms/integrations/bedrock.ipynb
  Variables: conversation llm
  Usages: Bedrock ConversationBufferMemory ConversationChain bedrock boto3 chains credentials_profile_name input install langchain llms memory model_id pip predict verbose

PythonNotebook: /docs/modules/models/llms/integrations/cerebriumai_example.ipynb
  Variables: llm llm_chain os.environ["CEREBRIUMAI_API_KEY"] prompt question template
  Usages: CerebriumAI LLMChain PromptTemplate cerebrium endpoint_url environ input_variables install ip3 langchain llms run

PythonNotebook: /docs/modules/models/llms/integrations/cohere.ipynb
  Variables: COHERE_API_KEY llm llm_chain prompt question template
  Usages: Cohere LLMChain PromptTemplate cohere cohere_api_key getpass input_variables install langchain llms run

PythonNotebook: /docs/modules/models/llms/integrations/ctransformers.ipynb
  Variables: llm llm_chain prompt response template
  Usages: CTransformers LLMChain PromptTemplate StreamingStdOutCallbackHandler callbacks ctransformers input_variables install langchain llms model pip print run streaming_stdout

PythonNotebook: /docs/modules/models/llms/integrations/databricks.ipynb
  Functions: transform_input transform_output
  Variables: full_prompt llm os.environ["DATABRICKS_TOKEN"] request["prompt"]
  Usages: Databricks cluster_driver_port cluster_id dbutils endpoint_name environ get host langchain llms model_kwargs request response secrets stop transform_input_fn transform_output_fn upper

PythonNotebook: /docs/modules/models/llms/integrations/deepinfra_example.ipynb
  Variables: DEEPINFRA_API_TOKEN llm llm.model_kwargs llm_chain os.environ["DEEPINFRA_API_TOKEN"] prompt question template
  Usages: DeepInfra LLMChain PromptTemplate environ getpass input_variables langchain llms model_id model_kwargs run

PythonNotebook: /docs/modules/models/llms/integrations/forefrontai_example.ipynb
  Variables: FOREFRONTAI_API_KEY llm llm_chain os.environ["FOREFRONTAI_API_KEY"] prompt question template
  Usages: ForefrontAI LLMChain PromptTemplate endpoint_url environ getpass input_variables langchain llms run

PythonNotebook: /docs/modules/models/llms/integrations/google_vertex_ai_palm.ipynb
  Variables: llm llm_chain prompt question template
  Usages: LLMChain PromptTemplate VertexAI input_variables langchain llms run

PythonNotebook: /docs/modules/models/llms/integrations/gooseai_example.ipynb
  Variables: GOOSEAI_API_KEY llm llm_chain os.environ["GOOSEAI_API_KEY"] prompt question template
  Usages: GooseAI LLMChain PromptTemplate environ getpass input_variables install langchain llms openai pip3 run

PythonNotebook: /docs/modules/models/llms/integrations/gpt4all.ipynb
  Variables: callbacks llm llm_chain local_path prompt question template
  Usages: GPT4All LLMChain PromptTemplate StreamingStdOutCallbackHandler backend dev gpt4all input_variables install langchain llms model null pip run streaming_stdout verbose

PythonNotebook: /docs/modules/models/llms/integrations/huggingface_hub.ipynb
  Variables: HUGGINGFACEHUB_API_TOKEN llm llm_chain os.environ["HUGGINGFACEHUB_API_TOKEN"] prompt question repo_id template
  Usages: HuggingFaceHub LLMChain PromptTemplate dev environ getpass huggingface_hub input_variables install langchain model_kwargs null print run

PythonNotebook: /docs/modules/models/llms/integrations/huggingface_pipelines.ipynb
  Variables: llm llm_chain prompt question template
  Usages: HuggingFacePipeline LLMChain PromptTemplate dev from_model_id input_variables install langchain model_id model_kwargs null print run task transformers

PythonNotebook: /docs/modules/models/llms/integrations/huggingface_textgen_inference.ipynb
  Variables: llm
  Usages: HuggingFaceTextGenInference inference_server_url max_new_tokens repetition_penalty temperature top_k top_p typical_p

PythonNotebook: /docs/modules/models/llms/integrations/jsonformer_experimental.ipynb
  Methods: ask_star_coder
  Variables: HF_TOKEN decoder_schema generated headers hf_model json_former original_model payload prompt response results url
  Usages: ERROR HuggingFacePipeline JsonFormer Optional arg_schema args basicConfig content data decode dev dumps environ experimental float format get install int json json_schema jsonformer langchain level llms loads logging max_new_tokens model name null pipeline post predict print query raise_for_status requests stop str temperature tool tools transformers typing upgrade

PythonNotebook: /docs/modules/models/llms/integrations/llamacpp.ipynb
  Variables: CMAKE_ARGS FORCE_CMAKE callback_manager llm llm_chain n_batch n_gpu_layers prompt question template
  Usages: CallbackManager LLMChain LlamaCpp PromptTemplate StreamingStdOutCallbackHandler callbacks cpp force input_variables install langchain llama llms manager model_path pip python reinstall run streaming_stdout upgrade verbose

PythonNotebook: /docs/modules/models/llms/integrations/manifest.ipynb
  Variables: _prompt llm llms manifest manifest1 manifest2 manifest3 model_lab mp_chain prompt state_of_the_union text_splitter
  Usages: CharacterTextSplitter Manifest ManifestWrapper MapReduceChain ModelLaboratory PromptTemplate chains client client_connection client_name compare from_params get_model_params input_variables install langchain llm_kwargs mapreduce model_laboratory open print read run template

PythonNotebook: /docs/modules/models/llms/integrations/modal.ipynb
  Variables: llm llm_chain prompt question template
  Usages: LLMChain Modal PromptTemplate client endpoint_url input_variables install langchain llms modal new odal run token

PythonNotebook: /docs/modules/models/llms/integrations/mosaicml.ipynb
  Variables: MOSAICML_API_TOKEN llm llm_chain os.environ["MOSAICML_API_TOKEN"] prompt question template
  Usages: LLMChain MosaicML PromptTemplate environ getpass inject_instruction_format input_variables langchain llms model_kwargs run

PythonNotebook: /docs/modules/models/llms/integrations/nlpcloud.ipynb
  Variables: NLPCLOUD_API_KEY llm llm_chain os.environ["NLPCLOUD_API_KEY"] prompt question template
  Usages: LLMChain NLPCloud PromptTemplate environ getpass input_variables install langchain llms nlpcloud run

PythonNotebook: /docs/modules/models/llms/integrations/openai.ipynb
  Variables: OPENAI_API_KEY llm llm_chain os.environ["OPENAI_API_KEY"] os.environ["OPENAI_PROXY"] prompt question template
  Usages: LLMChain OpenAI PromptTemplate environ getpass input_variables langchain llms run

PythonNotebook: /docs/modules/models/llms/integrations/openlm.ipynb
  Variables: llm llm_chain os.environ["HF_API_TOKEN"] os.environ["OPENAI_API_KEY"] prompt question result template
  Usages: LLMChain OpenLM PromptTemplate environ format getpass input_variables langchain llms model print run subprocess

PythonNotebook: /docs/modules/models/llms/integrations/petals_example.ipynb
  Variables: HUGGINGFACE_API_KEY llm llm_chain os.environ["HUGGINGFACE_API_KEY"] prompt question template
  Usages: LLMChain Petals PromptTemplate environ getpass input_variables install ip3 langchain llms model_name petals run

PythonNotebook: /docs/modules/models/llms/integrations/pipelineai_example.ipynb
  Variables: llm llm_chain os.environ["PIPELINE_API_KEY"] prompt question template
  Usages: LLMChain PipelineAI PromptTemplate environ input_variables install langchain llms pipeline pipeline_key pipeline_kwargs run

PythonNotebook: /docs/modules/models/llms/integrations/predictionguard.ipynb
  Variables: llm_chain os.environ["OPENAI_API_KEY"] os.environ["PREDICTIONGUARD_TOKEN"] pgllm prompt question template
  Usages: LLMChain PredictionGuard PromptTemplate adjective environ format input_variables install langchain llm llms model output pip predict predictionguard query subject verbose

PythonNotebook: /docs/modules/models/llms/integrations/promptlayer_openai.ipynb
  Variables: OPENAI_API_KEY PROMPTLAYER_API_KEY llm llm_results os.environ["OPENAI_API_KEY"] os.environ["PROMPTLAYER_API_KEY"] pl_request_id
  Usages: PromptLayerOpenAI environ generate generation_info generations getpass install langchain llms pl_tags promptlayer request_id res return_pl_id score track

PythonNotebook: /docs/modules/models/llms/integrations/rellm_experimental.ipynb
  Variables: generated hf_model model original_model pattern prompt
  Usages: ERROR HuggingFacePipeline RELLM basicConfig compile dev experimental generate install langchain level llms logging max_new_tokens null pipeline predict print regex rellm stop transformers

PythonNotebook: /docs/modules/models/llms/integrations/replicate.ipynb
  Variables: REPLICATE_API_TOKEN catchphrase chain chain_three chain_two dolly_llm image_output img llm os.environ["REPLICATE_API_TOKEN"] overall_chain prompt response second_prompt text2image third_prompt
  Usages: BytesIO Image LLMChain PIL PromptTemplate Replicate SimpleSequentialChain chains content environ get getpass input input_variables install langchain llms model open print replicate requests run template verbose

PythonNotebook: /docs/modules/models/llms/integrations/runhouse.ipynb
  Functions: inference_fn load_pipeline
  Variables: gpu llm llm_chain model model_id pipe pipeline prompt question template tokenizer
  Usages: AutoModelForCausalLM AutoTokenizer LLMChain PromptTemplate SelfHostedHuggingFaceLLM SelfHostedPipeline blob cluster dumps from_pipeline from_pretrained hardware input_variables install instance_type langchain len llms max_new_tokens model_load_fn model_reqs name path pickle run runhouse save stop task transformers use_spot

PythonNotebook: /docs/modules/models/llms/integrations/sagemaker.ipynb
  Classes: ContentHandler
  Methods: transform_input transform_output
  Variables: PROMPT accepts chain content_handler content_type docs example_doc_1 input_str prompt_template query response_json
  Usages: Dict Document LLMContentHandler PromptTemplate SagemakerEndpoint boto3 bytes chains credentials_profile_name decode docstore document dumps encode endpoint_name input_variables install ip3 json langchain llm llms load_qa_chain loads model_kwargs output page_content prompt question_answering read region_name return_only_outputs sagemaker_endpoint self str template typing

PythonNotebook: /docs/modules/models/llms/integrations/stochasticai.ipynb
  Variables: STOCHASTICAI_API_KEY YOUR_API_URL llm llm_chain os.environ["STOCHASTICAI_API_KEY"] prompt question template
  Usages: LLMChain PromptTemplate StochasticAI api_url environ getpass input_variables langchain llms run

PythonNotebook: /docs/modules/models/llms/integrations/writer.ipynb
  Variables: WRITER_API_KEY llm llm_chain os.environ["WRITER_API_KEY"] prompt question template
  Usages: LLMChain PromptTemplate Writer environ getpass input_variables langchain llms run

PythonNotebook: /docs/modules/models/text_embedding/examples/aleph_alpha.ipynb
  Variables: doc_result document embeddings query query_result text
  Usages: AlephAlphaAsymmetricSemanticEmbedding AlephAlphaSymmetricSemanticEmbedding embed_documents embed_query langchain

PythonNotebook: /docs/modules/models/text_embedding/examples/amazon_bedrock.ipynb
  Variables: embeddings
  Usages: BedrockEmbeddings boto3 credentials_profile_name embed_documents embed_query install langchain pip

PythonNotebook: /docs/modules/models/text_embedding/examples/azureopenai.ipynb
  Variables: doc_result embeddings os.environ["OPENAI_API_BASE"] os.environ["OPENAI_API_KEY"] os.environ["OPENAI_API_TYPE"] os.environ["OPENAI_API_VERSION"] query_result text
  Usages: OpenAIEmbeddings deployment embed_documents embed_query environ langchain

PythonNotebook: /docs/modules/models/text_embedding/examples/cohere.ipynb
  Variables: doc_result embeddings query_result text
  Usages: CohereEmbeddings cohere_api_key embed_documents embed_query langchain

PythonNotebook: /docs/modules/models/text_embedding/examples/dashscope.ipynb
  Variables: doc_results embeddings query_result text
  Usages: DashScopeEmbeddings dashscope_api_key embed_documents embed_query langchain model print

PythonNotebook: /docs/modules/models/text_embedding/examples/deepinfra.ipynb
  Variables: DEEPINFRA_API_TOKEN docs document_numpy document_result embeddings os.environ["DEEPINFRA_API_TOKEN"] query query_numpy query_result similarity
  Usages: DeepInfraEmbeddings array doc doc_res dot embed_documents embed_instruction embed_query environ getpass langchain linalg model_id norm numpy print query_instruction zip

PythonNotebook: /docs/modules/models/text_embedding/examples/elasticsearch.ipynb
  Variables: document_embeddings documents embeddings es_connection model_id query query_embedding
  Usages: Elasticsearch ElasticsearchEmbeddings basic_auth elasticsearch embed_documents embed_query embedding enumerate es_cloud_id es_password es_user from_credentials from_es_connection hosts install langchain print

PythonNotebook: /docs/modules/models/text_embedding/examples/embaas.ipynb
  Variables: doc_text doc_text_embedding doc_texts doc_texts_embeddings embaas_api_key embeddings os.environ["EMBAAS_API_KEY"]
  Usages: EmbaasEmbeddings embed_documents embed_query enumerate environ instruction langchain model print

PythonNotebook: /docs/modules/models/text_embedding/examples/fake.ipynb
  Variables: doc_results embeddings query_result
  Usages: FakeEmbeddings embed_documents embed_query langchain size

PythonNotebook: /docs/modules/models/text_embedding/examples/google_vertex_ai_palm.ipynb
  Variables: doc_result embeddings query_result text
  Usages: VertexAIEmbeddings embed_documents embed_query langchain

PythonNotebook: /docs/modules/models/text_embedding/examples/huggingface_hub.ipynb
  Variables: doc_result embeddings query_result text
  Usages: HuggingFaceEmbeddings embed_documents embed_query langchain

PythonNotebook: /docs/modules/models/text_embedding/examples/huggingface_instruct.ipynb
  Variables: embeddings query_result text
  Usages: HuggingFaceInstructEmbeddings embed_query langchain query_instruction

PythonNotebook: /docs/modules/models/text_embedding/examples/jina.ipynb
  Variables: doc_result embeddings query_result text
  Usages: JinaEmbeddings embed_documents embed_query jina_auth_token langchain model_name

PythonNotebook: /docs/modules/models/text_embedding/examples/llamacpp.ipynb
  Variables: doc_result llama query_result text
  Usages: LlamaCppEmbeddings cpp embed_documents embed_query embeddings install langchain model_path python

PythonNotebook: /docs/modules/models/text_embedding/examples/minimax.ipynb
  Variables: document_numpy document_result document_text embeddings os.environ["MINIMAX_API_KEY"] os.environ["MINIMAX_GROUP_ID"] query_numpy query_result query_text similarity
  Usages: MiniMaxEmbeddings array dot embed_documents embed_query environ langchain linalg norm numpy print

PythonNotebook: /docs/modules/models/text_embedding/examples/modelscope_hub.ipynb
  Variables: doc_results embeddings model_id query_result text
  Usages: ModelScopeEmbeddings embed_documents embed_query langchain

PythonNotebook: /docs/modules/models/text_embedding/examples/mosaicml.ipynb
  Variables: MOSAICML_API_TOKEN document_numpy document_result document_text embeddings os.environ["MOSAICML_API_TOKEN"] query_numpy query_result query_text similarity
  Usages: MosaicMLInstructorEmbeddings array dot embed_documents embed_query environ getpass langchain linalg norm numpy print query_instruction

PythonNotebook: /docs/modules/models/text_embedding/examples/openai.ipynb
  Variables: doc_result embeddings os.environ["OPENAI_PROXY"] query_result text
  Usages: OpenAIEmbeddings embed_documents embed_query environ langchain openai

PythonNotebook: /docs/modules/models/text_embedding/examples/sagemaker-endpoint.ipynb
  Classes: ContentHandler
  Methods: transform_input transform_output
  Variables: accepts content_handler content_type doc_results embeddings input_str query_result response_json
  Usages: ContentHandlerBase Dict List SagemakerEndpointEmbeddings boto3 bytes decode dumps embed_documents embed_query encode endpoint_name float inputs install ip3 json langchain list llms loads model_kwargs output read region_name sagemaker_endpoint self str typing

PythonNotebook: /docs/modules/models/text_embedding/examples/self-hosted.ipynb
  Functions: get_pipeline inference_fn
  Variables: embeddings gpu model model_id query_result text tokenizer
  Usages: AutoModelForCausalLM AutoTokenizer SelfHostedEmbeddings SelfHostedHuggingFaceEmbeddings SelfHostedHuggingFaceInstructEmbeddings cluster emb embed_query from_pretrained hardware instance_type isinstance langchain list model_load_fn model_reqs name pipeline prompt runhouse transformers use_spot

PythonNotebook: /docs/modules/models/text_embedding/examples/sentence_transformers.ipynb
  Variables: doc_result embeddings query_result text
  Usages: HuggingFaceEmbeddings SentenceTransformerEmbeddings dev embed_documents embed_query install langchain model_name null sentence_transformers

PythonNotebook: /docs/modules/models/text_embedding/examples/tensorflowhub.ipynb
  Variables: doc_results embeddings query_result text
  Usages: TensorflowHubEmbeddings embed_documents embed_query langchain

# How to create a custom example selector
## Implement custom example selector
## Use custom example selector
# Initialize example selector.
# Select examples
# -> array([{'foo': '2'}, {'foo': '3'}], dtype=object)
# Add new example to the set of examples
# -> [{'foo': '1'}, {'foo': '2'}, {'foo': '3'}, {'foo': '4'}]
# Select examples
# -> array([{'foo': '1'}, {'foo': '4'}], dtype=object)

PythonNotebook: /docs/modules/prompts/example_selectors/examples/length_based.ipynb
  Variables: dynamic_prompt example_prompt example_selector examples long_string new_example
  Usages: FewShotPromptTemplate LengthBasedExampleSelector PromptTemplate add_example adjective format input_variables langchain max_length prefix print prompts suffix template

PythonNotebook: /docs/modules/prompts/example_selectors/examples/mmr.ipynb
  Variables: example_prompt example_selector examples mmr_prompt similar_prompt
  Usages: FAISS FewShotPromptTemplate MaxMarginalRelevanceExampleSelector OpenAIEmbeddings PromptTemplate SemanticSimilarityExampleSelector adjective embeddings format from_examples input_variables langchain prefix print prompts suffix template vectorstores

PythonNotebook: /docs/modules/prompts/example_selectors/examples/ngram_overlap.ipynb
  Variables: dynamic_prompt example_prompt example_selector example_selector.threshold examples new_example
  Usages: FewShotPromptTemplate NGramOverlapExampleSelector PromptTemplate add_example format input_variables langchain ngram_overlap prefix print prompts sentence suffix template threshold

PythonNotebook: /docs/modules/prompts/example_selectors/examples/similarity.ipynb
  Variables: example_prompt example_selector examples similar_prompt
  Usages: Chroma FewShotPromptTemplate OpenAIEmbeddings PromptTemplate SemanticSimilarityExampleSelector add_example adjective embeddings format from_examples input_variables langchain prefix print prompts suffix template vectorstores

PythonNotebook: /docs/modules/prompts/output_parsers/examples/comma_separated.ipynb
  Variables: _input format_instructions model output output_parser prompt
  Usages: ChatOpenAI ChatPromptTemplate CommaSeparatedListOutputParser HumanMessagePromptTemplate OpenAI PromptTemplate chat_models format get_format_instructions input_variables langchain llms output_parsers parse partial_variables prompts subject temperature template

PythonNotebook: /docs/modules/prompts/output_parsers/examples/datetime.ipynb
  Variables: chain output output_parser prompt template
  Usages: DatetimeOutputParser LLMChain OpenAI PromptTemplate chains from_template get_format_instructions langchain llm llms output_parsers parse partial_variables prompts run

PythonNotebook: /docs/modules/prompts/output_parsers/examples/enum.ipynb
  Classes: Colors
  Variables: BLUE GREEN RED parser
  Usages: Enum EnumOutputParser enum langchain output_parsers parse

PythonNotebook: /docs/modules/prompts/output_parsers/examples/output_fixing_parser.ipynb
  Classes: Actor
  Variables: actor_query film_names: misformatted name: new_parser parser
  Usages: BaseModel ChatOpenAI ChatPromptTemplate Field HumanMessagePromptTemplate List OpenAI OutputFixingParser PromptTemplate PydanticOutputParser chat_models description film_names from_llm langchain llm llms name output_parsers parse prompts pydantic pydantic_object str typing validator

PythonNotebook: /docs/modules/prompts/output_parsers/examples/pydantic.ipynb
  Classes: Actor Joke
  Methods: question_ends_with_question_mark
  Variables: _input actor_query film_names: joke_query model model_name name: output parser prompt punchline: setup: temperature
  Usages: BaseModel ChatOpenAI ChatPromptTemplate Field HumanMessagePromptTemplate List OpenAI PromptTemplate PydanticOutputParser ValueError chat_models cls description field film_names format_prompt get_format_instructions input_variables langchain llms name output_parsers parse partial_variables prompts punchline pydantic pydantic_object query setup str template to_string typing validator

PythonNotebook: /docs/modules/prompts/output_parsers/examples/retry.ipynb
  Classes: Action
  Variables: action: action_input: bad_response fix_parser parser prompt prompt_value retry_parser template
  Usages: BaseModel ChatOpenAI ChatPromptTemplate Field HumanMessagePromptTemplate List OpenAI OutputFixingParser PromptTemplate PydanticOutputParser RetryOutputParser RetryWithErrorOutputParser action action_input chat_models description format_prompt from_llm get_format_instructions input_variables langchain llm llms output_parsers parse parse_with_prompt partial_variables prompts pydantic pydantic_object query str temperature typing validator

PythonNotebook: /docs/modules/prompts/output_parsers/examples/structured.ipynb
  Variables: _input chat_model format_instructions model output output_parser prompt response_schemas
  Usages: ChatOpenAI ChatPromptTemplate HumanMessagePromptTemplate OpenAI PromptTemplate ResponseSchema StructuredOutputParser chat_models content description format_prompt from_response_schemas from_template get_format_instructions input_variables langchain llms messages name output_parsers parse partial_variables prompts question temperature template to_messages to_string

PythonNotebook: /docs/modules/prompts/prompt_templates/examples/connecting_to_a_feature_store.ipynb
  Classes: FeastPromptTemplate FeatureformPromptTemplate TectonPromptTemplate
  Methods: format
  Variables: chain client driver_id feast_repo_path feature_service feature_vector fpf kwargs["acc_rate"] kwargs["avg_daily_trips"] kwargs["conv_rate"] kwargs["transaction_count_1d"] kwargs["transaction_count_30d"] prompt prompt_template store template user_id workspace
  Usages: ChatOpenAI Client FeatureStore FeatureformPrompTemplate LLMChain PromptTemplate StringPromptTemplate chains chat_models entity_rows feast featureform features from_template get_feature_service get_online_features get_workspace host input_variables join_keys kwargs langchain llm pop print prompts repo_path run self str tecton to_dict

PythonNotebook: /docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb
  Functions: get_source_code
  Classes: FunctionExplainerPromptTemplate
  Methods: _prompt_type format validate_input_variables
  Variables: fn_explainer prompt source_code
  Usages: BaseModel StringPromptTemplate ValueError __name__ cls function_name getsource input_variables inspect kwargs langchain len print prompts pydantic self str validator

File: /docs/modules/prompts/prompt_templates/examples/example_prompt.json

File: /docs/modules/prompts/prompt_templates/examples/examples.json

File: /docs/modules/prompts/prompt_templates/examples/examples.yaml

PythonNotebook: /docs/modules/prompts/prompt_templates/examples/few_shot_examples.ipynb
  Variables: example_prompt example_selector examples prompt question selected_examples
  Usages: Chroma FewShotPromptTemplate OpenAIEmbeddings PromptTemplate SemanticSimilarityExampleSelector embeddings example few_shot format from_examples input input_variables items langchain print prompts select_examples suffix template vectorstores

File: /docs/modules/prompts/prompt_templates/examples/few_shot_prompt.json

File: /docs/modules/prompts/prompt_templates/examples/few_shot_prompt.yaml

File: /docs/modules/prompts/prompt_templates/examples/few_shot_prompt_example_prompt.json

File: /docs/modules/prompts/prompt_templates/examples/few_shot_prompt_examples_in.json

File: /docs/modules/prompts/prompt_templates/examples/few_shot_prompt_yaml_examples.yaml

PythonNotebook: /docs/modules/prompts/prompt_templates/examples/partial.ipynb
  Functions: _get_datetime
  Variables: now partial_prompt prompt
  Usages: PromptTemplate adjective bar date datetime foo format input_variables langchain partial partial_variables print prompts strftime template

PythonNotebook: /docs/modules/prompts/prompt_templates/examples/prompt_composition.ipynb
  Variables: example_prompt example_template full_prompt full_template input_prompts introduction_prompt introduction_template pipeline_prompt start_prompt start_template
  Usages: PipelinePromptTemplate PromptTemplate example_a example_q final_prompt format from_template input input_variables langchain person pipeline pipeline_prompts print prompt prompts

PythonNotebook: /docs/modules/prompts/prompt_templates/examples/prompt_serialization.ipynb
  Variables: prompt
  Usages: adjective cat content example_prompt examples few_shot_prompt few_shot_prompt_example_prompt few_shot_prompt_examples_in few_shot_prompt_yaml_examples format json langchain load_prompt output_parser parse print prompt_with_output_parser prompts simple_prompt simple_prompt_with_template_file simple_template txt yaml

File: /docs/modules/prompts/prompt_templates/examples/prompt_with_output_parser.json

File: /docs/modules/prompts/prompt_templates/examples/simple_prompt.json

File: /docs/modules/prompts/prompt_templates/examples/simple_prompt.yaml

File: /docs/modules/prompts/prompt_templates/examples/simple_prompt_with_template_file.json

File: /docs/modules/prompts/prompt_templates/examples/simple_template.txt

File: /tests/integration_tests/vectorstores/cassettes/test_elasticsearch/TestElasticsearch.test_custom_index_add_documents.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_elasticsearch/TestElasticsearch.test_custom_index_from_documents.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_elasticsearch/TestElasticsearch.test_default_index_from_documents.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_pinecone/TestPinecone.test_from_texts.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_pinecone/TestPinecone.test_from_texts_with_metadatas.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_pinecone/TestPinecone.test_from_texts_with_scores.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_weaviate/TestWeaviate.test_max_marginal_relevance_search.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_weaviate/TestWeaviate.test_max_marginal_relevance_search_by_vector.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_weaviate/TestWeaviate.test_max_marginal_relevance_search_with_filter.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_weaviate/TestWeaviate.test_similarity_search_with_metadata.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_weaviate/TestWeaviate.test_similarity_search_with_metadata_and_filter.yaml

File: /tests/integration_tests/vectorstores/cassettes/test_weaviate/TestWeaviate.test_similarity_search_without_metadata.yaml

Python: /tests/unit_tests/document_loaders/loaders/vendors/test_docugami.py
  Functions: test_docugami_initialization
  Methods: test_docugami_loader_local
  Variables: DOCUGAMI_XML_PATH docs loader xpath
  Usages: DocugamiLoader Path __file__ access_token docset_id document_loaders endswith file_paths get langchain len load mark metadata page_content parent pathlib pytest requires startswith str

File: /tests/unit_tests/document_loaders/test_docs/csv/test_nominal.csv

File: /tests/unit_tests/document_loaders/test_docs/csv/test_one_col.csv

File: /tests/unit_tests/document_loaders/test_docs/csv/test_one_row.csv

File: /tests/unit_tests/tools/openapi/test_specs/robot_openapi.yaml

File: /docs/modules/indexes/document_loaders/examples/example_data/conllu.conllu

File: /docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json

File: /docs/modules/indexes/document_loaders/examples/example_data/factbook.xml

HTML: /docs/modules/indexes/document_loaders/examples/example_data/fake-content.html
# My First Heading

File: /docs/modules/indexes/document_loaders/examples/example_data/fake-email.eml

File: /docs/modules/indexes/document_loaders/examples/example_data/fake_conversations.json

File: /docs/modules/indexes/document_loaders/examples/example_data/fake_rule.toml

File: /docs/modules/indexes/document_loaders/examples/example_data/mlb_teams_2012.csv

PythonNotebook: /docs/modules/indexes/document_loaders/examples/example_data/notebook.ipynb
  Variables: loader
  Usages: NotebookLoader document_loaders include_outputs langchain load max_output_length remove_newline

File: /docs/modules/indexes/document_loaders/examples/example_data/sitemap.xml

File: /docs/modules/indexes/document_loaders/examples/example_data/telegram.json

File: /docs/modules/indexes/document_loaders/examples/example_data/testing.enex

File: /docs/modules/indexes/document_loaders/examples/example_data/whatsapp_chat.txt

File: /tests/unit_tests/tools/openapi/test_specs/apis-guru/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/biztoc/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/calculator/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/datasette/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/freetv-app/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/joinmilo/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/klarna/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/milo/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/quickchart/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/robot/apispec.yaml

File: /tests/unit_tests/tools/openapi/test_specs/schooldigger/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/shop/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/slack/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/speak/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/urlbox/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/wellknown/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/wolframalpha/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/wolframcloud/apispec.json

File: /tests/unit_tests/tools/openapi/test_specs/zapier/apispec.json

File: /docs/modules/indexes/document_loaders/examples/example_data/fake_discord_data/output.txt

File: /docs/modules/indexes/document_loaders/examples/example_data/fake_discord_data/package/messages/c105765859191975936/messages.csv

File: /docs/modules/indexes/document_loaders/examples/example_data/fake_discord_data/package/messages/c278566343836565505/messages.csv

File: /docs/modules/indexes/document_loaders/examples/example_data/fake_discord_data/package/messages/c279692806442844161/messages.csv

File: /docs/modules/indexes/document_loaders/examples/example_data/fake_discord_data/package/messages/c280973436971515906/messages.csv
